{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 399us/step - loss: 15298.9524 - val_loss: 14600.8096\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12102.5769 - val_loss: 8133.3581\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4027.0853 - val_loss: 724.2095\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 158.7079 - val_loss: 46.2251\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 33.9046 - val_loss: 28.6413\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 24.8493 - val_loss: 27.3941\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 23.4408 - val_loss: 27.2721\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.7128 - val_loss: 27.0816\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.5632 - val_loss: 27.2931\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3576 - val_loss: 27.4334\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2940 - val_loss: 27.4861\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0977 - val_loss: 26.9528\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.0106 - val_loss: 27.2800\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0080 - val_loss: 27.0415\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.0479 - val_loss: 26.7153\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.8785 - val_loss: 27.2183\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0165 - val_loss: 27.2160\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0750 - val_loss: 26.7980\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8354 - val_loss: 27.1306\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1510 - val_loss: 26.5977\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1599 - val_loss: 27.3497\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0229 - val_loss: 26.7605\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2957 - val_loss: 26.8086\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7156 - val_loss: 26.8559\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9304 - val_loss: 26.2694\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8562 - val_loss: 26.9124\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9199 - val_loss: 27.8565\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0298 - val_loss: 26.2380\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0225 - val_loss: 26.2055\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0848 - val_loss: 27.4827\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8740 - val_loss: 27.6460\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4713 - val_loss: 26.6547\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9321 - val_loss: 26.3343\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9345 - val_loss: 26.1307\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1967 - val_loss: 26.1544\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7319 - val_loss: 26.6198\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9611 - val_loss: 26.6555\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7232 - val_loss: 26.1447\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6768 - val_loss: 27.1372\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8410 - val_loss: 25.7938\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8331 - val_loss: 26.0919\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8772 - val_loss: 26.2575\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9985 - val_loss: 25.7059\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7104 - val_loss: 26.5468\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8587 - val_loss: 26.5475\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8950 - val_loss: 26.2342\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.8963 - val_loss: 25.7652\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8526 - val_loss: 26.7727\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.6275 - val_loss: 26.3362\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1250 - val_loss: 26.3044\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8059 - val_loss: 26.5437\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8189 - val_loss: 26.5156\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1665 - val_loss: 27.3490\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4831 - val_loss: 26.6213\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1053 - val_loss: 25.8901\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8162 - val_loss: 25.8615\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.5708 - val_loss: 25.9487\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9327 - val_loss: 26.2011\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9927 - val_loss: 27.5887\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1209 - val_loss: 25.8387\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8345 - val_loss: 26.4319\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7427 - val_loss: 26.0493\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9111 - val_loss: 27.2286\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4121 - val_loss: 27.2026\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2979 - val_loss: 25.5585\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8945 - val_loss: 25.2575\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7306 - val_loss: 26.1722\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2052 - val_loss: 26.3090\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8922 - val_loss: 27.2435\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1388 - val_loss: 25.4379\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8486 - val_loss: 26.7440\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7242 - val_loss: 25.7152\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6081 - val_loss: 27.0841\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0435 - val_loss: 26.8864\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9580 - val_loss: 26.3314\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9747 - val_loss: 25.8009\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7584 - val_loss: 26.1724\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2293 - val_loss: 26.5582\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.7727 - val_loss: 25.4672\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2437 - val_loss: 28.2208\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2588 - val_loss: 25.9680\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.7225 - val_loss: 27.0172\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3033 - val_loss: 26.0074\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5251 - val_loss: 26.5677\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8271 - val_loss: 25.9912\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7576 - val_loss: 25.8224\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8038 - val_loss: 25.6990\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8643 - val_loss: 26.4672\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9898 - val_loss: 26.1919\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6695 - val_loss: 25.2185\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1560 - val_loss: 25.4543\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5400 - val_loss: 26.2382\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.0575 - val_loss: 26.2079\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1044 - val_loss: 26.0773\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6049 - val_loss: 27.1566\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1367 - val_loss: 27.0912\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.7189 - val_loss: 25.5954\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9242 - val_loss: 25.9467\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0321 - val_loss: 26.5598\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2887 - val_loss: 25.5527\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8145 - val_loss: 25.7435\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.6966 - val_loss: 25.9664\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9000 - val_loss: 26.1542\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.2155 - val_loss: 27.2340\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1009 - val_loss: 27.3190\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4398 - val_loss: 26.7642\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6269 - val_loss: 27.3915\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5392 - val_loss: 26.5793\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0916 - val_loss: 28.9387\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.0020 - val_loss: 26.0212\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4257 - val_loss: 25.6080\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7779 - val_loss: 25.9261\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8927 - val_loss: 26.4972\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2477 - val_loss: 25.8223\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9116 - val_loss: 29.7094\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2581 - val_loss: 25.7945\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2568 - val_loss: 26.2761\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.8500 - val_loss: 26.2741\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7251 - val_loss: 27.2180\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6042 - val_loss: 28.2440\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2823 - val_loss: 27.3621\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.9744 - val_loss: 26.3346\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.1525 - val_loss: 26.6976\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.4917 - val_loss: 27.1419\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.1444 - val_loss: 25.9602\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4600 - val_loss: 28.6346\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3684 - val_loss: 27.1352\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.6450 - val_loss: 25.6429\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8388 - val_loss: 25.5555\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0128 - val_loss: 27.3981\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.7491 - val_loss: 25.6581\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9086 - val_loss: 25.4817\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8900 - val_loss: 26.2806\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6788 - val_loss: 29.1230\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.5498 - val_loss: 26.5874\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1956 - val_loss: 25.9443\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2444 - val_loss: 26.0916\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9708 - val_loss: 25.5551\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9403 - val_loss: 25.6172\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7215 - val_loss: 27.6665\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8219 - val_loss: 26.2032\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5337 - val_loss: 25.4179\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2372 - val_loss: 26.0833\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1166 - val_loss: 26.9362\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1603 - val_loss: 25.9194\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1642 - val_loss: 25.6516\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3533 - val_loss: 25.7456\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.2180 - val_loss: 25.8299\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.3231 - val_loss: 26.3947\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.6768 - val_loss: 25.7049\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.7776 - val_loss: 25.9588\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.0906 - val_loss: 26.7656\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0440 - val_loss: 25.5342\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.2626 - val_loss: 26.5746\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9369 - val_loss: 25.9141\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8735 - val_loss: 26.1044\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4368 - val_loss: 27.0124\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2553 - val_loss: 26.8348\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.8196 - val_loss: 25.9378\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8139 - val_loss: 26.2434\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5246 - val_loss: 26.0270\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5437 - val_loss: 27.9036\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.8739 - val_loss: 27.9617\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.8734 - val_loss: 26.8305\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.5381 - val_loss: 26.6911\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.0111 - val_loss: 25.8796\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1371 - val_loss: 26.0696\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1280 - val_loss: 26.2136\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2078 - val_loss: 25.6851\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.2964 - val_loss: 25.3472\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.6135 - val_loss: 27.9870\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0696 - val_loss: 26.9238\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8956 - val_loss: 27.5109\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.0048 - val_loss: 26.8392\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2533 - val_loss: 25.1239\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.3590 - val_loss: 28.9292\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 22.9317 - val_loss: 25.4500\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8280 - val_loss: 25.2141\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.7436 - val_loss: 27.4954\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.9886 - val_loss: 26.7363\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8206 - val_loss: 25.9369\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.8023 - val_loss: 26.1063\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8463 - val_loss: 25.9431\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6753 - val_loss: 25.4617\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.1495 - val_loss: 25.3659\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.5313 - val_loss: 26.8691\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5121 - val_loss: 25.2517\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.1281 - val_loss: 25.3515\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.3209 - val_loss: 28.7097\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8545 - val_loss: 24.7110\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.4715 - val_loss: 25.3912\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3160 - val_loss: 25.3210\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.9527 - val_loss: 25.6591\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.3082 - val_loss: 24.9029\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.0213 - val_loss: 26.3920\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8767 - val_loss: 25.5134\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.0451 - val_loss: 24.5312\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.2799 - val_loss: 24.8912\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.8035 - val_loss: 25.0745\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.8555 - val_loss: 23.9099\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.0078 - val_loss: 24.4467\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.7319 - val_loss: 26.3320\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.8688 - val_loss: 23.1384\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.7631 - val_loss: 26.6287\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.7902 - val_loss: 24.1293\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.2646 - val_loss: 23.3061\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.9257 - val_loss: 22.9317\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8192 - val_loss: 22.9151\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6365 - val_loss: 25.0843\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3701 - val_loss: 25.5061\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6790 - val_loss: 21.6455\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.0870 - val_loss: 21.4143\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.4297 - val_loss: 22.9109\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7333 - val_loss: 21.2310\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.9158 - val_loss: 21.4375\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1118 - val_loss: 23.3570\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.7740 - val_loss: 20.7859\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7075 - val_loss: 20.6965\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7020 - val_loss: 20.3897\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3173 - val_loss: 21.2150\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.9452 - val_loss: 20.0531\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.7612 - val_loss: 19.5457\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4764 - val_loss: 19.6622\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1833 - val_loss: 20.3145\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9219 - val_loss: 18.9382\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4015 - val_loss: 18.7152\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0339 - val_loss: 20.0648\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8820 - val_loss: 21.1106\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7473 - val_loss: 19.8631\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.6050 - val_loss: 18.4544\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.2579 - val_loss: 18.5389\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.2588 - val_loss: 19.0121\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.3279 - val_loss: 18.2816\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.0064 - val_loss: 19.3914\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.4559 - val_loss: 18.2205\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.7508 - val_loss: 18.0136\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4172 - val_loss: 18.3579\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.5773 - val_loss: 20.3001\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9702 - val_loss: 19.4822\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4458 - val_loss: 18.1010\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.9018 - val_loss: 18.3981\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.0918 - val_loss: 18.2630\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.8035 - val_loss: 19.0853\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.5085 - val_loss: 17.8904\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.3400 - val_loss: 18.0915\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8737 - val_loss: 17.2173\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1990 - val_loss: 17.8773\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.0444 - val_loss: 17.3418\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.4060 - val_loss: 17.4556\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.7846 - val_loss: 18.2083\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0318 - val_loss: 17.1240\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.8281 - val_loss: 17.9955\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9380 - val_loss: 18.4494\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.5305 - val_loss: 17.2900\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9921 - val_loss: 16.9286\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.1421 - val_loss: 20.1035\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.7069 - val_loss: 17.3103\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.9307 - val_loss: 17.0595\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2489 - val_loss: 17.1412\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8812 - val_loss: 16.8530\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2851 - val_loss: 16.4608\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9206 - val_loss: 17.0501\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3199 - val_loss: 17.8821\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1649 - val_loss: 16.0614\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8032 - val_loss: 16.7076\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 14.5062 - val_loss: 17.3799\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4914 - val_loss: 16.2911\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5390 - val_loss: 16.7039\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6284 - val_loss: 16.9299\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4238 - val_loss: 17.2986\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.1616 - val_loss: 16.3523\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7942 - val_loss: 19.0993\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5212 - val_loss: 16.8921\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1043 - val_loss: 17.1083\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0898 - val_loss: 15.7563\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3306 - val_loss: 16.7646\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3656 - val_loss: 15.7322\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7286 - val_loss: 16.6210\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2251 - val_loss: 16.6079\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.7062 - val_loss: 16.4109\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.7556 - val_loss: 16.5955\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.0031 - val_loss: 16.0990\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1135 - val_loss: 18.4081\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.9879 - val_loss: 17.5309\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9638 - val_loss: 16.2658\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3299 - val_loss: 17.1265\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2477 - val_loss: 16.4770\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9635 - val_loss: 17.4242\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.2330 - val_loss: 15.6988\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3422 - val_loss: 15.6404\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5180 - val_loss: 16.3412\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.1508 - val_loss: 15.6655\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4695 - val_loss: 15.4911\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4103 - val_loss: 15.5730\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2684 - val_loss: 15.1549\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.0394 - val_loss: 15.1261\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9688 - val_loss: 15.0770\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6283 - val_loss: 14.2340\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9930 - val_loss: 15.3451\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.1287 - val_loss: 15.2435\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8614 - val_loss: 16.3203\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6648 - val_loss: 19.2959\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.5779 - val_loss: 15.4434\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.5978 - val_loss: 15.0943\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6065 - val_loss: 15.0127\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9543 - val_loss: 16.4848\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1392 - val_loss: 14.6534\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1196 - val_loss: 16.2797\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1198 - val_loss: 15.3814\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1680 - val_loss: 15.9441\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.7908 - val_loss: 14.2081\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3472 - val_loss: 14.3710\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5356 - val_loss: 14.9261\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3354 - val_loss: 13.8015\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7793 - val_loss: 15.5316\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.5130 - val_loss: 16.1387\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7946 - val_loss: 15.0789\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8969 - val_loss: 15.0012\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4342 - val_loss: 13.7770\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1183 - val_loss: 14.4871\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1472 - val_loss: 13.4964\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.8793 - val_loss: 14.4253\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9561 - val_loss: 13.2444\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2671 - val_loss: 18.0027\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.2198 - val_loss: 13.1665\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.5189 - val_loss: 13.5944\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7488 - val_loss: 14.7700\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8536 - val_loss: 13.7194\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.2258 - val_loss: 13.7933\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7764 - val_loss: 17.1089\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3364 - val_loss: 15.2852\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4415 - val_loss: 13.4101\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4736 - val_loss: 13.3935\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0505 - val_loss: 13.5037\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6114 - val_loss: 13.1051\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2338 - val_loss: 13.8140\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1867 - val_loss: 14.4485\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2748 - val_loss: 13.9591\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5455 - val_loss: 12.4421\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1821 - val_loss: 14.6681\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7291 - val_loss: 14.3366\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2490 - val_loss: 14.0806\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9127 - val_loss: 13.2114\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8194 - val_loss: 12.5180\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3568 - val_loss: 13.4045\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0596 - val_loss: 12.4947\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1926 - val_loss: 12.5371\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.0670 - val_loss: 14.1262\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.3301 - val_loss: 12.3645\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.5360 - val_loss: 12.4304\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 10.3245 - val_loss: 13.9362\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.5576 - val_loss: 14.8976\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9957 - val_loss: 14.8537\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.5750 - val_loss: 12.3194\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0013 - val_loss: 13.8639\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9550 - val_loss: 12.4566\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1051 - val_loss: 13.5650\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1455 - val_loss: 12.3196\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2012 - val_loss: 13.5898\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0408 - val_loss: 11.9743\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9040 - val_loss: 12.0763\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2607 - val_loss: 12.5310\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0343 - val_loss: 11.9453\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2540 - val_loss: 13.7213\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8133 - val_loss: 11.9225\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1027 - val_loss: 13.4889\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2487 - val_loss: 13.3504\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5303 - val_loss: 12.8897\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2053 - val_loss: 14.6386\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2779 - val_loss: 13.2895\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2608 - val_loss: 13.5831\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.9387 - val_loss: 19.3178\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7917 - val_loss: 11.9173\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6931 - val_loss: 11.7965\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7608 - val_loss: 11.7469\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5697 - val_loss: 13.7537\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6112 - val_loss: 13.6887\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0257 - val_loss: 12.9977\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3165 - val_loss: 12.8757\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3598 - val_loss: 12.0700\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7968 - val_loss: 12.1015\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8245 - val_loss: 13.0736\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7517 - val_loss: 11.7101\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7421 - val_loss: 13.0330\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7153 - val_loss: 14.3290\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0356 - val_loss: 11.9091\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8527 - val_loss: 12.7661\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7048 - val_loss: 12.3333\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8017 - val_loss: 11.4424\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2324 - val_loss: 11.3980\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2348 - val_loss: 11.8979\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3265 - val_loss: 11.8514\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8099 - val_loss: 11.5108\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1284 - val_loss: 11.6454\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6284 - val_loss: 13.0896\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7029 - val_loss: 11.6672\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2757 - val_loss: 13.2119\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4834 - val_loss: 11.3288\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8832 - val_loss: 11.6271\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2698 - val_loss: 11.2516\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5724 - val_loss: 12.3130\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2867 - val_loss: 11.4896\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2825 - val_loss: 11.8187\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6684 - val_loss: 11.2907\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2102 - val_loss: 11.0271\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1679 - val_loss: 11.0851\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0684 - val_loss: 12.1816\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3018 - val_loss: 10.8902\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8729 - val_loss: 12.1028\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2767 - val_loss: 11.6427\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5262 - val_loss: 11.2034\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2026 - val_loss: 10.8529\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8929 - val_loss: 12.5274\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1561 - val_loss: 10.9452\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5746 - val_loss: 12.3514\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4994 - val_loss: 10.8944\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2045 - val_loss: 12.2153\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.298 - 0s 86us/step - loss: 9.2476 - val_loss: 11.9183\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3658 - val_loss: 11.6022\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3053 - val_loss: 11.3039\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9965 - val_loss: 11.2751\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2866 - val_loss: 11.2288\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0014 - val_loss: 10.9584\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9685 - val_loss: 11.0863\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2370 - val_loss: 11.4556\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3057 - val_loss: 11.7056\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0070 - val_loss: 11.1785\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6772 - val_loss: 10.9696\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8107 - val_loss: 10.9213\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8241 - val_loss: 10.3890\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8584 - val_loss: 10.4006\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5738 - val_loss: 11.0511\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1193 - val_loss: 11.2373\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1709 - val_loss: 11.2212\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1089 - val_loss: 12.5560\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4058 - val_loss: 11.5496\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8654 - val_loss: 11.4641\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7891 - val_loss: 10.8402\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2758 - val_loss: 13.0913\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4959 - val_loss: 10.9102\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7121 - val_loss: 11.3274\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9956 - val_loss: 10.9601\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7076 - val_loss: 10.7543\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4984 - val_loss: 10.3885\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9831 - val_loss: 10.6902\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4027 - val_loss: 10.3904\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9415 - val_loss: 11.5175\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0914 - val_loss: 10.5094\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2159 - val_loss: 11.6374\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5547 - val_loss: 11.0655\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6515 - val_loss: 10.1065\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7555 - val_loss: 11.3860\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6385 - val_loss: 10.7283\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3584 - val_loss: 11.8280\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7589 - val_loss: 10.3485\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8679 - val_loss: 11.1136\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9693 - val_loss: 10.5865\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6640 - val_loss: 10.2582\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3966 - val_loss: 10.5087\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1070 - val_loss: 10.7316\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8159 - val_loss: 10.5165\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8525 - val_loss: 10.1415\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2360 - val_loss: 10.1669\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6295 - val_loss: 10.8506\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6236 - val_loss: 10.3501\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5440 - val_loss: 10.2082\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4887 - val_loss: 11.7366\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7873 - val_loss: 10.8133\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6315 - val_loss: 10.3661\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4807 - val_loss: 10.1682\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6091 - val_loss: 12.2261\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8131 - val_loss: 10.1034\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0118 - val_loss: 10.9768\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6696 - val_loss: 10.2978\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4575 - val_loss: 10.5707\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9867 - val_loss: 10.6473\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8933 - val_loss: 12.4228\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0672 - val_loss: 10.2097\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6196 - val_loss: 10.5183\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6903 - val_loss: 10.2879\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8708 - val_loss: 10.5901\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3617 - val_loss: 11.2002\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6646 - val_loss: 10.3876\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5494 - val_loss: 11.0823\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7047 - val_loss: 11.1415\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2433 - val_loss: 9.9658\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8758 - val_loss: 11.0302\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5763 - val_loss: 10.9043\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7003 - val_loss: 9.9770\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1115 - val_loss: 10.4317\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0274 - val_loss: 10.4935\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6231 - val_loss: 10.7367\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4905 - val_loss: 10.7404\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4439 - val_loss: 10.3064\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5373 - val_loss: 10.4479\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5372 - val_loss: 10.0546\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8164 - val_loss: 11.0500\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8732 - val_loss: 11.5872\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7469 - val_loss: 10.4845\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7603 - val_loss: 10.6585\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4982 - val_loss: 10.5476\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6210 - val_loss: 10.3135\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4448 - val_loss: 9.9418\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5679 - val_loss: 10.6673\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7468 - val_loss: 10.9425\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5868 - val_loss: 9.8468\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4895 - val_loss: 9.7968\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6990 - val_loss: 10.4589\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3684 - val_loss: 10.5715\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7220 - val_loss: 10.5680\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1485 - val_loss: 11.4456\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5327 - val_loss: 10.4020\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6191 - val_loss: 9.7867\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2573 - val_loss: 11.0933\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3007 - val_loss: 10.7355\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6863 - val_loss: 10.8868\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6486 - val_loss: 10.3780\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.4893 - val_loss: 9.8877\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5993 - val_loss: 11.1017\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.5818 - val_loss: 9.6994\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3966 - val_loss: 9.9230\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8593 - val_loss: 10.3326\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.3027 - val_loss: 9.8577\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2745 - val_loss: 10.6950\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3024 - val_loss: 10.4790\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7184 - val_loss: 10.1463\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4416 - val_loss: 13.2648\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6622 - val_loss: 9.8213\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5019 - val_loss: 10.7502\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3950 - val_loss: 11.4844\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9632 - val_loss: 9.8230\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7638 - val_loss: 11.1965\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4845 - val_loss: 10.1590\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2887 - val_loss: 10.2315\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2619 - val_loss: 10.6582\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9149 - val_loss: 11.1528\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6628 - val_loss: 10.4022\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5617 - val_loss: 11.3302\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5395 - val_loss: 10.1696\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5041 - val_loss: 9.8583\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6326 - val_loss: 10.6971\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7190 - val_loss: 11.1042\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5819 - val_loss: 10.6650\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4046 - val_loss: 9.9821\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4808 - val_loss: 10.0219\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9006 - val_loss: 10.1607\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3542 - val_loss: 9.9609\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4190 - val_loss: 9.8099\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7060 - val_loss: 10.2043\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8403 - val_loss: 9.9116\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1266 - val_loss: 9.7642\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5042 - val_loss: 10.0340\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3427 - val_loss: 9.7076\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3049 - val_loss: 10.0939\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6577 - val_loss: 10.2766\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1675 - val_loss: 10.9578\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4250 - val_loss: 10.1956\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6806 - val_loss: 9.8948\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4989 - val_loss: 9.8936\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2664 - val_loss: 9.7797\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6779 - val_loss: 9.7303\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4274 - val_loss: 12.0143\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7032 - val_loss: 9.8347\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2919 - val_loss: 10.5360\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6476 - val_loss: 11.2913\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5782 - val_loss: 9.5199\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6494 - val_loss: 9.8814\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4793 - val_loss: 9.4934\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.4907 - val_loss: 10.2421\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4459 - val_loss: 9.9250\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3289 - val_loss: 9.8819\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1086 - val_loss: 10.3558\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4889 - val_loss: 10.5989\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.2804 - val_loss: 9.6845\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6197 - val_loss: 10.8656\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4640 - val_loss: 10.4034\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6537 - val_loss: 11.1240\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5791 - val_loss: 10.1186\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4084 - val_loss: 9.8267\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5549 - val_loss: 9.9071\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2147 - val_loss: 9.5177\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4615 - val_loss: 9.7805\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4534 - val_loss: 9.6752\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2717 - val_loss: 10.0291\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2103 - val_loss: 10.7580\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1306 - val_loss: 10.1063\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2228 - val_loss: 9.8748\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3588 - val_loss: 10.2117\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2300 - val_loss: 10.3326\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7898 - val_loss: 9.7819\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5317 - val_loss: 9.8196\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2930 - val_loss: 10.5605\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2199 - val_loss: 9.5176\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4044 - val_loss: 11.0125\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6505 - val_loss: 9.9621\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4798 - val_loss: 9.6292\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5410 - val_loss: 9.9987\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1584 - val_loss: 11.6840\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8992 - val_loss: 9.9618\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8222 - val_loss: 10.4509\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5823 - val_loss: 9.6264\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3418 - val_loss: 9.5350\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8639 - val_loss: 10.8272\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0160 - val_loss: 9.9101\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5329 - val_loss: 12.3648\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8757 - val_loss: 11.3097\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2322 - val_loss: 10.0335\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0932 - val_loss: 12.0975\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6274 - val_loss: 11.0786\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6705 - val_loss: 10.3817\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4072 - val_loss: 9.9499\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6090 - val_loss: 9.9105\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2233 - val_loss: 10.1912\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4675 - val_loss: 10.2702\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4070 - val_loss: 10.3480\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0360 - val_loss: 12.1420\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0441 - val_loss: 9.8501\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6016 - val_loss: 9.3040\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3276 - val_loss: 11.4359\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3031 - val_loss: 10.0055\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6298 - val_loss: 9.8682\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2108 - val_loss: 9.5815\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2418 - val_loss: 10.1545\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3306 - val_loss: 10.3595\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6098 - val_loss: 9.7303\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6214 - val_loss: 10.9853\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7033 - val_loss: 9.7717\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4550 - val_loss: 9.5853\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5767 - val_loss: 11.5721\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0301 - val_loss: 10.0202\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5021 - val_loss: 9.8833\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9600 - val_loss: 10.2390\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4383 - val_loss: 10.4724\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0820 - val_loss: 9.9765\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7994 - val_loss: 10.2670\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3515 - val_loss: 9.7687\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6457 - val_loss: 9.6671\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6305 - val_loss: 9.5844\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0581 - val_loss: 10.7126\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2484 - val_loss: 9.4891\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1482 - val_loss: 9.7776\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4722 - val_loss: 9.8917\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5542 - val_loss: 9.6701\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3623 - val_loss: 9.7934\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5435 - val_loss: 10.7292\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5284 - val_loss: 11.1199\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5214 - val_loss: 9.3618\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.2933 - val_loss: 9.6156\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4793 - val_loss: 10.8384\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6876 - val_loss: 10.7264\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7020 - val_loss: 9.7238\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1245 - val_loss: 10.2840\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9404 - val_loss: 10.1829\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9394 - val_loss: 10.1407\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2850 - val_loss: 10.7229\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3602 - val_loss: 9.4852\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3937 - val_loss: 9.5536\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2881 - val_loss: 9.6730\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3993 - val_loss: 10.6487\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1788 - val_loss: 11.2163\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3717 - val_loss: 9.8306\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2375 - val_loss: 10.7626\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9460 - val_loss: 10.8073\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8309 - val_loss: 9.6744\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5044 - val_loss: 10.2929\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4982 - val_loss: 9.8768\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2450 - val_loss: 9.3224\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2959 - val_loss: 10.6900\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4921 - val_loss: 10.4799\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4381 - val_loss: 10.4948\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7218 - val_loss: 11.2844\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4800 - val_loss: 10.0017\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1588 - val_loss: 11.7813\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7579 - val_loss: 9.9514\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2249 - val_loss: 10.2206\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3156 - val_loss: 10.0025\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1739 - val_loss: 9.5669\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7642 - val_loss: 10.9493\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.2528 - val_loss: 9.6429\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2824 - val_loss: 10.0562\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7065 - val_loss: 9.4758\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6018 - val_loss: 10.0568\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2016 - val_loss: 10.0636\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2156 - val_loss: 9.5568\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2446 - val_loss: 9.2806\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.3737 - val_loss: 9.9223\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2106 - val_loss: 9.1529\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5361 - val_loss: 11.0986\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7342 - val_loss: 9.1560\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7126 - val_loss: 11.6945\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.2953 - val_loss: 9.3861\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4044 - val_loss: 11.3531\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7.9634 - val_loss: 9.2850\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1871 - val_loss: 9.8738\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2184 - val_loss: 9.5618\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.4075 - val_loss: 11.1674\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.6820 - val_loss: 10.1553\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.1289 - val_loss: 9.6687\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3641 - val_loss: 11.7372\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7535 - val_loss: 9.3459\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1996 - val_loss: 10.1918\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2286 - val_loss: 9.5386\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1342 - val_loss: 9.5515\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2426 - val_loss: 9.7629\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.2309 - val_loss: 9.9828\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1361 - val_loss: 9.4507\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3748 - val_loss: 9.6440\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1629 - val_loss: 9.7223\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1042 - val_loss: 9.8122\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4692 - val_loss: 10.5448\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3762 - val_loss: 9.5669\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4554 - val_loss: 9.6781\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1993 - val_loss: 9.5224\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0626 - val_loss: 10.1632\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0870 - val_loss: 11.5615\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5334 - val_loss: 10.9640\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5440 - val_loss: 9.6261\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8037 - val_loss: 11.7359\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8439 - val_loss: 9.8029\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2792 - val_loss: 9.6450\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0635 - val_loss: 9.3837\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2057 - val_loss: 10.0845\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8671 - val_loss: 11.6923\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4089 - val_loss: 9.2140\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3617 - val_loss: 9.2761\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1207 - val_loss: 9.9172\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9659 - val_loss: 10.3438\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1768 - val_loss: 9.4553\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.4540 - val_loss: 9.5937\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4980 - val_loss: 9.6731\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5422 - val_loss: 10.4005\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6744 - val_loss: 9.6775\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6625 - val_loss: 9.5659\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1981 - val_loss: 10.2859\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5342 - val_loss: 9.2567\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2405 - val_loss: 9.6204\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5116 - val_loss: 10.0154\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3828 - val_loss: 9.2809\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0487 - val_loss: 9.4842\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8803 - val_loss: 9.3915\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1651 - val_loss: 9.3854\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1574 - val_loss: 9.3590\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6028 - val_loss: 9.6691\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3117 - val_loss: 10.2706\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1125 - val_loss: 11.4052\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2385 - val_loss: 10.5340\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1222 - val_loss: 9.1133\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4286 - val_loss: 9.9436\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2598 - val_loss: 10.3135\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2456 - val_loss: 10.2018\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7147 - val_loss: 10.7204\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2543 - val_loss: 9.7587\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4048 - val_loss: 11.1666\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5371 - val_loss: 10.2019\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2936 - val_loss: 10.2781\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0450 - val_loss: 10.9771\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3141 - val_loss: 9.4942\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7407 - val_loss: 11.1835\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5574 - val_loss: 9.6792\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3325 - val_loss: 10.6362\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1624 - val_loss: 9.8310\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9171 - val_loss: 11.4874\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3141 - val_loss: 10.1080\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6023 - val_loss: 11.8096\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4107 - val_loss: 9.3856\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1706 - val_loss: 9.8108\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1958 - val_loss: 9.7840\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3040 - val_loss: 12.2429\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6696 - val_loss: 9.5884\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5071 - val_loss: 11.6904\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6140 - val_loss: 9.4605\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6648 - val_loss: 11.0838\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2262 - val_loss: 9.6350\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1777 - val_loss: 9.4508\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1085 - val_loss: 10.1899\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4168 - val_loss: 9.4880\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3021 - val_loss: 9.7413\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2436 - val_loss: 9.9449\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0799 - val_loss: 9.7479\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1275 - val_loss: 10.3075\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.6466 - val_loss: 9.5379\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2523 - val_loss: 9.3429\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.2165 - val_loss: 10.5895\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5650 - val_loss: 10.1916\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5579 - val_loss: 9.4070\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1013 - val_loss: 9.7273\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0777 - val_loss: 9.7857\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1713 - val_loss: 9.3050\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2624 - val_loss: 9.6120\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1081 - val_loss: 10.0272\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4909 - val_loss: 10.0157\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3873 - val_loss: 11.6293\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2240 - val_loss: 9.0565\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2228 - val_loss: 9.2551\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6411 - val_loss: 10.3578\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3970 - val_loss: 10.3335\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8877 - val_loss: 9.5481\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4654 - val_loss: 9.4387\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3421 - val_loss: 9.5262\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1848 - val_loss: 10.2212\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1939 - val_loss: 9.2181\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2509 - val_loss: 10.6316\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1985 - val_loss: 10.3949\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0634 - val_loss: 9.5073\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6463 - val_loss: 9.9312\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.3477 - val_loss: 10.8998\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9547 - val_loss: 9.5748\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1716 - val_loss: 9.7436\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3942 - val_loss: 9.5381\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4630 - val_loss: 9.7360\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4100 - val_loss: 9.5988\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2000 - val_loss: 10.7415\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9892 - val_loss: 10.3629\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1580 - val_loss: 9.6120\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1191 - val_loss: 9.9376\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.3966 - val_loss: 9.5008\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2586 - val_loss: 10.4870\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2043 - val_loss: 9.4867\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2364 - val_loss: 9.5722\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2556 - val_loss: 9.1751\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.1043 - val_loss: 9.4197\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0241 - val_loss: 9.2006\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6862 - val_loss: 9.5391\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2006 - val_loss: 10.5668\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2632 - val_loss: 9.7448\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7026 - val_loss: 10.2355\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4549 - val_loss: 9.7356\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0672 - val_loss: 9.2161\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6777 - val_loss: 10.3210\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5772 - val_loss: 9.7540\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5582 - val_loss: 11.3713\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0639 - val_loss: 9.4818\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2820 - val_loss: 10.1749\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2501 - val_loss: 9.4480\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1361 - val_loss: 9.0344\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4431 - val_loss: 10.1127\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5437 - val_loss: 9.6408\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2260 - val_loss: 9.3846\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.1625 - val_loss: 8.9768\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3468 - val_loss: 10.6168\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 7.9833 - val_loss: 9.2332\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.3026 - val_loss: 9.2116\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2337 - val_loss: 10.6402\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1468 - val_loss: 9.4358\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5624 - val_loss: 9.9630\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3466 - val_loss: 9.0731\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1307 - val_loss: 10.1052\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0184 - val_loss: 9.2374\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1474 - val_loss: 8.8785\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5017 - val_loss: 9.1694\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.2726 - val_loss: 9.7600\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0255 - val_loss: 11.2584\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1433 - val_loss: 9.9122\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8185 - val_loss: 10.5579\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7198 - val_loss: 9.4141\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 7.9149 - val_loss: 9.8447\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1597 - val_loss: 10.7738\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.4402 - val_loss: 9.1753\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9922 - val_loss: 11.8223\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6169 - val_loss: 9.9115\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6966 - val_loss: 9.9430\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2382 - val_loss: 11.2456\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.1994 - val_loss: 9.3628\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7298 - val_loss: 9.0542\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1200 - val_loss: 9.5463\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.1192 - val_loss: 10.2290\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7143 - val_loss: 9.7759\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.1976 - val_loss: 10.8429\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2713 - val_loss: 9.4138\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.2122 - val_loss: 10.1283\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4917 - val_loss: 9.4948\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2882 - val_loss: 9.9395\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.3157 - val_loss: 13.1022\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3725 - val_loss: 9.2230\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.0961 - val_loss: 9.7589\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3088 - val_loss: 8.9518\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2202 - val_loss: 9.0512\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2760 - val_loss: 9.0659\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2215 - val_loss: 9.9850\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0149 - val_loss: 9.9190\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1204 - val_loss: 10.4624\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5914 - val_loss: 11.3348\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9650 - val_loss: 9.6201\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1048 - val_loss: 9.3542\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0207 - val_loss: 9.4925\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1811 - val_loss: 12.7050\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6918 - val_loss: 9.4007\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4943 - val_loss: 11.1257\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4210 - val_loss: 10.8685\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8393 - val_loss: 9.6069\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6477 - val_loss: 10.5385\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2937 - val_loss: 9.9039\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0634 - val_loss: 9.2684\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6731 - val_loss: 10.0848\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9131 - val_loss: 9.4658\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.1497 - val_loss: 9.2474\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1175 - val_loss: 9.3009\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3073 - val_loss: 9.6692\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3080 - val_loss: 9.4801\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.0473 - val_loss: 9.6460\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5177 - val_loss: 9.6700\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.2902 - val_loss: 9.4714\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0448 - val_loss: 12.4588\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7683 - val_loss: 9.1139\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1495 - val_loss: 9.5285\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3504 - val_loss: 9.6468\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6679 - val_loss: 9.4715\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4245 - val_loss: 10.3169\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4115 - val_loss: 12.3030\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4822 - val_loss: 9.8206\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0773 - val_loss: 9.4146\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0704 - val_loss: 10.9572\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3033 - val_loss: 9.5240\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1037 - val_loss: 9.2945\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9898 - val_loss: 10.8519\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1232 - val_loss: 9.0583\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.8974 - val_loss: 9.8095\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0191 - val_loss: 13.9384\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4755 - val_loss: 9.4999\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 7.9639 - val_loss: 9.2493\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3081 - val_loss: 9.3290\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8868 - val_loss: 9.6078\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.9401 - val_loss: 10.0028\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5477 - val_loss: 9.2001\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0996 - val_loss: 9.4496\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5821 - val_loss: 9.1825\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5475 - val_loss: 8.9903\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3328 - val_loss: 10.3208\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3802 - val_loss: 9.3984\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2489 - val_loss: 9.5510\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1538 - val_loss: 9.0802\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.9429 - val_loss: 9.2270\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1998 - val_loss: 9.3332\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0471 - val_loss: 10.8309\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8226 - val_loss: 10.4620\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0563 - val_loss: 9.3365\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4516 - val_loss: 9.5615\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.1212 - val_loss: 11.4595\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3497 - val_loss: 9.5403\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.2478 - val_loss: 10.1792\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6995 - val_loss: 9.0151\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3055 - val_loss: 9.8130\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6421 - val_loss: 9.5335\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1740 - val_loss: 9.5562\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4053 - val_loss: 9.9665\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2614 - val_loss: 12.9456\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8161 - val_loss: 9.7395\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.0743 - val_loss: 9.0880\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0589 - val_loss: 9.8852\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.0427 - val_loss: 8.9059\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3606 - val_loss: 9.3892\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1260 - val_loss: 9.6056\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.1816 - val_loss: 9.9602\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.0809 - val_loss: 9.0818\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6141 - val_loss: 8.9533\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2192 - val_loss: 9.0378\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0570 - val_loss: 9.7075\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3323 - val_loss: 9.0286\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2263 - val_loss: 9.5584\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6899 - val_loss: 9.6889\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1771 - val_loss: 9.6029\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8738 - val_loss: 10.6335\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0478 - val_loss: 9.1200\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.0745 - val_loss: 9.5826\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2760 - val_loss: 10.6990\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.0533 - val_loss: 9.3221\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8230 - val_loss: 9.8754\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.0496 - val_loss: 8.9284\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.1071 - val_loss: 11.9779\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1762 - val_loss: 12.2556\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.1963 - val_loss: 9.0525\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.3525 - val_loss: 10.5162\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.1708 - val_loss: 11.0281\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.3466 - val_loss: 9.3533\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.2610 - val_loss: 10.0276\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.2585 - val_loss: 9.2976\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 7.9925 - val_loss: 9.1693\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 7.9433 - val_loss: 10.0676\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.3629 - val_loss: 9.0333\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.2108 - val_loss: 8.8673\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2978 - val_loss: 9.2503\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.3289 - val_loss: 9.9840\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.2725 - val_loss: 9.2843\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.1545 - val_loss: 10.0502\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.0233 - val_loss: 9.2551\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.4505 - val_loss: 9.2145\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4461 - val_loss: 11.4763\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.3329 - val_loss: 9.0957\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2655 - val_loss: 13.2750\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3196 - val_loss: 8.9958\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.5542 - val_loss: 9.9335\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8327 - val_loss: 10.8835\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.7190 - val_loss: 9.0997\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8048 - val_loss: 9.1835\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.2301 - val_loss: 8.9931\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5689 - val_loss: 9.5582\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5503 - val_loss: 10.2470\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4509 - val_loss: 9.1860\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.1966 - val_loss: 12.3654\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1273 - val_loss: 9.3061\n",
      "8.392627192809519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.8570180e+00, -3.9408441e+00,  7.2892344e-01,  3.1818991e+00,\n",
       "          1.7379852e-01],\n",
       "        [ 4.8498923e-01,  2.2124915e-01,  1.3970534e+00, -9.2249840e-02,\n",
       "          1.8553475e-01],\n",
       "        [ 4.1066033e-01, -7.3397189e-01,  1.5632068e+00,  1.2909333e-03,\n",
       "          2.7794605e-01],\n",
       "        [ 4.8958164e-02,  1.3235503e-01, -2.6381847e-01, -2.8422618e-02,\n",
       "         -1.2957168e-01],\n",
       "        [-3.0976489e-01, -3.3997875e-01, -3.2791993e-01,  2.3502815e+00,\n",
       "          1.5243411e-01]], dtype=float32),\n",
       " array([-1.2804192 , -4.8387356 ,  0.67493284,  4.6894226 , -1.4223769 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.04466793, -1.1157516 , -0.80700076,  0.850554  , -0.1578632 ,\n",
       "          1.0087914 , -0.7737305 , -0.16204798, -0.20315029, -0.7507175 ],\n",
       "        [-1.8287063 ,  1.5374163 ,  2.4561803 , -2.0010529 ,  2.1122358 ,\n",
       "         -2.3331237 ,  1.7706631 ,  2.0696056 ,  1.7042559 ,  2.2953892 ],\n",
       "        [ 0.38807407, -0.11482041,  0.4736252 ,  0.04187075, -0.11231745,\n",
       "         -0.5329389 ,  0.64970165,  0.71567327,  0.7192641 ,  0.7849098 ],\n",
       "        [ 1.8815773 , -1.153711  , -1.82633   ,  2.21176   , -1.3038579 ,\n",
       "          1.931188  , -1.7534695 , -2.1952965 , -1.5270703 , -2.1724968 ],\n",
       "        [-2.1369095 ,  2.0088618 ,  1.3817532 , -1.316086  ,  1.8027331 ,\n",
       "         -2.0715456 ,  1.1563628 ,  1.9076434 ,  2.0305595 ,  1.5967591 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.9127289, -2.0059154, -1.8668149,  1.9830815, -2.0359724,\n",
       "         1.8450818, -1.9514823, -2.0186894, -1.8743601, -1.9198427],\n",
       "       dtype=float32),\n",
       " array([[ 2.0236204],\n",
       "        [-1.5109483],\n",
       "        [-2.085673 ],\n",
       "        [ 1.7350324],\n",
       "        [-1.7227299],\n",
       "        [ 2.1974897],\n",
       "        [-1.5997254],\n",
       "        [-1.6618727],\n",
       "        [-1.9375598],\n",
       "        [-1.8036714]], dtype=float32),\n",
       " array([1.8749593], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_adam_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 161us/step - loss: 15381.2223 - val_loss: 15061.6928\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14212.6980 - val_loss: 12870.0707\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9106.8802 - val_loss: 3510.8101\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 776.7761 - val_loss: 103.5136\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 57.7395 - val_loss: 35.6825\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 32.0997 - val_loss: 28.5255\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 26.7083 - val_loss: 26.1373\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 24.2755 - val_loss: 25.3384\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.2828 - val_loss: 25.0671\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.7058 - val_loss: 24.9840\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.3738 - val_loss: 24.9984\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 22.1558 - val_loss: 24.9561\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.9845 - val_loss: 24.8987\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.8558 - val_loss: 24.9566\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.7568 - val_loss: 24.9639\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.6065 - val_loss: 24.8701\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.5260 - val_loss: 24.9326\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.3993 - val_loss: 25.0419\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.2694 - val_loss: 24.9705\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.2045 - val_loss: 25.0618\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.1429 - val_loss: 25.0223\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 21.0314 - val_loss: 24.9934\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.9676 - val_loss: 25.0713\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.8775 - val_loss: 25.0141\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.8224 - val_loss: 25.0539\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.7375 - val_loss: 25.1233\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 20.6567 - val_loss: 25.0990\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.6036 - val_loss: 25.0215\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.5289 - val_loss: 25.0665\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.4728 - val_loss: 25.1173\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.4872 - val_loss: 25.2225\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.3391 - val_loss: 25.0434\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.3069 - val_loss: 25.0537\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.2332 - val_loss: 25.1027\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 20.1925 - val_loss: 25.1321\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 20.0932 - val_loss: 25.0416\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.0630 - val_loss: 25.2032\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 20.0189 - val_loss: 25.1282\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.9610 - val_loss: 25.1357\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.9059 - val_loss: 25.0684\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.8588 - val_loss: 25.0701\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.8125 - val_loss: 25.0771\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.8102 - val_loss: 25.0531\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.7673 - val_loss: 25.0973\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.6838 - val_loss: 25.0812\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 19.6707 - val_loss: 24.9748\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 19.6082 - val_loss: 25.0661\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.5701 - val_loss: 24.9629\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.4995 - val_loss: 25.0700\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.5336 - val_loss: 25.0601\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.5160 - val_loss: 24.8739\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.4601 - val_loss: 24.9510\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.3692 - val_loss: 24.9182\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.3760 - val_loss: 24.9462\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.3552 - val_loss: 24.8798\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.3059 - val_loss: 24.8438\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.2572 - val_loss: 24.9296\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.2218 - val_loss: 24.8834\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.2064 - val_loss: 24.8469\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1979 - val_loss: 24.8329\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.2091 - val_loss: 24.8378\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.1627 - val_loss: 24.8301\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.0964 - val_loss: 24.7843\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0748 - val_loss: 24.7919\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0760 - val_loss: 24.7255\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.0184 - val_loss: 24.7847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0296 - val_loss: 24.7764\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9917 - val_loss: 24.7270\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.0083 - val_loss: 24.6411\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.9563 - val_loss: 24.7192\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.9562 - val_loss: 24.6903\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.9329 - val_loss: 24.6950\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8910 - val_loss: 24.5853\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8874 - val_loss: 24.6242\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8790 - val_loss: 24.6663\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8645 - val_loss: 24.5722\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.8448 - val_loss: 24.5600\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.8198 - val_loss: 24.5139\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.8375 - val_loss: 24.5155\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7824 - val_loss: 24.5072\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.7747 - val_loss: 24.5090\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.7588 - val_loss: 24.4888\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.7499 - val_loss: 24.4841\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7267 - val_loss: 24.4663\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7393 - val_loss: 24.3554\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6757 - val_loss: 24.4225\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.7121 - val_loss: 24.3488\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.6595 - val_loss: 24.3978\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.6593 - val_loss: 24.3486\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.6576 - val_loss: 24.3040\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6543 - val_loss: 24.3210\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6379 - val_loss: 24.3474\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6357 - val_loss: 24.3195\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5938 - val_loss: 24.2610\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6079 - val_loss: 24.3145\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.6005 - val_loss: 24.2419\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5530 - val_loss: 24.2475\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5664 - val_loss: 24.2320\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.5290 - val_loss: 24.2080\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5510 - val_loss: 24.1417\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5305 - val_loss: 24.2403\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.5071 - val_loss: 24.2030\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4977 - val_loss: 24.1979\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4699 - val_loss: 24.1461\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.4734 - val_loss: 24.1235\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4951 - val_loss: 24.1673\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.4746 - val_loss: 24.0384\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4523 - val_loss: 24.0920\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4392 - val_loss: 24.0666\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4175 - val_loss: 24.0581\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3988 - val_loss: 24.0771\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.4047 - val_loss: 24.0698\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.3841 - val_loss: 24.0142\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.3753 - val_loss: 23.9869\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3881 - val_loss: 23.9784\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3807 - val_loss: 23.9483\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.3801 - val_loss: 23.9635\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.3597 - val_loss: 23.9609\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.3498 - val_loss: 23.9283\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.3210 - val_loss: 23.9240\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.3451 - val_loss: 23.8728\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.3252 - val_loss: 23.8948\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.3026 - val_loss: 23.8538\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.3096 - val_loss: 23.8652\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 18.3184 - val_loss: 23.8046\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.2790 - val_loss: 23.9154\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.2917 - val_loss: 23.8068\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.2524 - val_loss: 23.8408\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.2851 - val_loss: 23.7785\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.2485 - val_loss: 23.7820\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.2344 - val_loss: 23.7700\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.2543 - val_loss: 23.7190\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2332 - val_loss: 23.7439\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.2114 - val_loss: 23.7262\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.1871 - val_loss: 23.6858\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.2067 - val_loss: 23.6761\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.2055 - val_loss: 23.6970\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.1803 - val_loss: 23.6638\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.1671 - val_loss: 23.6608\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.1713 - val_loss: 23.7016\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.1495 - val_loss: 23.6381\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1398 - val_loss: 23.6217\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1491 - val_loss: 23.5853\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1428 - val_loss: 23.6358\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.1278 - val_loss: 23.5856\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1093 - val_loss: 23.5990\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.1022 - val_loss: 23.5681\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1062 - val_loss: 23.5830\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.1036 - val_loss: 23.5322\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.0864 - val_loss: 23.5389\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.0809 - val_loss: 23.4687\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.0908 - val_loss: 23.4545\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0571 - val_loss: 23.5101\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.0680 - val_loss: 23.4484\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.0429 - val_loss: 23.4591\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0381 - val_loss: 23.4297\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.0115 - val_loss: 23.4010\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.0200 - val_loss: 23.4719\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0006 - val_loss: 23.4106\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9950 - val_loss: 23.3900\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0148 - val_loss: 23.3434\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.0037 - val_loss: 23.3669\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9686 - val_loss: 23.3406\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9684 - val_loss: 23.3419\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9725 - val_loss: 23.3476\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9823 - val_loss: 23.2828\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.9552 - val_loss: 23.2701\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9425 - val_loss: 23.3256\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 61us/step - loss: 17.9504 - val_loss: 23.2132\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.9150 - val_loss: 23.3004\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.9272 - val_loss: 23.2464\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9527 - val_loss: 23.2817\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.9109 - val_loss: 23.1692\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.9046 - val_loss: 23.2058\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8950 - val_loss: 23.1480\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8717 - val_loss: 23.1407\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8858 - val_loss: 23.1431\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.8890 - val_loss: 23.1237\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8706 - val_loss: 23.1720\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.8643 - val_loss: 23.0863\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8336 - val_loss: 23.0553\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8305 - val_loss: 23.0464\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.8648 - val_loss: 23.0278\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8404 - val_loss: 23.0738\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8223 - val_loss: 23.0310\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.8024 - val_loss: 23.0289\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.8133 - val_loss: 22.9774\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.8383 - val_loss: 22.9850\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.7886 - val_loss: 23.0346\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 59us/step - loss: 17.7924 - val_loss: 23.0065\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.7804 - val_loss: 22.9256\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7639 - val_loss: 22.9115\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7748 - val_loss: 22.9222\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7480 - val_loss: 22.9072\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.7579 - val_loss: 22.9415\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7456 - val_loss: 22.8749\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7318 - val_loss: 22.8687\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.7176 - val_loss: 22.8415\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7171 - val_loss: 22.8418\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.7182 - val_loss: 22.8185\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6961 - val_loss: 22.8001\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.7160 - val_loss: 22.8345\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.6914 - val_loss: 22.7412\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6858 - val_loss: 22.7462\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.6710 - val_loss: 22.7199\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6619 - val_loss: 22.7241\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.6517 - val_loss: 22.7511\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6413 - val_loss: 22.7084\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6565 - val_loss: 22.7365\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6516 - val_loss: 22.6459\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.6231 - val_loss: 22.6998\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.6190 - val_loss: 22.6370\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.5979 - val_loss: 22.6527\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.5884 - val_loss: 22.5951\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.6131 - val_loss: 22.6165\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.6038 - val_loss: 22.5895\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5793 - val_loss: 22.5872\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.5663 - val_loss: 22.5646\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5663 - val_loss: 22.6015\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5668 - val_loss: 22.4797\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.5389 - val_loss: 22.5409\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5487 - val_loss: 22.4812\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.5515 - val_loss: 22.5067\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.5271 - val_loss: 22.4250\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.5445 - val_loss: 22.4943\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.5322 - val_loss: 22.3793\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5226 - val_loss: 22.4206\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5228 - val_loss: 22.4042\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4916 - val_loss: 22.3645\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5013 - val_loss: 22.3223\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4712 - val_loss: 22.3740\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.4825 - val_loss: 22.3687\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4635 - val_loss: 22.2830\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4467 - val_loss: 22.3003\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4524 - val_loss: 22.2674\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.4475 - val_loss: 22.2387\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4375 - val_loss: 22.2148\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.4207 - val_loss: 22.2454\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4121 - val_loss: 22.2315\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.4145 - val_loss: 22.1595\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.4150 - val_loss: 22.1571\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3948 - val_loss: 22.1529\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.3866 - val_loss: 22.1259\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.3569 - val_loss: 22.1573\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3580 - val_loss: 22.0999\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3499 - val_loss: 22.1048\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.3618 - val_loss: 22.0602\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3510 - val_loss: 22.0500\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.3348 - val_loss: 22.0172\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3217 - val_loss: 22.0426\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.3495 - val_loss: 22.0099\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.3240 - val_loss: 22.0232\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.2925 - val_loss: 21.9582\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.2920 - val_loss: 21.9570\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.2738 - val_loss: 21.9358\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.2643 - val_loss: 21.9034\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2597 - val_loss: 21.8855\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.2519 - val_loss: 21.8676\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.2637 - val_loss: 21.8547\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2306 - val_loss: 21.8363\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.2388 - val_loss: 21.7719\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.2078 - val_loss: 21.8180\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2330 - val_loss: 21.7868\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.2144 - val_loss: 21.7160\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1968 - val_loss: 21.7693\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1946 - val_loss: 21.7184\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1732 - val_loss: 21.7203\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.1645 - val_loss: 21.6958\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.1738 - val_loss: 21.6370\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.1612 - val_loss: 21.6849\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.1417 - val_loss: 21.6008\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.1362 - val_loss: 21.5972\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1056 - val_loss: 21.5750\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0962 - val_loss: 21.5615\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.0912 - val_loss: 21.5150\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.1033 - val_loss: 21.5502\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0897 - val_loss: 21.5274\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0634 - val_loss: 21.4728\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0530 - val_loss: 21.4090\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.0548 - val_loss: 21.4251\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0569 - val_loss: 21.4085\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.0196 - val_loss: 21.4339\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9978 - val_loss: 21.3655\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0111 - val_loss: 21.3483\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9844 - val_loss: 21.3794\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.9761 - val_loss: 21.3253\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9623 - val_loss: 21.2901\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9568 - val_loss: 21.2585\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9390 - val_loss: 21.2456\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.9466 - val_loss: 21.2548\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9187 - val_loss: 21.1614\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9112 - val_loss: 21.1550\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9040 - val_loss: 21.1735\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.8967 - val_loss: 21.1824\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8728 - val_loss: 21.0583\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8578 - val_loss: 21.0947\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.8521 - val_loss: 21.1024\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8439 - val_loss: 21.0233\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.8181 - val_loss: 21.0047\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8137 - val_loss: 21.0172\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.8122 - val_loss: 20.9738\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.7922 - val_loss: 20.9628\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.7944 - val_loss: 20.9313\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7848 - val_loss: 20.8961\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.7468 - val_loss: 20.8752\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7536 - val_loss: 20.8082\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7249 - val_loss: 20.8651\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7518 - val_loss: 20.7884\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.7624 - val_loss: 20.8082\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7157 - val_loss: 20.8175\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.6752 - val_loss: 20.7014\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6726 - val_loss: 20.7062\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.6472 - val_loss: 20.7175\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.6300 - val_loss: 20.6942\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6303 - val_loss: 20.6683\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6155 - val_loss: 20.5999\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6038 - val_loss: 20.5961\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5780 - val_loss: 20.5576\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5600 - val_loss: 20.5449\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.5546 - val_loss: 20.5511\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5747 - val_loss: 20.5171\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5368 - val_loss: 20.5938\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5253 - val_loss: 20.4257\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5129 - val_loss: 20.4426\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.5206 - val_loss: 20.4550\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.4806 - val_loss: 20.3566\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4682 - val_loss: 20.3531\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4721 - val_loss: 20.3625\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4358 - val_loss: 20.3455\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4161 - val_loss: 20.3113\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4045 - val_loss: 20.2693\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.3905 - val_loss: 20.2840\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3847 - val_loss: 20.2120\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.3707 - val_loss: 20.2167\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3541 - val_loss: 20.1807\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.3362 - val_loss: 20.1635\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.3388 - val_loss: 20.1032\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3086 - val_loss: 20.1534\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.2927 - val_loss: 20.1139\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 16.2825 - val_loss: 20.0708\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2616 - val_loss: 20.0193\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2481 - val_loss: 20.0030\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.2464 - val_loss: 20.0047\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2145 - val_loss: 19.9310\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.2000 - val_loss: 19.9661\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.1810 - val_loss: 19.9143\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1823 - val_loss: 19.9298\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.1542 - val_loss: 19.8679\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.1513 - val_loss: 19.8749\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1433 - val_loss: 19.7861\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1186 - val_loss: 19.8309\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0984 - val_loss: 19.7762\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0823 - val_loss: 19.7795\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0630 - val_loss: 19.7368\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.0630 - val_loss: 19.7102\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0408 - val_loss: 19.7305\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0214 - val_loss: 19.6880\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0122 - val_loss: 19.6580\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9953 - val_loss: 19.6498\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9788 - val_loss: 19.6369\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9869 - val_loss: 19.5575\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.9454 - val_loss: 19.5890\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.9484 - val_loss: 19.5547\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9241 - val_loss: 19.5104\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9057 - val_loss: 19.5304\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8877 - val_loss: 19.4692\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8843 - val_loss: 19.4166\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.8609 - val_loss: 19.4494\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.8361 - val_loss: 19.4037\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.8158 - val_loss: 19.3661\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8058 - val_loss: 19.3712\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8020 - val_loss: 19.3331\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7751 - val_loss: 19.2854\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.7714 - val_loss: 19.3210\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7353 - val_loss: 19.2814\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7268 - val_loss: 19.2410\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7263 - val_loss: 19.2142\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6975 - val_loss: 19.2279\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6837 - val_loss: 19.1749\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6661 - val_loss: 19.1936\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6558 - val_loss: 19.2225\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6356 - val_loss: 19.1630\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6387 - val_loss: 19.1007\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5904 - val_loss: 19.1238\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.5852 - val_loss: 19.0947\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.5744 - val_loss: 19.0500\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.5472 - val_loss: 19.0376\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5565 - val_loss: 19.0561\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5306 - val_loss: 18.9751\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5181 - val_loss: 19.0009\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5011 - val_loss: 18.9331\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4833 - val_loss: 18.9167\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.4566 - val_loss: 18.9539\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.4561 - val_loss: 18.9121\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4329 - val_loss: 18.9191\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4132 - val_loss: 18.8523\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4013 - val_loss: 18.8804\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3886 - val_loss: 18.8193\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3645 - val_loss: 18.8280\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3437 - val_loss: 18.7767\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3360 - val_loss: 18.7312\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3255 - val_loss: 18.7324\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3020 - val_loss: 18.7437\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2836 - val_loss: 18.6971\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.2751 - val_loss: 18.7114\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.2502 - val_loss: 18.7107\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2560 - val_loss: 18.6712\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2319 - val_loss: 18.6254\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2025 - val_loss: 18.5851\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1854 - val_loss: 18.6229\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1745 - val_loss: 18.6312\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1606 - val_loss: 18.5477\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1488 - val_loss: 18.5675\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1217 - val_loss: 18.5499\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1375 - val_loss: 18.5161\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1087 - val_loss: 18.4616\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0856 - val_loss: 18.4821\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0718 - val_loss: 18.4949\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0529 - val_loss: 18.4481\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0423 - val_loss: 18.4487\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0214 - val_loss: 18.4298\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0012 - val_loss: 18.3842\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9885 - val_loss: 18.3546\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9745 - val_loss: 18.3713\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9561 - val_loss: 18.3629\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9379 - val_loss: 18.3251\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9243 - val_loss: 18.3340\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9101 - val_loss: 18.2881\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.8982 - val_loss: 18.2714\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8803 - val_loss: 18.2445\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8527 - val_loss: 18.2365\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8462 - val_loss: 18.2726\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.8330 - val_loss: 18.1827\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8200 - val_loss: 18.2030\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7977 - val_loss: 18.1951\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.8060 - val_loss: 18.1570\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7783 - val_loss: 18.1269\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7609 - val_loss: 18.1617\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7362 - val_loss: 18.1280\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.7369 - val_loss: 18.1281\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.7017 - val_loss: 18.1159\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6938 - val_loss: 18.1089\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6944 - val_loss: 18.0644\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6572 - val_loss: 18.1199\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6457 - val_loss: 18.0423\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6394 - val_loss: 18.0275\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6167 - val_loss: 18.0021\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6123 - val_loss: 18.0348\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6084 - val_loss: 17.9473\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.5880 - val_loss: 17.9443\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5591 - val_loss: 17.9774\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5391 - val_loss: 17.9305\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5239 - val_loss: 17.9069\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.5188 - val_loss: 17.9157\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4871 - val_loss: 17.8825\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4929 - val_loss: 17.9084\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.4939 - val_loss: 17.9106\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.4682 - val_loss: 17.8562\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.4571 - val_loss: 17.8350\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.4325 - val_loss: 17.8448\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.3996 - val_loss: 17.8194\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4063 - val_loss: 17.8093\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3848 - val_loss: 17.8389\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3710 - val_loss: 17.7982\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.3445 - val_loss: 17.7441\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.3271 - val_loss: 17.7569\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.3116 - val_loss: 17.7202\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.2990 - val_loss: 17.7244\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.2997 - val_loss: 17.6615\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 62us/step - loss: 14.2724 - val_loss: 17.7014\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 14.2618 - val_loss: 17.6871\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 14.2402 - val_loss: 17.6738\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.2388 - val_loss: 17.6827\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.2229 - val_loss: 17.6077\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.1961 - val_loss: 17.6537\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.1892 - val_loss: 17.5747\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.1732 - val_loss: 17.5944\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.1576 - val_loss: 17.5620\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.1468 - val_loss: 17.5031\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.1322 - val_loss: 17.6058\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.1248 - val_loss: 17.5517\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.0858 - val_loss: 17.5173\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0890 - val_loss: 17.5512\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.0742 - val_loss: 17.4644\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0572 - val_loss: 17.4949\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.0389 - val_loss: 17.4593\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.0235 - val_loss: 17.4572\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0186 - val_loss: 17.5077\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.9916 - val_loss: 17.4278\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.9861 - val_loss: 17.4168\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.9823 - val_loss: 17.3695\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.9450 - val_loss: 17.3786\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.9343 - val_loss: 17.3842\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.9547 - val_loss: 17.3727\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.9279 - val_loss: 17.3965\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.9064 - val_loss: 17.3543\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.8780 - val_loss: 17.3264\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.8719 - val_loss: 17.2891\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.8495 - val_loss: 17.2785\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.8418 - val_loss: 17.3005\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.8201 - val_loss: 17.2522\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.8138 - val_loss: 17.2771\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7990 - val_loss: 17.2505\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.7851 - val_loss: 17.1878\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.7699 - val_loss: 17.1914\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.7467 - val_loss: 17.2239\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.7412 - val_loss: 17.1592\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7219 - val_loss: 17.2033\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.7084 - val_loss: 17.1760\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.7012 - val_loss: 17.1442\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6774 - val_loss: 17.1503\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.6943 - val_loss: 17.1309\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6661 - val_loss: 17.1613\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6438 - val_loss: 17.0974\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6389 - val_loss: 17.1042\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6314 - val_loss: 17.0466\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.6068 - val_loss: 17.0618\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5827 - val_loss: 17.0410\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5771 - val_loss: 17.0516\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 13.5600 - val_loss: 17.0255\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.5499 - val_loss: 16.9820\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5391 - val_loss: 17.0119\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.5125 - val_loss: 16.9834\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.5281 - val_loss: 17.0224\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5052 - val_loss: 16.9130\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.4706 - val_loss: 16.9513\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.4619 - val_loss: 16.9037\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4480 - val_loss: 16.9008\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4355 - val_loss: 16.9239\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.4446 - val_loss: 16.9044\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4197 - val_loss: 16.9387\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.3932 - val_loss: 16.8482\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.3870 - val_loss: 16.8253\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.3794 - val_loss: 16.8509\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.3575 - val_loss: 16.7894\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.3519 - val_loss: 16.8526\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.3242 - val_loss: 16.8047\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.3225 - val_loss: 16.7807\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.3121 - val_loss: 16.7288\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.3275 - val_loss: 16.8028\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.2771 - val_loss: 16.6975\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.2747 - val_loss: 16.7469\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.2667 - val_loss: 16.7289\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2277 - val_loss: 16.7292\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2303 - val_loss: 16.7130\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.2146 - val_loss: 16.7247\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.2000 - val_loss: 16.6984\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.1861 - val_loss: 16.6546\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.1710 - val_loss: 16.6834\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.1669 - val_loss: 16.6365\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.1357 - val_loss: 16.6302\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1484 - val_loss: 16.5906\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.1156 - val_loss: 16.5999\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1032 - val_loss: 16.5796\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0839 - val_loss: 16.6169\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0835 - val_loss: 16.5585\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.0683 - val_loss: 16.5269\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.0645 - val_loss: 16.5703\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.0437 - val_loss: 16.5053\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0285 - val_loss: 16.4941\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0140 - val_loss: 16.4916\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.9995 - val_loss: 16.4657\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 12.9839 - val_loss: 16.4636\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.9802 - val_loss: 16.4844\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.9621 - val_loss: 16.4263\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9554 - val_loss: 16.4400\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.9412 - val_loss: 16.4305\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9158 - val_loss: 16.4079\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9231 - val_loss: 16.4404\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.9028 - val_loss: 16.4078\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.8957 - val_loss: 16.3467\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8732 - val_loss: 16.3499\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.8723 - val_loss: 16.4007\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8694 - val_loss: 16.3039\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8436 - val_loss: 16.3708\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8555 - val_loss: 16.3288\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8220 - val_loss: 16.3051\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8125 - val_loss: 16.2840\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7917 - val_loss: 16.2520\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8185 - val_loss: 16.2860\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7735 - val_loss: 16.2185\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.7664 - val_loss: 16.2539\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.7536 - val_loss: 16.2410\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7362 - val_loss: 16.2222\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7252 - val_loss: 16.2098\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7234 - val_loss: 16.2181\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7425 - val_loss: 16.2633\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6797 - val_loss: 16.1326\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6839 - val_loss: 16.1382\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6740 - val_loss: 16.1282\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6530 - val_loss: 16.1493\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.6481 - val_loss: 16.1332\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.6308 - val_loss: 16.1398\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.6259 - val_loss: 16.0679\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6221 - val_loss: 16.0932\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 12.6243 - val_loss: 16.1258\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.5891 - val_loss: 16.0469\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.5794 - val_loss: 16.0099\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5688 - val_loss: 16.0782\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.5711 - val_loss: 15.9995\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.5439 - val_loss: 16.0182\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.5368 - val_loss: 16.0396\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.5327 - val_loss: 15.9942\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.5135 - val_loss: 15.9564\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5170 - val_loss: 15.9878\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.4988 - val_loss: 15.9757\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4784 - val_loss: 15.9216\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4762 - val_loss: 15.9564\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.4581 - val_loss: 15.9451\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4581 - val_loss: 15.9189\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.4798 - val_loss: 15.8691\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4270 - val_loss: 15.9300\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.4189 - val_loss: 15.8887\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4193 - val_loss: 15.8526\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.3966 - val_loss: 15.8992\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.3940 - val_loss: 15.8515\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.3786 - val_loss: 15.8203\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.3727 - val_loss: 15.7763\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.3798 - val_loss: 15.8891\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.3585 - val_loss: 15.7667\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.3498 - val_loss: 15.8576\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.3284 - val_loss: 15.8005\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.3290 - val_loss: 15.7692\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 12.3111 - val_loss: 15.7434\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.3027 - val_loss: 15.7503\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2898 - val_loss: 15.6874\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.2759 - val_loss: 15.7496\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2623 - val_loss: 15.7200\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2775 - val_loss: 15.7338\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.2549 - val_loss: 15.6894\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2403 - val_loss: 15.7061\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.2263 - val_loss: 15.6853\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.2229 - val_loss: 15.6606\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2142 - val_loss: 15.6305\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 12.2006 - val_loss: 15.6186\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1905 - val_loss: 15.6220\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1779 - val_loss: 15.6591\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1741 - val_loss: 15.6534\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1652 - val_loss: 15.6290\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1485 - val_loss: 15.5950\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1570 - val_loss: 15.5090\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.1295 - val_loss: 15.6101\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1268 - val_loss: 15.5791\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.1215 - val_loss: 15.5189\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.1102 - val_loss: 15.5373\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1002 - val_loss: 15.5050\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.1040 - val_loss: 15.5464\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.0832 - val_loss: 15.4955\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.0730 - val_loss: 15.4790\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0704 - val_loss: 15.5015\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.0521 - val_loss: 15.4794\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.0543 - val_loss: 15.4509\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0501 - val_loss: 15.4568\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.0358 - val_loss: 15.4441\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0183 - val_loss: 15.5118\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.0147 - val_loss: 15.4576\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.0099 - val_loss: 15.3958\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0050 - val_loss: 15.4237\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.9919 - val_loss: 15.3722\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9837 - val_loss: 15.3669\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9807 - val_loss: 15.3782\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9583 - val_loss: 15.3829\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9589 - val_loss: 15.3824\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9418 - val_loss: 15.3627\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9388 - val_loss: 15.3907\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9386 - val_loss: 15.3164\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9305 - val_loss: 15.3163\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.9164 - val_loss: 15.3588\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.9153 - val_loss: 15.3157\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8995 - val_loss: 15.2865\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.9503 - val_loss: 15.2954\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.8887 - val_loss: 15.2773\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.8730 - val_loss: 15.2565\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8781 - val_loss: 15.2711\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.8681 - val_loss: 15.2522\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.8479 - val_loss: 15.2562\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8451 - val_loss: 15.2543\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.8442 - val_loss: 15.2767\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8270 - val_loss: 15.1940\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8338 - val_loss: 15.1806\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8108 - val_loss: 15.1729\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8187 - val_loss: 15.2459\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7973 - val_loss: 15.1564\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.7895 - val_loss: 15.2132\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.7780 - val_loss: 15.1737\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7775 - val_loss: 15.1511\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7843 - val_loss: 15.1415\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.7727 - val_loss: 15.1702\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.7624 - val_loss: 15.0942\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7646 - val_loss: 15.0679\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7526 - val_loss: 15.1075\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.7344 - val_loss: 15.1047\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.7376 - val_loss: 15.1090\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7225 - val_loss: 15.1008\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7313 - val_loss: 15.1322\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.7129 - val_loss: 15.0747\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.7045 - val_loss: 15.0966\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6946 - val_loss: 15.0581\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.6935 - val_loss: 15.0480\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.6909 - val_loss: 15.0422\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.6700 - val_loss: 15.0272\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.6718 - val_loss: 15.0836\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.6511 - val_loss: 15.0031\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.6522 - val_loss: 14.9956\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.6758 - val_loss: 14.9641\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6484 - val_loss: 15.0029\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6376 - val_loss: 14.9719\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.6544 - val_loss: 14.9592\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6201 - val_loss: 14.9874\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6124 - val_loss: 14.9338\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.6174 - val_loss: 14.9575\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6081 - val_loss: 14.8924\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.6033 - val_loss: 14.9454\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5960 - val_loss: 14.9396\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.69 - 0s 72us/step - loss: 11.5842 - val_loss: 14.9315\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5860 - val_loss: 14.8964\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.5771 - val_loss: 14.9439\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5751 - val_loss: 14.8929\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5574 - val_loss: 14.9160\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5549 - val_loss: 14.9071\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.5579 - val_loss: 14.8812\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5542 - val_loss: 14.8819\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.5429 - val_loss: 14.8965\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5263 - val_loss: 14.8366\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5242 - val_loss: 14.8430\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5217 - val_loss: 14.7790\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5322 - val_loss: 14.8671\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4959 - val_loss: 14.7750\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5116 - val_loss: 14.7799\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5135 - val_loss: 14.8410\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4918 - val_loss: 14.8025\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4976 - val_loss: 14.7775\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5040 - val_loss: 14.8187\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4697 - val_loss: 14.7745\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4945 - val_loss: 14.7934\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4722 - val_loss: 14.7397\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4641 - val_loss: 14.7756\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.4524 - val_loss: 14.7108\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4538 - val_loss: 14.7439\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4327 - val_loss: 14.7219\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 11.4421 - val_loss: 14.7179\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4273 - val_loss: 14.7422\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.4247 - val_loss: 14.7012\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4426 - val_loss: 14.6602\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4135 - val_loss: 14.7690\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4051 - val_loss: 14.7190\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 11.4081 - val_loss: 14.7119\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.4024 - val_loss: 14.7125\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4100 - val_loss: 14.6344\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.4008 - val_loss: 14.6492\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3993 - val_loss: 14.6617\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3687 - val_loss: 14.6054\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 11.3759 - val_loss: 14.5984\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.3900 - val_loss: 14.6123\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3671 - val_loss: 14.6228\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.3511 - val_loss: 14.5958\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.3506 - val_loss: 14.5932\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3480 - val_loss: 14.5909\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3412 - val_loss: 14.5945\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 11.3369 - val_loss: 14.6051\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3437 - val_loss: 14.6252\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3257 - val_loss: 14.5534\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 11.3332 - val_loss: 14.5531\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 11.3185 - val_loss: 14.5764\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3202 - val_loss: 14.5970\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3097 - val_loss: 14.5453\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3080 - val_loss: 14.5323\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.2921 - val_loss: 14.5482\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2914 - val_loss: 14.5136\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2845 - val_loss: 14.5675\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2812 - val_loss: 14.5442\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.2809 - val_loss: 14.5060\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2721 - val_loss: 14.5642\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2715 - val_loss: 14.5183\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2773 - val_loss: 14.5147\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2665 - val_loss: 14.4911\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2617 - val_loss: 14.4849\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.2603 - val_loss: 14.4797\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.2450 - val_loss: 14.4875\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.2498 - val_loss: 14.4957\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2374 - val_loss: 14.4890\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2481 - val_loss: 14.5127\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2366 - val_loss: 14.4497\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2318 - val_loss: 14.4406\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.2345 - val_loss: 14.4072\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2292 - val_loss: 14.4901\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2078 - val_loss: 14.4032\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.2073 - val_loss: 14.4350\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2113 - val_loss: 14.4402\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.2032 - val_loss: 14.3930\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2027 - val_loss: 14.4100\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.1945 - val_loss: 14.3980\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.1869 - val_loss: 14.3693\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.1897 - val_loss: 14.3791\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.1733 - val_loss: 14.4012\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.1818 - val_loss: 14.4059\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.1710 - val_loss: 14.4216\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 11.1710 - val_loss: 14.3938\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.1602 - val_loss: 14.3117\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.1860 - val_loss: 14.3580\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.1645 - val_loss: 14.3430\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.1530 - val_loss: 14.3682\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.1429 - val_loss: 14.3538\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.1548 - val_loss: 14.3740\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.1392 - val_loss: 14.3204\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.1341 - val_loss: 14.3368\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 11.1355 - val_loss: 14.3200\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.1202 - val_loss: 14.3675\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.1230 - val_loss: 14.3301\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.1199 - val_loss: 14.2820\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.1186 - val_loss: 14.2876\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.1182 - val_loss: 14.2688\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.1256 - val_loss: 14.3006\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.1052 - val_loss: 14.3085\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.1077 - val_loss: 14.2476\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.1020 - val_loss: 14.3165\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0885 - val_loss: 14.2939\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0887 - val_loss: 14.2357\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.0879 - val_loss: 14.2335\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.0898 - val_loss: 14.2891\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.0803 - val_loss: 14.2548\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.0821 - val_loss: 14.2173\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0839 - val_loss: 14.2155\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.0621 - val_loss: 14.2658\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.0695 - val_loss: 14.2456\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0626 - val_loss: 14.2395\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.0521 - val_loss: 14.2422\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.0466 - val_loss: 14.2225\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 11.0536 - val_loss: 14.2471\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.0402 - val_loss: 14.2129\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.0443 - val_loss: 14.2181\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.0562 - val_loss: 14.2361\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.0472 - val_loss: 14.1921\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.0308 - val_loss: 14.1964\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.0324 - val_loss: 14.2104\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0283 - val_loss: 14.1888\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.0265 - val_loss: 14.1339\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.0264 - val_loss: 14.1821\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.0063 - val_loss: 14.1970\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.0068 - val_loss: 14.1482\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.0064 - val_loss: 14.1501\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 11.0234 - val_loss: 14.1780\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.9919 - val_loss: 14.1958\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.9991 - val_loss: 14.1121\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.9994 - val_loss: 14.1546\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.9857 - val_loss: 14.1336\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.9948 - val_loss: 14.1304\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.9953 - val_loss: 14.1013\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 10.9905 - val_loss: 14.1334\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.9809 - val_loss: 14.1207\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.9830 - val_loss: 14.1606\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.9699 - val_loss: 14.1182\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.9767 - val_loss: 14.0989\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.9642 - val_loss: 14.1180\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.9605 - val_loss: 14.0976\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.9523 - val_loss: 14.0998\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9536 - val_loss: 14.0772\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.9507 - val_loss: 14.0644\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.9532 - val_loss: 14.0804\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.9400 - val_loss: 14.1208\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.9439 - val_loss: 14.1205\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.9344 - val_loss: 14.0624\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.9346 - val_loss: 14.0477\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.9358 - val_loss: 14.0740\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.9280 - val_loss: 14.0485\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 10.9292 - val_loss: 14.0304\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.9483 - val_loss: 14.0771\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9201 - val_loss: 14.0046\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9129 - val_loss: 14.0381\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.9286 - val_loss: 14.0040\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9081 - val_loss: 14.0181\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9157 - val_loss: 14.0676\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.9114 - val_loss: 14.0576\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8973 - val_loss: 14.0124\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.9041 - val_loss: 14.0411\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.8922 - val_loss: 14.0033\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.8900 - val_loss: 14.0129\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8844 - val_loss: 13.9993\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.8881 - val_loss: 14.0172\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8797 - val_loss: 13.9553\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8874 - val_loss: 13.9317\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8803 - val_loss: 13.9476\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8830 - val_loss: 14.0201\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8750 - val_loss: 13.9603\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.8841 - val_loss: 13.9661\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.8636 - val_loss: 13.9452\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8718 - val_loss: 13.9487\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 10.8710 - val_loss: 13.9729\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.8559 - val_loss: 13.9008\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8621 - val_loss: 13.9147\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8525 - val_loss: 13.9644\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8599 - val_loss: 13.9288\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8552 - val_loss: 13.9472\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.8625 - val_loss: 13.9582\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.8396 - val_loss: 13.8982\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8361 - val_loss: 13.9240\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8431 - val_loss: 13.8874\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8321 - val_loss: 13.9246\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8285 - val_loss: 13.9174\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8258 - val_loss: 13.9165\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.8239 - val_loss: 13.8932\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.8388 - val_loss: 13.8832\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.8244 - val_loss: 13.9589\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8110 - val_loss: 13.8803\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 10.8158 - val_loss: 13.8471\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8189 - val_loss: 13.9187\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.8160 - val_loss: 13.9210\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.8191 - val_loss: 13.8429\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.8177 - val_loss: 13.9120\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.8051 - val_loss: 13.8776\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.8000 - val_loss: 13.8072\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.7973 - val_loss: 13.8454\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7973 - val_loss: 13.8777\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7944 - val_loss: 13.8707\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.7930 - val_loss: 13.8620\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.7794 - val_loss: 13.7992\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.7805 - val_loss: 13.8356\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 10.7870 - val_loss: 13.8073\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7772 - val_loss: 13.8482\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.7713 - val_loss: 13.8939\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.7765 - val_loss: 13.8293\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.7841 - val_loss: 13.8282\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7661 - val_loss: 13.7944\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7623 - val_loss: 13.8047\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.7700 - val_loss: 13.8318\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7702 - val_loss: 13.8088\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7577 - val_loss: 13.7899\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.7580 - val_loss: 13.7751\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.7588 - val_loss: 13.8457\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7497 - val_loss: 13.8066\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 10.80 - 0s 70us/step - loss: 10.7449 - val_loss: 13.7810\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.7496 - val_loss: 13.8080\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7435 - val_loss: 13.7820\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7362 - val_loss: 13.7717\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7537 - val_loss: 13.8352\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7346 - val_loss: 13.7595\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7450 - val_loss: 13.7546\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.7298 - val_loss: 13.7691\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7262 - val_loss: 13.7815\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.7272 - val_loss: 13.7824\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.7358 - val_loss: 13.7829\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7181 - val_loss: 13.7128\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7208 - val_loss: 13.7367\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7219 - val_loss: 13.7176\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.7181 - val_loss: 13.7697\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7135 - val_loss: 13.7364\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7238 - val_loss: 13.7704\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.7179 - val_loss: 13.7806\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.6998 - val_loss: 13.7166\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 10.7136 - val_loss: 13.7226\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7029 - val_loss: 13.7034\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6997 - val_loss: 13.7050\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6963 - val_loss: 13.7582\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.7064 - val_loss: 13.7689\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.6895 - val_loss: 13.6898\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.6889 - val_loss: 13.6774\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.7030 - val_loss: 13.7397\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.6896 - val_loss: 13.6997\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.6867 - val_loss: 13.7033\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.04 - 0s 73us/step - loss: 10.6770 - val_loss: 13.7085\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 10.6739 - val_loss: 13.6795\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6781 - val_loss: 13.6746\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.6964 - val_loss: 13.6979\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6742 - val_loss: 13.6709\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6683 - val_loss: 13.6408\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.6736 - val_loss: 13.6525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6710 - val_loss: 13.6886\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6644 - val_loss: 13.6579\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6751 - val_loss: 13.6657\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6593 - val_loss: 13.7079\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6633 - val_loss: 13.6743\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6546 - val_loss: 13.6802\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6550 - val_loss: 13.6631\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6529 - val_loss: 13.6373\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 10.6505 - val_loss: 13.6669\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6442 - val_loss: 13.6367\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.6492 - val_loss: 13.6288\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6423 - val_loss: 13.6552\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6474 - val_loss: 13.6461\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.6416 - val_loss: 13.6283\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6518 - val_loss: 13.6140\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6351 - val_loss: 13.6542\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 10.6443 - val_loss: 13.6384\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.6335 - val_loss: 13.6022\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6268 - val_loss: 13.6170\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 10.6242 - val_loss: 13.5845\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 10.00 - 0s 70us/step - loss: 10.6215 - val_loss: 13.6053\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 10.6352 - val_loss: 13.6452\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.6205 - val_loss: 13.6170\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6240 - val_loss: 13.5841\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6136 - val_loss: 13.5617\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6161 - val_loss: 13.5980\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.6160 - val_loss: 13.5891\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.6082 - val_loss: 13.5875\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6195 - val_loss: 13.5481\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 10.6111 - val_loss: 13.6145\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.6015 - val_loss: 13.5924\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 10.6100 - val_loss: 13.5706\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.5954 - val_loss: 13.6033\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.5968 - val_loss: 13.5713\n",
      "10.178486833002715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.735459  ,  1.512964  , -0.9534252 ,  0.2851437 ,  0.21476173],\n",
       "        [-0.3644975 ,  0.17933501,  0.08643351,  0.17940907,  0.37122297],\n",
       "        [-0.25589183,  0.3030813 , -0.65861595,  0.25401184,  1.0806919 ],\n",
       "        [-0.00475568, -0.12505244,  0.06604748, -0.23160335, -0.06284132],\n",
       "        [-0.33606777,  0.2998244 , -0.38623354,  0.24782605,  0.47182074]],\n",
       "       dtype=float32),\n",
       " array([-1.1685587 ,  0.18270569, -2.1370645 , -2.0967648 ,  0.98221433],\n",
       "       dtype=float32),\n",
       " array([[ 0.34434235,  0.9961434 , -0.909173  , -0.10154836, -0.11217956,\n",
       "          0.68737555, -0.836845  , -0.8146233 ,  0.39974737,  0.19688311],\n",
       "        [ 0.00518829,  0.35857517, -0.20548156,  0.6715773 ,  0.02417268,\n",
       "          0.20903912, -0.8605323 , -0.330376  ,  0.7886449 , -0.07456108],\n",
       "        [-0.42959216,  1.7828122 , -1.6797296 ,  0.87457407,  0.1795188 ,\n",
       "         -0.00354172, -1.9708226 , -0.8495077 ,  1.8167931 , -0.83034974],\n",
       "        [ 0.34314525,  1.4293534 , -1.7443739 ,  1.8708669 , -0.76664364,\n",
       "          0.6622897 , -1.9422776 , -0.675986  ,  1.1608183 , -1.112257  ],\n",
       "        [-0.16760087,  0.5554568 , -1.0744983 ,  0.7131611 , -0.23643723,\n",
       "          0.6984752 , -0.05431034,  0.2530816 ,  0.01955596, -0.05733106]],\n",
       "       dtype=float32),\n",
       " array([ 0.6162513 , -2.395149  ,  2.5079172 , -2.7229228 ,  0.6228047 ,\n",
       "        -0.46556646,  2.9976914 ,  0.9711465 , -2.822031  ,  1.5730109 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.43850464],\n",
       "        [-3.4597886 ],\n",
       "        [ 3.6595244 ],\n",
       "        [-3.3736079 ],\n",
       "        [ 0.75608796],\n",
       "        [-0.8728891 ],\n",
       "        [ 4.2050543 ],\n",
       "        [ 1.5466384 ],\n",
       "        [-3.565297  ],\n",
       "        [ 1.98523   ]], dtype=float32),\n",
       " array([2.3311372], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, sgd, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sgd_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 181us/step - loss: 14217.5951 - val_loss: 11931.1442\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8865.1863 - val_loss: 5218.4369\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 2635.8128 - val_loss: 627.3284\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 161.3543 - val_loss: 26.9307\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.5122 - val_loss: 27.1677\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.3049 - val_loss: 27.4670\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.9623 - val_loss: 27.3877\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.1843 - val_loss: 28.6419\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8406 - val_loss: 36.6624\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 24.0122 - val_loss: 27.2600\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.9896 - val_loss: 27.6765\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.4865 - val_loss: 28.1892\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.1789 - val_loss: 26.1819\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3420 - val_loss: 27.2213\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.0857 - val_loss: 32.5034\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.9123 - val_loss: 28.0580\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 24.1078 - val_loss: 30.9114\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.1174 - val_loss: 26.4792\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.5699 - val_loss: 28.0149\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 24.1252 - val_loss: 28.7818\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5429 - val_loss: 29.9745\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.8101 - val_loss: 27.8454\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.6643 - val_loss: 26.5121\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.2625 - val_loss: 27.2219\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.6974 - val_loss: 25.1996\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6622 - val_loss: 26.3477\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.2656 - val_loss: 27.6917\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.2068 - val_loss: 27.9416\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6229 - val_loss: 28.1643\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.0484 - val_loss: 27.3296\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4847 - val_loss: 26.6760\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3488 - val_loss: 28.7454\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 24.0328 - val_loss: 29.9297\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.1877 - val_loss: 31.8493\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4435 - val_loss: 26.3487\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0835 - val_loss: 29.9202\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.0924 - val_loss: 30.4765\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8147 - val_loss: 29.0910\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.3044 - val_loss: 26.1177\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4457 - val_loss: 25.4911\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.0990 - val_loss: 26.7049\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5833 - val_loss: 25.7589\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.9859 - val_loss: 26.2960\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8039 - val_loss: 29.4235\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.1795 - val_loss: 27.8685\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2693 - val_loss: 26.1235\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.0098 - val_loss: 26.6905\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.9368 - val_loss: 26.4515\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.1101 - val_loss: 26.7736\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 23.6227 - val_loss: 27.0374\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.3600 - val_loss: 25.9212\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.9244 - val_loss: 25.6552\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6233 - val_loss: 32.5735\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 23.7769 - val_loss: 30.9822\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.6993 - val_loss: 25.6106\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5763 - val_loss: 26.7263\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6132 - val_loss: 26.1699\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.4150 - val_loss: 27.4745\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.2086 - val_loss: 29.0916\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.9846 - val_loss: 26.6667\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.2038 - val_loss: 27.4746\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 23.5238 - val_loss: 29.2419\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.2169 - val_loss: 29.0111\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.4494 - val_loss: 25.3494\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.0388 - val_loss: 31.7682\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.7396 - val_loss: 29.1167\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 23.2837 - val_loss: 26.9280\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.8203 - val_loss: 26.1273\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.5269 - val_loss: 27.2120\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4382 - val_loss: 26.0024\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.2824 - val_loss: 25.6429\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.7291 - val_loss: 26.0981\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8984 - val_loss: 26.0466\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.9897 - val_loss: 41.7830\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.0804 - val_loss: 25.5889\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.2302 - val_loss: 26.4449\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.0096 - val_loss: 27.9254\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.6787 - val_loss: 27.5047\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.3250 - val_loss: 26.8722\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7085 - val_loss: 25.7820\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 23.0957 - val_loss: 27.0905\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.5813 - val_loss: 27.9878\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5165 - val_loss: 25.8218\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.3730 - val_loss: 28.0763\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.5981 - val_loss: 30.6721\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 24.0406 - val_loss: 25.9008\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6079 - val_loss: 27.7619\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9842 - val_loss: 26.1845\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.8653 - val_loss: 27.2371\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.7097 - val_loss: 28.6642\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.3718 - val_loss: 26.2087\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.3853 - val_loss: 26.3185\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.2810 - val_loss: 26.5424\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0769 - val_loss: 27.2191\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.8618 - val_loss: 25.5057\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.0367 - val_loss: 25.4183\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.7686 - val_loss: 25.4168\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 22.7680 - val_loss: 25.6157\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9504 - val_loss: 26.9177\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2018 - val_loss: 26.7079\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.4765 - val_loss: 27.0433\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.6563 - val_loss: 28.9446\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.2876 - val_loss: 27.0372\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.2013 - val_loss: 25.6374\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.8137 - val_loss: 27.1608\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.4298 - val_loss: 28.0573\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.6134 - val_loss: 25.8132\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0602 - val_loss: 27.1856\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.9580 - val_loss: 25.3040\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.4315 - val_loss: 26.4928\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.0861 - val_loss: 26.0558\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.2041 - val_loss: 29.4668\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.6011 - val_loss: 37.9179\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.2024 - val_loss: 30.0186\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.8927 - val_loss: 25.6036\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.3607 - val_loss: 24.2498\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.7920 - val_loss: 26.0645\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 20.6355 - val_loss: 24.3929\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.6813 - val_loss: 25.1366\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.2096 - val_loss: 24.0703\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.3162 - val_loss: 25.9470\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.8023 - val_loss: 25.3811\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.4680 - val_loss: 24.9034\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.8064 - val_loss: 23.0238\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.9992 - val_loss: 24.1410\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.2198 - val_loss: 24.3777\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 19.0219 - val_loss: 21.7077\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.8154 - val_loss: 22.0141\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.4598 - val_loss: 24.0611\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.8195 - val_loss: 21.5431\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.9747 - val_loss: 20.9821\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.8481 - val_loss: 26.0624\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.2253 - val_loss: 21.6496\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.9736 - val_loss: 20.1505\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.3706 - val_loss: 19.8522\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.7594 - val_loss: 21.0581\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2776 - val_loss: 21.7178\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.9308 - val_loss: 20.5770\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.2199 - val_loss: 19.2126\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.8825 - val_loss: 21.1238\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6416 - val_loss: 19.6921\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.5765 - val_loss: 19.7532\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.2240 - val_loss: 21.0101\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.3682 - val_loss: 19.6614\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6485 - val_loss: 19.9962\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.0694 - val_loss: 18.0043\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.2117 - val_loss: 18.1287\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.0644 - val_loss: 19.2973\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.2526 - val_loss: 18.8040\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.2139 - val_loss: 17.5899\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.5027 - val_loss: 19.8785\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.9429 - val_loss: 19.7271\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.8668 - val_loss: 19.5099\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.7463 - val_loss: 19.9172\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7413 - val_loss: 18.3529\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1191 - val_loss: 18.5615\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1152 - val_loss: 19.0267\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4999 - val_loss: 18.0031\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.9731 - val_loss: 23.8617\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.6300 - val_loss: 19.4466\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.7621 - val_loss: 20.1713\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.7401 - val_loss: 18.2200\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.9198 - val_loss: 18.6176\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.2876 - val_loss: 17.1907\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.7854 - val_loss: 19.3493\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.7815 - val_loss: 19.2448\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.5342 - val_loss: 17.7958\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.4936 - val_loss: 18.2900\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.5507 - val_loss: 18.7572\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.3881 - val_loss: 20.0592\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.2021 - val_loss: 17.2655\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.2451 - val_loss: 24.6302\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.5168 - val_loss: 17.4255\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3016 - val_loss: 17.9669\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.2566 - val_loss: 18.5188\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.6646 - val_loss: 23.1189\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7136 - val_loss: 18.0459\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.5512 - val_loss: 17.4592\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.9856 - val_loss: 18.4323\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.2724 - val_loss: 16.6606\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9999 - val_loss: 17.3319\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.0757 - val_loss: 17.0483\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.5398 - val_loss: 17.8201\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.7210 - val_loss: 17.4904\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.9020 - val_loss: 18.4915\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1435 - val_loss: 16.8990\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.6297 - val_loss: 18.2185\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.5607 - val_loss: 25.2136\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.3820 - val_loss: 25.8402\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.6787 - val_loss: 17.7133\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.4263 - val_loss: 19.7895\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.0702 - val_loss: 19.8895\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.8638 - val_loss: 17.1321\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.2561 - val_loss: 18.0152\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.4459 - val_loss: 17.1074\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.5584 - val_loss: 17.3384\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.0987 - val_loss: 17.5087\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.3241 - val_loss: 17.2433\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.0326 - val_loss: 16.9390\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4875 - val_loss: 18.3314\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8807 - val_loss: 16.0772\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.8588 - val_loss: 16.2177\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.3800 - val_loss: 17.3144\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3032 - val_loss: 16.0636\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.0225 - val_loss: 16.4900\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.7290 - val_loss: 16.1919\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6673 - val_loss: 17.7523\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.1778 - val_loss: 17.6969\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3554 - val_loss: 17.4704\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.4424 - val_loss: 16.1626\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4850 - val_loss: 17.9805\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1033 - val_loss: 20.2834\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1750 - val_loss: 17.3128\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.4266 - val_loss: 16.3847\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.1904 - val_loss: 19.2228\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4605 - val_loss: 15.8711\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6676 - val_loss: 19.1284\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9920 - val_loss: 15.5617\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7925 - val_loss: 17.6808\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.4293 - val_loss: 21.1509\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.0736 - val_loss: 16.0806\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.6844 - val_loss: 15.1790\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.3375 - val_loss: 22.9215\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.3549 - val_loss: 17.5559\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.3516 - val_loss: 15.6415\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9446 - val_loss: 15.0253\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.5065 - val_loss: 19.6457\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7593 - val_loss: 17.1171\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.1709 - val_loss: 15.5751\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.1332 - val_loss: 16.5765\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.0742 - val_loss: 16.2323\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.0616 - val_loss: 20.3703\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.8913 - val_loss: 19.3436\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.3156 - val_loss: 17.8419\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.6960 - val_loss: 15.7652\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.3026 - val_loss: 14.3175\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.9777 - val_loss: 16.0380\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.5888 - val_loss: 16.6499\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9718 - val_loss: 17.4701\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.2964 - val_loss: 14.2531\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.2910 - val_loss: 14.1932\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.9122 - val_loss: 14.7415\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.0626 - val_loss: 14.3555\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.7709 - val_loss: 17.0645\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.2716 - val_loss: 16.4079\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.3480 - val_loss: 18.4097\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.6527 - val_loss: 14.8098\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3183 - val_loss: 14.3387\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.4391 - val_loss: 16.5169\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9592 - val_loss: 14.8747\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1983 - val_loss: 14.0818\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.0802 - val_loss: 13.7065\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.2186 - val_loss: 15.9352\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0663 - val_loss: 16.1660\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.9931 - val_loss: 17.6234\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5192 - val_loss: 16.1473\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4533 - val_loss: 13.3579\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9204 - val_loss: 14.9524\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.2514 - val_loss: 14.6755\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.2067 - val_loss: 12.5517\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.9008 - val_loss: 13.5614\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.4889 - val_loss: 20.0352\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3083 - val_loss: 14.2277\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3546 - val_loss: 13.7028\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.5941 - val_loss: 17.3658\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3648 - val_loss: 16.2822\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.7921 - val_loss: 17.0392\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.4380 - val_loss: 15.8848\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.7576 - val_loss: 14.2685\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.1696 - val_loss: 13.9530\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.3495 - val_loss: 12.2377\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.1699 - val_loss: 16.3283\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.5721 - val_loss: 15.3418\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2631 - val_loss: 23.7646\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.5207 - val_loss: 15.1369\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3452 - val_loss: 12.0233\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.6328 - val_loss: 13.8930\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.5360 - val_loss: 16.0039\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.8310 - val_loss: 13.0974\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0965 - val_loss: 14.4605\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9634 - val_loss: 14.0175\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9524 - val_loss: 13.0227\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.1747 - val_loss: 12.5829\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.7140 - val_loss: 15.9942\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.8438 - val_loss: 13.1481\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5190 - val_loss: 13.6906\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6755 - val_loss: 14.3306\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8320 - val_loss: 12.9980\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.8426 - val_loss: 13.2782\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4949 - val_loss: 16.8345\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4050 - val_loss: 12.2189\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6709 - val_loss: 15.4958\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2376 - val_loss: 18.3011\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.7756 - val_loss: 17.8483\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.6776 - val_loss: 14.4102\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3491 - val_loss: 12.1936\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6532 - val_loss: 13.9429\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2016 - val_loss: 17.0758\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.3953 - val_loss: 12.4461\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4608 - val_loss: 11.5160\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3685 - val_loss: 11.5907\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.1663 - val_loss: 12.1362\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7151 - val_loss: 14.1252\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5384 - val_loss: 12.2408\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.7766 - val_loss: 11.9892\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4735 - val_loss: 12.1212\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3941 - val_loss: 11.7031\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4218 - val_loss: 14.7749\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0538 - val_loss: 12.1162\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.4766 - val_loss: 11.5929\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.2078 - val_loss: 13.0240\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0786 - val_loss: 12.0338\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8236 - val_loss: 12.6171\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.1747 - val_loss: 12.3331\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1133 - val_loss: 11.1698\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 10.0202 - val_loss: 11.3477\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3847 - val_loss: 14.0154\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.0432 - val_loss: 11.1874\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 10.5218 - val_loss: 11.7137\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0171 - val_loss: 12.8342\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8648 - val_loss: 12.9340\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.3699 - val_loss: 17.5792\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2031 - val_loss: 11.4873\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3006 - val_loss: 12.8484\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6926 - val_loss: 11.9181\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.0547 - val_loss: 12.8625\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1444 - val_loss: 14.6892\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.4664 - val_loss: 11.7243\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4415 - val_loss: 11.8564\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.7227 - val_loss: 17.9574\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0097 - val_loss: 12.0926\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5972 - val_loss: 12.3793\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.4573 - val_loss: 12.1776\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2507 - val_loss: 15.5768\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2573 - val_loss: 11.1283\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9898 - val_loss: 22.6348\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.1209 - val_loss: 11.3193\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.1776 - val_loss: 12.7031\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2792 - val_loss: 12.0381\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.1123 - val_loss: 12.6748\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.2416 - val_loss: 11.0740\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9556 - val_loss: 11.9513\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.0099 - val_loss: 14.2275\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.3708 - val_loss: 11.1269\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2692 - val_loss: 12.7358\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.2113 - val_loss: 11.8489\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1446 - val_loss: 12.0987\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9835 - val_loss: 11.4860\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3152 - val_loss: 13.3803\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0297 - val_loss: 13.3444\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9472 - val_loss: 17.3709\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.1210 - val_loss: 10.9686\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.3292 - val_loss: 12.7585\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1425 - val_loss: 11.2629\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8956 - val_loss: 13.6180\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1773 - val_loss: 12.0788\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1639 - val_loss: 11.1070\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1137 - val_loss: 12.3530\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0924 - val_loss: 12.3292\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0538 - val_loss: 15.1112\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4990 - val_loss: 12.2814\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.1225 - val_loss: 12.2564\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7540 - val_loss: 11.5041\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0753 - val_loss: 13.4339\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5259 - val_loss: 10.9379\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9076 - val_loss: 15.6015\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.1341 - val_loss: 14.3154\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0275 - val_loss: 13.0717\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7167 - val_loss: 14.3488\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6547 - val_loss: 11.5369\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7891 - val_loss: 12.5254\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5909 - val_loss: 27.2681\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.9469 - val_loss: 20.8774\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6380 - val_loss: 15.8268\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1943 - val_loss: 12.2030\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9766 - val_loss: 10.9300\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4006 - val_loss: 11.5346\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8255 - val_loss: 11.3187\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9492 - val_loss: 11.8456\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9615 - val_loss: 10.7637\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0031 - val_loss: 12.2974\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7793 - val_loss: 13.8630\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8586 - val_loss: 11.6466\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0238 - val_loss: 11.1832\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0656 - val_loss: 10.7865\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7290 - val_loss: 10.8017\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7062 - val_loss: 11.5684\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.9721 - val_loss: 11.2912\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9712 - val_loss: 11.8134\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6343 - val_loss: 12.6386\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8782 - val_loss: 11.1965\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6563 - val_loss: 10.9353\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5243 - val_loss: 10.3659\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7154 - val_loss: 10.7591\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4814 - val_loss: 10.5257\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3807 - val_loss: 10.8639\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5544 - val_loss: 18.6766\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8062 - val_loss: 11.1619\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8717 - val_loss: 12.0484\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4284 - val_loss: 11.8048\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6970 - val_loss: 11.6248\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.5176 - val_loss: 11.3437\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6169 - val_loss: 11.1647\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.7731 - val_loss: 13.8520\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8781 - val_loss: 10.5850\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9619 - val_loss: 11.4300\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3307 - val_loss: 11.2969\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8306 - val_loss: 11.6886\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5894 - val_loss: 13.3379\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9406 - val_loss: 10.3730\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6689 - val_loss: 11.5203\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4728 - val_loss: 12.2185\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1383 - val_loss: 10.3278\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8920 - val_loss: 10.6985\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7620 - val_loss: 10.8543\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5903 - val_loss: 13.2629\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0367 - val_loss: 11.8543\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8223 - val_loss: 10.3115\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4429 - val_loss: 10.3294\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4310 - val_loss: 12.8130\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9441 - val_loss: 11.4658\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2530 - val_loss: 14.2568\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9403 - val_loss: 10.6432\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3947 - val_loss: 13.9969\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9041 - val_loss: 10.5176\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7089 - val_loss: 14.4316\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8906 - val_loss: 11.6172\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4368 - val_loss: 12.0111\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8279 - val_loss: 12.7076\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4097 - val_loss: 10.8173\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5460 - val_loss: 10.9504\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9639 - val_loss: 10.2696\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6721 - val_loss: 12.0814\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6204 - val_loss: 10.8276\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.8020 - val_loss: 10.2603\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.8037 - val_loss: 13.2174\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1375 - val_loss: 10.6609\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4355 - val_loss: 14.5100\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7328 - val_loss: 12.8996\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8372 - val_loss: 10.9671\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7450 - val_loss: 11.1418\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2611 - val_loss: 15.4325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7529 - val_loss: 10.4942\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3525 - val_loss: 10.3202\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6601 - val_loss: 11.6823\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1171 - val_loss: 10.7560\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8908 - val_loss: 10.8032\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7528 - val_loss: 10.1086\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6872 - val_loss: 15.1168\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.9591 - val_loss: 14.4284\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6720 - val_loss: 10.3202\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4655 - val_loss: 10.3401\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2351 - val_loss: 12.2315\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8922 - val_loss: 12.1369\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3267 - val_loss: 10.8929\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5866 - val_loss: 10.4598\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9685 - val_loss: 11.7908\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5791 - val_loss: 11.7375\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5097 - val_loss: 13.0984\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8984 - val_loss: 10.3777\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4198 - val_loss: 11.2397\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2760 - val_loss: 10.5513\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5459 - val_loss: 13.0556\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5969 - val_loss: 11.0535\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2983 - val_loss: 10.8447\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4602 - val_loss: 10.7061\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5912 - val_loss: 11.0041\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8387 - val_loss: 12.8688\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1208 - val_loss: 12.5616\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6693 - val_loss: 10.4591\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7971 - val_loss: 10.1382\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2662 - val_loss: 12.6447\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.7494 - val_loss: 12.2975\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5163 - val_loss: 10.8773\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.2596 - val_loss: 14.0142\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5647 - val_loss: 10.3079\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7533 - val_loss: 11.8744\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3747 - val_loss: 10.6580\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2338 - val_loss: 10.0317\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8601 - val_loss: 10.9018\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4735 - val_loss: 12.6845\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4110 - val_loss: 11.5747\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5304 - val_loss: 11.3028\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0769 - val_loss: 15.4519\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7010 - val_loss: 10.8421\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5763 - val_loss: 10.2792\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2651 - val_loss: 10.6868\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2178 - val_loss: 16.8237\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4980 - val_loss: 11.1863\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4501 - val_loss: 11.0627\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3217 - val_loss: 10.9799\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4130 - val_loss: 9.9947\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3332 - val_loss: 17.0175\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6106 - val_loss: 15.8507\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4962 - val_loss: 11.9199\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2823 - val_loss: 11.2875\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4129 - val_loss: 9.9336\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4468 - val_loss: 11.2338\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4685 - val_loss: 10.3385\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5928 - val_loss: 15.7721\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7783 - val_loss: 13.8981\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4960 - val_loss: 12.9346\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5149 - val_loss: 12.4541\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5904 - val_loss: 15.4032\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6571 - val_loss: 13.3322\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4080 - val_loss: 10.3935\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2869 - val_loss: 11.6449\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4464 - val_loss: 10.5414\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4760 - val_loss: 12.5265\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4265 - val_loss: 10.0936\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.7522 - val_loss: 10.5334\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6847 - val_loss: 10.1762\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2235 - val_loss: 11.5786\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8221 - val_loss: 12.0460\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3291 - val_loss: 16.3306\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2218 - val_loss: 12.5702\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8914 - val_loss: 12.3944\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1582 - val_loss: 16.6414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7796 - val_loss: 11.4798\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0832 - val_loss: 15.6113\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.6929 - val_loss: 10.0649\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.2975 - val_loss: 9.9821\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1441 - val_loss: 10.6239\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5496 - val_loss: 10.7577\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4440 - val_loss: 12.5462\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3570 - val_loss: 10.5684\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2225 - val_loss: 10.7323\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6720 - val_loss: 10.3583\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2799 - val_loss: 11.3667\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5227 - val_loss: 10.1586\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6250 - val_loss: 12.1818\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4187 - val_loss: 10.6491\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2613 - val_loss: 12.8872\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4123 - val_loss: 10.9056\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4525 - val_loss: 11.6926\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5290 - val_loss: 11.6610\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4085 - val_loss: 12.4651\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0667 - val_loss: 10.5879\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3069 - val_loss: 11.3170\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8390 - val_loss: 10.7145\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7926 - val_loss: 11.4720\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3534 - val_loss: 10.8710\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4363 - val_loss: 11.1228\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9958 - val_loss: 9.7601\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.7484 - val_loss: 14.5325\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2810 - val_loss: 12.7536\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5528 - val_loss: 16.2831\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4748 - val_loss: 9.6876\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3339 - val_loss: 12.4995\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5955 - val_loss: 12.9531\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4320 - val_loss: 10.2085\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3104 - val_loss: 12.0511\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7143 - val_loss: 10.3694\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.7454 - val_loss: 10.5530\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6410 - val_loss: 9.8526\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4133 - val_loss: 10.3804\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5545 - val_loss: 10.2513\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3306 - val_loss: 12.2351\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6073 - val_loss: 11.4112\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3870 - val_loss: 10.3107\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5220 - val_loss: 9.9334\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3228 - val_loss: 9.8496\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1427 - val_loss: 10.8679\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7175 - val_loss: 11.5584\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2669 - val_loss: 10.6663\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3883 - val_loss: 10.7092\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8272 - val_loss: 10.0222\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8893 - val_loss: 12.1231\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2681 - val_loss: 11.4896\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7036 - val_loss: 10.5344\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2123 - val_loss: 11.1244\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4441 - val_loss: 9.6138\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3386 - val_loss: 9.9388\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4517 - val_loss: 10.1280\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3564 - val_loss: 12.8900\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3699 - val_loss: 11.2485\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2744 - val_loss: 10.2806\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4194 - val_loss: 9.9816\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8894 - val_loss: 12.5312\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4635 - val_loss: 15.1516\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3658 - val_loss: 10.5543\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4354 - val_loss: 12.2080\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3308 - val_loss: 10.0695\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1236 - val_loss: 10.8779\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3947 - val_loss: 10.8357\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4498 - val_loss: 9.6398\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0863 - val_loss: 9.9230\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3477 - val_loss: 10.5921\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2996 - val_loss: 11.7273\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.7558 - val_loss: 14.1727\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2098 - val_loss: 10.0773\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5976 - val_loss: 10.0567\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1181 - val_loss: 10.0564\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5044 - val_loss: 10.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0310 - val_loss: 12.3216\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5938 - val_loss: 10.7503\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2592 - val_loss: 9.9071\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5714 - val_loss: 12.0624\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8001 - val_loss: 10.1417\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2336 - val_loss: 10.7915\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4152 - val_loss: 13.2635\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1394 - val_loss: 9.6415\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3796 - val_loss: 12.0249\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0727 - val_loss: 12.9972\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8384 - val_loss: 9.8650\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.0844 - val_loss: 10.7263\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1643 - val_loss: 12.6815\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9829 - val_loss: 10.0046\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1005 - val_loss: 11.8989\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2991 - val_loss: 11.2275\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0716 - val_loss: 12.4538\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1577 - val_loss: 11.1822\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4589 - val_loss: 16.2787\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7513 - val_loss: 10.4509\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0258 - val_loss: 11.0437\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3116 - val_loss: 11.0870\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4524 - val_loss: 11.1809\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7412 - val_loss: 10.4744\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3589 - val_loss: 10.0244\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3870 - val_loss: 11.2112\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4402 - val_loss: 9.9850\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3725 - val_loss: 13.1587\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3927 - val_loss: 11.8202\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1505 - val_loss: 10.0241\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4532 - val_loss: 10.4617\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6035 - val_loss: 10.3698\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9594 - val_loss: 10.5676\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3645 - val_loss: 12.6559\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1963 - val_loss: 12.1658\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3950 - val_loss: 11.3467\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4220 - val_loss: 11.3267\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3822 - val_loss: 9.8061\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6566 - val_loss: 10.2058\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0976 - val_loss: 12.9973\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9407 - val_loss: 14.6973\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5620 - val_loss: 9.7787\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7696 - val_loss: 11.8203\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2361 - val_loss: 9.8214\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1130 - val_loss: 10.5160\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4252 - val_loss: 9.9075\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1259 - val_loss: 13.4550\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3056 - val_loss: 10.0734\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9809 - val_loss: 13.3979\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6753 - val_loss: 11.2103\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0768 - val_loss: 12.4747\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2305 - val_loss: 10.7953\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5995 - val_loss: 10.2454\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0893 - val_loss: 10.3471\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4271 - val_loss: 9.5944\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3840 - val_loss: 13.3160\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2639 - val_loss: 12.5520\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0074 - val_loss: 9.6125\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1936 - val_loss: 10.5940\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9360 - val_loss: 9.6193\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5108 - val_loss: 9.5720\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5434 - val_loss: 10.5552\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.0263 - val_loss: 10.2893\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5065 - val_loss: 11.4254\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7709 - val_loss: 9.7875\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4094 - val_loss: 14.9824\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0432 - val_loss: 14.2689\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4788 - val_loss: 9.5500\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9007 - val_loss: 11.4273\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4398 - val_loss: 9.6311\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9459 - val_loss: 9.7574\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5149 - val_loss: 10.5071\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2741 - val_loss: 9.6455\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.9876 - val_loss: 10.7112\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3886 - val_loss: 12.9322\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6330 - val_loss: 10.2522\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4637 - val_loss: 9.6366\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1585 - val_loss: 11.1101\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2806 - val_loss: 10.1461\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5824 - val_loss: 10.0619\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6750 - val_loss: 11.3876\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2639 - val_loss: 10.2507\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2514 - val_loss: 10.7212\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1656 - val_loss: 9.9702\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3538 - val_loss: 10.1334\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3614 - val_loss: 10.2302\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2130 - val_loss: 10.5591\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9210 - val_loss: 10.4657\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3797 - val_loss: 10.7636\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0571 - val_loss: 10.6113\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3199 - val_loss: 11.5747\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9950 - val_loss: 10.6123\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3497 - val_loss: 10.1973\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0774 - val_loss: 15.4758\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0062 - val_loss: 12.5446\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0316 - val_loss: 10.2161\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0160 - val_loss: 12.9037\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2547 - val_loss: 9.8625\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1618 - val_loss: 10.7510\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2959 - val_loss: 10.7176\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2021 - val_loss: 10.9975\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8242 - val_loss: 9.6263\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4142 - val_loss: 10.8202\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3347 - val_loss: 9.5039\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2960 - val_loss: 10.9347\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4301 - val_loss: 9.7584\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1829 - val_loss: 10.3935\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1223 - val_loss: 10.2203\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8526 - val_loss: 10.3657\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1249 - val_loss: 10.7122\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1862 - val_loss: 13.3309\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2659 - val_loss: 10.7520\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3573 - val_loss: 9.6411\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1823 - val_loss: 11.1053\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3938 - val_loss: 10.7209\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0754 - val_loss: 10.9240\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0836 - val_loss: 11.5630\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1145 - val_loss: 10.1180\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1838 - val_loss: 11.0510\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1641 - val_loss: 10.7995\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7161 - val_loss: 10.7689\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4497 - val_loss: 10.6451\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1761 - val_loss: 10.0607\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1265 - val_loss: 10.2480\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1853 - val_loss: 15.6156\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5376 - val_loss: 9.9719\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3855 - val_loss: 9.4608\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3518 - val_loss: 10.8412\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1812 - val_loss: 10.3274\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4554 - val_loss: 10.2458\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3829 - val_loss: 9.6565\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2094 - val_loss: 10.9230\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5028 - val_loss: 10.1446\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1320 - val_loss: 11.5604\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0383 - val_loss: 13.4152\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1476 - val_loss: 9.8327\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1572 - val_loss: 12.9486\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7134 - val_loss: 9.3865\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3211 - val_loss: 10.1632\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1538 - val_loss: 9.8198\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1701 - val_loss: 13.2333\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5125 - val_loss: 10.6285\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4452 - val_loss: 13.3463\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5058 - val_loss: 9.6799\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3857 - val_loss: 11.5771\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3141 - val_loss: 12.1064\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3370 - val_loss: 10.7276\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4874 - val_loss: 10.0804\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1271 - val_loss: 9.7336\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3148 - val_loss: 15.1934\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.7221 - val_loss: 13.4804\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9074 - val_loss: 11.8107\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9132 - val_loss: 11.2261\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2388 - val_loss: 9.5768\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9868 - val_loss: 10.6534\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5473 - val_loss: 9.7574\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1815 - val_loss: 9.9993\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2673 - val_loss: 11.7348\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6738 - val_loss: 9.8735\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2969 - val_loss: 9.4000\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4375 - val_loss: 9.8320\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7818 - val_loss: 10.5841\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6046 - val_loss: 9.9118\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2167 - val_loss: 10.5991\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2438 - val_loss: 9.6553\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1212 - val_loss: 9.5700\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8672 - val_loss: 10.7300\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1638 - val_loss: 12.9679\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9588 - val_loss: 14.6244\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4464 - val_loss: 10.5228\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7922 - val_loss: 9.9273\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5709 - val_loss: 9.7384\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3874 - val_loss: 10.1290\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3435 - val_loss: 10.4811\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0431 - val_loss: 13.6006\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3589 - val_loss: 10.5479\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9826 - val_loss: 11.2549\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4534 - val_loss: 9.8416\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3490 - val_loss: 10.0008\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3284 - val_loss: 9.9559\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1205 - val_loss: 11.0378\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9708 - val_loss: 10.9818\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0945 - val_loss: 10.3105\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4630 - val_loss: 12.1870\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0979 - val_loss: 10.0387\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6167 - val_loss: 9.7651\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8457 - val_loss: 10.9948\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3041 - val_loss: 10.5325\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9080 - val_loss: 10.4824\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2777 - val_loss: 12.7183\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2041 - val_loss: 14.3576\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7647 - val_loss: 13.1812\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0738 - val_loss: 12.2446\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2810 - val_loss: 9.9438\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4755 - val_loss: 10.2850\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3504 - val_loss: 10.2182\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1458 - val_loss: 9.6268\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3360 - val_loss: 12.4551\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2829 - val_loss: 11.3988\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2698 - val_loss: 14.5989\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0135 - val_loss: 13.9795\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1643 - val_loss: 10.2345\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5975 - val_loss: 9.7166\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2040 - val_loss: 11.5559\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1154 - val_loss: 13.6151\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4382 - val_loss: 12.5237\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6804 - val_loss: 12.7993\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2961 - val_loss: 13.1938\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8208 - val_loss: 10.1503\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6697 - val_loss: 10.1900\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1925 - val_loss: 9.8984\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3539 - val_loss: 12.3695\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1168 - val_loss: 12.2901\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2833 - val_loss: 11.6589\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1961 - val_loss: 10.0141\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1069 - val_loss: 9.6153\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2429 - val_loss: 10.0532\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1186 - val_loss: 10.3753\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2198 - val_loss: 9.5786\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7279 - val_loss: 10.6271\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0499 - val_loss: 14.3958\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3697 - val_loss: 10.2709\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0149 - val_loss: 9.5998\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3860 - val_loss: 13.4974\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2000 - val_loss: 10.9088\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2298 - val_loss: 9.5167\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6089 - val_loss: 10.6865\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9636 - val_loss: 10.2424\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4282 - val_loss: 10.2692\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0830 - val_loss: 9.5146\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2266 - val_loss: 9.9447\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3463 - val_loss: 9.4704\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2161 - val_loss: 11.4866\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.3159 - val_loss: 12.2309\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1965 - val_loss: 9.6396\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2065 - val_loss: 10.9600\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2811 - val_loss: 13.3219\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8680 - val_loss: 9.5215\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2944 - val_loss: 11.1895\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0894 - val_loss: 10.0217\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9318 - val_loss: 10.0645\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5796 - val_loss: 9.3127\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2443 - val_loss: 9.8156\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0371 - val_loss: 9.7750\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2327 - val_loss: 9.5347\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3486 - val_loss: 9.5923\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0474 - val_loss: 12.1577\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3597 - val_loss: 9.8382\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2546 - val_loss: 16.0395\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0542 - val_loss: 11.8600\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3823 - val_loss: 13.6802\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1355 - val_loss: 10.1195\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9650 - val_loss: 10.0762\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0606 - val_loss: 9.7192\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4744 - val_loss: 12.7491\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1223 - val_loss: 11.3417\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2483 - val_loss: 10.3316\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9956 - val_loss: 10.3852\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1099 - val_loss: 9.9856\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9840 - val_loss: 9.9063\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1031 - val_loss: 9.8917\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8980 - val_loss: 9.7664\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5594 - val_loss: 9.6049\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0139 - val_loss: 10.8396\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2148 - val_loss: 9.7917\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1238 - val_loss: 10.9648\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1530 - val_loss: 11.3849\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3956 - val_loss: 9.9792\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 8.8801 - val_loss: 11.0014\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.6904 - val_loss: 13.4093\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8806 - val_loss: 12.2960\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8723 - val_loss: 9.6068\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0533 - val_loss: 13.6402\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9213 - val_loss: 14.2621\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0856 - val_loss: 10.7010\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7976 - val_loss: 9.1931\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4157 - val_loss: 9.4624\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9173 - val_loss: 9.8661\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3851 - val_loss: 10.5160\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6992 - val_loss: 11.0478\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 9.2253 - val_loss: 10.3931\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2643 - val_loss: 10.3394\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8609 - val_loss: 9.7247\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9122 - val_loss: 13.4206\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2631 - val_loss: 10.2711\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7996 - val_loss: 12.6206\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1441 - val_loss: 9.7825\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2886 - val_loss: 14.5185\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8366 - val_loss: 10.4717\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8347 - val_loss: 9.6910\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0552 - val_loss: 10.6038\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1352 - val_loss: 12.4878\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1896 - val_loss: 12.4251\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2984 - val_loss: 9.4508\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5477 - val_loss: 9.7461\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5003 - val_loss: 11.6731\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0338 - val_loss: 9.6565\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0161 - val_loss: 12.0030\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 8.7763 - val_loss: 10.3522\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.2969 - val_loss: 11.2517\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7578 - val_loss: 9.3296\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9709 - val_loss: 9.9332\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2395 - val_loss: 9.5305\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2045 - val_loss: 16.3874\n",
      "Epoch 899/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9285 - val_loss: 15.3696\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5300 - val_loss: 9.3012\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1938 - val_loss: 11.8736\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8077 - val_loss: 9.5524\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8757 - val_loss: 9.2441\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3147 - val_loss: 10.5925\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6648 - val_loss: 11.6987\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7497 - val_loss: 10.2506\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.3784 - val_loss: 10.1400\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1676 - val_loss: 9.8515\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1460 - val_loss: 9.2785\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1884 - val_loss: 9.6683\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4540 - val_loss: 13.1683\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2986 - val_loss: 9.6901\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5300 - val_loss: 9.7503\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9216 - val_loss: 9.3496\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9872 - val_loss: 10.3231\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2511 - val_loss: 9.4729\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0375 - val_loss: 9.4447\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5493 - val_loss: 12.3713\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0436 - val_loss: 9.9077\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1419 - val_loss: 9.9663\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1547 - val_loss: 9.7071\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0915 - val_loss: 10.3258\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2898 - val_loss: 9.7348\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9052 - val_loss: 10.6974\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0869 - val_loss: 10.1106\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5774 - val_loss: 11.6583\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9080 - val_loss: 9.4042\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8616 - val_loss: 10.5175\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9876 - val_loss: 9.6562\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1250 - val_loss: 9.6380\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5361 - val_loss: 14.8270\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.0101 - val_loss: 9.3899\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8670 - val_loss: 10.9767\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2152 - val_loss: 10.7882\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2602 - val_loss: 9.8106\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1995 - val_loss: 10.8873\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2015 - val_loss: 9.4710\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0174 - val_loss: 11.1211\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8457 - val_loss: 13.5154\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3702 - val_loss: 9.5095\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8328 - val_loss: 13.6485\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8478 - val_loss: 9.4995\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.388 - 0s 80us/step - loss: 9.1357 - val_loss: 11.7944\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3273 - val_loss: 10.5605\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2699 - val_loss: 10.3573\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3013 - val_loss: 9.3188\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8256 - val_loss: 9.6522\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1624 - val_loss: 15.1739\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1374 - val_loss: 9.7383\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8662 - val_loss: 9.5816\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1219 - val_loss: 11.1769\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1241 - val_loss: 9.7746\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.9133 - val_loss: 14.7845\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5691 - val_loss: 11.8321\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0691 - val_loss: 15.3805\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1824 - val_loss: 10.5673\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3109 - val_loss: 10.9521\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2706 - val_loss: 9.3384\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2810 - val_loss: 10.4835\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0234 - val_loss: 9.3917\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0123 - val_loss: 9.1987\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1883 - val_loss: 14.6120\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 8.9657 - val_loss: 10.2257\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5548 - val_loss: 9.8584\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3537 - val_loss: 11.2901\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9577 - val_loss: 13.9408\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5038 - val_loss: 9.9548\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3396 - val_loss: 10.0049\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.6231 - val_loss: 10.7210\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6620 - val_loss: 10.2398\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1353 - val_loss: 10.5915\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9114 - val_loss: 10.0865\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0591 - val_loss: 10.5483\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9005 - val_loss: 13.1751\n",
      "Epoch 975/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1630 - val_loss: 13.5370\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8264 - val_loss: 9.8346\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3834 - val_loss: 9.8731\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8812 - val_loss: 11.5120\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2158 - val_loss: 11.0674\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9255 - val_loss: 10.5970\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1957 - val_loss: 12.3923\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3446 - val_loss: 10.5341\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1901 - val_loss: 10.2208\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1640 - val_loss: 9.3724\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4958 - val_loss: 9.3252\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7154 - val_loss: 11.8509\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3232 - val_loss: 9.4843\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0002 - val_loss: 9.6071\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1500 - val_loss: 10.1700\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2603 - val_loss: 9.3650\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1405 - val_loss: 13.1140\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9570 - val_loss: 9.6305\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1128 - val_loss: 9.6259\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0967 - val_loss: 9.9120\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8385 - val_loss: 12.5920\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5563 - val_loss: 14.6276\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9900 - val_loss: 9.2991\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4785 - val_loss: 9.9260\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7303 - val_loss: 9.9037\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0381 - val_loss: 12.9081\n",
      "9.799620223256339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.040715  ,  1.9107448 , -0.50606513,  0.23552966,  4.00791   ],\n",
       "        [ 0.0605912 , -0.42037275, -0.95976573,  0.25010136, -0.22545198],\n",
       "        [-0.03241482, -0.3982603 , -1.2158897 ,  0.3858007 ,  0.7284332 ],\n",
       "        [ 0.06817721, -0.04882022,  0.21853457, -0.17706281, -0.15395164],\n",
       "        [-2.4575658 ,  0.26456547,  0.00555125,  0.22875123,  0.39058363]],\n",
       "       dtype=float32),\n",
       " array([-4.5629473,  1.2408018, -0.643358 , -1.8417199,  4.92513  ],\n",
       "       dtype=float32),\n",
       " array([[-0.8038125 , -1.6059295 ,  1.727186  , -2.1359577 , -1.252713  ,\n",
       "          0.88312626, -2.0819345 ,  1.682701  ,  1.7572473 , -1.9208413 ],\n",
       "        [-1.128511  , -0.18315767,  0.11853484, -0.8263691 ,  0.14108095,\n",
       "          0.6052395 , -0.6848179 ,  0.93781143,  1.0299915 , -0.12960964],\n",
       "        [ 0.9671655 ,  0.62195504, -0.46195695,  0.5778812 ,  0.7990196 ,\n",
       "          0.09482208, -0.15707502, -0.2578131 , -0.53039825,  0.35888937],\n",
       "        [-0.8796793 , -2.0494566 ,  1.3003944 , -1.408047  , -1.8007536 ,\n",
       "          1.8571298 , -1.0469927 ,  1.9892737 ,  1.9464415 , -1.2768618 ],\n",
       "        [ 1.6640763 ,  2.3410115 , -1.1922314 ,  1.2982446 ,  2.227757  ,\n",
       "         -2.2286136 ,  1.8991611 , -1.8597252 , -2.2210283 ,  1.8074648 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.8561763,  2.0774853, -2.0045648,  2.0264144,  2.0425987,\n",
       "        -1.9292771,  2.0592148, -2.0884008, -2.018756 ,  2.0145082],\n",
       "       dtype=float32),\n",
       " array([[ 1.2785925],\n",
       "        [ 2.1676295],\n",
       "        [-1.7983633],\n",
       "        [ 1.893914 ],\n",
       "        [ 1.9857693],\n",
       "        [-1.4778928],\n",
       "        [ 2.0701516],\n",
       "        [-2.2066073],\n",
       "        [-1.9170063],\n",
       "        [ 1.8325909]], dtype=float32),\n",
       " array([2.599905], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, RMSprop, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_rmsprop_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 611us/step - loss: 489.4934 - val_loss: 265.9840\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 184.5561 - val_loss: 72.9809\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 73.7055 - val_loss: 34.6586\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 29.7164 - val_loss: 21.9354\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 22.1657 - val_loss: 24.0587\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 20.8951 - val_loss: 19.8322\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 19.1510 - val_loss: 18.1865\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.6815 - val_loss: 17.4036\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 17.8381 - val_loss: 16.4024\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.0180 - val_loss: 15.1919\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 16.2478 - val_loss: 14.4083\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.2735 - val_loss: 13.2250\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 14.5692 - val_loss: 12.4440\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.0504 - val_loss: 11.7372\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.2917 - val_loss: 11.7034\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4149 - val_loss: 11.2690\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 12.0425 - val_loss: 11.1489\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.6980 - val_loss: 10.9035\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.2746 - val_loss: 10.7309\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.8192 - val_loss: 10.7119\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.6882 - val_loss: 10.4930\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 10.2348 - val_loss: 10.4724\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 9.7899 - val_loss: 10.3863\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.5466 - val_loss: 10.0912\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 9.1593 - val_loss: 10.4329\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.9785 - val_loss: 10.3021\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.1004 - val_loss: 10.2327\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.6224 - val_loss: 10.2320\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.0354 - val_loss: 10.2762\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.7381 - val_loss: 10.0663\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.5711 - val_loss: 10.0417\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6687 - val_loss: 10.0380\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6586 - val_loss: 9.8472\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4994 - val_loss: 9.9066\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2956 - val_loss: 9.9969\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4997 - val_loss: 9.9156\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5014 - val_loss: 9.7974\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4868 - val_loss: 9.6369\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3731 - val_loss: 9.7888\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3866 - val_loss: 9.6844\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2614 - val_loss: 9.8082\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2573 - val_loss: 9.6193\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2085 - val_loss: 9.4975\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 8.0267 - val_loss: 9.2437\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.2972 - val_loss: 9.3103\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2126 - val_loss: 9.0860\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2589 - val_loss: 9.2563\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1206 - val_loss: 9.2050\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1384 - val_loss: 8.8869\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2794 - val_loss: 8.9915\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3325 - val_loss: 9.1412\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6462 - val_loss: 9.0420\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9528 - val_loss: 9.0640\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8240 - val_loss: 8.8667\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7185 - val_loss: 8.4855\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5470 - val_loss: 8.6651\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5755 - val_loss: 8.4310\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8291 - val_loss: 8.4430\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6465 - val_loss: 8.5966\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5603 - val_loss: 8.2474\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 7.3643 - val_loss: 8.3143\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.3832 - val_loss: 8.3239\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2430 - val_loss: 8.2937\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1605 - val_loss: 8.3712\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1275 - val_loss: 8.3015\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3474 - val_loss: 8.6120\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0640 - val_loss: 8.6421\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9979 - val_loss: 8.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9700 - val_loss: 8.4870\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9200 - val_loss: 8.4859\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8057 - val_loss: 8.6894\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9418 - val_loss: 8.6097\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8893 - val_loss: 8.9353\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8368 - val_loss: 8.6759\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8823 - val_loss: 8.6250\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8130 - val_loss: 8.6621\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7602 - val_loss: 8.7106\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8128 - val_loss: 8.5377\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6311 - val_loss: 8.7994\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5852 - val_loss: 8.6578\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6186 - val_loss: 8.5164\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5740 - val_loss: 8.4292\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4813 - val_loss: 8.4053\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4589 - val_loss: 8.4529\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6163 - val_loss: 8.4654\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4811 - val_loss: 8.6214\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6471 - val_loss: 8.4775\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4914 - val_loss: 8.2905\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3699 - val_loss: 8.5748\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5141 - val_loss: 8.6822\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5305 - val_loss: 8.4386\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4956 - val_loss: 8.6506\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7619 - val_loss: 8.4773\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5273 - val_loss: 8.2822\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4386 - val_loss: 8.3238\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4865 - val_loss: 8.7779\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3483 - val_loss: 8.2323\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.3963 - val_loss: 8.4737\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6383 - val_loss: 8.8915\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5333 - val_loss: 8.3118\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7051 - val_loss: 8.2656\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3296 - val_loss: 8.5460\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2340 - val_loss: 8.6722\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4815 - val_loss: 8.4376\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3323 - val_loss: 8.7602\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4568 - val_loss: 8.4299\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2887 - val_loss: 8.7224\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2348 - val_loss: 8.4938\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3315 - val_loss: 8.5430\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3495 - val_loss: 8.7184\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3177 - val_loss: 8.6254\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2289 - val_loss: 8.5500\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1317 - val_loss: 8.6440\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2536 - val_loss: 8.6629\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3961 - val_loss: 8.5667\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2462 - val_loss: 8.2552\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2490 - val_loss: 8.3111\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2671 - val_loss: 9.1085\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3908 - val_loss: 8.6818\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1380 - val_loss: 8.6242\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2261 - val_loss: 8.4011\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.1719 - val_loss: 8.3763\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3231 - val_loss: 8.7914\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2369 - val_loss: 8.4644\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1939 - val_loss: 8.6278\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2305 - val_loss: 8.9037\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0211 - val_loss: 8.6029\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3607 - val_loss: 8.5847\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2136 - val_loss: 8.4436\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1302 - val_loss: 8.5231\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0007 - val_loss: 8.9140\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0970 - val_loss: 8.7066\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0178 - val_loss: 8.4675\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.0608 - val_loss: 8.7915\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1538 - val_loss: 8.7334\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3103 - val_loss: 9.0298\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3445 - val_loss: 8.7117\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0431 - val_loss: 9.1761\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1681 - val_loss: 9.4379\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3056 - val_loss: 8.7944\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1296 - val_loss: 8.6958\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1386 - val_loss: 8.5160\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0368 - val_loss: 8.5587\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2490 - val_loss: 9.1855\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2312 - val_loss: 9.3719\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5254 - val_loss: 8.4996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9199 - val_loss: 8.7661\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9834 - val_loss: 8.7115\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0614 - val_loss: 9.1092\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1990 - val_loss: 9.2231\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0241 - val_loss: 8.7052\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0688 - val_loss: 8.8461\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9908 - val_loss: 8.8117\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9331 - val_loss: 8.9184\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0228 - val_loss: 8.6467\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9186 - val_loss: 8.9963\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1118 - val_loss: 8.6965\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9544 - val_loss: 8.8518\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9285 - val_loss: 8.6148\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.0837 - val_loss: 9.0249\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1703 - val_loss: 9.0941\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1353 - val_loss: 9.1959\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1308 - val_loss: 8.5889\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7686 - val_loss: 9.4031\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1363 - val_loss: 9.2901\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2694 - val_loss: 9.4860\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0056 - val_loss: 9.0338\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2248 - val_loss: 9.2879\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0496 - val_loss: 8.6403\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0966 - val_loss: 8.6659\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8753 - val_loss: 8.6643\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0320 - val_loss: 8.5024\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1498 - val_loss: 8.7941\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9700 - val_loss: 8.7402\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2495 - val_loss: 8.6681\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8396 - val_loss: 9.3937\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2847 - val_loss: 8.5773\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0607 - val_loss: 9.0640\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0914 - val_loss: 8.5798\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2717 - val_loss: 9.0280\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0694 - val_loss: 8.6067\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0650 - val_loss: 8.8552\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8476 - val_loss: 8.5241\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9046 - val_loss: 8.8502\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8898 - val_loss: 9.2660\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9256 - val_loss: 8.2724\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9030 - val_loss: 8.8402\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8360 - val_loss: 8.9026\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1007 - val_loss: 8.7820\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8047 - val_loss: 8.5229\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4542 - val_loss: 8.8652\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9376 - val_loss: 8.8436\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0555 - val_loss: 8.8021\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9703 - val_loss: 8.8244\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8547 - val_loss: 8.5955\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8399 - val_loss: 8.9334\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9406 - val_loss: 8.8814\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4481 - val_loss: 9.2156\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1605 - val_loss: 9.0802\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1045 - val_loss: 9.1018\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0812 - val_loss: 9.1666\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8725 - val_loss: 8.8208\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9480 - val_loss: 9.0537\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9791 - val_loss: 8.9654\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8044 - val_loss: 8.7272\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7653 - val_loss: 8.7632\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8879 - val_loss: 9.0885\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8213 - val_loss: 8.9858\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8972 - val_loss: 9.2019\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2230 - val_loss: 9.2599\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3819 - val_loss: 9.0934\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9389 - val_loss: 9.2232\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9296 - val_loss: 9.0069\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9516 - val_loss: 8.6258\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7914 - val_loss: 8.5927\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8753 - val_loss: 8.9264\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1552 - val_loss: 8.8850\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9649 - val_loss: 8.7633\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9770 - val_loss: 8.7331\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7337 - val_loss: 8.5974\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6796 - val_loss: 8.7558\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7563 - val_loss: 8.5264\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6730 - val_loss: 8.8145\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.6988 - val_loss: 8.9727\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6714 - val_loss: 8.9155\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8483 - val_loss: 8.9942\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6484 - val_loss: 8.5680\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4001 - val_loss: 9.3968\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.0417 - val_loss: 8.6552\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7188 - val_loss: 8.7940\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9138 - val_loss: 8.8228\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7907 - val_loss: 8.7065\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9453 - val_loss: 8.7685\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8055 - val_loss: 8.4501\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0366 - val_loss: 8.8702\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9646 - val_loss: 8.8319\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8185 - val_loss: 8.7128\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8177 - val_loss: 8.3711\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8118 - val_loss: 8.8066\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7562 - val_loss: 8.4631\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8956 - val_loss: 8.7344\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7017 - val_loss: 8.7422\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9168 - val_loss: 9.1985\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9202 - val_loss: 8.6469\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9843 - val_loss: 9.1762\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9412 - val_loss: 8.8780\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7117 - val_loss: 8.8268\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6545 - val_loss: 8.3521\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7173 - val_loss: 8.5776\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6751 - val_loss: 8.5504\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6904 - val_loss: 8.8724\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6785 - val_loss: 8.6518\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7106 - val_loss: 8.7720\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6686 - val_loss: 8.4509\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8840 - val_loss: 8.8370\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7986 - val_loss: 8.9098\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8649 - val_loss: 8.9056\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8171 - val_loss: 9.1217\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8124 - val_loss: 8.5874\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8010 - val_loss: 8.7219\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4576 - val_loss: 8.7333\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6772 - val_loss: 9.5810\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9477 - val_loss: 8.6075\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9839 - val_loss: 9.1656\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7613 - val_loss: 8.5792\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7281 - val_loss: 8.7809\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7183 - val_loss: 8.3778\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7908 - val_loss: 8.6742\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6840 - val_loss: 8.7179\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6285 - val_loss: 8.7923\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7222 - val_loss: 8.5100\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7773 - val_loss: 8.6893\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6325 - val_loss: 8.4489\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8409 - val_loss: 8.6133\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7338 - val_loss: 9.0849\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6289 - val_loss: 8.7271\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6868 - val_loss: 8.3768\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6486 - val_loss: 8.7272\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6555 - val_loss: 8.5414\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6118 - val_loss: 8.6572\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6440 - val_loss: 8.7931\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9721 - val_loss: 9.3535\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8332 - val_loss: 8.7356\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7155 - val_loss: 8.7330\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5219 - val_loss: 8.7381\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7745 - val_loss: 8.5685\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8631 - val_loss: 9.0468\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9113 - val_loss: 8.2580\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2328 - val_loss: 9.1343\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9451 - val_loss: 8.5503\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9883 - val_loss: 8.6593\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8711 - val_loss: 8.4937\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2480 - val_loss: 8.9337\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9063 - val_loss: 8.4222\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7514 - val_loss: 8.6261\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9614 - val_loss: 8.6381\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9471 - val_loss: 8.6034\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7180 - val_loss: 9.1239\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9274 - val_loss: 8.9264\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6296 - val_loss: 8.6098\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5465 - val_loss: 8.5843\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5661 - val_loss: 8.7717\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6371 - val_loss: 8.6593\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6057 - val_loss: 8.5379\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6924 - val_loss: 8.8739\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8109 - val_loss: 8.8020\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6286 - val_loss: 8.5572\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9409 - val_loss: 8.7118\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8959 - val_loss: 8.9334\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7675 - val_loss: 8.6010\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8915 - val_loss: 9.0092\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7554 - val_loss: 8.7270\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6009 - val_loss: 8.6302\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5773 - val_loss: 8.2444\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5804 - val_loss: 8.6271\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5566 - val_loss: 8.4182\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7553 - val_loss: 8.4535\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6442 - val_loss: 8.4808\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5750 - val_loss: 8.7956\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6135 - val_loss: 8.8937\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5660 - val_loss: 8.5878\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7763 - val_loss: 8.9100\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6634 - val_loss: 8.6024\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5902 - val_loss: 8.5222\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5409 - val_loss: 8.3275\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6299 - val_loss: 8.7737\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8141 - val_loss: 8.5076\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7680 - val_loss: 8.8822\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6816 - val_loss: 8.6695\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6785 - val_loss: 8.6215\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6109 - val_loss: 8.5743\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6116 - val_loss: 8.6343\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5858 - val_loss: 8.6718\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6584 - val_loss: 8.6671\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6241 - val_loss: 8.6181\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5984 - val_loss: 8.6845\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9408 - val_loss: 8.6702\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2597 - val_loss: 8.6869\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1051 - val_loss: 9.1974\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.1462 - val_loss: 8.7373\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9416 - val_loss: 8.9660\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6340 - val_loss: 8.6766\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6201 - val_loss: 8.7616\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6012 - val_loss: 8.6087\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5483 - val_loss: 8.7210\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5668 - val_loss: 8.7126\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6402 - val_loss: 8.7804\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7276 - val_loss: 8.4634\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7478 - val_loss: 8.7951\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5276 - val_loss: 8.8805\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5387 - val_loss: 8.9573\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6277 - val_loss: 8.5542\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8214 - val_loss: 9.0466\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6059 - val_loss: 8.5515\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4922 - val_loss: 8.9638\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6755 - val_loss: 8.5383\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5377 - val_loss: 8.4109\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5593 - val_loss: 8.5352\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5144 - val_loss: 8.3448\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5347 - val_loss: 8.4900\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4802 - val_loss: 8.4100\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5485 - val_loss: 8.3120\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5419 - val_loss: 8.6461\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5618 - val_loss: 8.6060\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6025 - val_loss: 8.6541\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5471 - val_loss: 8.5966\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8960 - val_loss: 8.7799\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9396 - val_loss: 8.2973\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7864 - val_loss: 8.9520\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5117 - val_loss: 8.5091\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5465 - val_loss: 9.0575\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5894 - val_loss: 8.5338\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4786 - val_loss: 8.4836\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5286 - val_loss: 8.4314\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6161 - val_loss: 8.8241\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9507 - val_loss: 8.6771\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9098 - val_loss: 9.3102\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.6015 - val_loss: 8.5415\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5920 - val_loss: 8.8403\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5332 - val_loss: 8.5025\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5873 - val_loss: 8.5709\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5436 - val_loss: 8.5399\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5465 - val_loss: 8.3909\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5117 - val_loss: 8.7676\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1268 - val_loss: 9.3704\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2525 - val_loss: 8.4153\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8582 - val_loss: 8.8882\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5195 - val_loss: 8.3617\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6899 - val_loss: 8.8743\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4974 - val_loss: 8.5727\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6350 - val_loss: 8.6893\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5853 - val_loss: 8.4212\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6106 - val_loss: 8.8173\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5603 - val_loss: 8.3941\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4813 - val_loss: 8.6467\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7202 - val_loss: 8.7448\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5465 - val_loss: 8.7200\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5764 - val_loss: 8.4042\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6211 - val_loss: 8.7709\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5457 - val_loss: 8.5666\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4748 - val_loss: 8.7488\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5222 - val_loss: 8.5201\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5127 - val_loss: 8.4529\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5405 - val_loss: 8.4779\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7746 - val_loss: 8.5196\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7754 - val_loss: 8.7229\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4615 - val_loss: 8.4974\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5175 - val_loss: 8.5081\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6070 - val_loss: 8.4412\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5893 - val_loss: 8.7770\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0113 - val_loss: 8.8272\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6303 - val_loss: 8.4994\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4813 - val_loss: 8.7055\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6867 - val_loss: 8.4994\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8081 - val_loss: 8.6765\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6116 - val_loss: 8.0670\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1361 - val_loss: 9.2122\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0541 - val_loss: 8.1945\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8595 - val_loss: 8.7081\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6971 - val_loss: 8.6979\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8059 - val_loss: 8.4036\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6573 - val_loss: 8.5214\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6905 - val_loss: 8.4120\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5477 - val_loss: 8.6757\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8336 - val_loss: 8.8619\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0634 - val_loss: 8.5245\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5897 - val_loss: 8.5642\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5305 - val_loss: 8.6951\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5329 - val_loss: 8.4503\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4686 - val_loss: 8.7084\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5761 - val_loss: 8.8148\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6838 - val_loss: 8.5962\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5629 - val_loss: 8.8570\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6669 - val_loss: 8.4327\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7330 - val_loss: 8.3116\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8189 - val_loss: 9.0016\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7636 - val_loss: 8.2551\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4840 - val_loss: 8.4068\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7734 - val_loss: 8.4502\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5759 - val_loss: 8.7544\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5403 - val_loss: 8.3275\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5747 - val_loss: 8.4940\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5972 - val_loss: 8.5487\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5094 - val_loss: 8.5951\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5399 - val_loss: 8.4799\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5751 - val_loss: 8.7279\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.5467 - val_loss: 8.5077\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4876 - val_loss: 8.5921\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7261 - val_loss: 8.4413\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8892 - val_loss: 8.6134\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5110 - val_loss: 8.6981\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5191 - val_loss: 8.5433\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5088 - val_loss: 8.5662\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5271 - val_loss: 8.5173\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.4916 - val_loss: 8.4478\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8668 - val_loss: 8.5761\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1191 - val_loss: 9.4065\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9030 - val_loss: 8.5103\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6501 - val_loss: 8.7743\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6159 - val_loss: 8.7413\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4475 - val_loss: 8.5525\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4890 - val_loss: 8.5877\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7433 - val_loss: 8.4634\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2123 - val_loss: 8.7406\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9389 - val_loss: 8.4422\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3383 - val_loss: 9.2579\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1506 - val_loss: 8.5418\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0272 - val_loss: 8.8775\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0876 - val_loss: 8.4421\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6141 - val_loss: 8.6760\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5122 - val_loss: 8.5153\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4553 - val_loss: 8.2874\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4604 - val_loss: 8.5111\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4058 - val_loss: 8.2860\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4314 - val_loss: 8.6618\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5755 - val_loss: 8.6944\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4480 - val_loss: 8.4415\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5502 - val_loss: 8.5201\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6826 - val_loss: 8.8820\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7219 - val_loss: 8.4421\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4740 - val_loss: 8.6762\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6000 - val_loss: 8.5910\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7129 - val_loss: 8.3630\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6575 - val_loss: 8.6818\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8049 - val_loss: 8.4748\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5186 - val_loss: 8.3521\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5682 - val_loss: 8.8573\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5673 - val_loss: 8.5134\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6528 - val_loss: 8.5723\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5218 - val_loss: 8.7682\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5364 - val_loss: 8.7120\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4529 - val_loss: 8.5969\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4454 - val_loss: 8.7154\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4963 - val_loss: 8.6234\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4667 - val_loss: 8.4691\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4869 - val_loss: 8.5727\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5336 - val_loss: 8.7298\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5095 - val_loss: 8.6063\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5236 - val_loss: 8.6608\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5174 - val_loss: 8.5455\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4692 - val_loss: 8.3874\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5079 - val_loss: 8.4311\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4796 - val_loss: 8.4683\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4656 - val_loss: 9.0397\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7025 - val_loss: 8.5240\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6446 - val_loss: 8.8396\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7480 - val_loss: 8.4596\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5530 - val_loss: 8.9619\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5609 - val_loss: 8.6158\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7025 - val_loss: 9.1614\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7158 - val_loss: 8.6579\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4987 - val_loss: 8.7885\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4062 - val_loss: 8.3876\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5380 - val_loss: 8.4398\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5169 - val_loss: 8.5555\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5184 - val_loss: 8.5573\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5158 - val_loss: 8.7838\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6924 - val_loss: 8.4933\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6317 - val_loss: 8.8722\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6375 - val_loss: 8.3076\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.8313 - val_loss: 8.5470\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8971 - val_loss: 8.8163\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4515 - val_loss: 8.3501\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5690 - val_loss: 8.5034\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1557 - val_loss: 8.7672\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1328 - val_loss: 8.2177\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0276 - val_loss: 8.9578\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.6108 - val_loss: 8.7910\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4849 - val_loss: 8.5192\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4151 - val_loss: 8.6168\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5532 - val_loss: 8.2240\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.5558 - val_loss: 8.7262\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5431 - val_loss: 8.3625\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3674 - val_loss: 8.8181\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4313 - val_loss: 8.2802\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5354 - val_loss: 8.5499\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 5.5817 - val_loss: 8.4318\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.4292 - val_loss: 8.4428\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5658 - val_loss: 8.5635\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5567 - val_loss: 8.1903\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4809 - val_loss: 8.5260\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4158 - val_loss: 8.4550\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5381 - val_loss: 8.5501\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4280 - val_loss: 8.6871\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4234 - val_loss: 8.5182\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4342 - val_loss: 8.4463\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4436 - val_loss: 8.2174\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4804 - val_loss: 8.4546\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 5.4962 - val_loss: 8.4711\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4239 - val_loss: 8.4106\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5356 - val_loss: 8.3519\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5875 - val_loss: 8.1671\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7303 - val_loss: 8.6419\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6590 - val_loss: 8.3542\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4599 - val_loss: 8.8823\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5357 - val_loss: 8.3516\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6116 - val_loss: 8.4524\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6629 - val_loss: 8.8050\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5914 - val_loss: 8.3795\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5205 - val_loss: 8.6958\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5704 - val_loss: 8.1874\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5476 - val_loss: 8.3398\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8454 - val_loss: 8.6670\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5975 - val_loss: 8.3768\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6372 - val_loss: 8.6744\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5007 - val_loss: 8.1348\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6633 - val_loss: 8.6318\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4017 - val_loss: 8.0927\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5743 - val_loss: 8.3354\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3533 - val_loss: 8.2063\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4193 - val_loss: 8.5366\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5180 - val_loss: 8.6551\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5525 - val_loss: 8.5658\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7781 - val_loss: 8.2535\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9625 - val_loss: 8.9071\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8794 - val_loss: 8.5376\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8920 - val_loss: 9.2353\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6148 - val_loss: 8.2492\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6140 - val_loss: 8.8225\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6257 - val_loss: 8.2318\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6624 - val_loss: 8.6352\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8359 - val_loss: 8.4776\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4292 - val_loss: 8.9172\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6350 - val_loss: 8.6715\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5749 - val_loss: 8.5072\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5210 - val_loss: 8.6626\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4562 - val_loss: 8.3957\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5435 - val_loss: 8.7408\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6128 - val_loss: 8.4906\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6016 - val_loss: 8.8318\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4572 - val_loss: 8.2446\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5922 - val_loss: 8.2606\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4549 - val_loss: 8.6208\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7399 - val_loss: 8.5057\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7453 - val_loss: 8.7103\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5285 - val_loss: 8.5756\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5305 - val_loss: 8.2470\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3894 - val_loss: 8.7496\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4008 - val_loss: 8.7630\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4570 - val_loss: 8.5532\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5750 - val_loss: 8.7278\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4031 - val_loss: 8.2929\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4579 - val_loss: 8.6038\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4439 - val_loss: 8.4990\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4714 - val_loss: 8.6066\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4131 - val_loss: 8.3382\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4280 - val_loss: 8.5258\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4767 - val_loss: 8.2762\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.3363 - val_loss: 8.6642\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4909 - val_loss: 8.5976\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4777 - val_loss: 8.4625\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5099 - val_loss: 8.5120\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5348 - val_loss: 8.2083\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5384 - val_loss: 8.4067\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6623 - val_loss: 8.6962\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7191 - val_loss: 8.4581\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6357 - val_loss: 8.4865\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6888 - val_loss: 8.7318\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5874 - val_loss: 8.4841\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7910 - val_loss: 9.0425\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5339 - val_loss: 8.3884\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6291 - val_loss: 8.5547\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6227 - val_loss: 8.6083\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5770 - val_loss: 8.4475\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3788 - val_loss: 8.6434\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5395 - val_loss: 8.6816\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5778 - val_loss: 8.4819\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5643 - val_loss: 8.5323\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5444 - val_loss: 8.6420\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5304 - val_loss: 8.4260\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4220 - val_loss: 8.3850\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5606 - val_loss: 8.3218\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3293 - val_loss: 8.3746\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4734 - val_loss: 8.7972\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4825 - val_loss: 8.3320\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3909 - val_loss: 8.3974\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5377 - val_loss: 8.1880\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4448 - val_loss: 8.4338\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4663 - val_loss: 8.6947\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4611 - val_loss: 8.7098\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8037 - val_loss: 8.2265\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0102 - val_loss: 8.8122\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6659 - val_loss: 8.1754\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7382 - val_loss: 8.6585\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6419 - val_loss: 8.4315\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7302 - val_loss: 9.2958\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.8117 - val_loss: 8.3930\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4548 - val_loss: 8.7366\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4521 - val_loss: 8.2451\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3940 - val_loss: 8.4377\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3702 - val_loss: 8.3436\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3516 - val_loss: 8.6202\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4780 - val_loss: 8.3191\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5546 - val_loss: 8.8087\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7276 - val_loss: 8.3692\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3815 - val_loss: 8.5100\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4195 - val_loss: 8.2150\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5490 - val_loss: 8.5348\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3641 - val_loss: 8.5406\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4540 - val_loss: 8.6967\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3736 - val_loss: 8.3249\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3371 - val_loss: 8.5111\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3540 - val_loss: 8.4688\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4499 - val_loss: 8.4745\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4129 - val_loss: 8.5033\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5006 - val_loss: 8.5401\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6022 - val_loss: 8.5054\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4995 - val_loss: 8.8562\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5022 - val_loss: 8.3449\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5040 - val_loss: 8.8941\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5351 - val_loss: 8.3527\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5290 - val_loss: 8.6594\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5495 - val_loss: 8.7200\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4095 - val_loss: 8.0767\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5357 - val_loss: 8.5106\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4083 - val_loss: 8.4925\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4276 - val_loss: 8.6419\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3660 - val_loss: 8.4878\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5896 - val_loss: 8.4407\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4379 - val_loss: 8.4070\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6600 - val_loss: 8.4888\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2864 - val_loss: 8.7056\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6555 - val_loss: 8.4613\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5042 - val_loss: 8.7863\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4686 - val_loss: 8.5626\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.3996 - val_loss: 8.5612\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5426 - val_loss: 8.5685\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3777 - val_loss: 8.4854\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3495 - val_loss: 8.6605\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4161 - val_loss: 8.5143\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.5621 - val_loss: 8.6179\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3274 - val_loss: 8.3533\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4440 - val_loss: 8.5801\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4134 - val_loss: 8.2653\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3921 - val_loss: 8.5747\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3988 - val_loss: 8.3123\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4215 - val_loss: 8.7764\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3967 - val_loss: 8.5295\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4116 - val_loss: 8.3308\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3812 - val_loss: 8.4453\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4706 - val_loss: 8.3570\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5631 - val_loss: 8.4126\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3523 - val_loss: 8.8273\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3664 - val_loss: 8.3943\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3292 - val_loss: 8.6529\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6266 - val_loss: 8.2013\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4262 - val_loss: 8.5978\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4048 - val_loss: 8.4583\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3792 - val_loss: 8.2197\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4170 - val_loss: 8.3922\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4342 - val_loss: 8.3659\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4165 - val_loss: 8.5901\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3687 - val_loss: 8.2929\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3669 - val_loss: 8.5674\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3728 - val_loss: 8.2362\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4134 - val_loss: 8.4405\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4504 - val_loss: 8.5505\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4976 - val_loss: 8.3701\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4875 - val_loss: 8.4837\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4539 - val_loss: 8.4612\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3459 - val_loss: 8.5590\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4050 - val_loss: 8.1363\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4088 - val_loss: 8.4713\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3980 - val_loss: 8.3501\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4060 - val_loss: 8.4690\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4912 - val_loss: 8.5921\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5333 - val_loss: 8.4764\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6288 - val_loss: 8.7238\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9301 - val_loss: 8.3195\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6177 - val_loss: 9.0402\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4781 - val_loss: 8.4880\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4180 - val_loss: 8.7242\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4790 - val_loss: 8.6585\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4317 - val_loss: 8.4212\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3749 - val_loss: 8.3268\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3409 - val_loss: 8.5178\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4361 - val_loss: 8.4615\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7391 - val_loss: 8.6465\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7403 - val_loss: 8.7994\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9508 - val_loss: 8.5668\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2325 - val_loss: 9.4334\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9545 - val_loss: 8.4599\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.5293 - val_loss: 8.6196\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4550 - val_loss: 8.4146\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3725 - val_loss: 8.9232\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6904 - val_loss: 8.5944\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4255 - val_loss: 8.4775\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5941 - val_loss: 8.5142\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4575 - val_loss: 8.3957\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5072 - val_loss: 8.3054\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3924 - val_loss: 8.4785\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4926 - val_loss: 8.3156\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5139 - val_loss: 8.1450\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3482 - val_loss: 8.5065\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7433 - val_loss: 8.8154\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6835 - val_loss: 8.3462\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6817 - val_loss: 8.9515\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5733 - val_loss: 8.4236\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6521 - val_loss: 8.6820\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3194 - val_loss: 8.0574\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4239 - val_loss: 8.2659\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5738 - val_loss: 8.5173\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5304 - val_loss: 8.5584\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4648 - val_loss: 8.7154\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6310 - val_loss: 8.8627\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9228 - val_loss: 8.3333\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6184 - val_loss: 8.7071\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3535 - val_loss: 8.4159\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5032 - val_loss: 8.5942\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3999 - val_loss: 8.3709\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4646 - val_loss: 8.3579\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3545 - val_loss: 8.5668\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3830 - val_loss: 8.4452\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4472 - val_loss: 8.5802\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4219 - val_loss: 8.2155\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3712 - val_loss: 8.3910\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5524 - val_loss: 8.2254\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4617 - val_loss: 8.4823\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5192 - val_loss: 8.4140\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4610 - val_loss: 8.9067\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5129 - val_loss: 8.3367\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3586 - val_loss: 8.4844\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3474 - val_loss: 8.4461\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5014 - val_loss: 8.4993\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6321 - val_loss: 8.4201\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6252 - val_loss: 8.7072\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0039 - val_loss: 8.1843\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4667 - val_loss: 8.6992\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4207 - val_loss: 8.3547\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4920 - val_loss: 8.5765\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3701 - val_loss: 8.4534\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4117 - val_loss: 8.7905\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3019 - val_loss: 8.2264\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4443 - val_loss: 8.5298\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4872 - val_loss: 8.5663\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3588 - val_loss: 8.5192\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3768 - val_loss: 8.2825\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3638 - val_loss: 8.2597\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3317 - val_loss: 8.1528\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3980 - val_loss: 8.6762\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4666 - val_loss: 8.5534\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4301 - val_loss: 8.3639\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7469 - val_loss: 8.4078\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0519 - val_loss: 8.6969\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4619 - val_loss: 8.4732\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7311 - val_loss: 9.2617\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8439 - val_loss: 8.1479\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0837 - val_loss: 8.8867\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0628 - val_loss: 8.4200\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7666 - val_loss: 9.0437\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6687 - val_loss: 8.3540\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5607 - val_loss: 8.9979\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5968 - val_loss: 8.2824\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4011 - val_loss: 8.4159\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4277 - val_loss: 8.6066\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6351 - val_loss: 8.5655\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3259 - val_loss: 8.3704\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4403 - val_loss: 8.6436\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5938 - val_loss: 8.2681\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4340 - val_loss: 8.4902\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4356 - val_loss: 8.3157\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3800 - val_loss: 8.3279\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3568 - val_loss: 8.5551\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4285 - val_loss: 8.4570\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4268 - val_loss: 8.4168\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3418 - val_loss: 8.4237\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4565 - val_loss: 8.5253\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4486 - val_loss: 8.3397\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5799 - val_loss: 8.6604\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5526 - val_loss: 8.2616\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4932 - val_loss: 8.5700\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7235 - val_loss: 8.3658\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3962 - val_loss: 8.5345\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4563 - val_loss: 8.3100\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5109 - val_loss: 8.7336\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7028 - val_loss: 8.1642\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3768 - val_loss: 8.4710\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3482 - val_loss: 8.3992\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5866 - val_loss: 8.2217\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.4258 - val_loss: 8.4939\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3539 - val_loss: 8.0538\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4543 - val_loss: 8.6275\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4622 - val_loss: 8.3375\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7042 - val_loss: 8.3610\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6065 - val_loss: 8.6498\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5018 - val_loss: 8.4010\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4772 - val_loss: 8.0702\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4774 - val_loss: 8.5247\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4288 - val_loss: 8.3155\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5420 - val_loss: 8.4096\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5518 - val_loss: 8.6520\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5626 - val_loss: 8.6173\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3952 - val_loss: 8.3298\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4198 - val_loss: 8.2429\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5121 - val_loss: 8.4971\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4486 - val_loss: 8.3522\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3791 - val_loss: 8.7506\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4580 - val_loss: 8.1068\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3938 - val_loss: 8.4733\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9082 - val_loss: 8.2570\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9068 - val_loss: 8.6253\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6380 - val_loss: 8.3388\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3403 - val_loss: 8.8916\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7077 - val_loss: 8.5609\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4743 - val_loss: 8.3552\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3231 - val_loss: 8.3097\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4445 - val_loss: 8.6056\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3923 - val_loss: 8.3724\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3813 - val_loss: 8.1653\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3215 - val_loss: 8.7195\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4308 - val_loss: 8.4017\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6765 - val_loss: 8.5159\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4214 - val_loss: 8.5945\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3714 - val_loss: 8.3809\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3947 - val_loss: 8.3950\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3934 - val_loss: 8.5161\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3863 - val_loss: 8.2627\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.3360 - val_loss: 8.5364\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3194 - val_loss: 8.3902\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3329 - val_loss: 8.4964\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3669 - val_loss: 8.5570\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3512 - val_loss: 8.4747\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3812 - val_loss: 8.3817\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3590 - val_loss: 8.2283\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3846 - val_loss: 8.5250\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4612 - val_loss: 8.2874\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4401 - val_loss: 8.5313\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4324 - val_loss: 8.2607\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4970 - val_loss: 8.6784\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5068 - val_loss: 8.1314\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4465 - val_loss: 8.7690\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3592 - val_loss: 8.6728\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5503 - val_loss: 8.2531\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5050 - val_loss: 8.9200\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4551 - val_loss: 8.3714\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4068 - val_loss: 8.3698\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6516 - val_loss: 8.5198\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6966 - val_loss: 8.6064\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4368 - val_loss: 8.4256\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4301 - val_loss: 8.7972\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6171 - val_loss: 8.3886\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9886 - val_loss: 8.7538\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4452 - val_loss: 8.0183\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3449 - val_loss: 8.5702\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4215 - val_loss: 8.4034\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4981 - val_loss: 8.6077\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3583 - val_loss: 8.5525\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4176 - val_loss: 8.5002\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3208 - val_loss: 8.6013\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4015 - val_loss: 8.7123\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3923 - val_loss: 8.4460\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4849 - val_loss: 8.2753\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2948 - val_loss: 8.4170\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4433 - val_loss: 8.5856\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4668 - val_loss: 8.8579\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6452 - val_loss: 8.4599\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.5369 - val_loss: 8.4639\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3165 - val_loss: 8.3074\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3848 - val_loss: 8.5620\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4246 - val_loss: 8.1285\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4652 - val_loss: 8.7795\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3692 - val_loss: 8.1688\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5296 - val_loss: 8.7704\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3943 - val_loss: 8.3255\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5567 - val_loss: 8.3373\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4434 - val_loss: 8.6049\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4184 - val_loss: 8.3866\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3805 - val_loss: 8.4065\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5068 - val_loss: 8.3550\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8206 - val_loss: 8.1847\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4626 - val_loss: 8.6727\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3132 - val_loss: 8.6599\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3996 - val_loss: 8.6071\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4471 - val_loss: 8.5939\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4658 - val_loss: 8.2166\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3904 - val_loss: 8.6591\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3203 - val_loss: 8.2794\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4098 - val_loss: 8.5256\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3645 - val_loss: 8.2262\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3068 - val_loss: 8.2619\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3229 - val_loss: 8.2302\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3651 - val_loss: 8.6810\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5277 - val_loss: 8.4242\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5411 - val_loss: 8.4922\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4441 - val_loss: 8.3579\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4215 - val_loss: 8.4442\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4319 - val_loss: 8.8792\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5064 - val_loss: 8.4161\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3881 - val_loss: 8.4577\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3645 - val_loss: 8.4461\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3717 - val_loss: 8.5242\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4968 - val_loss: 8.5088\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7705 - val_loss: 8.1008\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6092 - val_loss: 8.4400\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3856 - val_loss: 8.0754\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4327 - val_loss: 8.6117\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3336 - val_loss: 8.5038\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3765 - val_loss: 8.5574\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3582 - val_loss: 8.3928\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4024 - val_loss: 8.2226\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5383 - val_loss: 8.9419\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4813 - val_loss: 8.2884\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4991 - val_loss: 8.5575\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4268 - val_loss: 8.2149\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3526 - val_loss: 8.6140\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4824 - val_loss: 8.3303\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3581 - val_loss: 8.3616\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3089 - val_loss: 8.4719\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2852 - val_loss: 8.5322\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2742 - val_loss: 8.5162\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3480 - val_loss: 8.5576\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3599 - val_loss: 8.5097\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2623 - val_loss: 8.1541\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3842 - val_loss: 8.2163\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3249 - val_loss: 8.4903\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3077 - val_loss: 8.3303\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3338 - val_loss: 8.6568\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4609 - val_loss: 8.2884\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5758 - val_loss: 8.7501\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4465 - val_loss: 8.3706\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.3200 - val_loss: 8.3059\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.3820 - val_loss: 8.4133\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4209 - val_loss: 8.8104\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5395 - val_loss: 8.4006\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3783 - val_loss: 8.5656\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4210 - val_loss: 8.3549\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3491 - val_loss: 8.5982\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4349 - val_loss: 8.2213\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2910 - val_loss: 8.7131\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3952 - val_loss: 8.2652\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4344 - val_loss: 8.4945\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6062 - val_loss: 8.4304\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3824 - val_loss: 8.4561\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 112us/step - loss: 5.5170 - val_loss: 8.7294\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3798 - val_loss: 8.1932\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5304 - val_loss: 8.5574\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0779 - val_loss: 8.3945\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6235 - val_loss: 9.0790\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4484 - val_loss: 8.2248\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4830 - val_loss: 8.5214\n",
      "7.348049567917646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.3014474e+00,  1.4394356e-01, -3.5244944e+00, -2.7126881e-01,\n",
       "          1.2644758e+00],\n",
       "        [ 6.7074114e-01,  4.1770625e+00,  1.4702228e+00, -6.0467738e-01,\n",
       "         -3.2465920e-01],\n",
       "        [-8.6659527e-01,  1.2346485e+00,  8.2131602e-02, -4.4805464e-01,\n",
       "          3.5124767e-01],\n",
       "        [-5.3141493e-01, -2.4980602e+00, -7.2767818e-01,  1.2974288e+00,\n",
       "         -7.4070722e-01],\n",
       "        [-4.9252494e-04,  1.1372557e+00,  3.6718842e-01, -3.8214630e-01,\n",
       "         -3.5903341e-01],\n",
       "        [-4.2035007e-01,  1.1405562e+00, -4.4138003e-02, -1.2157362e+00,\n",
       "          1.1794764e+00],\n",
       "        [-3.7090376e-01, -1.8450269e+00, -1.9506000e-01, -3.5734558e-01,\n",
       "          1.1783608e+00]], dtype=float32),\n",
       " array([ 0.96984047, -1.3914226 ,  0.11576169,  1.3145385 ,  2.0928488 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.6160322 ,  0.9530243 ,  0.17930102, -0.9975823 ,  1.1007676 ,\n",
       "         -0.7456692 , -0.3304568 ,  0.19905122, -1.0595914 , -0.10623842],\n",
       "        [-0.7635004 , -0.9496925 ,  0.12919922,  0.387145  , -0.09613319,\n",
       "          0.00956839,  0.7417729 ,  0.27164757, -0.10628817,  0.55780065],\n",
       "        [ 0.31907326,  0.49021652,  0.2615851 , -0.785633  ,  0.08093862,\n",
       "         -0.99012035, -0.7096637 ,  0.01767235, -0.56693894, -0.5294688 ],\n",
       "        [-0.870327  , -0.7060093 , -1.1051944 ,  0.15821281, -0.96649665,\n",
       "          0.84169906,  0.20140639, -1.0590584 ,  0.3358126 ,  1.0535098 ],\n",
       "        [-0.06660855,  0.49611688,  0.66428983, -0.2560128 ,  0.37629542,\n",
       "         -0.6502641 , -0.1591039 ,  0.6463532 , -0.36776826, -1.1845214 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.7298152,  1.6819575,  1.6071194, -1.6812743,  1.6723909,\n",
       "        -1.6886401, -1.6739763,  1.6320254, -1.6256436, -1.6657578],\n",
       "       dtype=float32),\n",
       " array([[ 0.90642226],\n",
       "        [ 1.247282  ],\n",
       "        [ 1.0211784 ],\n",
       "        [-1.0821296 ],\n",
       "        [ 0.9363251 ],\n",
       "        [-1.1373969 ],\n",
       "        [-1.1852093 ],\n",
       "        [ 0.6391684 ],\n",
       "        [-0.8882607 ],\n",
       "        [-1.4242892 ]], dtype=float32),\n",
       " array([1.6303458], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_adam_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 533us/step - loss: 621.0105 - val_loss: 663.1098\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 619.4033 - val_loss: 660.9359\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 617.1933 - val_loss: 658.4658\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 614.8645 - val_loss: 655.8079\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 612.3728 - val_loss: 653.1605\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 609.9278 - val_loss: 650.5040\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 607.5095 - val_loss: 647.8774\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 605.0589 - val_loss: 645.3099\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 602.6918 - val_loss: 642.7674\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 600.3059 - val_loss: 640.2927\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 598.0204 - val_loss: 637.7616\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 595.6416 - val_loss: 635.2842\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 593.3652 - val_loss: 632.8011\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 591.1176 - val_loss: 630.3207\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 588.8070 - val_loss: 627.9200\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 586.5976 - val_loss: 625.5190\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 584.3276 - val_loss: 623.1674\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 582.0904 - val_loss: 620.8131\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 579.8969 - val_loss: 618.3925\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 577.6539 - val_loss: 615.9861\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 575.4211 - val_loss: 613.5947\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 573.1902 - val_loss: 611.1940\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 570.9328 - val_loss: 608.8205\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 568.7191 - val_loss: 606.4328\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 566.5000 - val_loss: 604.0351\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 564.2717 - val_loss: 601.6530\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 562.0696 - val_loss: 599.2652\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 559.8086 - val_loss: 596.9233\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 557.6457 - val_loss: 594.5204\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 555.3766 - val_loss: 592.1647\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 553.1387 - val_loss: 589.8139\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 550.9265 - val_loss: 587.4138\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 548.6827 - val_loss: 584.9776\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 546.3946 - val_loss: 582.5567\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 544.1101 - val_loss: 580.1290\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 541.8451 - val_loss: 577.6400\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 539.5687 - val_loss: 575.1087\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 537.1767 - val_loss: 572.6477\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 534.8200 - val_loss: 570.1801\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 532.4939 - val_loss: 567.6507\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 530.0786 - val_loss: 565.1112\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 527.6896 - val_loss: 562.5138\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 525.2571 - val_loss: 559.9243\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 522.8094 - val_loss: 557.3303\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 520.3812 - val_loss: 554.6693\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 517.8840 - val_loss: 551.9810\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 515.3221 - val_loss: 549.2799\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 512.7958 - val_loss: 546.5022\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 510.1259 - val_loss: 543.7781\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 507.5666 - val_loss: 540.9275\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 504.8502 - val_loss: 538.1150\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 502.2197 - val_loss: 535.2137\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 499.4515 - val_loss: 532.3651\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 496.7390 - val_loss: 529.4414\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 493.9981 - val_loss: 526.4365\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 491.1454 - val_loss: 523.4497\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 488.3318 - val_loss: 520.3781\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 485.4040 - val_loss: 517.3169\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 482.4548 - val_loss: 514.2394\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 479.5369 - val_loss: 511.0555\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 476.5067 - val_loss: 507.8624\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 473.4742 - val_loss: 504.5997\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 470.3317 - val_loss: 501.3279\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 467.2650 - val_loss: 497.9025\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 463.9750 - val_loss: 494.5377\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 460.7618 - val_loss: 491.1006\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 457.4979 - val_loss: 487.6058\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 454.1479 - val_loss: 484.0637\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 450.8214 - val_loss: 480.3980\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 447.2740 - val_loss: 476.7686\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 443.8621 - val_loss: 472.9962\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 440.2169 - val_loss: 469.2854\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 436.6345 - val_loss: 465.5241\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 433.0244 - val_loss: 461.6418\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 429.2994 - val_loss: 457.7108\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 425.5365 - val_loss: 453.7197\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 421.7227 - val_loss: 449.6511\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 417.7807 - val_loss: 445.5477\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 413.8776 - val_loss: 441.3088\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 409.8370 - val_loss: 437.0449\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 405.7467 - val_loss: 432.7374\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 401.5813 - val_loss: 428.4128\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 397.4101 - val_loss: 423.9684\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 393.2035 - val_loss: 419.4097\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 388.8307 - val_loss: 414.8337\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 384.3942 - val_loss: 410.2715\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 379.9836 - val_loss: 405.5855\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 375.4705 - val_loss: 400.7503\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 370.8787 - val_loss: 395.8213\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 366.0783 - val_loss: 390.9536\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 361.4249 - val_loss: 385.9164\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 356.5977 - val_loss: 380.8462\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 351.7919 - val_loss: 375.6837\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 346.8900 - val_loss: 370.4849\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 341.9419 - val_loss: 365.2356\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 336.8374 - val_loss: 360.0361\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 331.8282 - val_loss: 354.7085\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 326.7253 - val_loss: 349.3023\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 321.6157 - val_loss: 343.8002\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 316.4512 - val_loss: 338.2607\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 311.0650 - val_loss: 332.8155\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 305.8526 - val_loss: 327.1809\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 300.4967 - val_loss: 321.5209\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 295.1140 - val_loss: 315.8299\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 289.6617 - val_loss: 310.0886\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 284.1936 - val_loss: 304.3069\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 278.7389 - val_loss: 298.4844\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 273.2040 - val_loss: 292.6648\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 267.6718 - val_loss: 286.8764\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 262.2307 - val_loss: 280.9757\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 256.6293 - val_loss: 275.1035\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 251.1064 - val_loss: 269.2144\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 245.4832 - val_loss: 263.3948\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 240.0078 - val_loss: 257.4775\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 234.4261 - val_loss: 251.6150\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 228.9400 - val_loss: 245.7436\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 223.4401 - val_loss: 239.8693\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 217.8849 - val_loss: 234.0874\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 212.5071 - val_loss: 228.2689\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 207.0875 - val_loss: 222.5070\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 201.6556 - val_loss: 216.8373\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 196.3647 - val_loss: 211.1288\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 191.0378 - val_loss: 205.5057\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 185.7717 - val_loss: 199.9615\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 180.7081 - val_loss: 194.3650\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 175.4851 - val_loss: 188.9475\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 170.4590 - val_loss: 183.5936\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 165.5002 - val_loss: 178.2548\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 160.5429 - val_loss: 173.0130\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 155.6914 - val_loss: 167.8365\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 150.8881 - val_loss: 162.7767\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 146.2391 - val_loss: 157.7553\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 141.6833 - val_loss: 152.8048\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 137.1394 - val_loss: 148.0250\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 132.7345 - val_loss: 143.3422\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 128.4234 - val_loss: 138.7665\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 124.2226 - val_loss: 134.2791\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 120.1037 - val_loss: 129.8801\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 116.0867 - val_loss: 125.5675\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 112.0855 - val_loss: 121.3885\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 108.3056 - val_loss: 117.2661\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 104.5993 - val_loss: 113.2502\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 100.8993 - val_loss: 109.4244\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 97.4577 - val_loss: 105.5694\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 93.9130 - val_loss: 101.9491\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 90.6813 - val_loss: 98.3487\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 87.4277 - val_loss: 94.9096\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 84.2928 - val_loss: 91.5864\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 81.2854 - val_loss: 88.3476\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 78.3644 - val_loss: 85.2125\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 75.6081 - val_loss: 82.1272\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 72.8194 - val_loss: 79.1868\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 70.1776 - val_loss: 76.3521\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 67.6218 - val_loss: 73.6340\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 65.2084 - val_loss: 71.0048\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 62.8763 - val_loss: 68.4477\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 60.6009 - val_loss: 66.0174\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 58.4301 - val_loss: 63.6777\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 56.3560 - val_loss: 61.4185\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 54.3988 - val_loss: 59.2071\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 52.4187 - val_loss: 57.1600\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 50.6157 - val_loss: 55.2092\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 48.9459 - val_loss: 53.3075\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 47.2538 - val_loss: 51.5465\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 45.7061 - val_loss: 49.8448\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 44.2143 - val_loss: 48.2213\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 42.8008 - val_loss: 46.6540\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 41.4193 - val_loss: 45.1519\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 40.1029 - val_loss: 43.7165\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 38.8867 - val_loss: 42.3419\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 37.6718 - val_loss: 41.0768\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 36.5964 - val_loss: 39.8277\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 35.5159 - val_loss: 38.6746\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 34.5197 - val_loss: 37.5753\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 33.5835 - val_loss: 36.5130\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 32.6637 - val_loss: 35.5364\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 31.8473 - val_loss: 34.5769\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 30.9838 - val_loss: 33.7262\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 30.2776 - val_loss: 32.8247\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 29.5060 - val_loss: 32.0151\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 28.8640 - val_loss: 31.2304\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 28.1785 - val_loss: 30.5280\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 27.5828 - val_loss: 29.8569\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 27.0246 - val_loss: 29.2125\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 26.4783 - val_loss: 28.6071\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 25.9740 - val_loss: 28.0296\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 25.4817 - val_loss: 27.5041\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 25.0454 - val_loss: 26.9876\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 24.6099 - val_loss: 26.5062\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.2326 - val_loss: 26.0296\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 23.8292 - val_loss: 25.6067\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 23.4750 - val_loss: 25.2011\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.1342 - val_loss: 24.8227\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 22.8177 - val_loss: 24.4522\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 22.5106 - val_loss: 24.0929\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 22.2178 - val_loss: 23.7625\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 21.9387 - val_loss: 23.4556\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.7126 - val_loss: 23.1478\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.4535 - val_loss: 22.8854\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.2331 - val_loss: 22.6307\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.0431 - val_loss: 22.3738\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 20.8254 - val_loss: 22.1544\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.6507 - val_loss: 21.9292\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 20.4758 - val_loss: 21.7211\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.3137 - val_loss: 21.5308\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.1667 - val_loss: 21.3547\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.0285 - val_loss: 21.1866\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.8992 - val_loss: 21.0234\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.7616 - val_loss: 20.8796\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.6518 - val_loss: 20.7392\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.5389 - val_loss: 20.6130\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.4383 - val_loss: 20.4844\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.3351 - val_loss: 20.3691\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.2507 - val_loss: 20.2533\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.1549 - val_loss: 20.1556\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.0860 - val_loss: 20.0483\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.9985 - val_loss: 19.9604\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 73us/step - loss: 18.9332 - val_loss: 19.8732\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.8622 - val_loss: 19.7944\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.8000 - val_loss: 19.7083\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 18.7325 - val_loss: 19.6279\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 18.6778 - val_loss: 19.5512\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.6171 - val_loss: 19.4855\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.5680 - val_loss: 19.4210\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.5141 - val_loss: 19.3575\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.4666 - val_loss: 19.2940\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4223 - val_loss: 19.2343\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.3760 - val_loss: 19.1818\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 18.3310 - val_loss: 19.1324\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.2918 - val_loss: 19.0826\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2579 - val_loss: 19.0314\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.2239 - val_loss: 18.9863\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.1904 - val_loss: 18.9477\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.1602 - val_loss: 18.9133\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.1327 - val_loss: 18.8819\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.1057 - val_loss: 18.8499\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 18.0817 - val_loss: 18.8145\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.0573 - val_loss: 18.7822\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.0297 - val_loss: 18.7584\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.0114 - val_loss: 18.7265\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.9928 - val_loss: 18.6956\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.9635 - val_loss: 18.6757\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.9464 - val_loss: 18.6482\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.9243 - val_loss: 18.6263\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.9067 - val_loss: 18.6003\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 17.8883 - val_loss: 18.5772\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.8730 - val_loss: 18.5512\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 17.8529 - val_loss: 18.5359\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.8375 - val_loss: 18.5196\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.8256 - val_loss: 18.4997\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.8088 - val_loss: 18.4835\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7991 - val_loss: 18.4621\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7799 - val_loss: 18.4460\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7660 - val_loss: 18.4345\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7545 - val_loss: 18.4173\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7399 - val_loss: 18.4021\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7292 - val_loss: 18.3849\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.7159 - val_loss: 18.3757\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.7035 - val_loss: 18.3614\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6916 - val_loss: 18.3476\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6802 - val_loss: 18.3372\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6695 - val_loss: 18.3255\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.6580 - val_loss: 18.3131\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.6456 - val_loss: 18.3016\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6356 - val_loss: 18.2884\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.6244 - val_loss: 18.2752\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.6146 - val_loss: 18.2657\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6036 - val_loss: 18.2541\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.5942 - val_loss: 18.2414\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 17.5840 - val_loss: 18.2314\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 17.5738 - val_loss: 18.2219\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5641 - val_loss: 18.2148\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5551 - val_loss: 18.2047\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.5443 - val_loss: 18.1962\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5356 - val_loss: 18.1895\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.5261 - val_loss: 18.1805\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5158 - val_loss: 18.1711\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 17.5062 - val_loss: 18.1604\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4976 - val_loss: 18.1520\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4876 - val_loss: 18.1429\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4781 - val_loss: 18.1353\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4689 - val_loss: 18.1267\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4605 - val_loss: 18.1167\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4515 - val_loss: 18.1075\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4442 - val_loss: 18.0974\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4343 - val_loss: 18.0887\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4271 - val_loss: 18.0843\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.4183 - val_loss: 18.0764\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.4093 - val_loss: 18.0708\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4009 - val_loss: 18.0621\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3945 - val_loss: 18.0555\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3859 - val_loss: 18.0459\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3768 - val_loss: 18.0403\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 17.3684 - val_loss: 18.0346\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3604 - val_loss: 18.0305\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.3510 - val_loss: 18.0229\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3448 - val_loss: 18.0183\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3347 - val_loss: 18.0098\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.3266 - val_loss: 18.0010\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3189 - val_loss: 17.9946\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.3109 - val_loss: 17.9846\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3040 - val_loss: 17.9764\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2942 - val_loss: 17.9713\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2857 - val_loss: 17.9663\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2780 - val_loss: 17.9608\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2691 - val_loss: 17.9544\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2625 - val_loss: 17.9467\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2542 - val_loss: 17.9423\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2456 - val_loss: 17.9368\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2373 - val_loss: 17.9297\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2289 - val_loss: 17.9211\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.2208 - val_loss: 17.9151\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2129 - val_loss: 17.9095\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2076 - val_loss: 17.9045\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1993 - val_loss: 17.8975\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1906 - val_loss: 17.8923\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1827 - val_loss: 17.8870\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1746 - val_loss: 17.8813\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.1684 - val_loss: 17.8757\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1594 - val_loss: 17.8715\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1527 - val_loss: 17.8653\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.1445 - val_loss: 17.8591\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1376 - val_loss: 17.8536\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1286 - val_loss: 17.8502\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1222 - val_loss: 17.8456\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1148 - val_loss: 17.8389\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1061 - val_loss: 17.8325\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0991 - val_loss: 17.8246\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0917 - val_loss: 17.8186\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.0855 - val_loss: 17.8133\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0769 - val_loss: 17.8080\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0717 - val_loss: 17.7979\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.0609 - val_loss: 17.7926\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0535 - val_loss: 17.7862\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.0468 - val_loss: 17.7802\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0392 - val_loss: 17.7750\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0316 - val_loss: 17.7702\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0240 - val_loss: 17.7654\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0162 - val_loss: 17.7601\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0105 - val_loss: 17.7548\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0010 - val_loss: 17.7495\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.9946 - val_loss: 17.7434\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9914 - val_loss: 17.7353\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.9783 - val_loss: 17.7282\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9712 - val_loss: 17.7234\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9639 - val_loss: 17.7174\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9564 - val_loss: 17.7111\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9489 - val_loss: 17.7053\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9416 - val_loss: 17.7016\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9344 - val_loss: 17.6930\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9269 - val_loss: 17.6864\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9190 - val_loss: 17.6815\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.9131 - val_loss: 17.6779\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9043 - val_loss: 17.6728\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.8988 - val_loss: 17.6682\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8907 - val_loss: 17.6632\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.8839 - val_loss: 17.6554\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8765 - val_loss: 17.6517\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8681 - val_loss: 17.6441\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.8607 - val_loss: 17.6390\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8544 - val_loss: 17.6324\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.8480 - val_loss: 17.6288\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8398 - val_loss: 17.6214\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8333 - val_loss: 17.6168\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.8249 - val_loss: 17.6110\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8188 - val_loss: 17.6028\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8107 - val_loss: 17.5983\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8055 - val_loss: 17.5919\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7965 - val_loss: 17.5869\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 16.7896 - val_loss: 17.5828\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7821 - val_loss: 17.5774\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7753 - val_loss: 17.5723\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7700 - val_loss: 17.5665\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7610 - val_loss: 17.5624\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.7551 - val_loss: 17.5570\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7460 - val_loss: 17.5536\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7392 - val_loss: 17.5489\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7323 - val_loss: 17.5433\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7257 - val_loss: 17.5377\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.7195 - val_loss: 17.5303\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7116 - val_loss: 17.5247\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.7042 - val_loss: 17.5198\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.6970 - val_loss: 17.5150\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 16.6911 - val_loss: 17.5120\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6832 - val_loss: 17.5051\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.6767 - val_loss: 17.4983\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.6726 - val_loss: 17.4956\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6624 - val_loss: 17.4891\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6566 - val_loss: 17.4859\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.6488 - val_loss: 17.4798\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 16.6423 - val_loss: 17.4764\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.6354 - val_loss: 17.4698\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6280 - val_loss: 17.4642\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6212 - val_loss: 17.4589\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.6151 - val_loss: 17.4552\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 16.6065 - val_loss: 17.4503\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6013 - val_loss: 17.4437\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5929 - val_loss: 17.4388\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5865 - val_loss: 17.4328\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5797 - val_loss: 17.4265\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5729 - val_loss: 17.4204\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.5652 - val_loss: 17.4141\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5589 - val_loss: 17.4076\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5516 - val_loss: 17.4006\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5452 - val_loss: 17.3955\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.5390 - val_loss: 17.3912\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5321 - val_loss: 17.3890\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5257 - val_loss: 17.3827\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5189 - val_loss: 17.3801\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.5116 - val_loss: 17.3757\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5039 - val_loss: 17.3705\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4978 - val_loss: 17.3657\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4904 - val_loss: 17.3587\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.4841 - val_loss: 17.3540\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4773 - val_loss: 17.3473\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4699 - val_loss: 17.3419\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 16.4629 - val_loss: 17.3367\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 16.4561 - val_loss: 17.3327\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4499 - val_loss: 17.3265\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4438 - val_loss: 17.3216\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 16.4372 - val_loss: 17.3151\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.4292 - val_loss: 17.3103\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4230 - val_loss: 17.3045\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 16.4168 - val_loss: 17.2973\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4097 - val_loss: 17.2925\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4029 - val_loss: 17.2891\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3981 - val_loss: 17.2818\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3908 - val_loss: 17.2772\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3834 - val_loss: 17.2741\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3761 - val_loss: 17.2689\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3698 - val_loss: 17.2635\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3642 - val_loss: 17.2583\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3563 - val_loss: 17.2533\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3503 - val_loss: 17.2484\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3429 - val_loss: 17.2429\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 16.3366 - val_loss: 17.2378\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3289 - val_loss: 17.2320\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3236 - val_loss: 17.2267\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3161 - val_loss: 17.2225\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3091 - val_loss: 17.2180\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.3032 - val_loss: 17.2137\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2971 - val_loss: 17.2076\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2896 - val_loss: 17.2037\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.2836 - val_loss: 17.1992\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2774 - val_loss: 17.1909\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 16.2699 - val_loss: 17.1842\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2624 - val_loss: 17.1789\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2556 - val_loss: 17.1737\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2499 - val_loss: 17.1697\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2436 - val_loss: 17.1646\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.2364 - val_loss: 17.1577\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2306 - val_loss: 17.1519\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.2232 - val_loss: 17.1450\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.2166 - val_loss: 17.1405\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2101 - val_loss: 17.1364\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 16.2029 - val_loss: 17.1302\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 16.1965 - val_loss: 17.1239\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.1906 - val_loss: 17.1219\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1838 - val_loss: 17.1161\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1783 - val_loss: 17.1102\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1730 - val_loss: 17.1070\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1635 - val_loss: 17.1000\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1572 - val_loss: 17.0963\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1513 - val_loss: 17.0913\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1450 - val_loss: 17.0849\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1398 - val_loss: 17.0774\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 16.1320 - val_loss: 17.0740\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1249 - val_loss: 17.0685\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.1185 - val_loss: 17.0623\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1117 - val_loss: 17.0563\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1051 - val_loss: 17.0513\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 16.0985 - val_loss: 17.0443\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 16.0917 - val_loss: 17.0392\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 16.0849 - val_loss: 17.0322\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.0787 - val_loss: 17.0263\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.0725 - val_loss: 17.0235\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0665 - val_loss: 17.0186\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0586 - val_loss: 17.0123\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.0529 - val_loss: 17.0067\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0461 - val_loss: 17.0015\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0395 - val_loss: 16.9971\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 16.0336 - val_loss: 16.9894\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0266 - val_loss: 16.9834\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0203 - val_loss: 16.9787\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0132 - val_loss: 16.9734\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.0072 - val_loss: 16.9679\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0025 - val_loss: 16.9627\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9936 - val_loss: 16.9583\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 15.9883 - val_loss: 16.9540\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 15.9806 - val_loss: 16.9454\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9760 - val_loss: 16.9384\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9672 - val_loss: 16.9341\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.9613 - val_loss: 16.9290\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9550 - val_loss: 16.9223\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9484 - val_loss: 16.9189\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.9421 - val_loss: 16.9124\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.9353 - val_loss: 16.9057\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9287 - val_loss: 16.9008\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9221 - val_loss: 16.8966\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.9161 - val_loss: 16.8922\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.9090 - val_loss: 16.8881\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.9029 - val_loss: 16.8821\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8965 - val_loss: 16.8775\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8894 - val_loss: 16.8729\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8834 - val_loss: 16.8677\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8765 - val_loss: 16.8619\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8704 - val_loss: 16.8566\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8637 - val_loss: 16.8510\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.8580 - val_loss: 16.8455\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8514 - val_loss: 16.8392\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8451 - val_loss: 16.8341\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8383 - val_loss: 16.8299\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8318 - val_loss: 16.8243\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8262 - val_loss: 16.8172\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8188 - val_loss: 16.8117\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8127 - val_loss: 16.8068\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8086 - val_loss: 16.8012\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8003 - val_loss: 16.7952\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7940 - val_loss: 16.7878\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7885 - val_loss: 16.7832\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7815 - val_loss: 16.7785\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 15.7747 - val_loss: 16.7747\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7683 - val_loss: 16.7678\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7634 - val_loss: 16.7636\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7559 - val_loss: 16.7558\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7494 - val_loss: 16.7507\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7426 - val_loss: 16.7452\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7369 - val_loss: 16.7392\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7305 - val_loss: 16.7337\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.7256 - val_loss: 16.7255\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7184 - val_loss: 16.7212\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7108 - val_loss: 16.7171\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7048 - val_loss: 16.7132\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6987 - val_loss: 16.7104\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 15.6920 - val_loss: 16.7070\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 15.6856 - val_loss: 16.7022\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6785 - val_loss: 16.6953\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 15.6728 - val_loss: 16.6907\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6674 - val_loss: 16.6845\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 15.6611 - val_loss: 16.6795\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 15.6538 - val_loss: 16.6746\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6481 - val_loss: 16.6681\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6405 - val_loss: 16.6618\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6343 - val_loss: 16.6561\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 15.6280 - val_loss: 16.6496\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6218 - val_loss: 16.6465\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6155 - val_loss: 16.6418\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6097 - val_loss: 16.6364\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6042 - val_loss: 16.6323\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5967 - val_loss: 16.6258\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5900 - val_loss: 16.6218\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5837 - val_loss: 16.6161\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5778 - val_loss: 16.6096\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.5719 - val_loss: 16.6068\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.5648 - val_loss: 16.6014\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5586 - val_loss: 16.5962\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.5517 - val_loss: 16.5910\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5465 - val_loss: 16.5862\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5397 - val_loss: 16.5808\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.5324 - val_loss: 16.5755\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5274 - val_loss: 16.5695\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 15.5199 - val_loss: 16.5647\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5140 - val_loss: 16.5592\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.5088 - val_loss: 16.5543\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5020 - val_loss: 16.5481\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4954 - val_loss: 16.5459\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4898 - val_loss: 16.5408\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4835 - val_loss: 16.5370\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4762 - val_loss: 16.5307\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.4696 - val_loss: 16.5251\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.4640 - val_loss: 16.5203\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4580 - val_loss: 16.5128\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.4507 - val_loss: 16.5072\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4442 - val_loss: 16.5023\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.4385 - val_loss: 16.4977\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4338 - val_loss: 16.4918\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4253 - val_loss: 16.4856\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4202 - val_loss: 16.4823\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4123 - val_loss: 16.4754\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.4070 - val_loss: 16.4682\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4009 - val_loss: 16.4628\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.3953 - val_loss: 16.4534\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3872 - val_loss: 16.4481\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.3814 - val_loss: 16.4435\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3751 - val_loss: 16.4393\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 146us/step - loss: 15.3689 - val_loss: 16.4338\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.3647 - val_loss: 16.4275\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 15.3565 - val_loss: 16.4194\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 15.3501 - val_loss: 16.4138\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 15.3454 - val_loss: 16.4072\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.3391 - val_loss: 16.4003\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3307 - val_loss: 16.3930\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.3275 - val_loss: 16.3884\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 15.3198 - val_loss: 16.3843\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 55us/step - loss: 15.3135 - val_loss: 16.3773\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 15.3073 - val_loss: 16.3723\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 15.3000 - val_loss: 16.3671\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 72us/step - loss: 15.2937 - val_loss: 16.3628\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 15.2903 - val_loss: 16.3575\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 15.2819 - val_loss: 16.3519\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 15.2757 - val_loss: 16.3479\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 15.2697 - val_loss: 16.3400\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 15.2620 - val_loss: 16.3354\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.2579 - val_loss: 16.3322\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 15.2500 - val_loss: 16.3239\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 15.2430 - val_loss: 16.3191\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2380 - val_loss: 16.3120\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.2315 - val_loss: 16.3075\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.2246 - val_loss: 16.3006\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 15.2183 - val_loss: 16.2951\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.2113 - val_loss: 16.2908\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 15.2065 - val_loss: 16.2858\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 38us/step - loss: 15.1997 - val_loss: 16.2805\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1939 - val_loss: 16.2747\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 15.1877 - val_loss: 16.2711\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1813 - val_loss: 16.2659\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1765 - val_loss: 16.2594\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1678 - val_loss: 16.2542\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 15.1620 - val_loss: 16.2499\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 40us/step - loss: 15.1559 - val_loss: 16.2431\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1499 - val_loss: 16.2378\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 15.1465 - val_loss: 16.2305\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1375 - val_loss: 16.2254\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1308 - val_loss: 16.2203\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 15.1250 - val_loss: 16.2166\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1191 - val_loss: 16.2117\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1121 - val_loss: 16.2057\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.1060 - val_loss: 16.2020\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 15.1001 - val_loss: 16.1954\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0935 - val_loss: 16.1883\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0864 - val_loss: 16.1816\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0813 - val_loss: 16.1755\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 15.0743 - val_loss: 16.1691\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0687 - val_loss: 16.1655\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0610 - val_loss: 16.1597\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 15.0546 - val_loss: 16.1543\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.0493 - val_loss: 16.1488\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.0428 - val_loss: 16.1442\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.0365 - val_loss: 16.1358\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 15.0295 - val_loss: 16.1302\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 15.0250 - val_loss: 16.1224\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 15.0178 - val_loss: 16.1195\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 15.0115 - val_loss: 16.1144\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.0047 - val_loss: 16.1089\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.9992 - val_loss: 16.1042\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 70us/step - loss: 14.9929 - val_loss: 16.0983\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 55us/step - loss: 14.9860 - val_loss: 16.0926\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9817 - val_loss: 16.0887\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.9743 - val_loss: 16.0813\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9692 - val_loss: 16.0730\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9612 - val_loss: 16.0687\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9556 - val_loss: 16.0610\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9494 - val_loss: 16.0542\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9431 - val_loss: 16.0483\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9373 - val_loss: 16.0419\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.9302 - val_loss: 16.0378\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9244 - val_loss: 16.0348\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9186 - val_loss: 16.0300\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.9127 - val_loss: 16.0230\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9058 - val_loss: 16.0181\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.9001 - val_loss: 16.0129\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.8935 - val_loss: 16.0061\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 14.8884 - val_loss: 15.9996\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8816 - val_loss: 15.9921\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8756 - val_loss: 15.9867\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.8689 - val_loss: 15.9808\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 14.8621 - val_loss: 15.9751\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8566 - val_loss: 15.9701\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8509 - val_loss: 15.9626\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8442 - val_loss: 15.9578\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.8381 - val_loss: 15.9497\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 15us/step - loss: 14.8313 - val_loss: 15.9450\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.8251 - val_loss: 15.9396\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 57us/step - loss: 14.8187 - val_loss: 15.9351\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.8134 - val_loss: 15.9302\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.8067 - val_loss: 15.9235\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.8011 - val_loss: 15.9154\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 163us/step - loss: 14.7937 - val_loss: 15.9100\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 14.7884 - val_loss: 15.9047\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7817 - val_loss: 15.8970\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.7759 - val_loss: 15.8900\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.7694 - val_loss: 15.8831\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7639 - val_loss: 15.8792\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7558 - val_loss: 15.8743\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 14.7526 - val_loss: 15.8721\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.7438 - val_loss: 15.8645\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.7375 - val_loss: 15.8583\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 156us/step - loss: 14.7316 - val_loss: 15.8523\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 33us/step - loss: 14.7273 - val_loss: 15.8452\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 14.7194 - val_loss: 15.8413\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 14.7133 - val_loss: 15.8345\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 14.7060 - val_loss: 15.8300\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 14.7010 - val_loss: 15.8245\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6938 - val_loss: 15.8177\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6880 - val_loss: 15.8100\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6818 - val_loss: 15.8050\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.6751 - val_loss: 15.7978\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6690 - val_loss: 15.7887\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6648 - val_loss: 15.7824\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6582 - val_loss: 15.7757\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6532 - val_loss: 15.7709\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6450 - val_loss: 15.7675\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.6401 - val_loss: 15.7631\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6327 - val_loss: 15.7591\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6270 - val_loss: 15.7546\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6216 - val_loss: 15.7483\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6154 - val_loss: 15.7448\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.6104 - val_loss: 15.7423\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 14.6031 - val_loss: 15.7350\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5973 - val_loss: 15.7281\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5908 - val_loss: 15.7221\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5846 - val_loss: 15.7151\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5774 - val_loss: 15.7089\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 14.5719 - val_loss: 15.7035\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.5651 - val_loss: 15.6983\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 14.5591 - val_loss: 15.6916\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5525 - val_loss: 15.6876\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5485 - val_loss: 15.6826\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 14.5405 - val_loss: 15.6780\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 61us/step - loss: 14.5340 - val_loss: 15.6719\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 14.5298 - val_loss: 15.6641\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.5212 - val_loss: 15.6588\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 14.5152 - val_loss: 15.6525\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.5117 - val_loss: 15.6482\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.97 - 0s 29us/step - loss: 14.5028 - val_loss: 15.6422\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 121us/step - loss: 14.4976 - val_loss: 15.6379\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.4918 - val_loss: 15.6297\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.4848 - val_loss: 15.6232\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4780 - val_loss: 15.6179\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.4719 - val_loss: 15.6102\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.4671 - val_loss: 15.6013\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 14.4594 - val_loss: 15.5973\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 14.4530 - val_loss: 15.5916\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 14.4474 - val_loss: 15.5851\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.4412 - val_loss: 15.5831\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.4347 - val_loss: 15.5781\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4276 - val_loss: 15.5711\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4225 - val_loss: 15.5656\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.4162 - val_loss: 15.5585\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4093 - val_loss: 15.5526\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4034 - val_loss: 15.5472\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3977 - val_loss: 15.5424\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.3914 - val_loss: 15.5364\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3851 - val_loss: 15.5310\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3794 - val_loss: 15.5244\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3726 - val_loss: 15.5192\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3664 - val_loss: 15.5138\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.3602 - val_loss: 15.5068\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3546 - val_loss: 15.5009\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 14.3476 - val_loss: 15.4943\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3415 - val_loss: 15.4873\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3351 - val_loss: 15.4825\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3294 - val_loss: 15.4774\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3232 - val_loss: 15.4710\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3186 - val_loss: 15.4666\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.3103 - val_loss: 15.4602\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.3045 - val_loss: 15.4540\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.2987 - val_loss: 15.4473\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.2919 - val_loss: 15.4411\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.2859 - val_loss: 15.4375\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.2795 - val_loss: 15.4316\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.2745 - val_loss: 15.4269\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.2667 - val_loss: 15.4209\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.2611 - val_loss: 15.4158\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.2541 - val_loss: 15.4074\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2486 - val_loss: 15.3995\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 14.2422 - val_loss: 15.3942\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 14.2363 - val_loss: 15.3893\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.2309 - val_loss: 15.3825\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.2245 - val_loss: 15.3760\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.2171 - val_loss: 15.3700\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.2119 - val_loss: 15.3642\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.2045 - val_loss: 15.3594\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1984 - val_loss: 15.3541\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.1921 - val_loss: 15.3473\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.1864 - val_loss: 15.3398\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.1821 - val_loss: 15.3319\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.1730 - val_loss: 15.3266\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.1672 - val_loss: 15.3215\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.1622 - val_loss: 15.3177\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1550 - val_loss: 15.3107\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1496 - val_loss: 15.3066\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1428 - val_loss: 15.3028\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.1365 - val_loss: 15.2964\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1305 - val_loss: 15.2896\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1243 - val_loss: 15.2829\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1185 - val_loss: 15.2755\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.1125 - val_loss: 15.2708\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1058 - val_loss: 15.2637\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1003 - val_loss: 15.2567\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.0937 - val_loss: 15.2499\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 14.0870 - val_loss: 15.2418\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.0835 - val_loss: 15.2324\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0749 - val_loss: 15.2262\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0686 - val_loss: 15.2213\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0637 - val_loss: 15.2164\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0561 - val_loss: 15.2075\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.0509 - val_loss: 15.2005\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.0444 - val_loss: 15.1960\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 160us/step - loss: 14.0386 - val_loss: 15.1886\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 14.0317 - val_loss: 15.1827\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 14.0253 - val_loss: 15.1774\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.0188 - val_loss: 15.1737\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 14.0133 - val_loss: 15.1679\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.0066 - val_loss: 15.1635\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.0006 - val_loss: 15.1601\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9978 - val_loss: 15.1539\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9880 - val_loss: 15.1489\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9833 - val_loss: 15.1402\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9746 - val_loss: 15.1330\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9682 - val_loss: 15.1255\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9632 - val_loss: 15.1185\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9567 - val_loss: 15.1111\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9507 - val_loss: 15.1038\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 13.9442 - val_loss: 15.1002\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9382 - val_loss: 15.0932\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.9324 - val_loss: 15.0875\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.9267 - val_loss: 15.0792\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9200 - val_loss: 15.0714\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.9142 - val_loss: 15.0657\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9075 - val_loss: 15.0603\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.9015 - val_loss: 15.0564\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8948 - val_loss: 15.0508\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8892 - val_loss: 15.0423\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8832 - val_loss: 15.0370\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 13.8765 - val_loss: 15.0317\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.8717 - val_loss: 15.0257\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8647 - val_loss: 15.0176\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8595 - val_loss: 15.0114\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8521 - val_loss: 15.0073\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 13.8463 - val_loss: 15.0009\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.8422 - val_loss: 14.9956\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.8337 - val_loss: 14.9901\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8280 - val_loss: 14.9843\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8230 - val_loss: 14.9759\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.8153 - val_loss: 14.9704\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8096 - val_loss: 14.9672\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.8032 - val_loss: 14.9635\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.7987 - val_loss: 14.9616\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.7914 - val_loss: 14.9548\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.7861 - val_loss: 14.9493\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.7792 - val_loss: 14.9448\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.7729 - val_loss: 14.9403\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7667 - val_loss: 14.9350\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7624 - val_loss: 14.9316\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 13.7539 - val_loss: 14.9261\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.7480 - val_loss: 14.9221\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 65us/step - loss: 13.7419 - val_loss: 14.9166\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 13.7357 - val_loss: 14.9098\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.7304 - val_loss: 14.9051\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7243 - val_loss: 14.9000\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.7184 - val_loss: 14.8973\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.7113 - val_loss: 14.8891\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7051 - val_loss: 14.8808\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6994 - val_loss: 14.8734\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 13.6935 - val_loss: 14.8661\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.6870 - val_loss: 14.8601\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6813 - val_loss: 14.8536\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.6752 - val_loss: 14.8490\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6690 - val_loss: 14.8423\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6629 - val_loss: 14.8374\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.6575 - val_loss: 14.8319\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6512 - val_loss: 14.8232\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6442 - val_loss: 14.8178\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6386 - val_loss: 14.8118\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6322 - val_loss: 14.8069\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6262 - val_loss: 14.8022\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6210 - val_loss: 14.7978\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6151 - val_loss: 14.7905\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.6088 - val_loss: 14.7866\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6025 - val_loss: 14.7809\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5963 - val_loss: 14.7747\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5899 - val_loss: 14.7689\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.5837 - val_loss: 14.7609\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.5783 - val_loss: 14.7556\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.5710 - val_loss: 14.7499\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5657 - val_loss: 14.7443\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5596 - val_loss: 14.7364\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5534 - val_loss: 14.7306\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5479 - val_loss: 14.7262\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5406 - val_loss: 14.7201\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5357 - val_loss: 14.7126\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.5289 - val_loss: 14.7047\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 13.5231 - val_loss: 14.6987\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5168 - val_loss: 14.6929\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5107 - val_loss: 14.6881\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5049 - val_loss: 14.6841\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.4992 - val_loss: 14.6759\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.4922 - val_loss: 14.6713\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4855 - val_loss: 14.6635\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4808 - val_loss: 14.6567\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 13.4750 - val_loss: 14.6498\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4674 - val_loss: 14.6457\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4616 - val_loss: 14.6397\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.4551 - val_loss: 14.6316\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.4486 - val_loss: 14.6261\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4427 - val_loss: 14.6198\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4366 - val_loss: 14.6149\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4312 - val_loss: 14.6096\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4252 - val_loss: 14.6049\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4175 - val_loss: 14.5978\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 13.4110 - val_loss: 14.5914\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.4055 - val_loss: 14.5845\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3998 - val_loss: 14.5789\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3946 - val_loss: 14.5722\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3880 - val_loss: 14.5684\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3813 - val_loss: 14.5625\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3742 - val_loss: 14.5571\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3689 - val_loss: 14.5503\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3634 - val_loss: 14.5457\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3565 - val_loss: 14.5404\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3508 - val_loss: 14.5346\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3448 - val_loss: 14.5260\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3382 - val_loss: 14.5206\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3321 - val_loss: 14.5158\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3260 - val_loss: 14.5098\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3199 - val_loss: 14.5042\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3157 - val_loss: 14.5011\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3084 - val_loss: 14.4954\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3017 - val_loss: 14.4911\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 13.2962 - val_loss: 14.4829\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.2899 - val_loss: 14.4767\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2838 - val_loss: 14.4691\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2773 - val_loss: 14.4639\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.2719 - val_loss: 14.4618\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2657 - val_loss: 14.4548\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2587 - val_loss: 14.4487\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.2528 - val_loss: 14.4421\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2466 - val_loss: 14.4361\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2403 - val_loss: 14.4301\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2345 - val_loss: 14.4231\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.2282 - val_loss: 14.4178\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2234 - val_loss: 14.4085\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2160 - val_loss: 14.4020\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.2107 - val_loss: 14.3960\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2043 - val_loss: 14.3920\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.1985 - val_loss: 14.3882\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.1927 - val_loss: 14.3803\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1857 - val_loss: 14.3734\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1804 - val_loss: 14.3678\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 13.1740 - val_loss: 14.3627\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 13.1685 - val_loss: 14.3550\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 13.1619 - val_loss: 14.3486\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1571 - val_loss: 14.3412\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 13.1498 - val_loss: 14.3374\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1436 - val_loss: 14.3295\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1377 - val_loss: 14.3234\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1308 - val_loss: 14.3169\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1250 - val_loss: 14.3105\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.1193 - val_loss: 14.3057\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.1131 - val_loss: 14.2977\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1072 - val_loss: 14.2918\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1014 - val_loss: 14.2855\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 74us/step - loss: 13.0960 - val_loss: 14.2812\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0894 - val_loss: 14.2730\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0834 - val_loss: 14.2655\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 13.0775 - val_loss: 14.2580\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0715 - val_loss: 14.2527\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.0655 - val_loss: 14.2441\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0598 - val_loss: 14.2371\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0525 - val_loss: 14.2339\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0490 - val_loss: 14.2304\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0407 - val_loss: 14.2253\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 13.0354 - val_loss: 14.2196\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0288 - val_loss: 14.2130\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0230 - val_loss: 14.2074\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0168 - val_loss: 14.1989\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0113 - val_loss: 14.1925\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0048 - val_loss: 14.1847\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 12.9995 - val_loss: 14.1794\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9928 - val_loss: 14.1732\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9881 - val_loss: 14.1682\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.9809 - val_loss: 14.1588\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 12.9762 - val_loss: 14.1535\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.9688 - val_loss: 14.1459\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 12.9648 - val_loss: 14.1401\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.9575 - val_loss: 14.1351\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 12.9514 - val_loss: 14.1276\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9451 - val_loss: 14.1232\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.9390 - val_loss: 14.1193\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.9328 - val_loss: 14.1131\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9272 - val_loss: 14.1064\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9222 - val_loss: 14.0970\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9146 - val_loss: 14.0919\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9089 - val_loss: 14.0878\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.9032 - val_loss: 14.0829\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8969 - val_loss: 14.0751\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8904 - val_loss: 14.0703\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8854 - val_loss: 14.0651\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8789 - val_loss: 14.0568\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8728 - val_loss: 14.0504\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 12.8672 - val_loss: 14.0443\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8608 - val_loss: 14.0364\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8544 - val_loss: 14.0321\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8489 - val_loss: 14.0263\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8431 - val_loss: 14.0235\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 12.8367 - val_loss: 14.0182\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8312 - val_loss: 14.0114\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.8256 - val_loss: 14.0069\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8190 - val_loss: 14.0031\n",
      "12.113395901049598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.32678187,  0.5053104 , -0.33613378,  0.4672877 ,  0.44165695],\n",
       "        [ 0.27152878, -0.4408467 , -0.12857896,  0.5828751 ,  0.18301068],\n",
       "        [ 0.08714361, -0.37265682,  0.20364846,  0.6437265 , -0.3779322 ],\n",
       "        [ 0.40987688,  0.5625582 ,  0.25918117, -0.16702637, -0.29402474],\n",
       "        [ 0.06422357, -0.22536229,  0.21474718,  0.05188863, -0.4430298 ],\n",
       "        [-0.1012086 ,  0.04594173, -0.4449722 , -0.38039973, -0.41222817],\n",
       "        [ 0.26049674,  0.03159538, -0.15178236, -0.38217115, -0.69344676]],\n",
       "       dtype=float32),\n",
       " array([-0.89706916, -1.2289523 , -0.65544826,  0.27893022, -0.03108319],\n",
       "       dtype=float32),\n",
       " array([[-0.7750688 ,  0.909867  ,  0.13823867,  0.57529014,  0.7929965 ,\n",
       "          0.4392865 , -0.2287896 ,  0.7216724 , -0.02624827, -0.28536707],\n",
       "        [-0.34852847,  1.1567498 ,  0.5897626 , -0.11477017,  0.20439874,\n",
       "          0.7537237 ,  1.1456362 ,  0.8554879 ,  0.81595606, -0.02504966],\n",
       "        [-0.8791441 ,  0.9251317 ,  0.34827232,  0.03757575, -0.05452791,\n",
       "          0.56732494,  0.14910702,  0.19891144, -0.32644835, -0.71835357],\n",
       "        [-0.3494621 ,  0.37951577, -0.28799415,  0.2386336 ,  0.57678807,\n",
       "         -0.18660723,  0.9746583 ,  0.06481238, -0.1540429 , -0.8723812 ],\n",
       "        [-0.23747027,  0.23346925,  0.1888358 ,  0.5597001 , -0.4055036 ,\n",
       "         -0.50219256, -0.13338959,  0.47520453, -0.21063969, -0.4772555 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.82678795, -1.1165138 , -0.69008696, -0.6023473 , -0.6338969 ,\n",
       "        -0.47673967, -1.1519846 , -0.93685776, -0.36404744,  0.5799882 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.389323  ],\n",
       "        [-1.9704183 ],\n",
       "        [-0.91852367],\n",
       "        [-0.826026  ],\n",
       "        [-0.98012704],\n",
       "        [-0.8102034 ],\n",
       "        [-1.7581059 ],\n",
       "        [-1.4625664 ],\n",
       "        [-0.49039832],\n",
       "        [ 1.074158  ]], dtype=float32),\n",
       " array([1.2015303], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, sgd, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sgd_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 618us/step - loss: 570.4993 - val_loss: 554.0095\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 485.9171 - val_loss: 442.7641\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 378.8214 - val_loss: 321.9182\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 262.9954 - val_loss: 208.0035\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 150.6428 - val_loss: 104.2592\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 66.2069 - val_loss: 37.5847\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 25.8645 - val_loss: 20.4355\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5230 - val_loss: 15.7011\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 15.4021 - val_loss: 15.6602\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9710 - val_loss: 12.6978\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6908 - val_loss: 12.3268\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0114 - val_loss: 12.8461\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2006 - val_loss: 10.5683\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.1950 - val_loss: 11.9763\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8663 - val_loss: 11.1917\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8317 - val_loss: 10.9805\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.0572 - val_loss: 11.1517\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.7817 - val_loss: 11.6154\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.9880 - val_loss: 10.3352\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.4263 - val_loss: 11.9306\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.7905 - val_loss: 11.6629\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.6395 - val_loss: 12.0551\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.2509 - val_loss: 12.2352\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.2857 - val_loss: 11.5475\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 9.3905 - val_loss: 13.8697\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.9170 - val_loss: 11.4945\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 9.6071 - val_loss: 12.5485\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.2191 - val_loss: 11.5610\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5965 - val_loss: 12.3741\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.1620 - val_loss: 12.3864\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.3536 - val_loss: 10.9044\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9862 - val_loss: 11.7966\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5705 - val_loss: 11.1403\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 9.1890 - val_loss: 11.0845\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.5532 - val_loss: 11.9050\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.9924 - val_loss: 13.0062\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.8207 - val_loss: 10.9065\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6711 - val_loss: 11.6277\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9318 - val_loss: 13.0075\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.3962 - val_loss: 10.4594\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.0214 - val_loss: 11.1308\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1854 - val_loss: 11.1460\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1442 - val_loss: 12.0376\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.6873 - val_loss: 12.2067\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 9.7160 - val_loss: 12.2638\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1803 - val_loss: 10.7683\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.6599 - val_loss: 10.4928\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5586 - val_loss: 12.0660\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 8.5194 - val_loss: 14.7519\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.6875 - val_loss: 11.1623\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.6768 - val_loss: 10.2608\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1823 - val_loss: 11.8221\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.468 - 0s 80us/step - loss: 8.4359 - val_loss: 11.2969\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2801 - val_loss: 10.8137\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.5697 - val_loss: 11.3557\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.4452 - val_loss: 12.3909\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0232 - val_loss: 11.0436\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2403 - val_loss: 11.5651\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3470 - val_loss: 11.1209\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3371 - val_loss: 11.9960\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8991 - val_loss: 11.3225\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2729 - val_loss: 11.4480\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 8.2405 - val_loss: 12.4228\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.1951 - val_loss: 12.1192\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.7091 - val_loss: 11.1320\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.4291 - val_loss: 11.9942\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9794 - val_loss: 12.1348\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 8.4457 - val_loss: 11.3456\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4524 - val_loss: 12.2241\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4224 - val_loss: 13.6073\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.5142 - val_loss: 12.4404\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.9687 - val_loss: 11.8257\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.1213 - val_loss: 12.4995\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3541 - val_loss: 11.8171\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5062 - val_loss: 11.2852\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.9244 - val_loss: 12.1396\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0896 - val_loss: 10.8496\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9686 - val_loss: 14.5595\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4789 - val_loss: 14.4064\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.6627 - val_loss: 11.6563\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2479 - val_loss: 11.9936\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 8.9934 - val_loss: 11.9437\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.3887 - val_loss: 13.7785\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.1534 - val_loss: 10.4777\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.8555 - val_loss: 11.2565\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1993 - val_loss: 13.7471\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.9226 - val_loss: 11.2765\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.3136 - val_loss: 11.2461\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2376 - val_loss: 11.3170\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.4443 - val_loss: 13.3568\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.5059 - val_loss: 11.7011\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.2490 - val_loss: 12.0166\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.2306 - val_loss: 11.8922\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0098 - val_loss: 11.2461\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.6431 - val_loss: 11.6141\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8998 - val_loss: 11.4612\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.3635 - val_loss: 14.7961\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.7968 - val_loss: 13.3166\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0142 - val_loss: 10.7241\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.4517 - val_loss: 12.0904\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2988 - val_loss: 10.9031\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2396 - val_loss: 11.7391\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8551 - val_loss: 11.1010\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.9517 - val_loss: 11.8281\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.4036 - val_loss: 10.9778\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.1221 - val_loss: 10.7742\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0417 - val_loss: 11.1876\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5452 - val_loss: 12.4681\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.6663 - val_loss: 11.0519\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0027 - val_loss: 11.5790\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2131 - val_loss: 11.2318\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2782 - val_loss: 12.8609\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7288 - val_loss: 11.4782\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2721 - val_loss: 11.8663\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.6465 - val_loss: 10.5117\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3951 - val_loss: 11.4495\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3349 - val_loss: 12.1391\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.4049 - val_loss: 11.4412\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9195 - val_loss: 11.5348\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9043 - val_loss: 11.8199\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9367 - val_loss: 12.4307\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 8.2837 - val_loss: 14.1391\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.4291 - val_loss: 11.1208\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8781 - val_loss: 11.6679\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.5498 - val_loss: 13.2025\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.6916 - val_loss: 11.4713\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6716 - val_loss: 12.1172\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.8434 - val_loss: 12.8987\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 8.2532 - val_loss: 12.2543\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 72us/step - loss: 8.7146 - val_loss: 10.6616\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5601 - val_loss: 11.1044\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.6158 - val_loss: 11.0431\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8740 - val_loss: 10.7471\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.3937 - val_loss: 12.0462\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2926 - val_loss: 11.1474\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9837 - val_loss: 11.3254\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5797 - val_loss: 10.9177\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.1630 - val_loss: 13.0320\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.1603 - val_loss: 11.6629\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8310 - val_loss: 12.6000\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5503 - val_loss: 10.8606\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5720 - val_loss: 15.0478\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9941 - val_loss: 13.9886\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9767 - val_loss: 12.2289\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 8.4903 - val_loss: 13.1946\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9441 - val_loss: 11.0655\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0426 - val_loss: 11.1108\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.7876 - val_loss: 15.7777\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.9510 - val_loss: 11.1252\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0200 - val_loss: 11.6862\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8095 - val_loss: 13.1486\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0116 - val_loss: 14.2529\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5153 - val_loss: 11.6971\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7948 - val_loss: 13.5410\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0912 - val_loss: 13.1098\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3631 - val_loss: 12.9566\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.3368 - val_loss: 12.9713\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7388 - val_loss: 12.5569\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.3091 - val_loss: 12.0038\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2943 - val_loss: 11.0303\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6066 - val_loss: 11.1751\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9206 - val_loss: 11.1413\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.4967 - val_loss: 11.4417\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.7785 - val_loss: 11.3724\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2318 - val_loss: 11.9706\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.9002 - val_loss: 11.3373\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.8814 - val_loss: 11.7942\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8980 - val_loss: 12.0784\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.1773 - val_loss: 11.5430\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8715 - val_loss: 11.6820\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.8679 - val_loss: 11.4812\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.0022 - val_loss: 12.9354\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0460 - val_loss: 11.4790\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.8171 - val_loss: 11.9642\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.1323 - val_loss: 12.3119\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 8.2450 - val_loss: 10.8596\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8318 - val_loss: 11.8948\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 8.3158 - val_loss: 13.2176\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9910 - val_loss: 12.8930\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9994 - val_loss: 11.0053\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0883 - val_loss: 11.6809\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.0052 - val_loss: 12.2956\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0695 - val_loss: 11.5588\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0033 - val_loss: 11.2474\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6826 - val_loss: 11.3206\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.9088 - val_loss: 13.0066\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.2296 - val_loss: 11.8416\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4654 - val_loss: 12.1713\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.8587 - val_loss: 11.1463\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.4398 - val_loss: 12.1202\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9870 - val_loss: 11.1892\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6985 - val_loss: 11.2786\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 8.0158 - val_loss: 11.2824\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.8750 - val_loss: 13.1484\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7372 - val_loss: 11.5005\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5654 - val_loss: 14.2401\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2032 - val_loss: 12.0540\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2111 - val_loss: 12.6615\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7758 - val_loss: 11.1369\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.7703 - val_loss: 12.1709\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7917 - val_loss: 11.7494\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6458 - val_loss: 15.8954\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.9779 - val_loss: 11.3089\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9792 - val_loss: 11.5828\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8938 - val_loss: 13.8816\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8604 - val_loss: 13.0787\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.6458 - val_loss: 12.1124\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6734 - val_loss: 13.7364\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5801 - val_loss: 11.4873\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0056 - val_loss: 12.3203\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2497 - val_loss: 12.0652\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7358 - val_loss: 11.5020\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.7786 - val_loss: 10.9415\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8504 - val_loss: 12.1834\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7167 - val_loss: 12.1461\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.6838 - val_loss: 11.0188\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9098 - val_loss: 12.8910\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 8.1659 - val_loss: 11.2861\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.1876 - val_loss: 12.1898\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0435 - val_loss: 11.4900\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3910 - val_loss: 11.9727\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 7.6653 - val_loss: 11.0906\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0204 - val_loss: 11.1803\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.8151 - val_loss: 15.1456\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.2842 - val_loss: 13.1945\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.3573 - val_loss: 11.8700\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2255 - val_loss: 13.3430\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7356 - val_loss: 11.2817\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7762 - val_loss: 11.3132\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7018 - val_loss: 12.3092\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9103 - val_loss: 11.5591\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.5197 - val_loss: 11.4989\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8401 - val_loss: 11.3958\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9056 - val_loss: 11.0539\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8595 - val_loss: 11.8182\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5271 - val_loss: 14.0694\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0521 - val_loss: 11.5129\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8405 - val_loss: 10.9614\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6892 - val_loss: 11.3572\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.3010 - val_loss: 12.4800\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0840 - val_loss: 12.4731\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0300 - val_loss: 11.3109\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.6796 - val_loss: 10.8636\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5055 - val_loss: 10.6720\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8432 - val_loss: 11.2256\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8782 - val_loss: 14.5244\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.4241 - val_loss: 12.0235\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4751 - val_loss: 11.2698\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.9671 - val_loss: 11.3061\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2104 - val_loss: 12.7020\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5280 - val_loss: 10.8508\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 8.2467 - val_loss: 11.2759\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7286 - val_loss: 12.3148\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0507 - val_loss: 11.4383\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2632 - val_loss: 11.2878\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5504 - val_loss: 13.4143\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6689 - val_loss: 11.1824\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4537 - val_loss: 10.4613\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2258 - val_loss: 12.0335\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.5928 - val_loss: 11.4786\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0092 - val_loss: 11.4762\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.9428 - val_loss: 11.0618\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5641 - val_loss: 14.7562\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 8.3548 - val_loss: 11.4101\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7706 - val_loss: 13.5556\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5786 - val_loss: 11.9089\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8020 - val_loss: 11.5841\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2558 - val_loss: 11.4048\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5075 - val_loss: 12.9311\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.7765 - val_loss: 11.4233\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7982 - val_loss: 10.8643\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4342 - val_loss: 11.5026\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.8366 - val_loss: 11.2720\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3957 - val_loss: 10.7277\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7483 - val_loss: 10.3826\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.1017 - val_loss: 11.0535\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2809 - val_loss: 11.9512\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5684 - val_loss: 11.5059\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4123 - val_loss: 13.9566\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 8.2140 - val_loss: 11.3054\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7857 - val_loss: 12.8775\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8987 - val_loss: 10.7494\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5366 - val_loss: 10.5831\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.7437 - val_loss: 10.7923\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4303 - val_loss: 11.0211\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2340 - val_loss: 12.0223\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0266 - val_loss: 12.7733\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9404 - val_loss: 12.6620\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.4047 - val_loss: 10.8091\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5454 - val_loss: 11.3084\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4504 - val_loss: 11.2127\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5308 - val_loss: 12.4295\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.2669 - val_loss: 10.6813\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2996 - val_loss: 9.8445\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0033 - val_loss: 10.7008\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3145 - val_loss: 10.6296\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.4030 - val_loss: 10.2775\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.2768 - val_loss: 10.9409\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 7.1222 - val_loss: 14.6297\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8173 - val_loss: 11.6248\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9538 - val_loss: 10.8751\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5609 - val_loss: 10.8710\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1703 - val_loss: 11.5938\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6749 - val_loss: 10.0077\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5193 - val_loss: 10.6134\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6676 - val_loss: 11.0471\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5513 - val_loss: 9.9217\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.4330 - val_loss: 11.3543\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9307 - val_loss: 10.5342\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4023 - val_loss: 10.5372\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3608 - val_loss: 10.7550\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3537 - val_loss: 10.8493\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5340 - val_loss: 15.0311\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4491 - val_loss: 11.2338\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5304 - val_loss: 10.5785\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2893 - val_loss: 10.3205\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6524 - val_loss: 9.9947\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3273 - val_loss: 14.8871\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.7505 - val_loss: 10.1434\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3255 - val_loss: 9.5795\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4509 - val_loss: 10.6381\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.025 - 0s 80us/step - loss: 7.0753 - val_loss: 10.6790\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1019 - val_loss: 11.0148\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.9642 - val_loss: 10.0833\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9965 - val_loss: 11.4008\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.0603 - val_loss: 9.3198\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 7.1693 - val_loss: 10.1428\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6209 - val_loss: 9.8775\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.7495 - val_loss: 10.4733\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2880 - val_loss: 11.0816\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.1591 - val_loss: 10.3240\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.3310 - val_loss: 9.1936\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9274 - val_loss: 10.8550\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1266 - val_loss: 11.2491\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6507 - val_loss: 9.7916\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0345 - val_loss: 10.4905\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2992 - val_loss: 9.5802\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4360 - val_loss: 10.9389\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4418 - val_loss: 10.2159\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1327 - val_loss: 10.8113\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.3389 - val_loss: 9.2299\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0413 - val_loss: 11.5751\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2088 - val_loss: 9.4448\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9071 - val_loss: 8.6442\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3412 - val_loss: 9.3560\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0175 - val_loss: 8.8993\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0215 - val_loss: 9.0932\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1775 - val_loss: 9.9621\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6359 - val_loss: 10.0022\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.0860 - val_loss: 9.9393\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1824 - val_loss: 9.6814\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2150 - val_loss: 9.6097\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4262 - val_loss: 11.2909\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.2616 - val_loss: 9.2700\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1597 - val_loss: 8.8359\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1039 - val_loss: 9.1036\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.4258 - val_loss: 9.2789\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.9243 - val_loss: 9.8687\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0270 - val_loss: 8.9884\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.2450 - val_loss: 9.6874\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.0417 - val_loss: 9.7904\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.1760 - val_loss: 11.1275\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8884 - val_loss: 9.7006\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0902 - val_loss: 9.1604\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7394 - val_loss: 11.6900\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1965 - val_loss: 9.5667\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3131 - val_loss: 10.2865\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9619 - val_loss: 9.0242\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5287 - val_loss: 8.7994\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4647 - val_loss: 9.3260\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1900 - val_loss: 9.3838\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6564 - val_loss: 9.7865\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0641 - val_loss: 10.1557\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4197 - val_loss: 9.3633\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0084 - val_loss: 8.9074\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 6.9217 - val_loss: 11.2844\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3983 - val_loss: 11.9836\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9511 - val_loss: 10.4433\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2309 - val_loss: 8.6339\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2245 - val_loss: 9.5568\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9578 - val_loss: 9.1253\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2345 - val_loss: 11.2688\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3751 - val_loss: 9.7413\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3317 - val_loss: 10.4054\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0917 - val_loss: 8.9395\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0368 - val_loss: 9.1246\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0305 - val_loss: 9.8617\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4811 - val_loss: 9.6958\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9036 - val_loss: 9.2385\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2889 - val_loss: 9.0555\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9517 - val_loss: 9.5412\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1189 - val_loss: 9.2175\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0503 - val_loss: 9.1764\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1100 - val_loss: 10.3750\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8661 - val_loss: 9.6218\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1150 - val_loss: 10.8560\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5198 - val_loss: 10.6558\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0609 - val_loss: 9.7338\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7826 - val_loss: 10.2566\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2428 - val_loss: 9.6121\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9804 - val_loss: 10.8977\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0411 - val_loss: 9.0007\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6935 - val_loss: 10.0323\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2267 - val_loss: 8.5243\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0695 - val_loss: 9.2439\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3889 - val_loss: 9.2232\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7669 - val_loss: 8.9121\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2381 - val_loss: 9.8059\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0430 - val_loss: 9.6312\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9156 - val_loss: 10.9355\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8642 - val_loss: 10.4264\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9791 - val_loss: 9.4539\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8824 - val_loss: 12.0163\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4285 - val_loss: 8.7061\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9805 - val_loss: 8.9706\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1790 - val_loss: 9.8503\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3705 - val_loss: 12.4121\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.2009 - val_loss: 9.1263\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8193 - val_loss: 9.8496\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.3356 - val_loss: 9.2820\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8641 - val_loss: 8.9403\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.5031 - val_loss: 10.0500\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9858 - val_loss: 9.0720\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.8865 - val_loss: 8.7070\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9635 - val_loss: 8.5317\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5598 - val_loss: 8.7840\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1360 - val_loss: 9.4608\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0317 - val_loss: 9.5025\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7216 - val_loss: 8.6542\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.9663 - val_loss: 9.0613\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.0903 - val_loss: 11.1657\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1154 - val_loss: 9.0564\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9480 - val_loss: 9.1784\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9431 - val_loss: 8.9717\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9335 - val_loss: 8.8208\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.8920 - val_loss: 8.9059\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4725 - val_loss: 10.7397\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8267 - val_loss: 10.0766\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8983 - val_loss: 9.3190\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6207 - val_loss: 9.8282\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.8238 - val_loss: 9.6534\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9609 - val_loss: 9.0670\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6612 - val_loss: 8.5811\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1536 - val_loss: 9.8291\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0284 - val_loss: 11.6489\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8008 - val_loss: 9.7266\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.3141 - val_loss: 10.4852\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8977 - val_loss: 8.6215\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1604 - val_loss: 8.7254\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.9690 - val_loss: 9.9051\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5833 - val_loss: 8.8066\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0763 - val_loss: 10.4681\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.1221 - val_loss: 9.8110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3373 - val_loss: 9.3952\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7773 - val_loss: 8.6689\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0862 - val_loss: 11.1018\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7215 - val_loss: 12.0745\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1103 - val_loss: 9.5018\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1138 - val_loss: 8.8330\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8398 - val_loss: 9.1220\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 6.6873 - val_loss: 9.2780\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5597 - val_loss: 9.2960\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.8016 - val_loss: 11.1767\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8072 - val_loss: 14.0884\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6903 - val_loss: 9.6660\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5441 - val_loss: 9.2633\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7002 - val_loss: 9.4417\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7139 - val_loss: 10.1420\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7516 - val_loss: 10.9327\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1216 - val_loss: 10.5312\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1324 - val_loss: 10.8632\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6991 - val_loss: 8.7124\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2242 - val_loss: 9.0622\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0794 - val_loss: 10.4330\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.0507 - val_loss: 8.9205\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9599 - val_loss: 10.0955\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.0352 - val_loss: 8.9581\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7175 - val_loss: 9.1586\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.3665 - val_loss: 8.9815\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6793 - val_loss: 10.4462\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8368 - val_loss: 9.3223\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0907 - val_loss: 10.4892\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8275 - val_loss: 10.1049\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6241 - val_loss: 9.0410\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6971 - val_loss: 11.5890\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9848 - val_loss: 8.9694\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3460 - val_loss: 10.5363\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3175 - val_loss: 10.0956\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8484 - val_loss: 8.9000\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1477 - val_loss: 9.0834\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5930 - val_loss: 9.1356\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8806 - val_loss: 12.0529\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3184 - val_loss: 10.7571\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2004 - val_loss: 8.8545\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6146 - val_loss: 9.6526\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6663 - val_loss: 9.3433\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6486 - val_loss: 8.9667\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2523 - val_loss: 9.0525\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7195 - val_loss: 8.6109\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9500 - val_loss: 9.2028\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7284 - val_loss: 9.0116\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2232 - val_loss: 10.3129\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7287 - val_loss: 8.8752\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6363 - val_loss: 9.0092\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1048 - val_loss: 9.7875\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5097 - val_loss: 9.2563\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3915 - val_loss: 9.1864\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7519 - val_loss: 9.1032\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8919 - val_loss: 9.4113\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0917 - val_loss: 10.7119\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9375 - val_loss: 9.4752\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1973 - val_loss: 9.1072\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9580 - val_loss: 9.2888\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8901 - val_loss: 10.5031\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8143 - val_loss: 10.2505\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3684 - val_loss: 9.1136\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4573 - val_loss: 9.5496\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1002 - val_loss: 8.9211\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8738 - val_loss: 9.4700\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1243 - val_loss: 9.7922\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.5383 - val_loss: 9.5208\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.9081 - val_loss: 9.4199\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 7.5196 - val_loss: 12.1435\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7596 - val_loss: 9.2440\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0690 - val_loss: 9.1771\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8624 - val_loss: 9.0732\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6772 - val_loss: 9.8150\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0304 - val_loss: 9.4539\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8703 - val_loss: 11.3472\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0775 - val_loss: 10.4772\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 7.0561 - val_loss: 10.1401\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9140 - val_loss: 9.0449\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.9307 - val_loss: 8.8229\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7379 - val_loss: 8.8477\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7718 - val_loss: 9.9051\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3811 - val_loss: 9.3597\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4883 - val_loss: 9.5803\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6985 - val_loss: 9.9174\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0339 - val_loss: 9.3760\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9612 - val_loss: 10.1242\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.1254 - val_loss: 9.1962\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7606 - val_loss: 9.1924\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7793 - val_loss: 9.0987\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1704 - val_loss: 9.2067\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7229 - val_loss: 9.6673\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6469 - val_loss: 11.7204\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3289 - val_loss: 8.8730\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6934 - val_loss: 10.0500\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7626 - val_loss: 11.5121\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0135 - val_loss: 9.3289\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9116 - val_loss: 9.6022\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6970 - val_loss: 10.3216\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1878 - val_loss: 10.3219\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9127 - val_loss: 9.4792\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0107 - val_loss: 11.5948\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0946 - val_loss: 9.8580\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8991 - val_loss: 9.8216\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8971 - val_loss: 9.5814\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8162 - val_loss: 11.2270\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6947 - val_loss: 9.0251\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9501 - val_loss: 9.3720\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7117 - val_loss: 10.1386\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9014 - val_loss: 9.4019\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8697 - val_loss: 8.9879\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9292 - val_loss: 9.3552\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7825 - val_loss: 10.7471\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8889 - val_loss: 9.8718\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8237 - val_loss: 9.3875\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5579 - val_loss: 9.3661\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6838 - val_loss: 9.8945\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7545 - val_loss: 11.0442\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7421 - val_loss: 8.8260\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7759 - val_loss: 10.4507\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.0121 - val_loss: 9.2084\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.1862 - val_loss: 8.7727\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5102 - val_loss: 8.8334\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5377 - val_loss: 9.5284\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1795 - val_loss: 10.8602\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9311 - val_loss: 10.6151\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7197 - val_loss: 9.2042\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0916 - val_loss: 9.7940\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5756 - val_loss: 9.0648\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8507 - val_loss: 8.9903\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.3881 - val_loss: 10.5151\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.6550 - val_loss: 9.1360\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8468 - val_loss: 10.2010\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0312 - val_loss: 8.9244\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9552 - val_loss: 10.8302\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6837 - val_loss: 8.9935\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8972 - val_loss: 9.7217\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0747 - val_loss: 9.0384\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8053 - val_loss: 9.5007\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4834 - val_loss: 9.4096\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8195 - val_loss: 8.6561\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6031 - val_loss: 9.0556\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6686 - val_loss: 8.9674\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2473 - val_loss: 8.9941\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6665 - val_loss: 8.6052\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8001 - val_loss: 9.3090\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6246 - val_loss: 9.3795\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6181 - val_loss: 9.6691\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.6634 - val_loss: 8.8042\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2255 - val_loss: 9.5121\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5227 - val_loss: 9.0760\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7641 - val_loss: 10.2549\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9633 - val_loss: 8.9182\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.7046 - val_loss: 12.5543\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7973 - val_loss: 10.1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.5569 - val_loss: 8.8692\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6983 - val_loss: 10.8994\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9084 - val_loss: 9.3215\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6958 - val_loss: 13.8138\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0282 - val_loss: 10.5733\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9655 - val_loss: 8.6908\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7683 - val_loss: 9.6533\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6970 - val_loss: 9.6685\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 6.9510 - val_loss: 8.6271\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.1501 - val_loss: 9.2093\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.6017 - val_loss: 9.0751\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2037 - val_loss: 9.9505\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6333 - val_loss: 9.3137\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7585 - val_loss: 8.9904\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0310 - val_loss: 9.2497\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8390 - val_loss: 10.0743\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4691 - val_loss: 9.6002\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 7.0955 - val_loss: 8.8781\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2312 - val_loss: 9.4737\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8876 - val_loss: 9.3680\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.2145 - val_loss: 9.5547\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6233 - val_loss: 9.9829\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7749 - val_loss: 9.2991\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1542 - val_loss: 9.4151\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2586 - val_loss: 8.7527\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7433 - val_loss: 9.0725\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.8250 - val_loss: 9.3521\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8490 - val_loss: 8.9672\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.3469 - val_loss: 10.4522\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7442 - val_loss: 8.9187\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.0020 - val_loss: 9.1661\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8883 - val_loss: 11.3455\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.1243 - val_loss: 9.0303\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9014 - val_loss: 9.7669\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7060 - val_loss: 9.7458\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7829 - val_loss: 9.0551\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8882 - val_loss: 10.4148\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8020 - val_loss: 9.1412\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6370 - val_loss: 10.5227\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6431 - val_loss: 10.6224\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7793 - val_loss: 9.6033\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7974 - val_loss: 9.0687\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8172 - val_loss: 9.1770\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8005 - val_loss: 10.1391\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8614 - val_loss: 9.2592\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5006 - val_loss: 9.7031\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7250 - val_loss: 8.9981\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8545 - val_loss: 10.6080\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7570 - val_loss: 8.8805\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7228 - val_loss: 10.3922\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.6322 - val_loss: 9.0081\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.1615 - val_loss: 9.3741\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8453 - val_loss: 9.1743\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.7337 - val_loss: 11.2836\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7852 - val_loss: 8.7470\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6707 - val_loss: 8.2752\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0464 - val_loss: 8.7728\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9320 - val_loss: 9.1616\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9552 - val_loss: 10.1288\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7240 - val_loss: 8.6061\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7062 - val_loss: 8.9964\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5240 - val_loss: 9.1085\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8175 - val_loss: 9.0961\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5422 - val_loss: 8.9221\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9112 - val_loss: 11.0361\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7507 - val_loss: 9.8078\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.0650 - val_loss: 10.6888\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4942 - val_loss: 9.1658\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6815 - val_loss: 9.4607\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8328 - val_loss: 9.0269\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7815 - val_loss: 10.3813\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7778 - val_loss: 8.9985\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9983 - val_loss: 9.5215\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6390 - val_loss: 10.4831\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5568 - val_loss: 9.5509\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6275 - val_loss: 9.3812\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8330 - val_loss: 9.0060\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7194 - val_loss: 9.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1054 - val_loss: 9.0537\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8800 - val_loss: 9.2364\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6842 - val_loss: 8.5482\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1119 - val_loss: 9.9207\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8751 - val_loss: 9.2797\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8266 - val_loss: 8.8021\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.4704 - val_loss: 9.4937\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5246 - val_loss: 8.9610\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8133 - val_loss: 9.9572\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0055 - val_loss: 8.6653\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1737 - val_loss: 8.7696\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.6242 - val_loss: 10.7888\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6379 - val_loss: 8.8285\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9802 - val_loss: 8.6538\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0283 - val_loss: 9.8078\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5330 - val_loss: 12.2664\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9868 - val_loss: 8.7947\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 6.5174 - val_loss: 9.0130\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5663 - val_loss: 10.8343\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9949 - val_loss: 9.5396\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9885 - val_loss: 8.7432\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.9877 - val_loss: 10.1880\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6953 - val_loss: 10.6436\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7783 - val_loss: 8.9679\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9923 - val_loss: 10.3475\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8238 - val_loss: 9.0382\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.6815 - val_loss: 9.2601\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5142 - val_loss: 8.8006\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6272 - val_loss: 9.7724\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1034 - val_loss: 8.8032\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6309 - val_loss: 9.1811\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.9096 - val_loss: 8.9809\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4561 - val_loss: 8.9504\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.5842 - val_loss: 9.4029\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0215 - val_loss: 8.9241\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7319 - val_loss: 9.0516\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5727 - val_loss: 10.3787\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7618 - val_loss: 8.6581\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7285 - val_loss: 10.7748\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.8900 - val_loss: 9.0289\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.5793 - val_loss: 9.1881\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6834 - val_loss: 10.2035\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9382 - val_loss: 10.4788\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4972 - val_loss: 9.1681\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5587 - val_loss: 8.8661\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7149 - val_loss: 10.4465\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5008 - val_loss: 9.0006\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8231 - val_loss: 8.7846\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.2856 - val_loss: 8.7079\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8495 - val_loss: 8.9507\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5485 - val_loss: 8.5914\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3663 - val_loss: 9.7019\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6107 - val_loss: 10.1681\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.8819 - val_loss: 9.9338\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6176 - val_loss: 10.8358\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7132 - val_loss: 8.6242\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8039 - val_loss: 8.7660\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8283 - val_loss: 9.0295\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9097 - val_loss: 8.8371\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3729 - val_loss: 8.6133\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6040 - val_loss: 8.8569\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6511 - val_loss: 11.6506\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5299 - val_loss: 9.3566\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8559 - val_loss: 8.9408\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3461 - val_loss: 9.5300\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6201 - val_loss: 9.3475\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9001 - val_loss: 8.7606\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8985 - val_loss: 8.4114\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4828 - val_loss: 8.9352\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7371 - val_loss: 9.6719\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8847 - val_loss: 9.2780\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.1659 - val_loss: 10.0437\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7208 - val_loss: 9.2234\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 6.6675 - val_loss: 9.4878\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6735 - val_loss: 9.0065\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.7117 - val_loss: 9.2723\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5767 - val_loss: 8.8532\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6076 - val_loss: 8.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9519 - val_loss: 8.9136\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4955 - val_loss: 9.6921\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9545 - val_loss: 8.5998\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5423 - val_loss: 10.2811\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3277 - val_loss: 9.6422\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6766 - val_loss: 10.4028\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7901 - val_loss: 9.2450\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5446 - val_loss: 8.8362\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3940 - val_loss: 9.7772\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8691 - val_loss: 10.0274\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4752 - val_loss: 10.3566\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6368 - val_loss: 8.6463\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.0321 - val_loss: 8.9823\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6519 - val_loss: 9.5650\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8958 - val_loss: 10.5353\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8739 - val_loss: 8.5718\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5309 - val_loss: 10.6307\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8594 - val_loss: 9.1278\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7575 - val_loss: 9.5505\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.9466 - val_loss: 8.6332\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6334 - val_loss: 12.1137\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9682 - val_loss: 8.8549\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6283 - val_loss: 9.8695\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8130 - val_loss: 9.3759\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0236 - val_loss: 9.9313\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6451 - val_loss: 9.0578\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3904 - val_loss: 8.8363\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5970 - val_loss: 8.6873\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7132 - val_loss: 11.7457\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8459 - val_loss: 9.5542\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4385 - val_loss: 10.2611\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5900 - val_loss: 11.0225\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.5957 - val_loss: 9.4744\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3397 - val_loss: 10.5979\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 6.8373 - val_loss: 8.5280\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.7122 - val_loss: 9.6726\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5097 - val_loss: 9.4926\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5513 - val_loss: 8.4607\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.5573 - val_loss: 11.4150\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3164 - val_loss: 9.9621\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6231 - val_loss: 8.9120\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8056 - val_loss: 8.4434\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4177 - val_loss: 9.0410\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4589 - val_loss: 10.7312\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5588 - val_loss: 8.8186\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6455 - val_loss: 11.5830\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7642 - val_loss: 9.4500\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7833 - val_loss: 8.5574\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.4985 - val_loss: 8.6308\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3132 - val_loss: 8.4413\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.5225 - val_loss: 9.3244\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6305 - val_loss: 9.2134\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9339 - val_loss: 8.7091\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7936 - val_loss: 9.2070\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.3575 - val_loss: 9.2643\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.0699 - val_loss: 9.0611\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4997 - val_loss: 8.7371\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6218 - val_loss: 8.7565\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7646 - val_loss: 8.9624\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5296 - val_loss: 8.5908\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9016 - val_loss: 9.5048\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.4254 - val_loss: 8.7675\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6492 - val_loss: 8.6576\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7666 - val_loss: 9.1313\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6221 - val_loss: 8.7282\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6500 - val_loss: 11.9141\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9412 - val_loss: 10.3367\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.3388 - val_loss: 9.2260\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9036 - val_loss: 11.6257\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8858 - val_loss: 8.9443\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4684 - val_loss: 9.6664\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.8196 - val_loss: 9.2508\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.7602 - val_loss: 10.4288\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8452 - val_loss: 10.5162\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6603 - val_loss: 12.6576\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.2359 - val_loss: 9.5990\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.3317 - val_loss: 9.1932\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.5298 - val_loss: 8.8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7794 - val_loss: 10.2342\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7360 - val_loss: 9.1056\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6288 - val_loss: 8.4611\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1763 - val_loss: 10.1321\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4756 - val_loss: 9.0405\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5886 - val_loss: 8.5278\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7841 - val_loss: 10.0414\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6657 - val_loss: 8.8930\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7880 - val_loss: 9.1111\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7177 - val_loss: 10.0484\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.6015 - val_loss: 10.0601\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6684 - val_loss: 9.1362\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.5981 - val_loss: 9.2827\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.3872 - val_loss: 9.9966\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 6.6436 - val_loss: 8.9464\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6200 - val_loss: 9.0819\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.3824 - val_loss: 10.0020\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.5476 - val_loss: 8.2567\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4232 - val_loss: 9.2742\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9979 - val_loss: 8.5732\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.2363 - val_loss: 10.8857\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5733 - val_loss: 9.2266\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0195 - val_loss: 8.5325\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4352 - val_loss: 8.8798\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3121 - val_loss: 8.5068\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7462 - val_loss: 10.1294\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.4744 - val_loss: 11.0425\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5144 - val_loss: 9.2018\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7748 - val_loss: 8.6461\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6010 - val_loss: 9.0825\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.3576 - val_loss: 8.9068\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9448 - val_loss: 8.6554\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7055 - val_loss: 9.6823\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5975 - val_loss: 9.0276\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4732 - val_loss: 11.7272\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6231 - val_loss: 9.2146\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5331 - val_loss: 9.8590\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5789 - val_loss: 8.4950\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5294 - val_loss: 9.5304\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9722 - val_loss: 8.6459\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4779 - val_loss: 9.8307\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4940 - val_loss: 10.3501\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7548 - val_loss: 8.5682\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2097 - val_loss: 9.8802\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6181 - val_loss: 8.8550\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4640 - val_loss: 9.3663\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8759 - val_loss: 10.4535\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5034 - val_loss: 10.1195\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3922 - val_loss: 11.5758\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7929 - val_loss: 9.2007\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3168 - val_loss: 8.7550\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4331 - val_loss: 8.6727\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7739 - val_loss: 8.9270\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.5183 - val_loss: 10.0291\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7485 - val_loss: 8.8446\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5622 - val_loss: 8.7404\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.5311 - val_loss: 8.5727\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.8013 - val_loss: 8.4354\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5099 - val_loss: 8.5814\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8239 - val_loss: 10.3932\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4226 - val_loss: 8.8337\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3522 - val_loss: 11.7921\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3491 - val_loss: 9.5239\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4824 - val_loss: 9.0212\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2355 - val_loss: 9.9678\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7459 - val_loss: 9.3184\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7057 - val_loss: 9.1405\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4587 - val_loss: 8.7119\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6323 - val_loss: 8.2271\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.3468 - val_loss: 8.8837\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6069 - val_loss: 8.2488\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.7712 - val_loss: 8.4929\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4780 - val_loss: 9.9048\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 6.8428 - val_loss: 9.1897\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.3191 - val_loss: 9.2383\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5257 - val_loss: 8.9750\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7843 - val_loss: 8.8660\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8061 - val_loss: 8.5643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5140 - val_loss: 8.7493\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5232 - val_loss: 9.6769\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5737 - val_loss: 9.1654\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 6.3546 - val_loss: 8.7843\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3402 - val_loss: 8.7102\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.9579 - val_loss: 8.5108\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2286 - val_loss: 8.5187\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.9531 - val_loss: 8.5236\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.8266 - val_loss: 11.7530\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2927 - val_loss: 9.0067\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5821 - val_loss: 8.8537\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5258 - val_loss: 10.4676\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4796 - val_loss: 8.5685\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5987 - val_loss: 9.7723\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4225 - val_loss: 8.4152\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.4702 - val_loss: 10.6403\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3724 - val_loss: 8.5723\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6580 - val_loss: 9.2025\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3496 - val_loss: 9.2971\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6244 - val_loss: 11.7042\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 7.0373 - val_loss: 8.6793\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2084 - val_loss: 8.8763\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3085 - val_loss: 8.4285\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5281 - val_loss: 8.9807\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6647 - val_loss: 10.2659\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5557 - val_loss: 8.5476\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.3283 - val_loss: 9.2181\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5715 - val_loss: 9.2269\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6696 - val_loss: 10.9449\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9971 - val_loss: 8.4048\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6233 - val_loss: 8.9564\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8538 - val_loss: 8.4570\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3665 - val_loss: 8.7349\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.5609 - val_loss: 9.1294\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3424 - val_loss: 8.7867\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.2502 - val_loss: 10.0585\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.5025 - val_loss: 8.4604\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6181 - val_loss: 8.5104\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0345 - val_loss: 8.1528\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.2196 - val_loss: 9.2935\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0277 - val_loss: 8.7652\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6713 - val_loss: 8.7300\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7445 - val_loss: 9.9353\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.2044 - val_loss: 8.8163\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4204 - val_loss: 10.5744\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4547 - val_loss: 8.8321\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3089 - val_loss: 8.8578\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4647 - val_loss: 8.7641\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6708 - val_loss: 9.7272\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3711 - val_loss: 10.6801\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4144 - val_loss: 8.7094\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.9486 - val_loss: 8.7161\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.6319 - val_loss: 8.2418\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.2537 - val_loss: 9.3440\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7352 - val_loss: 8.4445\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3108 - val_loss: 8.6169\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4760 - val_loss: 8.3145\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4288 - val_loss: 8.3743\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7702 - val_loss: 9.5015\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4561 - val_loss: 9.0571\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.3767 - val_loss: 10.7970\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.1963 - val_loss: 9.6786\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3105 - val_loss: 8.7426\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4701 - val_loss: 9.1188\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.7431 - val_loss: 10.5480\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.4081 - val_loss: 8.8713\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.6044 - val_loss: 7.9919\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 6.5863 - val_loss: 10.1455\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.3843 - val_loss: 8.3075\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.4139 - val_loss: 8.8828\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.2290 - val_loss: 9.6759\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5945 - val_loss: 8.4601\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.3182 - val_loss: 8.6409\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.7670 - val_loss: 8.7608\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4608 - val_loss: 9.2378\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6461 - val_loss: 8.9352\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6219 - val_loss: 8.7680\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.0379 - val_loss: 10.7107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.6310 - val_loss: 10.2097\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.0677 - val_loss: 9.2315\n",
      "6.500162262027547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.0521784 , -1.4634523 ,  0.24550739, -0.28013533,  2.3670235 ],\n",
       "        [-0.4546824 ,  0.7057921 , -0.28376585,  0.23984396, -0.8959627 ],\n",
       "        [ 0.0064298 , -0.40686595,  0.281486  , -0.16083458, -0.2598355 ],\n",
       "        [ 0.5495598 , -1.0339217 ,  0.24700904, -0.7688213 ,  0.02956627],\n",
       "        [ 0.9584423 , -0.11621504, -0.22384478, -0.07986287,  0.01109351],\n",
       "        [ 0.47399732,  0.14581347, -1.1508749 ,  0.30089086, -0.02158288],\n",
       "        [-2.706805  ,  0.19745488,  0.07130721, -0.1323318 , -0.0571162 ]],\n",
       "       dtype=float32),\n",
       " array([-3.4098234, -0.4919587,  0.898459 ,  2.5389068,  1.4642333],\n",
       "       dtype=float32),\n",
       " array([[-0.42316115, -0.17429447, -0.19959188,  0.4047146 ,  0.7717366 ,\n",
       "          0.16241725,  0.0995411 ,  0.96356   ,  0.8580517 ,  0.24760881],\n",
       "        [-0.5710858 , -1.3214453 ,  0.7669146 , -0.34433833, -0.4714625 ,\n",
       "         -1.1420454 , -0.73165995, -1.4162073 , -0.7130513 ,  1.10632   ],\n",
       "        [-0.13199677, -0.07315946, -0.43981776,  0.9576466 ,  1.0045608 ,\n",
       "          0.7266145 ,  0.6845478 , -0.05125962,  0.8441416 , -0.6992406 ],\n",
       "        [ 0.11818451, -0.8587168 ,  0.10772494, -0.14692163, -0.41558746,\n",
       "         -0.7897178 , -1.124136  , -0.99068916, -1.0834894 ,  1.334677  ],\n",
       "        [-1.0120684 , -1.0328679 ,  1.2079678 , -0.31807765, -0.5789207 ,\n",
       "         -1.0947009 , -0.5749142 , -0.9339678 , -0.70249546,  0.6058816 ]],\n",
       "       dtype=float32),\n",
       " array([-0.6218747 , -1.0882821 ,  1.0291587 , -0.91096616, -0.9798771 ,\n",
       "        -1.1114923 , -1.0591949 , -1.0870541 , -1.1066515 ,  1.0574178 ],\n",
       "       dtype=float32),\n",
       " array([[-0.23026025],\n",
       "        [-1.0043865 ],\n",
       "        [ 0.91176593],\n",
       "        [-0.51496226],\n",
       "        [-0.71854883],\n",
       "        [-1.4392706 ],\n",
       "        [-0.7594005 ],\n",
       "        [-1.209534  ],\n",
       "        [-1.4121642 ],\n",
       "        [ 0.95300853]], dtype=float32),\n",
       " array([1.2985653], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, RMSprop, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_rmsprop_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1526 - val_loss: 0.0289\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0530 - val_loss: 0.0245\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0332 - val_loss: 0.0140\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0172 - val_loss: 0.0087\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0128 - val_loss: 0.0064\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0110 - val_loss: 0.0061\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0097 - val_loss: 0.0076\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0086 - val_loss: 0.0126\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 119us/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0095 - val_loss: 0.0070\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 91us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0059\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 126us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0075\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0062\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0076\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0082\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0078\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 98us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0057\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0063\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0088\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0035 - val_loss: 0.0072\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0073\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0068\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0064\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 97us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0088\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 223us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0028 - val_loss: 0.0076\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0063\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0071\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 134us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0066\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0064\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "0.013300913386046886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.52834713,  0.83573353,  0.45333087, -1.0012491 ,  0.25445122],\n",
       "        [ 0.46199694, -0.53941554,  0.2279119 ,  0.470724  ,  0.44075856],\n",
       "        [ 0.18718725,  0.15935434, -0.65702283,  1.1528752 , -0.19122952],\n",
       "        [ 0.26919115, -0.8904483 ,  0.36593682,  0.8754819 ,  0.40851948],\n",
       "        [ 0.2359367 ,  0.23076123, -0.00981364,  0.4126433 ,  0.0516181 ],\n",
       "        [ 0.7032039 ,  0.68483526,  0.44021496, -1.0094972 , -0.04320224],\n",
       "        [ 1.272396  ,  0.75202674,  0.5903234 ,  0.18815467,  0.07545901],\n",
       "        [-0.09521749, -0.24956042,  0.32168663,  0.12720127,  0.5466123 ],\n",
       "        [ 0.5446358 ,  0.74242383, -0.278611  , -0.2065337 , -0.40705204],\n",
       "        [-0.50552255, -0.22874223, -0.09178159,  0.09345325,  1.0397775 ],\n",
       "        [ 0.14352739, -0.13192219, -1.1096328 ,  0.35714725, -0.7433681 ],\n",
       "        [-1.0881563 , -0.6195883 , -0.7163196 , -0.17440686, -0.06130821],\n",
       "        [-0.7716965 , -0.38335508, -0.2565474 ,  0.09834147,  0.02720609],\n",
       "        [-0.11780426, -0.37827343, -1.4271189 , -2.22268   , -0.32066235],\n",
       "        [-0.1639678 , -0.80214095,  0.11220414,  0.07329514, -0.15189154],\n",
       "        [-0.49009985,  0.3848516 , -0.25758097, -0.02396008,  0.42418197],\n",
       "        [ 0.0186279 , -0.5992737 ,  1.5158395 ,  0.48387462,  0.836419  ],\n",
       "        [ 0.03836698, -0.42206144, -0.716243  , -0.47510958,  0.17504057],\n",
       "        [ 0.27976853, -0.53015965, -1.3951957 , -0.02817189, -1.4042172 ],\n",
       "        [-0.18947352, -0.35206297, -0.3050586 , -0.3145901 , -0.16009778],\n",
       "        [ 0.2837416 , -0.0795331 ,  0.28438088,  2.665116  , -0.270422  ],\n",
       "        [-0.09262886, -0.23330203, -0.44228652,  0.63120806,  0.50843465]],\n",
       "       dtype=float32),\n",
       " array([ 0.17049749, -0.16890024, -0.10675002,  0.4870269 ,  0.26810265],\n",
       "       dtype=float32),\n",
       " array([[-0.09891125, -0.25936854, -0.28690434, -0.02435916,  0.16801448,\n",
       "          0.19882625,  0.65613514,  0.1333101 , -0.08557455, -0.25086883],\n",
       "        [ 0.13879833, -0.06147862,  0.08134876,  0.75505817,  0.15673086,\n",
       "          0.14429298,  0.20411637, -0.3963936 ,  0.40605626,  0.03336571],\n",
       "        [-0.33666098,  0.18518528,  0.10715389,  0.4509762 ,  0.20183818,\n",
       "         -0.02684827, -0.28319776,  0.24322696,  0.71405077,  0.05984787],\n",
       "        [ 0.14511096, -0.02627329,  0.74654895,  0.29341474, -0.01106122,\n",
       "          0.16577706, -0.8448025 ,  0.15099093,  0.84299797, -0.05132347],\n",
       "        [ 0.16015616,  0.16825663, -0.33138344,  0.10504863,  0.14356871,\n",
       "         -0.12159442,  0.7229099 , -0.56105185, -0.5720543 ,  0.01668572]],\n",
       "       dtype=float32),\n",
       " array([-0.31771168,  0.12035585, -0.11627038,  0.10394531, -0.02025075,\n",
       "        -0.10573407, -0.05305393,  0.20040491,  0.14476132,  0.20682262],\n",
       "       dtype=float32),\n",
       " array([[-0.01141649],\n",
       "        [-0.00697642],\n",
       "        [-0.03350264],\n",
       "        [-0.17762233],\n",
       "        [-0.0082745 ],\n",
       "        [-0.00122851],\n",
       "        [ 0.3291451 ],\n",
       "        [ 0.01023164],\n",
       "        [-0.2697398 ],\n",
       "        [ 0.00070391]], dtype=float32),\n",
       " array([0.06651939], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_adam_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1086\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1098 - val_loss: 0.1085\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1096 - val_loss: 0.1082\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1094 - val_loss: 0.1080\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1091 - val_loss: 0.1077\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1089 - val_loss: 0.1074\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1086 - val_loss: 0.1071\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1083 - val_loss: 0.1068\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.1080 - val_loss: 0.1065\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1078 - val_loss: 0.1062\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1075 - val_loss: 0.1059\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.1072 - val_loss: 0.1056\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1069 - val_loss: 0.1053\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.1066 - val_loss: 0.1051\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.1063 - val_loss: 0.1048\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1061 - val_loss: 0.1045\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.1058 - val_loss: 0.1042\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.1055 - val_loss: 0.1039\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1052 - val_loss: 0.1036\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1050 - val_loss: 0.1033\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1047 - val_loss: 0.1031\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.1044 - val_loss: 0.1028\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.1041 - val_loss: 0.1025\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.1039 - val_loss: 0.1022\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 86us/step - loss: 0.1036 - val_loss: 0.1019\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.1033 - val_loss: 0.1017\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1031 - val_loss: 0.1014\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1028 - val_loss: 0.1011\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1026 - val_loss: 0.1009\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1023 - val_loss: 0.1006\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.1020 - val_loss: 0.1003\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1018 - val_loss: 0.1000\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1015 - val_loss: 0.0998\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.1013 - val_loss: 0.0995\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.1010 - val_loss: 0.0992\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1008 - val_loss: 0.0990\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1005 - val_loss: 0.0987\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.1003 - val_loss: 0.0985\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1000 - val_loss: 0.0982\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0998 - val_loss: 0.0980\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0995 - val_loss: 0.0977\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0993 - val_loss: 0.0974\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0990 - val_loss: 0.0972\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0988 - val_loss: 0.0969\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0985 - val_loss: 0.0967\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0983 - val_loss: 0.0964\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0981 - val_loss: 0.0962\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0978 - val_loss: 0.0959\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0976 - val_loss: 0.0957\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0973 - val_loss: 0.0954\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0971 - val_loss: 0.0952\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0969 - val_loss: 0.0949\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0966 - val_loss: 0.0947\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0964 - val_loss: 0.0944\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 82us/step - loss: 0.0962 - val_loss: 0.0942\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0959 - val_loss: 0.0940\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0957 - val_loss: 0.0937\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0955 - val_loss: 0.0935\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0952 - val_loss: 0.0932\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0950 - val_loss: 0.0930\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0948 - val_loss: 0.0928\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 81us/step - loss: 0.0945 - val_loss: 0.0925\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0943 - val_loss: 0.0923\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0941 - val_loss: 0.0921\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0939 - val_loss: 0.0918\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0937 - val_loss: 0.0916\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0934 - val_loss: 0.0914\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0932 - val_loss: 0.0911\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 101us/step - loss: 0.0930 - val_loss: 0.0909\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0928 - val_loss: 0.0907\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0926 - val_loss: 0.0905\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0924 - val_loss: 0.0902\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0921 - val_loss: 0.0900\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0919 - val_loss: 0.0898\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0917 - val_loss: 0.0896\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0915 - val_loss: 0.0893\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0913 - val_loss: 0.0891\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0911 - val_loss: 0.0889\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0909 - val_loss: 0.0887\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0907 - val_loss: 0.0885\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0905 - val_loss: 0.0883\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0903 - val_loss: 0.0881\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0901 - val_loss: 0.0878\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0899 - val_loss: 0.0876\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0897 - val_loss: 0.0874\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0895 - val_loss: 0.0872\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0893 - val_loss: 0.0870\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0891 - val_loss: 0.0868\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0889 - val_loss: 0.0866\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0887 - val_loss: 0.0864\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0885 - val_loss: 0.0862\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0883 - val_loss: 0.0860\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0881 - val_loss: 0.0858\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0879 - val_loss: 0.0856\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0877 - val_loss: 0.0854\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0875 - val_loss: 0.0852\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0874 - val_loss: 0.0850\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0871 - val_loss: 0.0848\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0870 - val_loss: 0.0846\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0868 - val_loss: 0.0844\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0866 - val_loss: 0.0842\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0864 - val_loss: 0.0840\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0862 - val_loss: 0.0838\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0860 - val_loss: 0.0836\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0858 - val_loss: 0.0834\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0856 - val_loss: 0.0832\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0854 - val_loss: 0.0830\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0853 - val_loss: 0.0828\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0851 - val_loss: 0.0826\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0849 - val_loss: 0.0824\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0847 - val_loss: 0.0822\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0845 - val_loss: 0.0820\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0844 - val_loss: 0.0818\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0842 - val_loss: 0.0816\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0840 - val_loss: 0.0815\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0839 - val_loss: 0.0813\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0837 - val_loss: 0.0811\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0835 - val_loss: 0.0809\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0833 - val_loss: 0.0807\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0832 - val_loss: 0.0806\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0830 - val_loss: 0.0804\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0828 - val_loss: 0.0802\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0827 - val_loss: 0.0800\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0825 - val_loss: 0.0798\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0823 - val_loss: 0.0796\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0821 - val_loss: 0.0795\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0820 - val_loss: 0.0793\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0818 - val_loss: 0.0791\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0816 - val_loss: 0.0789\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0815 - val_loss: 0.0788\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0813 - val_loss: 0.0786\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0812 - val_loss: 0.0784\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0810 - val_loss: 0.0783\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0808 - val_loss: 0.0781\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0807 - val_loss: 0.0779\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0805 - val_loss: 0.0778\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0804 - val_loss: 0.0776\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0802 - val_loss: 0.0774\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0801 - val_loss: 0.0773\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0799 - val_loss: 0.0771\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0797 - val_loss: 0.0769\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0796 - val_loss: 0.0767\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0794 - val_loss: 0.0766\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0793 - val_loss: 0.0764\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0791 - val_loss: 0.0762\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0790 - val_loss: 0.0761\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0788 - val_loss: 0.0759\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0787 - val_loss: 0.0758\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0785 - val_loss: 0.0756\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0784 - val_loss: 0.0754\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0782 - val_loss: 0.0753\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0781 - val_loss: 0.0751\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0779 - val_loss: 0.0750\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 80us/step - loss: 0.0778 - val_loss: 0.0748\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0776 - val_loss: 0.0747\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0775 - val_loss: 0.0745\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0773 - val_loss: 0.0743\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0772 - val_loss: 0.0742\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0770 - val_loss: 0.0740\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0769 - val_loss: 0.0739\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0768 - val_loss: 0.0737\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0766 - val_loss: 0.0736\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0765 - val_loss: 0.0734\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0763 - val_loss: 0.0733\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0762 - val_loss: 0.0731\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0761 - val_loss: 0.0730\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0759 - val_loss: 0.0728\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0758 - val_loss: 0.0727\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0757 - val_loss: 0.0725\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0754 - val_loss: 0.0722\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0752 - val_loss: 0.0721\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0751 - val_loss: 0.0720\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0750 - val_loss: 0.0718\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0748 - val_loss: 0.0717\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0747 - val_loss: 0.0715\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0746 - val_loss: 0.0714\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0745 - val_loss: 0.0712\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0743 - val_loss: 0.0711\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0742 - val_loss: 0.0710\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0741 - val_loss: 0.0708\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0739 - val_loss: 0.0707\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0738 - val_loss: 0.0705\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0737 - val_loss: 0.0704\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0735 - val_loss: 0.0703\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0734 - val_loss: 0.0701\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0733 - val_loss: 0.0700\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0732 - val_loss: 0.0699\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0730 - val_loss: 0.0697\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0729 - val_loss: 0.0696\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0728 - val_loss: 0.0695\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0727 - val_loss: 0.0693\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0726 - val_loss: 0.0692\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0724 - val_loss: 0.0691\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0723 - val_loss: 0.0689\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0722 - val_loss: 0.0688\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0721 - val_loss: 0.0687\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0720 - val_loss: 0.0685\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0718 - val_loss: 0.0684\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0717 - val_loss: 0.0683\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0716 - val_loss: 0.0682\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0715 - val_loss: 0.0680\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0714 - val_loss: 0.0679\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0712 - val_loss: 0.0678\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0711 - val_loss: 0.0676\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0710 - val_loss: 0.0675\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0709 - val_loss: 0.0674\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0708 - val_loss: 0.0673\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0707 - val_loss: 0.0671\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0706 - val_loss: 0.0670\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0704 - val_loss: 0.0669\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0703 - val_loss: 0.0668\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0702 - val_loss: 0.0667\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0701 - val_loss: 0.0665\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0700 - val_loss: 0.0664\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0699 - val_loss: 0.0663\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0698 - val_loss: 0.0662\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0697 - val_loss: 0.0661\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0695 - val_loss: 0.0659\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0694 - val_loss: 0.0658\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0693 - val_loss: 0.0657\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0692 - val_loss: 0.0656\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0691 - val_loss: 0.0655\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0690 - val_loss: 0.0653\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 89us/step - loss: 0.0689 - val_loss: 0.0652\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0688 - val_loss: 0.0651\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0687 - val_loss: 0.0650\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0686 - val_loss: 0.0649\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0685 - val_loss: 0.0648\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0684 - val_loss: 0.0647\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0683 - val_loss: 0.0645\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0682 - val_loss: 0.0644\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0681 - val_loss: 0.0643\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0680 - val_loss: 0.0642\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0679 - val_loss: 0.0641\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0678 - val_loss: 0.0640\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0677 - val_loss: 0.0639\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0676 - val_loss: 0.0637\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0674 - val_loss: 0.0636\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.0674 - val_loss: 0.0635\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0672 - val_loss: 0.0634\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0671 - val_loss: 0.0633\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0670 - val_loss: 0.0632\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0669 - val_loss: 0.0631\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0668 - val_loss: 0.0630\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0668 - val_loss: 0.0629\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0666 - val_loss: 0.0628\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0666 - val_loss: 0.0627\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0665 - val_loss: 0.0625\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0664 - val_loss: 0.0624\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0663 - val_loss: 0.0623\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0662 - val_loss: 0.0622\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0661 - val_loss: 0.0621\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0660 - val_loss: 0.0620\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0659 - val_loss: 0.0619\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0658 - val_loss: 0.0618\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0657 - val_loss: 0.0617\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0656 - val_loss: 0.0616\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0655 - val_loss: 0.0615\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0654 - val_loss: 0.0614\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0613\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0653 - val_loss: 0.0612\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0652 - val_loss: 0.0611\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0651 - val_loss: 0.0610\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0650 - val_loss: 0.0609\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0649 - val_loss: 0.0608\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0648 - val_loss: 0.0607\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0647 - val_loss: 0.0606\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0646 - val_loss: 0.0605\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0646 - val_loss: 0.0604\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0645 - val_loss: 0.0603\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0644 - val_loss: 0.0602\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0643 - val_loss: 0.0602\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0642 - val_loss: 0.0601\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0641 - val_loss: 0.0600\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0640 - val_loss: 0.0599\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0640 - val_loss: 0.0598\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0639 - val_loss: 0.0597\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0638 - val_loss: 0.0596\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0637 - val_loss: 0.0595\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0636 - val_loss: 0.0594\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0635 - val_loss: 0.0593\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0634 - val_loss: 0.0592\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0634 - val_loss: 0.0591\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0633 - val_loss: 0.0590\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0632 - val_loss: 0.0589\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0631 - val_loss: 0.0588\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0630 - val_loss: 0.0588\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0630 - val_loss: 0.0587\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0629 - val_loss: 0.0586\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0628 - val_loss: 0.0585\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0627 - val_loss: 0.0584\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0626 - val_loss: 0.0583\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0626 - val_loss: 0.0582\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0625 - val_loss: 0.0581\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0624 - val_loss: 0.0581\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0623 - val_loss: 0.0580\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0623 - val_loss: 0.0579\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0622 - val_loss: 0.0578\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0621 - val_loss: 0.0577\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0620 - val_loss: 0.0576\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0620 - val_loss: 0.0575\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0619 - val_loss: 0.0575\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0618 - val_loss: 0.0574\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0617 - val_loss: 0.0573\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0617 - val_loss: 0.0572\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0616 - val_loss: 0.0571\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0615 - val_loss: 0.0571\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0614 - val_loss: 0.0570\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0614 - val_loss: 0.0569\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0613 - val_loss: 0.0568\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0612 - val_loss: 0.0567\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0612 - val_loss: 0.0566\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0611 - val_loss: 0.0566\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0610 - val_loss: 0.0565\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0609 - val_loss: 0.0564\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0609 - val_loss: 0.0563\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0608 - val_loss: 0.0562\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0607 - val_loss: 0.0562\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0607 - val_loss: 0.0561\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0606 - val_loss: 0.0560\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0605 - val_loss: 0.0559\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0605 - val_loss: 0.0559\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0604 - val_loss: 0.0558\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0603 - val_loss: 0.0557\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.072 - 0s 87us/step - loss: 0.0603 - val_loss: 0.0556\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0602 - val_loss: 0.0556\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0601 - val_loss: 0.0555\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0601 - val_loss: 0.0554\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0600 - val_loss: 0.0553\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0599 - val_loss: 0.0552\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0599 - val_loss: 0.0552\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0598 - val_loss: 0.0551\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0597 - val_loss: 0.0550\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0597 - val_loss: 0.0550\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0596 - val_loss: 0.0549\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0595 - val_loss: 0.0548\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0595 - val_loss: 0.0547\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0594 - val_loss: 0.0547\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0593 - val_loss: 0.0546\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0593 - val_loss: 0.0545\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0592 - val_loss: 0.0545\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0592 - val_loss: 0.0544\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0591 - val_loss: 0.0543\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0590 - val_loss: 0.0542\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0590 - val_loss: 0.0542\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0589 - val_loss: 0.0541\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0588 - val_loss: 0.0540\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0588 - val_loss: 0.0540\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0587 - val_loss: 0.0539\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0587 - val_loss: 0.0538\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0586 - val_loss: 0.0537\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0585 - val_loss: 0.0537\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0585 - val_loss: 0.0536\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0584 - val_loss: 0.0535\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0584 - val_loss: 0.0535\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0583 - val_loss: 0.0534\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0582 - val_loss: 0.0533\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0582 - val_loss: 0.0533\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0581 - val_loss: 0.0532\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0581 - val_loss: 0.0531\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0580 - val_loss: 0.0531\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0580 - val_loss: 0.0530\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0579 - val_loss: 0.0529\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0578 - val_loss: 0.0529\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0578 - val_loss: 0.0528\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0577 - val_loss: 0.0527\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0577 - val_loss: 0.0527\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.0576 - val_loss: 0.0526\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0576 - val_loss: 0.0526\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0575 - val_loss: 0.0525\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0574 - val_loss: 0.0524\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0574 - val_loss: 0.0524\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0573 - val_loss: 0.0523\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0573 - val_loss: 0.0522\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0572 - val_loss: 0.0522\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0572 - val_loss: 0.0521\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0571 - val_loss: 0.0520\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0571 - val_loss: 0.0520\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0570 - val_loss: 0.0519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0570 - val_loss: 0.0519\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0569 - val_loss: 0.0518\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0569 - val_loss: 0.0517\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0568 - val_loss: 0.0517\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0567 - val_loss: 0.0516\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0567 - val_loss: 0.0516\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0566 - val_loss: 0.0515\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0566 - val_loss: 0.0514\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.050 - 0s 98us/step - loss: 0.0565 - val_loss: 0.0514\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0565 - val_loss: 0.0513\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0564 - val_loss: 0.0513\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0564 - val_loss: 0.0512\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0563 - val_loss: 0.0511\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0563 - val_loss: 0.0511\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0562 - val_loss: 0.0510\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0562 - val_loss: 0.0510\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0561 - val_loss: 0.0509\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0561 - val_loss: 0.0508\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0560 - val_loss: 0.0508\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0560 - val_loss: 0.0507\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0559 - val_loss: 0.0507\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0559 - val_loss: 0.0506\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0558 - val_loss: 0.0506\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0558 - val_loss: 0.0505\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0557 - val_loss: 0.0504\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0557 - val_loss: 0.0504\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0556 - val_loss: 0.0503\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0556 - val_loss: 0.0503\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0555 - val_loss: 0.0502\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0555 - val_loss: 0.0502\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0554 - val_loss: 0.0501\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0554 - val_loss: 0.0500\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0553 - val_loss: 0.0500\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0553 - val_loss: 0.0499\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0553 - val_loss: 0.0499\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0552 - val_loss: 0.0498\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0552 - val_loss: 0.0498\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0551 - val_loss: 0.0497\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0551 - val_loss: 0.0497\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0550 - val_loss: 0.0496\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0550 - val_loss: 0.0496\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0549 - val_loss: 0.0495\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0549 - val_loss: 0.0495\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0548 - val_loss: 0.0494\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0548 - val_loss: 0.0494\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0548 - val_loss: 0.0493\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0547 - val_loss: 0.0493\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0547 - val_loss: 0.0492\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0546 - val_loss: 0.0491\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0546 - val_loss: 0.0491\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0545 - val_loss: 0.0490\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0545 - val_loss: 0.0490\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0544 - val_loss: 0.0489\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0544 - val_loss: 0.0489\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0544 - val_loss: 0.0488\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0543 - val_loss: 0.0488\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0543 - val_loss: 0.0487\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0542 - val_loss: 0.0487\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0542 - val_loss: 0.0486\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0541 - val_loss: 0.0486\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0541 - val_loss: 0.0485\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0541 - val_loss: 0.0485\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0540 - val_loss: 0.0484\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0540 - val_loss: 0.0484\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0539 - val_loss: 0.0483\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0539 - val_loss: 0.0483\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0539 - val_loss: 0.0482\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0538 - val_loss: 0.0482\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0538 - val_loss: 0.0481\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0537 - val_loss: 0.0481\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0537 - val_loss: 0.0480\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0536 - val_loss: 0.0480\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0536 - val_loss: 0.0479\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0536 - val_loss: 0.0479\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0535 - val_loss: 0.0478\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0535 - val_loss: 0.0478\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0534 - val_loss: 0.0478\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0534 - val_loss: 0.0477\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0534 - val_loss: 0.0477\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0533 - val_loss: 0.0476\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0533 - val_loss: 0.0476\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0533 - val_loss: 0.0475\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0532 - val_loss: 0.0475\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0532 - val_loss: 0.0474\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0531 - val_loss: 0.0474\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0531 - val_loss: 0.0473\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0531 - val_loss: 0.0473\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0530 - val_loss: 0.0473\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0530 - val_loss: 0.0472\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0530 - val_loss: 0.0472\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0529 - val_loss: 0.0471\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0529 - val_loss: 0.0471\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0528 - val_loss: 0.0470\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0528 - val_loss: 0.0470\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0528 - val_loss: 0.0469\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0527 - val_loss: 0.0469\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0527 - val_loss: 0.0469\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0527 - val_loss: 0.0468\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0526 - val_loss: 0.0468\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0526 - val_loss: 0.0467\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0526 - val_loss: 0.0467\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0525 - val_loss: 0.0467\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0525 - val_loss: 0.0466\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0525 - val_loss: 0.0466\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0524 - val_loss: 0.0465\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0524 - val_loss: 0.0465\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0523 - val_loss: 0.0464\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0523 - val_loss: 0.0464\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0523 - val_loss: 0.0464\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0522 - val_loss: 0.0463\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0522 - val_loss: 0.0463\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0522 - val_loss: 0.0462\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0521 - val_loss: 0.0462\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0521 - val_loss: 0.0462\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0521 - val_loss: 0.0461\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0520 - val_loss: 0.0461\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0520 - val_loss: 0.0460\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0520 - val_loss: 0.0460\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0519 - val_loss: 0.0460\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0519 - val_loss: 0.0459\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0519 - val_loss: 0.0459\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0518 - val_loss: 0.0458\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0518 - val_loss: 0.0458\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0518 - val_loss: 0.0457\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0517 - val_loss: 0.0457\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0517 - val_loss: 0.0457\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0517 - val_loss: 0.0456\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0516 - val_loss: 0.0456\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0516 - val_loss: 0.0456\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0516 - val_loss: 0.0455\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0516 - val_loss: 0.0455\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0515 - val_loss: 0.0454\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0515 - val_loss: 0.0454\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0515 - val_loss: 0.0454\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0514 - val_loss: 0.0453\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0513 - val_loss: 0.0452\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0513 - val_loss: 0.0451\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0512 - val_loss: 0.0451\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0512 - val_loss: 0.0451\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0512 - val_loss: 0.0450\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0512 - val_loss: 0.0450\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0511 - val_loss: 0.0450\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0511 - val_loss: 0.0449\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0511 - val_loss: 0.0449\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0510 - val_loss: 0.0449\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0510 - val_loss: 0.0448\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0510 - val_loss: 0.0448\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0510 - val_loss: 0.0447\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0509 - val_loss: 0.0447\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0509 - val_loss: 0.0447\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0509 - val_loss: 0.0446\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0508 - val_loss: 0.0446\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0508 - val_loss: 0.0446\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.0508 - val_loss: 0.0445\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0507 - val_loss: 0.0445\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0507 - val_loss: 0.0445\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0507 - val_loss: 0.0444\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0507 - val_loss: 0.0444\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0506 - val_loss: 0.0444\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0506 - val_loss: 0.0443\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0506 - val_loss: 0.0443\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0506 - val_loss: 0.0443\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0505 - val_loss: 0.0442\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0505 - val_loss: 0.0442\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0505 - val_loss: 0.0442\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0505 - val_loss: 0.0441\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0504 - val_loss: 0.0441\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0504 - val_loss: 0.0441\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0504 - val_loss: 0.0440\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0503 - val_loss: 0.0440\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0503 - val_loss: 0.0440\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0503 - val_loss: 0.0439\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0503 - val_loss: 0.0439\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0502 - val_loss: 0.0439\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0502 - val_loss: 0.0438\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0502 - val_loss: 0.0438\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0502 - val_loss: 0.0438\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.0501 - val_loss: 0.0438\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0501 - val_loss: 0.0437\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0501 - val_loss: 0.0437\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0501 - val_loss: 0.0437\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0500 - val_loss: 0.0436\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0500 - val_loss: 0.0436\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0500 - val_loss: 0.0436\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0500 - val_loss: 0.0435\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0499 - val_loss: 0.0435\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0499 - val_loss: 0.0435\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0499 - val_loss: 0.0434\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0499 - val_loss: 0.0434\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0498 - val_loss: 0.0434\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0498 - val_loss: 0.0433\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0498 - val_loss: 0.0433\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0498 - val_loss: 0.0433\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0497 - val_loss: 0.0433\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0497 - val_loss: 0.0432\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0497 - val_loss: 0.0432\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0497 - val_loss: 0.0432\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0496 - val_loss: 0.0431\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0496 - val_loss: 0.0431\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0496 - val_loss: 0.0431\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0496 - val_loss: 0.0430\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0496 - val_loss: 0.0430\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0495 - val_loss: 0.0430\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0495 - val_loss: 0.0430\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0495 - val_loss: 0.0429\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0495 - val_loss: 0.0429\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0494 - val_loss: 0.0429\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0494 - val_loss: 0.0428\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0494 - val_loss: 0.0428\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0494 - val_loss: 0.0428\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0494 - val_loss: 0.0428\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0493 - val_loss: 0.0427\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0493 - val_loss: 0.0427\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0493 - val_loss: 0.0427\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0493 - val_loss: 0.0427\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0492 - val_loss: 0.0426\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0492 - val_loss: 0.0426\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0492 - val_loss: 0.0426\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0492 - val_loss: 0.0425\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0492 - val_loss: 0.0425\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0491 - val_loss: 0.0425\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0491 - val_loss: 0.0425\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0491 - val_loss: 0.0424\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0491 - val_loss: 0.0424\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0491 - val_loss: 0.0424\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0490 - val_loss: 0.0424\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0490 - val_loss: 0.0423\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0490 - val_loss: 0.0423\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0490 - val_loss: 0.0423\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0490 - val_loss: 0.0423\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 84us/step - loss: 0.0489 - val_loss: 0.0422\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0489 - val_loss: 0.0422\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0489 - val_loss: 0.0422\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0489 - val_loss: 0.0422\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0489 - val_loss: 0.0421\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0488 - val_loss: 0.0421\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0488 - val_loss: 0.0421\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0488 - val_loss: 0.0421\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0488 - val_loss: 0.0420\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0488 - val_loss: 0.0420\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0487 - val_loss: 0.0420\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0487 - val_loss: 0.0419\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0487 - val_loss: 0.0419\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0487 - val_loss: 0.0419\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0487 - val_loss: 0.0419\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0486 - val_loss: 0.0417\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0485 - val_loss: 0.0417\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0485 - val_loss: 0.0417\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0485 - val_loss: 0.0417\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0485 - val_loss: 0.0416\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0485 - val_loss: 0.0416\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0484 - val_loss: 0.0416\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0484 - val_loss: 0.0416\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0484 - val_loss: 0.0415\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0484 - val_loss: 0.0415\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0484 - val_loss: 0.0415\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0483 - val_loss: 0.0415\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0483 - val_loss: 0.0415\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0483 - val_loss: 0.0414\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0483 - val_loss: 0.0414\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0483 - val_loss: 0.0414\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0483 - val_loss: 0.0414\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0482 - val_loss: 0.0413\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0482 - val_loss: 0.0413\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0482 - val_loss: 0.0413\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0482 - val_loss: 0.0413\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0482 - val_loss: 0.0412\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0481 - val_loss: 0.0412\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0481 - val_loss: 0.0412\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0481 - val_loss: 0.0412\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0481 - val_loss: 0.0411\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0481 - val_loss: 0.0411\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0481 - val_loss: 0.0411\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0480 - val_loss: 0.0411\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0480 - val_loss: 0.0410\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0480 - val_loss: 0.0410\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0480 - val_loss: 0.0410\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0480 - val_loss: 0.0410\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0480 - val_loss: 0.0410\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0479 - val_loss: 0.0409\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0479 - val_loss: 0.0409\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0479 - val_loss: 0.0409\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0479 - val_loss: 0.0409\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0479 - val_loss: 0.0409\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0479 - val_loss: 0.0408\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0478 - val_loss: 0.0408\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0478 - val_loss: 0.0408\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0478 - val_loss: 0.0408\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0478 - val_loss: 0.0407\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0478 - val_loss: 0.0407\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0478 - val_loss: 0.0407\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0477 - val_loss: 0.0407\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0477 - val_loss: 0.0407\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0477 - val_loss: 0.0406\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0477 - val_loss: 0.0406\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0477 - val_loss: 0.0406\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0477 - val_loss: 0.0406\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0476 - val_loss: 0.0406\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0476 - val_loss: 0.0405\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0476 - val_loss: 0.0405\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0476 - val_loss: 0.0405\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0476 - val_loss: 0.0405\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0476 - val_loss: 0.0405\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0476 - val_loss: 0.0404\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0475 - val_loss: 0.0404\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0475 - val_loss: 0.0404\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0475 - val_loss: 0.0404\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.0475 - val_loss: 0.0404\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0475 - val_loss: 0.0403\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0475 - val_loss: 0.0403\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0474 - val_loss: 0.0403\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0474 - val_loss: 0.0403\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0474 - val_loss: 0.0403\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0474 - val_loss: 0.0402\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0473 - val_loss: 0.0402\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0473 - val_loss: 0.0401\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0473 - val_loss: 0.0400\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0472 - val_loss: 0.0400\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0472 - val_loss: 0.0400\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0472 - val_loss: 0.0400\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0472 - val_loss: 0.0400\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0472 - val_loss: 0.0400\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0472 - val_loss: 0.0399\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0472 - val_loss: 0.0399\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0471 - val_loss: 0.0399\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0471 - val_loss: 0.0399\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0471 - val_loss: 0.0399\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0471 - val_loss: 0.0398\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0471 - val_loss: 0.0398\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0471 - val_loss: 0.0398\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0471 - val_loss: 0.0398\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0470 - val_loss: 0.0398\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0470 - val_loss: 0.0398\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0470 - val_loss: 0.0397\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0470 - val_loss: 0.0397\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0470 - val_loss: 0.0397\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0470 - val_loss: 0.0397\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0470 - val_loss: 0.0397\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0470 - val_loss: 0.0396\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0469 - val_loss: 0.0396\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0469 - val_loss: 0.0396\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0469 - val_loss: 0.0396\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0469 - val_loss: 0.0396\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0469 - val_loss: 0.0396\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0469 - val_loss: 0.0395\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0469 - val_loss: 0.0395\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0469 - val_loss: 0.0395\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0468 - val_loss: 0.0395\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0395\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0395\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0394\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0394\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0468 - val_loss: 0.0394\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0468 - val_loss: 0.0394\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0468 - val_loss: 0.0394\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0467 - val_loss: 0.0394\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0467 - val_loss: 0.0393\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0467 - val_loss: 0.0392\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0466 - val_loss: 0.0392\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0466 - val_loss: 0.0392\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0466 - val_loss: 0.0392\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0466 - val_loss: 0.0392\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0466 - val_loss: 0.0392\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0466 - val_loss: 0.0391\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0466 - val_loss: 0.0391\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0466 - val_loss: 0.0391\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0465 - val_loss: 0.0391\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0465 - val_loss: 0.0391\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0465 - val_loss: 0.0391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0465 - val_loss: 0.0391\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0465 - val_loss: 0.0390\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0465 - val_loss: 0.0390\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0465 - val_loss: 0.0390\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0465 - val_loss: 0.0390\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0465 - val_loss: 0.0390\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0464 - val_loss: 0.0390\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.042 - 0s 84us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0464 - val_loss: 0.0389\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0464 - val_loss: 0.0388\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0463 - val_loss: 0.0388\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0388\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0388\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0388\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0463 - val_loss: 0.0388\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0387\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0387\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0463 - val_loss: 0.0387\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0463 - val_loss: 0.0387\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0462 - val_loss: 0.0387\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0462 - val_loss: 0.0387\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0462 - val_loss: 0.0386\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0385\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0461 - val_loss: 0.0384\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0384\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0461 - val_loss: 0.0384\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0460 - val_loss: 0.0383\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0460 - val_loss: 0.0383\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0460 - val_loss: 0.0383\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0460 - val_loss: 0.0383\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0460 - val_loss: 0.0383\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0383\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0459 - val_loss: 0.0383\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0382\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0459 - val_loss: 0.0381\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0458 - val_loss: 0.0381\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0458 - val_loss: 0.0380\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0458 - val_loss: 0.0380\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0458 - val_loss: 0.0380\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0458 - val_loss: 0.0380\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0457 - val_loss: 0.0380\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0457 - val_loss: 0.0380\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0457 - val_loss: 0.0380\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0457 - val_loss: 0.0380\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0457 - val_loss: 0.0379\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0378\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0456 - val_loss: 0.0377\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0377\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0456 - val_loss: 0.0377\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0377\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0377\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0377\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0455 - val_loss: 0.0377\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0377\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0455 - val_loss: 0.0376\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0454 - val_loss: 0.0376\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0454 - val_loss: 0.0376\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0454 - val_loss: 0.0376\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0454 - val_loss: 0.0375\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0454 - val_loss: 0.0374\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0453 - val_loss: 0.0374\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0453 - val_loss: 0.0373\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0373\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0452 - val_loss: 0.0373\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0373\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0452 - val_loss: 0.0373\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0371\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0370\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0451 - val_loss: 0.0370\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0370\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0370\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0451 - val_loss: 0.0370\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0450 - val_loss: 0.0370\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0450 - val_loss: 0.0369\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0449 - val_loss: 0.0369\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0368\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0449 - val_loss: 0.0367\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0367\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0449 - val_loss: 0.0367\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0449 - val_loss: 0.0367\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0448 - val_loss: 0.0367\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0448 - val_loss: 0.0366\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0366\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0447 - val_loss: 0.0366\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0447 - val_loss: 0.0365\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0364\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0364\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0447 - val_loss: 0.0364\n",
      "0.05239713564515114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.15466543,  0.33500695, -0.22603598,  0.24202079, -0.25258473],\n",
       "        [-0.38218412, -0.40062088, -0.16802473, -0.3437878 , -0.42388374],\n",
       "        [ 0.0499099 , -0.0906921 ,  0.3684227 ,  0.00163446,  0.1719199 ],\n",
       "        [-0.09412647,  0.00139144,  0.08812755, -0.18132171, -0.16838527],\n",
       "        [-0.06312627,  0.34138477, -0.22034194,  0.0208194 ,  0.19688359],\n",
       "        [ 0.04664409,  0.16729963, -0.25738886, -0.09335659,  0.10639455],\n",
       "        [ 0.11686406, -0.07738612, -0.31602105,  0.3241451 , -0.3652046 ],\n",
       "        [ 0.38073236,  0.36754438,  0.21985823,  0.08885082,  0.07217958],\n",
       "        [ 0.1605972 ,  0.33656296, -0.46458915, -0.27802265, -0.04338146],\n",
       "        [-0.3377804 , -0.12520391, -0.30150592,  0.06115614,  0.21955965],\n",
       "        [ 0.39431262,  0.30429143, -0.10956448, -0.04822128,  0.26329905],\n",
       "        [ 0.36336455, -0.31330788, -0.43760756,  0.203722  , -0.09788213],\n",
       "        [ 0.10529505, -0.02653422, -0.32440254, -0.28455693,  0.32107738],\n",
       "        [-0.08387168,  0.10036982, -0.05150648, -0.36198986,  0.2257339 ],\n",
       "        [ 0.27058816,  0.29617503,  0.06062755, -0.20700754,  0.4443149 ],\n",
       "        [ 0.02237491, -0.04013712, -0.12412615, -0.26711166, -0.15056232],\n",
       "        [-0.24708863,  0.06257153, -0.38135144,  0.27688485,  0.30283928],\n",
       "        [-0.31954762, -0.16923113, -0.18558954,  0.40771097,  0.25944835],\n",
       "        [ 0.06532561, -0.08907809, -0.42400134,  0.1847062 ,  0.03081782],\n",
       "        [ 0.08521007,  0.22061072,  0.14709795, -0.2240942 , -0.23960668],\n",
       "        [-0.26647487,  0.00521673,  0.20344256, -0.1692615 ,  0.34778088],\n",
       "        [-0.1631105 , -0.11452298, -0.2547934 ,  0.06879148, -0.4455866 ]],\n",
       "       dtype=float32),\n",
       " array([-0.00519863,  0.01155954,  0.00375473, -0.00803282,  0.01129913],\n",
       "       dtype=float32),\n",
       " array([[ 4.5237294e-01, -4.0660766e-01, -5.0046051e-01, -5.9955120e-02,\n",
       "         -3.1902635e-01,  4.8687419e-01, -3.3407301e-01,  5.7209355e-01,\n",
       "         -2.3174855e-01,  3.0735567e-01],\n",
       "        [-4.0403122e-01, -6.0369611e-01, -2.8727794e-02,  2.6063308e-01,\n",
       "         -6.1486000e-01, -2.1276861e-01,  4.8028442e-01,  1.0020271e-01,\n",
       "          5.0733447e-01,  2.4950273e-01],\n",
       "        [-6.1640936e-01, -4.6650779e-01,  3.9850602e-01, -2.6763085e-01,\n",
       "          5.9831417e-01, -2.4952133e-01,  3.0838758e-01, -4.1458160e-01,\n",
       "          6.3544288e-02, -5.0949651e-01],\n",
       "        [ 4.7769031e-01,  3.4790009e-01,  2.7184105e-01, -1.0583435e-02,\n",
       "          2.4268466e-01,  6.2751269e-01,  2.4543904e-01, -8.2741916e-02,\n",
       "          2.7180010e-01, -5.0664425e-01],\n",
       "        [ 3.3701348e-04, -3.0247375e-01, -1.6848914e-01,  2.4746069e-01,\n",
       "          1.4187108e-01,  4.5957965e-01,  4.8987731e-01, -5.3395373e-01,\n",
       "         -3.5919040e-01, -3.0879942e-01]], dtype=float32),\n",
       " array([-0.01326851, -0.00450621, -0.0111039 ,  0.00753123, -0.00328702,\n",
       "        -0.00549292,  0.01142411,  0.00011546, -0.00509167, -0.01098732],\n",
       "       dtype=float32),\n",
       " array([[-0.6826382 ],\n",
       "        [-0.23351437],\n",
       "        [-0.58104277],\n",
       "        [ 0.39366347],\n",
       "        [-0.17744204],\n",
       "        [-0.28075835],\n",
       "        [ 0.5910812 ],\n",
       "        [ 0.01009111],\n",
       "        [-0.26494548],\n",
       "        [-0.56462467]], dtype=float32),\n",
       " array([0.019289], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, sgd, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sgd_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1130 - val_loss: 0.0413\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0336 - val_loss: 0.0232\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0276 - val_loss: 0.0243\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0371 - val_loss: 0.0124\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0197 - val_loss: 0.0098\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0143 - val_loss: 0.0125\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0235 - val_loss: 0.0176\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0215 - val_loss: 0.0103\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0194 - val_loss: 0.0126\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0143 - val_loss: 0.0071\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0155 - val_loss: 0.0081\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0178 - val_loss: 0.0084\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0173 - val_loss: 0.0087\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0182 - val_loss: 0.0061\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0139 - val_loss: 0.0138\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0142 - val_loss: 0.0125\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0162 - val_loss: 0.0059\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0163 - val_loss: 0.0058\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0158 - val_loss: 0.0081\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0170 - val_loss: 0.0097\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0122 - val_loss: 0.0171\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0240 - val_loss: 0.0058\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0130 - val_loss: 0.0076\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0169 - val_loss: 0.0175\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0114 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0138 - val_loss: 0.0071\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0173\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0137 - val_loss: 0.0066\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0143 - val_loss: 0.0062\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0130 - val_loss: 0.0055\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0135\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0194 - val_loss: 0.0060\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0115 - val_loss: 0.0062\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0108 - val_loss: 0.0190\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0057\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0095 - val_loss: 0.0134\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0149 - val_loss: 0.0053\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0119\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0139 - val_loss: 0.0052\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0118 - val_loss: 0.0056\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0130\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0118 - val_loss: 0.0065\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0124 - val_loss: 0.0061\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0120 - val_loss: 0.0092\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0078 - val_loss: 0.0129\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0140 - val_loss: 0.0075\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0083 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0153 - val_loss: 0.0071\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0151 - val_loss: 0.0055\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0113 - val_loss: 0.0076\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0140 - val_loss: 0.0070\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0144 - val_loss: 0.0097\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0092\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0129\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0082 - val_loss: 0.0044\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0120\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0110 - val_loss: 0.0044\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0105\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0128\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0097 - val_loss: 0.0043\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0118 - val_loss: 0.0047\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0083 - val_loss: 0.0050\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0061 - val_loss: 0.0116\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0080 - val_loss: 0.0041\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0070 - val_loss: 0.0135\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0038\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0078 - val_loss: 0.0042\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0064\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0105\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0087 - val_loss: 0.0038\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0077\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0083\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0085\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0070\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0109\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0080\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0072\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0029\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0027\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0103\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0073 - val_loss: 0.0034\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 105us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0069\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0070\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0071\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 97us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0083\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0039 - val_loss: 0.0095\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0041 - val_loss: 0.0072\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0077\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0109\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0037\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0107\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0076 - val_loss: 0.0027\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0075\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "0.007797514088451862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.9145945 , -0.12913501, -0.24642639,  0.40171334,  1.3680431 ],\n",
       "        [-0.8668023 , -0.16185826,  0.18652105, -0.33462644, -1.1859984 ],\n",
       "        [ 0.44055393,  0.1127468 , -0.23819147, -0.10835653, -0.8668959 ],\n",
       "        [ 0.23763494, -0.19943859, -0.19944164, -0.09752297,  0.20187858],\n",
       "        [-0.41105303, -0.02768229, -0.04241125,  0.37080032, -0.3242732 ],\n",
       "        [-0.96965456,  0.03093935,  0.26701793,  0.54928356,  0.36871928],\n",
       "        [ 0.30110186, -0.05183277, -0.06449451, -0.4593259 , -0.04613569],\n",
       "        [ 0.43741667,  0.25347435,  0.0487202 , -0.61273867,  0.25911692],\n",
       "        [-1.2832496 ,  0.20398283,  0.03882313,  0.22506858, -0.11413242],\n",
       "        [ 0.47845155, -0.370283  ,  0.2078344 , -1.0852559 ,  0.44459882],\n",
       "        [ 0.20444775, -0.1775229 , -0.23451023, -0.1834604 , -0.44442996],\n",
       "        [-0.11470698, -0.190131  , -0.12929584, -0.6075552 , -0.10453427],\n",
       "        [ 0.8871584 ,  0.16898948, -0.08562088, -0.675391  , -0.35313955],\n",
       "        [-2.0737097 , -0.9207198 , -0.3516862 , -0.7254227 ,  2.3104286 ],\n",
       "        [-0.19022202,  0.02726427,  0.07278708, -0.19754001,  0.06288134],\n",
       "        [ 0.14285885,  0.31842005,  0.28666675,  0.08652303,  0.09077654],\n",
       "        [ 1.0335432 , -0.00811992, -0.05034282,  0.08882834, -0.0956375 ],\n",
       "        [-0.21436316,  0.20004429, -0.10178854, -0.14592543,  0.36289427],\n",
       "        [-1.6906929 ,  0.5025586 ,  0.3858853 ,  1.1450161 , -1.0174549 ],\n",
       "        [ 0.2566465 , -0.341598  , -0.15573004, -0.34513474,  1.4871545 ],\n",
       "        [ 1.0216631 , -0.22759515,  0.1011246 ,  0.4939649 , -3.5053122 ],\n",
       "        [-1.3426747 ,  0.31666502,  0.30865797,  0.12600683, -1.6378227 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.7361046 ,  0.18806331,  0.07369567,  0.10182856, -0.68004197],\n",
       "       dtype=float32),\n",
       " array([[-0.02512769,  0.0377699 ,  0.00465927, -0.02106136,  0.01986463,\n",
       "         -0.21553679, -0.01919809, -0.5956993 ,  0.02198359, -0.36432046],\n",
       "        [-0.03325113,  0.04466115, -0.03063808, -0.0045645 , -0.01218699,\n",
       "         -0.14173186,  0.00709675,  0.01227423,  0.0385311 ,  0.06877384],\n",
       "        [ 0.01281419,  0.04039108, -0.0324808 , -0.01149921, -0.00738997,\n",
       "         -0.08907679,  0.01000665, -0.14693215,  0.03081366, -0.41588873],\n",
       "        [ 0.0239707 , -0.00807863, -0.01329453,  0.00718469, -0.01832705,\n",
       "         -0.08385555,  0.01008494, -0.2991856 ,  0.00875278, -0.06012255],\n",
       "        [ 0.02444772, -0.03692086, -0.00412378, -0.00606098, -0.00137294,\n",
       "         -0.5236598 , -0.00800236,  0.86346585,  0.01660678, -1.0444324 ]],\n",
       "       dtype=float32),\n",
       " array([-0.02470235,  0.01201223, -0.01189536, -0.00159677,  0.00184503,\n",
       "        -0.3766083 ,  0.00111393,  0.45422786,  0.01266359, -0.69868714],\n",
       "       dtype=float32),\n",
       " array([[ 0.02355562],\n",
       "        [-0.02000182],\n",
       "        [-0.00192249],\n",
       "        [ 0.00276018],\n",
       "        [-0.00159464],\n",
       "        [-0.01229399],\n",
       "        [ 0.00333602],\n",
       "        [ 0.3298993 ],\n",
       "        [-0.00077189],\n",
       "        [-0.11162684]], dtype=float32),\n",
       " array([0.2921241], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, RMSprop, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_rmsprop_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 35.9393 - val_loss: 33.2300\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9473 - val_loss: 29.7199\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8578 - val_loss: 24.6995\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 26.4757 - val_loss: 18.4213\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 20.8247 - val_loss: 11.6272\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 14.3825 - val_loss: 5.7526\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0666 - val_loss: 2.4880\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2319 - val_loss: 3.1264\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5424 - val_loss: 6.3212\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4581 - val_loss: 7.5575\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 5.5191 - val_loss: 6.5848\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7887 - val_loss: 4.6309\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5170 - val_loss: 2.4948\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6209 - val_loss: 1.0754\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1622 - val_loss: 0.7064\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5857 - val_loss: 1.0945\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7159 - val_loss: 1.7239\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1446 - val_loss: 2.2124\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5530 - val_loss: 2.4013\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7918 - val_loss: 2.2884\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8302 - val_loss: 1.9485\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6961 - val_loss: 1.4851\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4419 - val_loss: 1.0047\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.1295 - val_loss: 0.6007\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8216 - val_loss: 0.3357\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.5715 - val_loss: 0.2268\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.4101 - val_loss: 0.2406\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3387 - val_loss: 0.3090\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3304 - val_loss: 0.3617\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.3450 - val_loss: 0.3594\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.3497 - val_loss: 0.3071\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3334 - val_loss: 0.2379\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3045 - val_loss: 0.1863\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2778 - val_loss: 0.1679\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2624 - val_loss: 0.1774\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2575 - val_loss: 0.1973\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2554 - val_loss: 0.2102\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2477 - val_loss: 0.2059\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.2292 - val_loss: 0.1833\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1998 - val_loss: 0.1487\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1635 - val_loss: 0.1117\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1263 - val_loss: 0.0814\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0946 - val_loss: 0.0635\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0729 - val_loss: 0.0594\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0635 - val_loss: 0.0661\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0655 - val_loss: 0.0783\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0757 - val_loss: 0.0897\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0890 - val_loss: 0.0953\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0996 - val_loss: 0.0923\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1030 - val_loss: 0.0808\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0969 - val_loss: 0.0633\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0822 - val_loss: 0.0439\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0626 - val_loss: 0.0269\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0429 - val_loss: 0.0156\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0114\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0196 - val_loss: 0.0137\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0288\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0361\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0340 - val_loss: 0.0407\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0371 - val_loss: 0.0415\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0371 - val_loss: 0.0386\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0347 - val_loss: 0.0330\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0259\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0187\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0210 - val_loss: 0.0128\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0175 - val_loss: 0.0090\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0073\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0073\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0149 - val_loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0092\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0162 - val_loss: 0.0080\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0066\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0066\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0069\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0131 - val_loss: 0.0073\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0078\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0116 - val_loss: 0.0077\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0048\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0040\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0037\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0098 - val_loss: 0.0034\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0096 - val_loss: 0.0031\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0089 - val_loss: 0.0027\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0027\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0085 - val_loss: 0.0027\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0021\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0020\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0020\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0021\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0021\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0019\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0015\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0015\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0015\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0013\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0013\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0010\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0010\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 9.9727e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0045 - val_loss: 9.8947e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 9.8211e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 9.7489e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 9.6752e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 9.5984e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 9.5174e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 9.4326e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 9.3449e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0043 - val_loss: 9.2560e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 9.1678e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 9.0813e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 8.9980e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 8.9182e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0042 - val_loss: 8.8421e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 8.7693e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 8.6989e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 8.6305e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 8.5634e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 8.4966e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 8.4305e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 8.3646e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 8.2995e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0040 - val_loss: 8.2351e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 250us/step - loss: 0.0040 - val_loss: 8.1719e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 8.1097e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 8.0488e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 7.9889e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 7.9296e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 7.8709e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 7.8125e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 7.7540e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 7.6956e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 7.6377e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 7.5801e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 7.5235e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 7.4684e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 7.4147e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 7.3626e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 7.3127e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 7.2643e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 7.2173e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 7.1716e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 7.1264e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 7.0817e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 7.0370e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 6.9922e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 6.9473e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 6.9022e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 6.8571e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 6.8125e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 6.7683e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 6.7247e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 6.6822e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 6.6407e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 6.6001e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 6.5604e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 6.5216e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 6.4834e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 6.4461e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 6.4091e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 6.3729e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 6.3370e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 6.3014e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 6.2664e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0034 - val_loss: 6.2321e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 6.1980e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 6.1644e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0033 - val_loss: 6.1312e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 6.0984e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 6.0659e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 6.0340e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 6.0020e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 5.9706e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 5.9394e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 5.9087e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 5.8784e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 5.8485e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 5.8190e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 5.7902e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 5.7616e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 5.7337e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 5.7061e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 5.6790e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 5.6521e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.6256e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 5.5993e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0031 - val_loss: 5.5733e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 5.5474e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.5219e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0031 - val_loss: 5.4966e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.4716e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.4469e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.4224e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 5.3983e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.3745e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.3509e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.3278e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 5.3048e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.2822e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.2598e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 5.2377e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 5.2158e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0030 - val_loss: 5.1941e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.1726e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 5.1514e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 5.1304e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 5.1097e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 5.0890e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 5.0685e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 5.0484e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 5.0285e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 5.0087e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 4.9892e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 4.9699e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 4.9508e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0029 - val_loss: 4.9318e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.9132e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 4.8946e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.8761e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.8580e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 4.8399e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0028 - val_loss: 4.8221e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.8045e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.7870e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 4.7697e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 4.7526e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 4.7355e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 4.7188e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 4.7021e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 4.6855e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 4.6692e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.6530e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.6370e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 4.6210e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.6052e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.5894e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.5739e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 4.5584e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.5433e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 4.5281e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 4.5131e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.4985e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.4836e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.4692e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.4546e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.4402e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.4259e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.4117e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.3977e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.3838e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 4.3701e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.3563e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.3428e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 4.3294e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0026 - val_loss: 4.3161e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.3028e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 4.2895e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.2765e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.2635e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.2507e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 4.2380e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0025 - val_loss: 4.2253e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.2126e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.2001e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.1878e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0025 - val_loss: 4.1755e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 4.1633e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0025 - val_loss: 4.1512e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.1392e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 4.1274e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 4.1153e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 4.1036e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0917e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0801e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0685e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0571e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 4.0457e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0344e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 4.0232e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 4.0121e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 4.0010e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 3.9900e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 3.9789e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 3.9681e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 3.9574e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 3.9465e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 3.9358e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.9252e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.9146e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.9042e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8938e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8835e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 3.8732e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8630e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 3.8529e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 3.8427e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8326e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8228e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.8129e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0023 - val_loss: 3.8028e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.7930e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 3.7833e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.7736e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.7639e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.7543e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.7449e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.7353e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.7259e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.7166e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.7072e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.6981e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.6887e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.6796e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0022 - val_loss: 3.6704e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.6613e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.6522e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.6432e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.6342e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.6254e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 3.6166e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 3.6078e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 3.5991e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 3.5904e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 3.5817e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 3.5731e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.5645e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 3.5558e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 3.5474e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 3.5388e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 3.5306e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 3.5222e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 3.5138e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.5055e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.4972e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.4891e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.4809e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 3.4728e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 3.4646e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 3.4565e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0021 - val_loss: 3.4485e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.4405e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.4326e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.4247e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.4168e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.4090e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 3.4011e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.3933e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 3.3857e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 3.3779e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.3702e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.3626e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.3550e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.3473e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 3.3398e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.3324e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.3248e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 3.3173e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.3099e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 3.3025e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 3.2951e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 3.2878e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2806e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2734e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2661e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2589e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2517e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2445e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2373e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2302e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2231e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2161e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.2092e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.2022e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.1951e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1882e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1814e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 3.1746e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 3.1677e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0019 - val_loss: 3.1609e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1540e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1473e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1404e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 3.1337e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 3.1270e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.1203e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.1137e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.1071e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.1005e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0939e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0873e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0808e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0744e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0018 - val_loss: 3.0680e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0615e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 3.0549e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0486e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0421e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0358e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0294e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0230e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0167e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 3.0104e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 3.0043e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.9981e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.9919e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 2.9856e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.9795e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 2.9734e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.9672e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0017 - val_loss: 2.9610e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9549e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9488e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9427e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 2.9367e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9307e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9248e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9188e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.9129e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.9070e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.9010e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.8951e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 2.8893e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8835e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8776e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8717e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8659e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 2.8601e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8543e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.8485e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8428e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8372e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8315e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 2.8257e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 2.8201e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.8145e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.8089e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.8032e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7978e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7921e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7866e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7811e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7755e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7700e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7646e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7590e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7535e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7481e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7427e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7372e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7318e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7265e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7211e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.7159e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7105e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.7052e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.6998e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.6946e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.6892e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.6840e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 2.6787e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.6735e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0016 - val_loss: 2.6683e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 2.6632e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0015 - val_loss: 2.6580e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6528e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.6477e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.6426e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6374e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.6323e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6272e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6221e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6170e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6120e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 2.6070e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.6020e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5969e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5920e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5869e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5820e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 2.5770e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5720e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5671e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.5622e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.5573e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0015 - val_loss: 2.5525e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5476e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5427e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0015 - val_loss: 2.5378e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.5330e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 2.5282e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5234e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5186e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5138e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 2.5090e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.5042e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4995e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4947e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4900e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4854e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4807e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4760e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4713e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4666e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4620e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4573e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0014 - val_loss: 2.4527e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4481e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4434e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4389e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4343e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4297e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4252e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.4206e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0014 - val_loss: 2.4161e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.4116e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.4070e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.4025e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.3981e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 2.3936e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.3891e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 2.3847e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.3802e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.3758e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.3714e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.3669e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.3626e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 2.3582e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 2.3537e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.3494e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 2.3450e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.3407e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3362e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3320e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3277e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.3235e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.3192e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.3148e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.3105e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.3063e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.3021e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2978e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 2.2935e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2893e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2851e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2809e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.2766e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 2.2725e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.2684e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2643e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2601e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.2559e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2518e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 2.2476e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2435e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2394e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2353e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2312e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 2.2271e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2231e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2191e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2150e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.2109e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2069e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.2029e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 2.1989e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 2.1949e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1909e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1869e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0012 - val_loss: 2.1830e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1790e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1750e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0012 - val_loss: 2.1711e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.1671e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1632e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1592e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1554e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1515e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1476e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1438e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1398e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1360e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1321e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1282e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1244e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0012 - val_loss: 2.1205e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.1166e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1129e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.1091e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.1054e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.1015e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0012 - val_loss: 2.0978e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.0940e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0902e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0864e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 2.0827e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0789e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0752e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0714e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0678e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 2.0640e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0604e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0567e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0530e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.0493e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0456e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0420e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 2.0384e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 2.0346e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 109us/step - loss: 0.0011 - val_loss: 2.0310e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0274e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0237e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.0202e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0166e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 2.0130e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 2.0094e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.0058e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 2.0022e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9987e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.9951e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 1.9916e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.9880e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9844e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.9809e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9774e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.9740e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9704e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9669e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9635e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9600e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9564e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9531e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9495e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9460e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9426e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9392e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9357e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9324e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0011 - val_loss: 1.9289e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.9256e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9222e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9188e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0011 - val_loss: 1.9154e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.9120e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0011 - val_loss: 1.9086e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9052e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.9018e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8985e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8951e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0011 - val_loss: 1.8918e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8885e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 1.8851e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 1.8818e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8786e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.8753e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8720e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 1.8687e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8654e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8620e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8588e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8555e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8523e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8491e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 1.8458e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8426e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8394e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8361e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8329e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0010 - val_loss: 1.8297e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8264e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8233e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8201e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8169e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8137e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8106e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.8075e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8044e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.8011e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 1.7979e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 1.7948e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9993e-04 - val_loss: 1.7916e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9801e-04 - val_loss: 1.7884e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9611e-04 - val_loss: 1.7855e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9420e-04 - val_loss: 1.7823e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9231e-04 - val_loss: 1.7793e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9042e-04 - val_loss: 1.7761e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8851e-04 - val_loss: 1.7730e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8662e-04 - val_loss: 1.7699e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8474e-04 - val_loss: 1.7669e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8287e-04 - val_loss: 1.7637e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8099e-04 - val_loss: 1.7607e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7913e-04 - val_loss: 1.7577e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.7726e-04 - val_loss: 1.7546e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.7539e-04 - val_loss: 1.7515e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7354e-04 - val_loss: 1.7485e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7169e-04 - val_loss: 1.7455e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6984e-04 - val_loss: 1.7424e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6799e-04 - val_loss: 1.7394e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6615e-04 - val_loss: 1.7364e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.6433e-04 - val_loss: 1.7334e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6249e-04 - val_loss: 1.7304e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6066e-04 - val_loss: 1.7274e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5884e-04 - val_loss: 1.7244e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5702e-04 - val_loss: 1.7214e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5521e-04 - val_loss: 1.7183e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5341e-04 - val_loss: 1.7153e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 9.5159e-04 - val_loss: 1.7124e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.4979e-04 - val_loss: 1.7094e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4799e-04 - val_loss: 1.7065e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4620e-04 - val_loss: 1.7035e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4441e-04 - val_loss: 1.7006e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4262e-04 - val_loss: 1.6977e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.4086e-04 - val_loss: 1.6947e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3907e-04 - val_loss: 1.6918e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3729e-04 - val_loss: 1.6888e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3552e-04 - val_loss: 1.6859e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3376e-04 - val_loss: 1.6830e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3202e-04 - val_loss: 1.6801e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3025e-04 - val_loss: 1.6772e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2850e-04 - val_loss: 1.6743e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2675e-04 - val_loss: 1.6714e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2500e-04 - val_loss: 1.6685e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2326e-04 - val_loss: 1.6656e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2154e-04 - val_loss: 1.6628e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1979e-04 - val_loss: 1.6599e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 9.1807e-04 - val_loss: 1.6570e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1634e-04 - val_loss: 1.6541e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1463e-04 - val_loss: 1.6513e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1291e-04 - val_loss: 1.6485e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1120e-04 - val_loss: 1.6457e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0948e-04 - val_loss: 1.6428e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0778e-04 - val_loss: 1.6400e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0608e-04 - val_loss: 1.6372e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0438e-04 - val_loss: 1.6344e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0269e-04 - val_loss: 1.6315e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0099e-04 - val_loss: 1.6286e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9932e-04 - val_loss: 1.6258e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9763e-04 - val_loss: 1.6230e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9596e-04 - val_loss: 1.6203e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9429e-04 - val_loss: 1.6175e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9262e-04 - val_loss: 1.6148e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9094e-04 - val_loss: 1.6120e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8928e-04 - val_loss: 1.6093e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8762e-04 - val_loss: 1.6065e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.8597e-04 - val_loss: 1.6037e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8432e-04 - val_loss: 1.6010e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8267e-04 - val_loss: 1.5981e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8102e-04 - val_loss: 1.5954e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7938e-04 - val_loss: 1.5926e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7775e-04 - val_loss: 1.5900e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7611e-04 - val_loss: 1.5872e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7449e-04 - val_loss: 1.5846e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7287e-04 - val_loss: 1.5818e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7124e-04 - val_loss: 1.5791e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6963e-04 - val_loss: 1.5764e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6801e-04 - val_loss: 1.5737e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6640e-04 - val_loss: 1.5711e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6479e-04 - val_loss: 1.5683e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6319e-04 - val_loss: 1.5656e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6159e-04 - val_loss: 1.5629e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5999e-04 - val_loss: 1.5603e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5840e-04 - val_loss: 1.5576e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5681e-04 - val_loss: 1.5549e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5521e-04 - val_loss: 1.5523e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5364e-04 - val_loss: 1.5496e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.5207e-04 - val_loss: 1.5470e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5049e-04 - val_loss: 1.5444e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4891e-04 - val_loss: 1.5417e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4734e-04 - val_loss: 1.5391e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.4577e-04 - val_loss: 1.5364e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4422e-04 - val_loss: 1.5337e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4266e-04 - val_loss: 1.5312e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4110e-04 - val_loss: 1.5286e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.3955e-04 - val_loss: 1.5260e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3801e-04 - val_loss: 1.5234e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3646e-04 - val_loss: 1.5208e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3492e-04 - val_loss: 1.5182e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3338e-04 - val_loss: 1.5156e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3185e-04 - val_loss: 1.5130e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3031e-04 - val_loss: 1.5104e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2880e-04 - val_loss: 1.5078e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2728e-04 - val_loss: 1.5053e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2575e-04 - val_loss: 1.5028e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 8.2424e-04 - val_loss: 1.5001e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2272e-04 - val_loss: 1.4976e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2122e-04 - val_loss: 1.4951e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1970e-04 - val_loss: 1.4925e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1821e-04 - val_loss: 1.4900e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1671e-04 - val_loss: 1.4874e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1520e-04 - val_loss: 1.4850e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1371e-04 - val_loss: 1.4824e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1222e-04 - val_loss: 1.4799e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1073e-04 - val_loss: 1.4774e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0925e-04 - val_loss: 1.4749e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0777e-04 - val_loss: 1.4723e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 8.0629e-04 - val_loss: 1.4699e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 8.0482e-04 - val_loss: 1.4674e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0335e-04 - val_loss: 1.4649e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0188e-04 - val_loss: 1.4624e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 8.0042e-04 - val_loss: 1.4599e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9895e-04 - val_loss: 1.4574e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9750e-04 - val_loss: 1.4550e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9605e-04 - val_loss: 1.4525e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9459e-04 - val_loss: 1.4500e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9314e-04 - val_loss: 1.4475e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9170e-04 - val_loss: 1.4451e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9027e-04 - val_loss: 1.4427e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8881e-04 - val_loss: 1.4403e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8738e-04 - val_loss: 1.4378e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8595e-04 - val_loss: 1.4354e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.8453e-04 - val_loss: 1.4330e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8309e-04 - val_loss: 1.4305e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8167e-04 - val_loss: 1.4282e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8026e-04 - val_loss: 1.4256e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7884e-04 - val_loss: 1.4233e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7742e-04 - val_loss: 1.4209e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7602e-04 - val_loss: 1.4185e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.7460e-04 - val_loss: 1.4161e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7321e-04 - val_loss: 1.4137e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7180e-04 - val_loss: 1.4113e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7040e-04 - val_loss: 1.4090e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 7.6901e-04 - val_loss: 1.4066e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6762e-04 - val_loss: 1.4041e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6622e-04 - val_loss: 1.4018e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6484e-04 - val_loss: 1.3994e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.6346e-04 - val_loss: 1.3971e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6208e-04 - val_loss: 1.3947e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6071e-04 - val_loss: 1.3924e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5932e-04 - val_loss: 1.3900e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5795e-04 - val_loss: 1.3877e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5659e-04 - val_loss: 1.3854e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5522e-04 - val_loss: 1.3830e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5386e-04 - val_loss: 1.3807e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5249e-04 - val_loss: 1.3784e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5114e-04 - val_loss: 1.3761e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4979e-04 - val_loss: 1.3737e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4843e-04 - val_loss: 1.3714e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4709e-04 - val_loss: 1.3691e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4573e-04 - val_loss: 1.3667e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4440e-04 - val_loss: 1.3645e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4306e-04 - val_loss: 1.3622e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4171e-04 - val_loss: 1.3599e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4038e-04 - val_loss: 1.3577e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3906e-04 - val_loss: 1.3553e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3773e-04 - val_loss: 1.3531e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3641e-04 - val_loss: 1.3508e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3508e-04 - val_loss: 1.3485e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3376e-04 - val_loss: 1.3462e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3244e-04 - val_loss: 1.3440e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3113e-04 - val_loss: 1.3418e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 7.2982e-04 - val_loss: 1.3396e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2851e-04 - val_loss: 1.3373e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2722e-04 - val_loss: 1.3351e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.2591e-04 - val_loss: 1.3328e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2461e-04 - val_loss: 1.3305e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2332e-04 - val_loss: 1.3283e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2201e-04 - val_loss: 1.3260e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2072e-04 - val_loss: 1.3239e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1943e-04 - val_loss: 1.3216e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1815e-04 - val_loss: 1.3194e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1687e-04 - val_loss: 1.3172e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1559e-04 - val_loss: 1.3150e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1431e-04 - val_loss: 1.3128e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1303e-04 - val_loss: 1.3106e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1176e-04 - val_loss: 1.3084e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1049e-04 - val_loss: 1.3062e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0922e-04 - val_loss: 1.3041e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0797e-04 - val_loss: 1.3019e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0671e-04 - val_loss: 1.2997e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0544e-04 - val_loss: 1.2976e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0418e-04 - val_loss: 1.2954e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0293e-04 - val_loss: 1.2932e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0168e-04 - val_loss: 1.2911e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.0044e-04 - val_loss: 1.2889e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9919e-04 - val_loss: 1.2868e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9794e-04 - val_loss: 1.2846e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9671e-04 - val_loss: 1.2825e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9547e-04 - val_loss: 1.2804e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9423e-04 - val_loss: 1.2782e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9300e-04 - val_loss: 1.2761e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9177e-04 - val_loss: 1.2740e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9055e-04 - val_loss: 1.2718e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8932e-04 - val_loss: 1.2697e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8810e-04 - val_loss: 1.2675e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8688e-04 - val_loss: 1.2655e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8567e-04 - val_loss: 1.2634e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8445e-04 - val_loss: 1.2613e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8323e-04 - val_loss: 1.2592e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 6.8203e-04 - val_loss: 1.2571e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.8082e-04 - val_loss: 1.2550e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7961e-04 - val_loss: 1.2528e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7841e-04 - val_loss: 1.2507e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.7722e-04 - val_loss: 1.2487e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7602e-04 - val_loss: 1.2467e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7483e-04 - val_loss: 1.2446e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 6.7363e-04 - val_loss: 1.2425e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7244e-04 - val_loss: 1.2405e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7126e-04 - val_loss: 1.2384e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7007e-04 - val_loss: 1.2363e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6889e-04 - val_loss: 1.2343e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6772e-04 - val_loss: 1.2322e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6653e-04 - val_loss: 1.2302e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6536e-04 - val_loss: 1.2282e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6419e-04 - val_loss: 1.2262e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6302e-04 - val_loss: 1.2241e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6185e-04 - val_loss: 1.2221e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6069e-04 - val_loss: 1.2201e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5953e-04 - val_loss: 1.2179e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5836e-04 - val_loss: 1.2160e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5721e-04 - val_loss: 1.2140e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5605e-04 - val_loss: 1.2120e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5490e-04 - val_loss: 1.2100e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5375e-04 - val_loss: 1.2080e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5260e-04 - val_loss: 1.2060e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5145e-04 - val_loss: 1.2040e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5032e-04 - val_loss: 1.2020e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4918e-04 - val_loss: 1.2000e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4804e-04 - val_loss: 1.1980e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4690e-04 - val_loss: 1.1961e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4577e-04 - val_loss: 1.1941e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4464e-04 - val_loss: 1.1921e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4351e-04 - val_loss: 1.1902e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4239e-04 - val_loss: 1.1883e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4126e-04 - val_loss: 1.1863e-04\n",
      "0.00013523049710784107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09056102, -0.14724083, -0.06855701,  0.17146902, -0.3879984 ],\n",
       "        [ 0.27192226,  0.921981  , -0.9026538 ,  0.77696645, -0.12618859],\n",
       "        [-0.1954985 , -0.44994113, -0.87345314, -0.84742135, -1.5475674 ]],\n",
       "       dtype=float32),\n",
       " array([-0.44390717,  0.5711888 ,  0.5365945 ,  0.6602212 , -0.46037558],\n",
       "       dtype=float32),\n",
       " array([[-0.11531635, -0.44183537,  0.258087  ,  0.62827104, -0.00892567,\n",
       "          0.20633645, -0.4556343 ,  0.44189495, -0.10829671, -0.09155259],\n",
       "        [ 0.00439368,  0.10963328,  0.59258795,  0.11617761, -0.23604786,\n",
       "          0.05818256,  0.2996943 , -0.3087977 ,  0.17428672, -0.22776653],\n",
       "        [ 0.2885124 , -0.00334982, -0.09641812,  0.33401057,  0.6127034 ,\n",
       "         -0.3943197 , -0.08687043, -0.56791085,  0.3044911 , -0.74831146],\n",
       "        [ 0.5503855 , -0.03132147,  0.5849338 , -0.32801402,  0.26754233,\n",
       "          0.34085748,  0.69905037,  0.06639531,  0.18797442,  0.03203891],\n",
       "        [-0.6844831 , -0.7957165 ,  0.17100662,  0.26193395, -0.08783596,\n",
       "          0.54160625,  0.1788535 ,  0.5429792 ,  0.33584514,  0.22201538]],\n",
       "       dtype=float32),\n",
       " array([ 0.7968411 ,  0.77375275,  0.82142097,  0.57121307,  0.7678531 ,\n",
       "        -0.7428108 ,  0.72235745, -0.74787897, -0.54680544, -0.7766491 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.67704165],\n",
       "        [ 0.53536767],\n",
       "        [ 0.7488453 ],\n",
       "        [ 0.23423666],\n",
       "        [ 0.5985145 ],\n",
       "        [-0.47138074],\n",
       "        [ 0.3358541 ],\n",
       "        [-0.47974572],\n",
       "        [-0.1679531 ],\n",
       "        [-0.60050315]], dtype=float32),\n",
       " array([0.8510351], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_adam_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 36.0148 - val_loss: 40.1148\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0130 - val_loss: 40.1120\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0105 - val_loss: 40.1084\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 36.0072 - val_loss: 40.1042\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 36.0034 - val_loss: 40.0993\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9990 - val_loss: 40.0939\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9941 - val_loss: 40.0880\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9887 - val_loss: 40.0817\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9830 - val_loss: 40.0749\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9768 - val_loss: 40.0678\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9704 - val_loss: 40.0604\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9636 - val_loss: 40.0527\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9566 - val_loss: 40.0447\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9494 - val_loss: 40.0365\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9419 - val_loss: 40.0280\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9342 - val_loss: 40.0194\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9264 - val_loss: 40.0106\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9184 - val_loss: 40.0017\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9103 - val_loss: 39.9926\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9021 - val_loss: 39.9834\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8937 - val_loss: 39.9741\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8852 - val_loss: 39.9647\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8767 - val_loss: 39.9552\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.8681 - val_loss: 39.9456\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.8593 - val_loss: 39.9359\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8506 - val_loss: 39.9262\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8417 - val_loss: 39.9164\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.8329 - val_loss: 39.9066\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8239 - val_loss: 39.8967\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.8150 - val_loss: 39.8868\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8060 - val_loss: 39.8769\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7969 - val_loss: 39.8669\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7878 - val_loss: 39.8569\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7788 - val_loss: 39.8468\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7696 - val_loss: 39.8368\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7605 - val_loss: 39.8267\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7513 - val_loss: 39.8166\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7421 - val_loss: 39.8064\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 35.7330 - val_loss: 39.7963\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7238 - val_loss: 39.7862\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7145 - val_loss: 39.7760\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7053 - val_loss: 39.7659\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6961 - val_loss: 39.7557\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6868 - val_loss: 39.7455\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6776 - val_loss: 39.7353\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6683 - val_loss: 39.7251\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6591 - val_loss: 39.7149\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.6498 - val_loss: 39.7047\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6406 - val_loss: 39.6945\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6313 - val_loss: 39.6843\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6220 - val_loss: 39.6741\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6127 - val_loss: 39.6639\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6035 - val_loss: 39.6537\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5942 - val_loss: 39.6435\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5849 - val_loss: 39.6333\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5756 - val_loss: 39.6231\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5664 - val_loss: 39.6129\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5571 - val_loss: 39.6027\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5478 - val_loss: 39.5925\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5385 - val_loss: 39.5823\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5293 - val_loss: 39.5721\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5200 - val_loss: 39.5619\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5107 - val_loss: 39.5517\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5015 - val_loss: 39.5415\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4922 - val_loss: 39.5313\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4829 - val_loss: 39.5211\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4737 - val_loss: 39.5109\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4644 - val_loss: 39.5007\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4551 - val_loss: 39.4905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.4459 - val_loss: 39.4803\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4366 - val_loss: 39.4701\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4274 - val_loss: 39.4600\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4181 - val_loss: 39.4498\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4089 - val_loss: 39.4396\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3996 - val_loss: 39.4294\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 101us/step - loss: 35.3904 - val_loss: 39.4193\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3811 - val_loss: 39.4091\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3719 - val_loss: 39.3989\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3626 - val_loss: 39.3888\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.3534 - val_loss: 39.3786\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3442 - val_loss: 39.3684\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3349 - val_loss: 39.3583\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.3257 - val_loss: 39.3481\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3165 - val_loss: 39.3380\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3072 - val_loss: 39.3279\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2980 - val_loss: 39.3177\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.2888 - val_loss: 39.3076\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2796 - val_loss: 39.2974\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2704 - val_loss: 39.2873\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2611 - val_loss: 39.2772\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2519 - val_loss: 39.2670\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2427 - val_loss: 39.2569\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2335 - val_loss: 39.2468\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2243 - val_loss: 39.2367\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2151 - val_loss: 39.2266\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2059 - val_loss: 39.2164\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1967 - val_loss: 39.2063\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1875 - val_loss: 39.1962\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1783 - val_loss: 39.1861\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1691 - val_loss: 39.1760\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1600 - val_loss: 39.1659\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.1508 - val_loss: 39.1558\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1416 - val_loss: 39.1457\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1324 - val_loss: 39.1356\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1232 - val_loss: 39.1256\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1141 - val_loss: 39.1155\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1049 - val_loss: 39.1054\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0957 - val_loss: 39.0953\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0866 - val_loss: 39.0852\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0774 - val_loss: 39.0752\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0682 - val_loss: 39.0651\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.0591 - val_loss: 39.0550\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0499 - val_loss: 39.0450\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0408 - val_loss: 39.0349\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.0316 - val_loss: 39.0248\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0225 - val_loss: 39.0148\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0133 - val_loss: 39.0047\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0042 - val_loss: 38.9947\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9950 - val_loss: 38.9846\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9859 - val_loss: 38.9746\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9767 - val_loss: 38.9645\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.9676 - val_loss: 38.9545\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9585 - val_loss: 38.9445\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.9493 - val_loss: 38.9344\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9402 - val_loss: 38.9244\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9311 - val_loss: 38.9144\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.9220 - val_loss: 38.9044\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 34.9128 - val_loss: 38.8943\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9037 - val_loss: 38.8843\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8946 - val_loss: 38.8743\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8855 - val_loss: 38.8643\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8764 - val_loss: 38.8543\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.8673 - val_loss: 38.8443\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8582 - val_loss: 38.8343\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8491 - val_loss: 38.8243\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.8400 - val_loss: 38.8143\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.8309 - val_loss: 38.8043\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.8218 - val_loss: 38.7943\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8127 - val_loss: 38.7843\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8036 - val_loss: 38.7743\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7945 - val_loss: 38.7643\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7854 - val_loss: 38.7543\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7763 - val_loss: 38.7443\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7672 - val_loss: 38.7343\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7582 - val_loss: 38.7244\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7491 - val_loss: 38.7144\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7400 - val_loss: 38.7044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7309 - val_loss: 38.6945\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7219 - val_loss: 38.6845\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7128 - val_loss: 38.6745\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.7037 - val_loss: 38.6646\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6947 - val_loss: 38.6546\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6856 - val_loss: 38.6447\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6765 - val_loss: 38.6347\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6675 - val_loss: 38.6248\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6584 - val_loss: 38.6148\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6494 - val_loss: 38.6049\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6403 - val_loss: 38.5949\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6313 - val_loss: 38.5850\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.6222 - val_loss: 38.5751\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6132 - val_loss: 38.5651\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6041 - val_loss: 38.5552\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5951 - val_loss: 38.5453\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5861 - val_loss: 38.5354\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5770 - val_loss: 38.5254\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5680 - val_loss: 38.5155\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5590 - val_loss: 38.5056\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 34.5499 - val_loss: 38.4957\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5409 - val_loss: 38.4858\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.5319 - val_loss: 38.4759\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5229 - val_loss: 38.4660\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 34.5139 - val_loss: 38.4561\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5048 - val_loss: 38.4462\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4958 - val_loss: 38.4363\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4868 - val_loss: 38.4264\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4778 - val_loss: 38.4165\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4688 - val_loss: 38.4066\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4598 - val_loss: 38.3967\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4508 - val_loss: 38.3868\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.4418 - val_loss: 38.3769\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4328 - val_loss: 38.3671\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4238 - val_loss: 38.3572\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4148 - val_loss: 38.3473\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4058 - val_loss: 38.3374\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3968 - val_loss: 38.3276\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.3878 - val_loss: 38.3177\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3789 - val_loss: 38.3079\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3699 - val_loss: 38.2980\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3609 - val_loss: 38.2881\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3519 - val_loss: 38.2783\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3429 - val_loss: 38.2684\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3340 - val_loss: 38.2586\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 34.3250 - val_loss: 38.2487\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.3160 - val_loss: 38.2389\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3071 - val_loss: 38.2290\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.2981 - val_loss: 38.2192\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2891 - val_loss: 38.2094\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.2802 - val_loss: 38.1995\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2712 - val_loss: 38.1897\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 34.2623 - val_loss: 38.1799\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2533 - val_loss: 38.1700\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2443 - val_loss: 38.1602\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.2354 - val_loss: 38.1504\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2265 - val_loss: 38.1406\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2175 - val_loss: 38.1308\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2086 - val_loss: 38.1209\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1996 - val_loss: 38.1111\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1907 - val_loss: 38.1013\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1817 - val_loss: 38.0915\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1728 - val_loss: 38.0817\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1639 - val_loss: 38.0719\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1550 - val_loss: 38.0621\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1460 - val_loss: 38.0523\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1371 - val_loss: 38.0425\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1282 - val_loss: 38.0327\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1193 - val_loss: 38.0229\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1103 - val_loss: 38.0132\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1014 - val_loss: 38.0034\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.0925 - val_loss: 37.9936\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0836 - val_loss: 37.9838\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.0747 - val_loss: 37.9740\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0658 - val_loss: 37.9643\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0569 - val_loss: 37.9545\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0480 - val_loss: 37.9447\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0391 - val_loss: 37.9350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.0302 - val_loss: 37.9252\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0213 - val_loss: 37.9154\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0124 - val_loss: 37.9057\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0035 - val_loss: 37.8959\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.9946 - val_loss: 37.8862\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.9857 - val_loss: 37.8764\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9768 - val_loss: 37.8667\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9679 - val_loss: 37.8569\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9590 - val_loss: 37.8472\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9502 - val_loss: 37.8374\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9413 - val_loss: 37.8277\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9324 - val_loss: 37.8180\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.9235 - val_loss: 37.8082\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9147 - val_loss: 37.7985\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9058 - val_loss: 37.7887\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8969 - val_loss: 37.7790\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8881 - val_loss: 37.7693\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.8792 - val_loss: 37.7596\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8703 - val_loss: 37.7499\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8615 - val_loss: 37.7401\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8526 - val_loss: 37.7304\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8438 - val_loss: 37.7207\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8349 - val_loss: 37.7110\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8260 - val_loss: 37.7013\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8172 - val_loss: 37.6916\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8083 - val_loss: 37.6819\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7995 - val_loss: 37.6722\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7907 - val_loss: 37.6625\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.7818 - val_loss: 37.6528\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7730 - val_loss: 37.6431\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7641 - val_loss: 37.6334\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7553 - val_loss: 37.6237\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7465 - val_loss: 37.6140\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7376 - val_loss: 37.6043\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7288 - val_loss: 37.5947\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7200 - val_loss: 37.5850\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7112 - val_loss: 37.5753\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7023 - val_loss: 37.5656\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6935 - val_loss: 37.5560\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6847 - val_loss: 37.5463\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6759 - val_loss: 37.5366\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.6671 - val_loss: 37.5270\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6583 - val_loss: 37.5173\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6494 - val_loss: 37.5076\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.6406 - val_loss: 37.4980\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6318 - val_loss: 37.4883\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6230 - val_loss: 37.4787\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6142 - val_loss: 37.4690\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6054 - val_loss: 37.4594\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.5966 - val_loss: 37.4497\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5878 - val_loss: 37.4401\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5790 - val_loss: 37.4304\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5702 - val_loss: 37.4208\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5614 - val_loss: 37.4112\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.5527 - val_loss: 37.4015\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5439 - val_loss: 37.3919\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5351 - val_loss: 37.3823\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5263 - val_loss: 37.3726\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.5175 - val_loss: 37.3630\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.5087 - val_loss: 37.3534\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5000 - val_loss: 37.3438\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4912 - val_loss: 37.3342\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4824 - val_loss: 37.3245\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4736 - val_loss: 37.3149\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4649 - val_loss: 37.3053\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4561 - val_loss: 37.2957\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4473 - val_loss: 37.2861\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4386 - val_loss: 37.2765\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4298 - val_loss: 37.2669\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4211 - val_loss: 37.2573\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4123 - val_loss: 37.2477\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4035 - val_loss: 37.2381\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3948 - val_loss: 37.2285\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3860 - val_loss: 37.2189\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3773 - val_loss: 37.2093\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3685 - val_loss: 37.1997\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3598 - val_loss: 37.1902\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3511 - val_loss: 37.1806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3423 - val_loss: 37.1710\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3336 - val_loss: 37.1614\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.3248 - val_loss: 37.1518\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3161 - val_loss: 37.1423\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3074 - val_loss: 37.1327\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2986 - val_loss: 37.1231\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2899 - val_loss: 37.1136\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2812 - val_loss: 37.1040\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2724 - val_loss: 37.0944\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2637 - val_loss: 37.0849\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2550 - val_loss: 37.0753\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2463 - val_loss: 37.0658\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2376 - val_loss: 37.0562\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.2288 - val_loss: 37.0467\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2201 - val_loss: 37.0371\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2114 - val_loss: 37.0276\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2027 - val_loss: 37.0180\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.1940 - val_loss: 37.0085\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 33.1853 - val_loss: 36.9989\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1766 - val_loss: 36.9894\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.1679 - val_loss: 36.9799\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 33.1592 - val_loss: 36.9703\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1505 - val_loss: 36.9608\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 33.1418 - val_loss: 36.9513\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1331 - val_loss: 36.9417\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 33.1244 - val_loss: 36.9322\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 33.1157 - val_loss: 36.9227\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1070 - val_loss: 36.9132\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0983 - val_loss: 36.9037\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0896 - val_loss: 36.8941\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0809 - val_loss: 36.8846\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0722 - val_loss: 36.8751\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0636 - val_loss: 36.8656\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0549 - val_loss: 36.8561\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0462 - val_loss: 36.8466\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0375 - val_loss: 36.8371\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0289 - val_loss: 36.8276\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0202 - val_loss: 36.8181\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0115 - val_loss: 36.8086\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0028 - val_loss: 36.7991\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9942 - val_loss: 36.7896\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9855 - val_loss: 36.7801\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.9769 - val_loss: 36.7706\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9682 - val_loss: 36.7612\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9595 - val_loss: 36.7517\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9509 - val_loss: 36.7422\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9422 - val_loss: 36.7327\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9336 - val_loss: 36.7232\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9249 - val_loss: 36.7138\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9163 - val_loss: 36.7043\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9076 - val_loss: 36.6948\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8990 - val_loss: 36.6853\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8903 - val_loss: 36.6759\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 32.8817 - val_loss: 36.6664\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8730 - val_loss: 36.6569\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8644 - val_loss: 36.6475\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8558 - val_loss: 36.6380\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8471 - val_loss: 36.6286\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8385 - val_loss: 36.6191\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8298 - val_loss: 36.6097\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8212 - val_loss: 36.6002\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.8126 - val_loss: 36.5908\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8040 - val_loss: 36.5813\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7953 - val_loss: 36.5719\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7867 - val_loss: 36.5624\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7781 - val_loss: 36.5530\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7695 - val_loss: 36.5436\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7609 - val_loss: 36.5341\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.7522 - val_loss: 36.5247\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7436 - val_loss: 36.5153\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.7350 - val_loss: 36.5058\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7264 - val_loss: 36.4964\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7178 - val_loss: 36.4870\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7092 - val_loss: 36.4776\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7006 - val_loss: 36.4681\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6920 - val_loss: 36.4587\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6834 - val_loss: 36.4493\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6748 - val_loss: 36.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6662 - val_loss: 36.4305\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6576 - val_loss: 36.4211\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6490 - val_loss: 36.4117\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.6404 - val_loss: 36.4022\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6318 - val_loss: 36.3928\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6232 - val_loss: 36.3834\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6146 - val_loss: 36.3740\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6060 - val_loss: 36.3646\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5974 - val_loss: 36.3552\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5889 - val_loss: 36.3458\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5803 - val_loss: 36.3365\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5717 - val_loss: 36.3271\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5631 - val_loss: 36.3177\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5545 - val_loss: 36.3083\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5460 - val_loss: 36.2989\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.5374 - val_loss: 36.2895\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5288 - val_loss: 36.2801\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5202 - val_loss: 36.2708\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5117 - val_loss: 36.2614\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5031 - val_loss: 36.2520\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4945 - val_loss: 36.2426\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.4860 - val_loss: 36.2333\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 32.4774 - val_loss: 36.2239\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4689 - val_loss: 36.2145\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4603 - val_loss: 36.2052\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4518 - val_loss: 36.1958\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4432 - val_loss: 36.1864\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4346 - val_loss: 36.1771\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4261 - val_loss: 36.1677\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4175 - val_loss: 36.1584\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4090 - val_loss: 36.1490\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.4005 - val_loss: 36.1397\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3919 - val_loss: 36.1303\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3834 - val_loss: 36.1210\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3748 - val_loss: 36.1116\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3663 - val_loss: 36.1023\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3577 - val_loss: 36.0929\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3492 - val_loss: 36.0836\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3407 - val_loss: 36.0743\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3321 - val_loss: 36.0649\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3236 - val_loss: 36.0556\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3151 - val_loss: 36.0463\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3066 - val_loss: 36.0369\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2980 - val_loss: 36.0276\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2895 - val_loss: 36.0183\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2810 - val_loss: 36.0090\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2725 - val_loss: 35.9996\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2639 - val_loss: 35.9903\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2554 - val_loss: 35.9810\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2469 - val_loss: 35.9717\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.2384 - val_loss: 35.9624\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2299 - val_loss: 35.9531\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2214 - val_loss: 35.9437\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2129 - val_loss: 35.9344\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.2044 - val_loss: 35.9251\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1958 - val_loss: 35.9158\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1873 - val_loss: 35.9065\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1788 - val_loss: 35.8972\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1703 - val_loss: 35.8879\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1618 - val_loss: 35.8786\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1533 - val_loss: 35.8693\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1448 - val_loss: 35.8600\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1363 - val_loss: 35.8507\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1279 - val_loss: 35.8415\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1194 - val_loss: 35.8322\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1109 - val_loss: 35.8229\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1024 - val_loss: 35.8136\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0939 - val_loss: 35.8043\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0854 - val_loss: 35.7950\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0769 - val_loss: 35.7858\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0684 - val_loss: 35.7765\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0600 - val_loss: 35.7672\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0515 - val_loss: 35.7579\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0430 - val_loss: 35.7487\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0345 - val_loss: 35.7394\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0261 - val_loss: 35.7301\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0176 - val_loss: 35.7209\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.0091 - val_loss: 35.7116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 32.0006 - val_loss: 35.7023\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9922 - val_loss: 35.6931\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9837 - val_loss: 35.6838\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9753 - val_loss: 35.6746\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9668 - val_loss: 35.6653\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9583 - val_loss: 35.6561\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9499 - val_loss: 35.6468\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9414 - val_loss: 35.6376\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9330 - val_loss: 35.6283\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9245 - val_loss: 35.6191\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9160 - val_loss: 35.6098\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9076 - val_loss: 35.6006\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8991 - val_loss: 35.5914\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8907 - val_loss: 35.5821\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8822 - val_loss: 35.5729\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8738 - val_loss: 35.5636\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8654 - val_loss: 35.5544\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8569 - val_loss: 35.5452\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8485 - val_loss: 35.5360\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.8400 - val_loss: 35.5267\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8316 - val_loss: 35.5175\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8232 - val_loss: 35.5083\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.8147 - val_loss: 35.4991\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8063 - val_loss: 35.4898\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7979 - val_loss: 35.4806\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7894 - val_loss: 35.4714\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7810 - val_loss: 35.4622\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7726 - val_loss: 35.4530\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7641 - val_loss: 35.4438\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.7557 - val_loss: 35.4346\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7473 - val_loss: 35.4254\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7389 - val_loss: 35.4161\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7305 - val_loss: 35.4069\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7220 - val_loss: 35.3977\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7136 - val_loss: 35.3885\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.7052 - val_loss: 35.3793\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6968 - val_loss: 35.3701\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6884 - val_loss: 35.3609\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6800 - val_loss: 35.3517\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.6716 - val_loss: 35.3426\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6632 - val_loss: 35.3334\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6547 - val_loss: 35.3242\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6463 - val_loss: 35.3150\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 31.6379 - val_loss: 35.3058\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6295 - val_loss: 35.2966\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6211 - val_loss: 35.2874\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.6127 - val_loss: 35.2783\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6043 - val_loss: 35.2691\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5959 - val_loss: 35.2599\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.5876 - val_loss: 35.2507\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5792 - val_loss: 35.2416\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.5708 - val_loss: 35.2324\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.5624 - val_loss: 35.2232\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5540 - val_loss: 35.2141\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5456 - val_loss: 35.2049\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5372 - val_loss: 35.1957\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5288 - val_loss: 35.1866\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5205 - val_loss: 35.1774\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5121 - val_loss: 35.1683\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5037 - val_loss: 35.1591\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4953 - val_loss: 35.1499\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4869 - val_loss: 35.1408\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4786 - val_loss: 35.1316\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4702 - val_loss: 35.1225\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 31.4618 - val_loss: 35.1133\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4534 - val_loss: 35.1042\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4451 - val_loss: 35.0950\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.4367 - val_loss: 35.0859\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.4283 - val_loss: 35.0768\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4200 - val_loss: 35.0676\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4116 - val_loss: 35.0585\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4033 - val_loss: 35.0493\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.3949 - val_loss: 35.0402\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3865 - val_loss: 35.0311\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3782 - val_loss: 35.0219\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3698 - val_loss: 35.0128\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3615 - val_loss: 35.0037\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.3531 - val_loss: 34.9946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.3448 - val_loss: 34.9854\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3364 - val_loss: 34.9763\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.3281 - val_loss: 34.9672\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3197 - val_loss: 34.9581\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3114 - val_loss: 34.9489\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3030 - val_loss: 34.9398\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.2947 - val_loss: 34.9307\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.2863 - val_loss: 34.9216\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.2780 - val_loss: 34.9125\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2697 - val_loss: 34.9034\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2613 - val_loss: 34.8943\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2530 - val_loss: 34.8852\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2446 - val_loss: 34.8761\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2363 - val_loss: 34.8670\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2280 - val_loss: 34.8579\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2197 - val_loss: 34.8488\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2113 - val_loss: 34.8397\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2030 - val_loss: 34.8306\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1947 - val_loss: 34.8215\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1863 - val_loss: 34.8124\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1780 - val_loss: 34.8033\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1697 - val_loss: 34.7942\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1614 - val_loss: 34.7851\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1531 - val_loss: 34.7760\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1447 - val_loss: 34.7669\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1364 - val_loss: 34.7578\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1281 - val_loss: 34.7488\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1198 - val_loss: 34.7397\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1115 - val_loss: 34.7306\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1032 - val_loss: 34.7215\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0949 - val_loss: 34.7124\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0866 - val_loss: 34.7034\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0782 - val_loss: 34.6943\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0699 - val_loss: 34.6852\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0616 - val_loss: 34.6762\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0533 - val_loss: 34.6671\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.0450 - val_loss: 34.6580\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0367 - val_loss: 34.6490\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0284 - val_loss: 34.6399\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0201 - val_loss: 34.6308\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0118 - val_loss: 34.6218\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0035 - val_loss: 34.6127\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9953 - val_loss: 34.6037\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9870 - val_loss: 34.5946\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9787 - val_loss: 34.5856\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9704 - val_loss: 34.5765\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9621 - val_loss: 34.5675\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9538 - val_loss: 34.5584\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9455 - val_loss: 34.5494\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9372 - val_loss: 34.5403\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9290 - val_loss: 34.5313\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9207 - val_loss: 34.5222\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9124 - val_loss: 34.5132\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9041 - val_loss: 34.5041\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8958 - val_loss: 34.4951\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8876 - val_loss: 34.4861\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8793 - val_loss: 34.4770\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8710 - val_loss: 34.4680\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8627 - val_loss: 34.4590\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8545 - val_loss: 34.4499\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8462 - val_loss: 34.4409\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8379 - val_loss: 34.4319\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8297 - val_loss: 34.4229\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8214 - val_loss: 34.4138\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.8131 - val_loss: 34.4048\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8049 - val_loss: 34.3958\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.7966 - val_loss: 34.3868\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7884 - val_loss: 34.3778\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7801 - val_loss: 34.3687\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7718 - val_loss: 34.3597\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.7636 - val_loss: 34.3507\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7553 - val_loss: 34.3417\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7471 - val_loss: 34.3327\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.7388 - val_loss: 34.3237\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7306 - val_loss: 34.3147\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7223 - val_loss: 34.3057\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.7141 - val_loss: 34.2967\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7058 - val_loss: 34.2877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6976 - val_loss: 34.2787\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.6893 - val_loss: 34.2697\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6811 - val_loss: 34.2607\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6729 - val_loss: 34.2517\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6646 - val_loss: 34.2427\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6564 - val_loss: 34.2337\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6481 - val_loss: 34.2247\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.6399 - val_loss: 34.2157\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.6317 - val_loss: 34.2067\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6234 - val_loss: 34.1977\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6152 - val_loss: 34.1887\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6070 - val_loss: 34.1797\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5988 - val_loss: 34.1708\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5905 - val_loss: 34.1618\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5823 - val_loss: 34.1528\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5741 - val_loss: 34.1438\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5658 - val_loss: 34.1348\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5576 - val_loss: 34.1259\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5494 - val_loss: 34.1169\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.5412 - val_loss: 34.1079\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5330 - val_loss: 34.0989\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.5247 - val_loss: 34.0900\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.5165 - val_loss: 34.0810\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5083 - val_loss: 34.0720\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5001 - val_loss: 34.0631\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4919 - val_loss: 34.0541\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4837 - val_loss: 34.0452\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4755 - val_loss: 34.0362\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4672 - val_loss: 34.0272\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4590 - val_loss: 34.0183\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4508 - val_loss: 34.0093\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4426 - val_loss: 34.0004\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4344 - val_loss: 33.9914\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4262 - val_loss: 33.9825\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4180 - val_loss: 33.9735\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4098 - val_loss: 33.9646\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4016 - val_loss: 33.9556\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3934 - val_loss: 33.9467\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.3852 - val_loss: 33.9377\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3770 - val_loss: 33.9288\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.3688 - val_loss: 33.9198\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3606 - val_loss: 33.9109\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3524 - val_loss: 33.9019\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3443 - val_loss: 33.8930\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3361 - val_loss: 33.8841\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3279 - val_loss: 33.8751\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3197 - val_loss: 33.8662\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3115 - val_loss: 33.8573\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3033 - val_loss: 33.8483\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.2951 - val_loss: 33.8394\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2870 - val_loss: 33.8305\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2788 - val_loss: 33.8216\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2706 - val_loss: 33.8126\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2624 - val_loss: 33.8037\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2542 - val_loss: 33.7948\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2461 - val_loss: 33.7859\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2379 - val_loss: 33.7769\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2297 - val_loss: 33.7680\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2215 - val_loss: 33.7591\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.2134 - val_loss: 33.7502\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2052 - val_loss: 33.7413\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1970 - val_loss: 33.7324\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1889 - val_loss: 33.7234\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1807 - val_loss: 33.7145\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1725 - val_loss: 33.7056\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1644 - val_loss: 33.6967\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1562 - val_loss: 33.6878\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1480 - val_loss: 33.6789\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1399 - val_loss: 33.6700\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 30.1317 - val_loss: 33.6611\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1236 - val_loss: 33.6522\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1154 - val_loss: 33.6433\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1073 - val_loss: 33.6344\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0991 - val_loss: 33.6255\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0909 - val_loss: 33.6166\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.0828 - val_loss: 33.6077\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.0746 - val_loss: 33.5988\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.0665 - val_loss: 33.5899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0583 - val_loss: 33.5811\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0502 - val_loss: 33.5722\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0420 - val_loss: 33.5633\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0339 - val_loss: 33.5544\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0258 - val_loss: 33.5455\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0176 - val_loss: 33.5366\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0095 - val_loss: 33.5277\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0013 - val_loss: 33.5189\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9932 - val_loss: 33.5100\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9851 - val_loss: 33.5011\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9769 - val_loss: 33.4922\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9688 - val_loss: 33.4834\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.9606 - val_loss: 33.4745\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9525 - val_loss: 33.4656\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9444 - val_loss: 33.4567\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.9363 - val_loss: 33.4479\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9281 - val_loss: 33.4390\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9200 - val_loss: 33.4301\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9119 - val_loss: 33.4213\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9037 - val_loss: 33.4124\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8956 - val_loss: 33.4035\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8875 - val_loss: 33.3947\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8794 - val_loss: 33.3858\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.8712 - val_loss: 33.3770\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8631 - val_loss: 33.3681\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8550 - val_loss: 33.3592\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8469 - val_loss: 33.3504\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8388 - val_loss: 33.3415\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8307 - val_loss: 33.3327\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8225 - val_loss: 33.3238\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 29.8144 - val_loss: 33.3150\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8063 - val_loss: 33.3061\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7982 - val_loss: 33.2973\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7901 - val_loss: 33.2885\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7820 - val_loss: 33.2796\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7739 - val_loss: 33.2708\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.7658 - val_loss: 33.2619\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7577 - val_loss: 33.2531\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7495 - val_loss: 33.2442\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7414 - val_loss: 33.2354\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7333 - val_loss: 33.2266\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7252 - val_loss: 33.2177\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7171 - val_loss: 33.2089\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7090 - val_loss: 33.2001\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7009 - val_loss: 33.1912\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6928 - val_loss: 33.1824\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6848 - val_loss: 33.1736\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6767 - val_loss: 33.1647\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.6686 - val_loss: 33.1559\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.6605 - val_loss: 33.1471\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.6524 - val_loss: 33.1383\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6443 - val_loss: 33.1295\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6362 - val_loss: 33.1206\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6281 - val_loss: 33.1118\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6200 - val_loss: 33.1030\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6119 - val_loss: 33.0942\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6039 - val_loss: 33.0854\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5958 - val_loss: 33.0765\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5877 - val_loss: 33.0677\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5796 - val_loss: 33.0589\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5715 - val_loss: 33.0501\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5634 - val_loss: 33.0413\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.5554 - val_loss: 33.0325\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5473 - val_loss: 33.0237\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5392 - val_loss: 33.0149\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 29.5311 - val_loss: 33.0061\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5231 - val_loss: 32.9973\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5150 - val_loss: 32.9885\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5069 - val_loss: 32.9797\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4988 - val_loss: 32.9709\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4908 - val_loss: 32.9621\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4827 - val_loss: 32.9533\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4746 - val_loss: 32.9445\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4666 - val_loss: 32.9357\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4585 - val_loss: 32.9269\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4504 - val_loss: 32.9181\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4424 - val_loss: 32.9093\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4343 - val_loss: 32.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4263 - val_loss: 32.8917\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.4182 - val_loss: 32.8829\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4101 - val_loss: 32.8741\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4021 - val_loss: 32.8654\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3940 - val_loss: 32.8566\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3860 - val_loss: 32.8478\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3779 - val_loss: 32.8390\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.3699 - val_loss: 32.8302\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3618 - val_loss: 32.8215\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3538 - val_loss: 32.8127\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3457 - val_loss: 32.8039\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.3377 - val_loss: 32.7951\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3296 - val_loss: 32.7864\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3216 - val_loss: 32.7776\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3135 - val_loss: 32.7688\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3055 - val_loss: 32.7600\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2974 - val_loss: 32.7513\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2894 - val_loss: 32.7425\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.2813 - val_loss: 32.7337\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2733 - val_loss: 32.7250\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2653 - val_loss: 32.7162\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2572 - val_loss: 32.7074\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2492 - val_loss: 32.6987\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2412 - val_loss: 32.6899\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.2331 - val_loss: 32.6812\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.2251 - val_loss: 32.6724\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.2171 - val_loss: 32.6636\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2090 - val_loss: 32.6549\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2010 - val_loss: 32.6461\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1930 - val_loss: 32.6374\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1849 - val_loss: 32.6286\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1769 - val_loss: 32.6199\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1689 - val_loss: 32.6111\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1608 - val_loss: 32.6024\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1528 - val_loss: 32.5936\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1448 - val_loss: 32.5849\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1368 - val_loss: 32.5761\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1287 - val_loss: 32.5674\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1207 - val_loss: 32.5586\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.1127 - val_loss: 32.5499\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.1047 - val_loss: 32.5412\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0967 - val_loss: 32.5324\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0887 - val_loss: 32.5237\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.0806 - val_loss: 32.5149\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.0726 - val_loss: 32.5062\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0646 - val_loss: 32.4975\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0566 - val_loss: 32.4887\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.0486 - val_loss: 32.4800\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0406 - val_loss: 32.4713\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.0326 - val_loss: 32.4625\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.0246 - val_loss: 32.4538\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 29.0165 - val_loss: 32.4451\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0085 - val_loss: 32.4364\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.0005 - val_loss: 32.4276\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9925 - val_loss: 32.4189\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9845 - val_loss: 32.4102\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9765 - val_loss: 32.4015\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 28.9685 - val_loss: 32.3927\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.9605 - val_loss: 32.3840\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.9525 - val_loss: 32.3753\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.9445 - val_loss: 32.3666\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9365 - val_loss: 32.3579\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9285 - val_loss: 32.3492\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9205 - val_loss: 32.3404\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.9125 - val_loss: 32.3317\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.9045 - val_loss: 32.3230\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.8965 - val_loss: 32.3143\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8886 - val_loss: 32.3056\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8806 - val_loss: 32.2969\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.8726 - val_loss: 32.2882\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8646 - val_loss: 32.2795\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8566 - val_loss: 32.2708\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 28.8486 - val_loss: 32.2621\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8406 - val_loss: 32.2534\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8326 - val_loss: 32.2447\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.8246 - val_loss: 32.2360\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8167 - val_loss: 32.2273\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8087 - val_loss: 32.2186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.8007 - val_loss: 32.2099\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7927 - val_loss: 32.2012\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7847 - val_loss: 32.1925\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7768 - val_loss: 32.1838\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7688 - val_loss: 32.1751\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.7608 - val_loss: 32.1664\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7528 - val_loss: 32.1577\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.7449 - val_loss: 32.1490\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7369 - val_loss: 32.1403\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7289 - val_loss: 32.1316\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7209 - val_loss: 32.1229\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.7130 - val_loss: 32.1143\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.7050 - val_loss: 32.1056\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6970 - val_loss: 32.0969\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.6891 - val_loss: 32.0882\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.6811 - val_loss: 32.0795\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 28.6731 - val_loss: 32.0708\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.6652 - val_loss: 32.0622\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6572 - val_loss: 32.0535\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.6492 - val_loss: 32.0448\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.6413 - val_loss: 32.0361\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6333 - val_loss: 32.0275\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.6254 - val_loss: 32.0188\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6174 - val_loss: 32.0101\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.6094 - val_loss: 32.0014\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 28.6015 - val_loss: 31.9928\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.5935 - val_loss: 31.9841\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5856 - val_loss: 31.9754\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.5776 - val_loss: 31.9668\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5697 - val_loss: 31.9581\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.5617 - val_loss: 31.9494\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5538 - val_loss: 31.9408\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5458 - val_loss: 31.9321\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.5379 - val_loss: 31.9234\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.5299 - val_loss: 31.9148\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5220 - val_loss: 31.9061\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.5140 - val_loss: 31.8975\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.5061 - val_loss: 31.8888\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4981 - val_loss: 31.8801\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4902 - val_loss: 31.8715\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4822 - val_loss: 31.8628\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.4743 - val_loss: 31.8542\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4664 - val_loss: 31.8455\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4584 - val_loss: 31.8369\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4505 - val_loss: 31.8282\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.4425 - val_loss: 31.8196\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.4346 - val_loss: 31.8109\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4267 - val_loss: 31.8023\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.4187 - val_loss: 31.7936\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.4108 - val_loss: 31.7850\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.4029 - val_loss: 31.7763\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3949 - val_loss: 31.7677\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3870 - val_loss: 31.7591\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.3791 - val_loss: 31.7504\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3711 - val_loss: 31.7418\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3632 - val_loss: 31.7331\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3553 - val_loss: 31.7245\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.3473 - val_loss: 31.7159\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.3394 - val_loss: 31.7072\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3315 - val_loss: 31.6986\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3236 - val_loss: 31.6900\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3156 - val_loss: 31.6813\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.3077 - val_loss: 31.6727\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2998 - val_loss: 31.6641\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.2919 - val_loss: 31.6554\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2839 - val_loss: 31.6468\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2760 - val_loss: 31.6382\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2681 - val_loss: 31.6296\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.2602 - val_loss: 31.6209\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.2523 - val_loss: 31.6123\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2444 - val_loss: 31.6037\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2364 - val_loss: 31.5951\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2285 - val_loss: 31.5864\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.2206 - val_loss: 31.5778\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.2127 - val_loss: 31.5692\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.2048 - val_loss: 31.5606\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1969 - val_loss: 31.5520\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1890 - val_loss: 31.5433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1811 - val_loss: 31.5347\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 28.1732 - val_loss: 31.5261\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 28.1652 - val_loss: 31.5175\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1573 - val_loss: 31.5089\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.1494 - val_loss: 31.5003\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1415 - val_loss: 31.4917\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1336 - val_loss: 31.4831\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1257 - val_loss: 31.4744\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.1178 - val_loss: 31.4658\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 28.1099 - val_loss: 31.4572\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.1020 - val_loss: 31.4486\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.0941 - val_loss: 31.4400\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0862 - val_loss: 31.4314\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0783 - val_loss: 31.4228\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 28.0704 - val_loss: 31.4142\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 28.0625 - val_loss: 31.4056\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0546 - val_loss: 31.3970\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0467 - val_loss: 31.3884\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0389 - val_loss: 31.3798\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0310 - val_loss: 31.3712\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0231 - val_loss: 31.3626\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 28.0152 - val_loss: 31.3540\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 28.0073 - val_loss: 31.3454\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.9994 - val_loss: 31.3368\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9915 - val_loss: 31.3283\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9836 - val_loss: 31.3197\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9757 - val_loss: 31.3111\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9679 - val_loss: 31.3025\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9600 - val_loss: 31.2939\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9521 - val_loss: 31.2853\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9442 - val_loss: 31.2767\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9363 - val_loss: 31.2681\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9284 - val_loss: 31.2596\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9206 - val_loss: 31.2510\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9127 - val_loss: 31.2424\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.9048 - val_loss: 31.2338\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.8969 - val_loss: 31.2252\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8890 - val_loss: 31.2166\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8812 - val_loss: 31.2081\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.8733 - val_loss: 31.1995\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8654 - val_loss: 31.1909\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 27.8576 - val_loss: 31.1823\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 27.8497 - val_loss: 31.1738\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8418 - val_loss: 31.1652\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8339 - val_loss: 31.1566\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8261 - val_loss: 31.1480\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8182 - val_loss: 31.1395\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.8103 - val_loss: 31.1309\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.8025 - val_loss: 31.1223\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7946 - val_loss: 31.1138\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 27.7867 - val_loss: 31.1052\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7789 - val_loss: 31.0966\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7710 - val_loss: 31.0881\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7631 - val_loss: 31.0795\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7553 - val_loss: 31.0709\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.7474 - val_loss: 31.0624\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7395 - val_loss: 31.0538\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7317 - val_loss: 31.0452\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.7238 - val_loss: 31.0367\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7160 - val_loss: 31.0281\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.7081 - val_loss: 31.0196\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.7003 - val_loss: 31.0110\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6924 - val_loss: 31.0025\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.6845 - val_loss: 30.9939\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6767 - val_loss: 30.9853\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6688 - val_loss: 30.9768\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 27.6610 - val_loss: 30.9682\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6531 - val_loss: 30.9597\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 27.6453 - val_loss: 30.9511\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6374 - val_loss: 30.9426\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 27.6296 - val_loss: 30.9340\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6217 - val_loss: 30.9255\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.6139 - val_loss: 30.9169\n",
      "26.277950286865234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.6969341 ,  0.06979498,  0.28582537,  0.41822234,  0.57309145],\n",
       "        [-0.83487827,  0.13838951, -0.31552014, -0.15850592,  0.01319952],\n",
       "        [ 0.23510711,  0.60765356,  0.4974175 , -0.6459303 , -0.79658496]],\n",
       "       dtype=float32),\n",
       " array([-0.04482594, -0.11760397,  0.04541907,  0.12816344, -0.04478743],\n",
       "       dtype=float32),\n",
       " array([[-0.12922443, -0.24938425,  0.37650347, -0.34034374,  0.4925372 ,\n",
       "         -0.14596096,  0.23394717, -0.51161826,  0.32250664, -0.47266975],\n",
       "        [-0.4601581 , -0.20304288,  0.12898397,  0.35232562, -0.21782877,\n",
       "         -0.5323065 ,  0.54631037, -0.6076844 ,  0.11552908,  0.18493894],\n",
       "        [ 0.40989572,  0.51775783, -0.45437357, -0.6242968 ,  0.5159074 ,\n",
       "          0.00154999,  0.58743036,  0.43919536, -0.5861541 ,  0.28069952],\n",
       "        [ 0.3327614 , -0.57590026, -0.6258745 ,  0.03992485, -0.4739152 ,\n",
       "         -0.13125879, -0.11803488,  0.28011855,  0.4137189 ,  0.18756658],\n",
       "        [-0.4215489 ,  0.27784476, -0.01601287, -0.2986401 , -0.5453293 ,\n",
       "         -0.23755017,  0.1732627 , -0.5701199 ,  0.4093129 , -0.3723423 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.11619627, -0.01250652, -0.12831204, -0.06509837, -0.0213843 ,\n",
       "         0.07500271, -0.09127137,  0.01765536,  0.06845487,  0.09653538],\n",
       "       dtype=float32),\n",
       " array([[ 0.61411554],\n",
       "        [-0.06467144],\n",
       "        [-0.6803136 ],\n",
       "        [-0.3349266 ],\n",
       "        [-0.11571417],\n",
       "        [ 0.39452717],\n",
       "        [-0.47941196],\n",
       "        [ 0.10262628],\n",
       "        [ 0.35161257],\n",
       "        [ 0.51766825]], dtype=float32),\n",
       " array([0.1928883], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, sgd, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sgd_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 36.6955 - val_loss: 35.8690\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5906 - val_loss: 33.9377\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5926 - val_loss: 32.3255\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 29.7695 - val_loss: 30.9800\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 27.9401 - val_loss: 29.6308\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 26.0108 - val_loss: 28.1308\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 23.9488 - val_loss: 26.4003\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 21.7663 - val_loss: 24.4611\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19.4989 - val_loss: 22.3390\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 17.1959 - val_loss: 20.0568\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 14.9129 - val_loss: 17.6573\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.7032 - val_loss: 15.2235\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 10.6145 - val_loss: 12.8410\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6884 - val_loss: 10.5860\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9581 - val_loss: 8.5220\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4471 - val_loss: 6.6950\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1664 - val_loss: 5.1304\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1144 - val_loss: 3.8337\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2782 - val_loss: 2.7931\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6353 - val_loss: 1.9847\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1575 - val_loss: 1.3768\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8138 - val_loss: 0.9343\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5736 - val_loss: 0.6224\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4097 - val_loss: 0.4096\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2997 - val_loss: 0.2693\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2262 - val_loss: 0.1803\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1772 - val_loss: 0.1265\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1442 - val_loss: 0.0959\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1219 - val_loss: 0.0801\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1066 - val_loss: 0.0731\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0959 - val_loss: 0.0710\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0882 - val_loss: 0.0713\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0825 - val_loss: 0.0725\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0781 - val_loss: 0.0737\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0746 - val_loss: 0.0745\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0716 - val_loss: 0.0749\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0690 - val_loss: 0.0748\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0666 - val_loss: 0.0742\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0644 - val_loss: 0.0734\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0624 - val_loss: 0.0722\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0604 - val_loss: 0.0709\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0585 - val_loss: 0.0694\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0567 - val_loss: 0.0678\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0549 - val_loss: 0.0661\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0531 - val_loss: 0.0640\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0514 - val_loss: 0.0630\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0497 - val_loss: 0.0585\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0490 - val_loss: 0.0693\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0577 - val_loss: 0.0517\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1080 - val_loss: 0.1118\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1328 - val_loss: 0.0675\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1053 - val_loss: 0.0909\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0744 - val_loss: 0.0535\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0576 - val_loss: 0.0674\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0494 - val_loss: 0.0491\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0455 - val_loss: 0.0596\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0432 - val_loss: 0.0469\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0570\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0413 - val_loss: 0.0448\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0588\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0428 - val_loss: 0.0442\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0464 - val_loss: 0.0698\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0536 - val_loss: 0.0511\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0663 - val_loss: 0.0945\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0803 - val_loss: 0.0689\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0940 - val_loss: 0.1247\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1008 - val_loss: 0.1117\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1257 - val_loss: 0.1591\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1303 - val_loss: 0.1140\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1308 - val_loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0857 - val_loss: 0.0590\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0675 - val_loss: 0.0635\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0501 - val_loss: 0.0407\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0445 - val_loss: 0.0520\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0404 - val_loss: 0.0353\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0408 - val_loss: 0.0522\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0350\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0505 - val_loss: 0.0658\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0615 - val_loss: 0.0493\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0814 - val_loss: 0.0983\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0923 - val_loss: 0.0758\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1017 - val_loss: 0.1077\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0881 - val_loss: 0.0738\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0868 - val_loss: 0.0936\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0745 - val_loss: 0.0635\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0751 - val_loss: 0.0781\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0648 - val_loss: 0.0522\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0625 - val_loss: 0.0633\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0530 - val_loss: 0.0428\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0505 - val_loss: 0.0536\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0448 - val_loss: 0.0386\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0445 - val_loss: 0.0501\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0400\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0453 - val_loss: 0.0523\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0474 - val_loss: 0.0503\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0582 - val_loss: 0.0599\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0724 - val_loss: 0.0668\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0941 - val_loss: 0.0528\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0841 - val_loss: 0.0499\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0677 - val_loss: 0.0333\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0457 - val_loss: 0.0304\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0261\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0254\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0335\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0307 - val_loss: 0.0398\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0438 - val_loss: 0.0866\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0717 - val_loss: 0.1161\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1195 - val_loss: 0.1500\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1247 - val_loss: 0.1087\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1264 - val_loss: 0.0893\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0910 - val_loss: 0.0465\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0786 - val_loss: 0.0485\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0543 - val_loss: 0.0249\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0427 - val_loss: 0.0332\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0192\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0293\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0270 - val_loss: 0.0195\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0283 - val_loss: 0.0337\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0275\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0386 - val_loss: 0.0523\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0491 - val_loss: 0.0531\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0702 - val_loss: 0.0856\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0837 - val_loss: 0.0769\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0994 - val_loss: 0.0814\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0808 - val_loss: 0.0542\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0733 - val_loss: 0.0539\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0536 - val_loss: 0.0337\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0489 - val_loss: 0.0409\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0418 - val_loss: 0.0279\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0429 - val_loss: 0.0387\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0281\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0446 - val_loss: 0.0393\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0434 - val_loss: 0.0286\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0450 - val_loss: 0.0408\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0433 - val_loss: 0.0331\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0477 - val_loss: 0.0531\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0527 - val_loss: 0.0568\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0719 - val_loss: 0.0833\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0825 - val_loss: 0.0758\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0915 - val_loss: 0.0673\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0656 - val_loss: 0.0435\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0529 - val_loss: 0.0377\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0359 - val_loss: 0.0245\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0261\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0248 - val_loss: 0.0205\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0261 - val_loss: 0.0277\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0356 - val_loss: 0.0373\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0552 - val_loss: 0.0523\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 156us/step - loss: 0.0866 - val_loss: 0.0444\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0813 - val_loss: 0.0369\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0600 - val_loss: 0.0226\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0190\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0267 - val_loss: 0.0204\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0291 - val_loss: 0.0468\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0434 - val_loss: 0.0720\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0747 - val_loss: 0.1071\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0965 - val_loss: 0.1056\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1124 - val_loss: 0.0840\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0856 - val_loss: 0.0561\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0785 - val_loss: 0.0445\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0563 - val_loss: 0.0273\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0468 - val_loss: 0.0271\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0176\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0299 - val_loss: 0.0216\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0163\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0258 - val_loss: 0.0236\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0266 - val_loss: 0.0223\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0321 - val_loss: 0.0357\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0413\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0537 - val_loss: 0.0607\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0649 - val_loss: 0.0662\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0818 - val_loss: 0.0685\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0733 - val_loss: 0.0567\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0711 - val_loss: 0.0480\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0523 - val_loss: 0.0352\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0474 - val_loss: 0.0336\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0387 - val_loss: 0.0266\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0305\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0265\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0314\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0420 - val_loss: 0.0266\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0437 - val_loss: 0.0308\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0267\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0406 - val_loss: 0.0347\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0401 - val_loss: 0.0396\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0504 - val_loss: 0.0594\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0627 - val_loss: 0.0734\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0847 - val_loss: 0.0721\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0746 - val_loss: 0.0580\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0658 - val_loss: 0.0409\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0421 - val_loss: 0.0289\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0234\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0201\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0246 - val_loss: 0.0204\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0255\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0390 - val_loss: 0.0290\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0541 - val_loss: 0.0360\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0651 - val_loss: 0.0262\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0515 - val_loss: 0.0212\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0372 - val_loss: 0.0135\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0126\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0134\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0415\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0805\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0817 - val_loss: 0.1135\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1069 - val_loss: 0.1130\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1151 - val_loss: 0.0738\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0777 - val_loss: 0.0519\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0704 - val_loss: 0.0370\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0526 - val_loss: 0.0257\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0449 - val_loss: 0.0219\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0158\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0163\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0137\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0219 - val_loss: 0.0174\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0186\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0276\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0323 - val_loss: 0.0368\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0462 - val_loss: 0.0531\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0592 - val_loss: 0.0669\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0791 - val_loss: 0.0668\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0737 - val_loss: 0.0606\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0721 - val_loss: 0.0453\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0510 - val_loss: 0.0352\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0445 - val_loss: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0347 - val_loss: 0.0246\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0348 - val_loss: 0.0251\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0340 - val_loss: 0.0246\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0392 - val_loss: 0.0270\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0404 - val_loss: 0.0254\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0428 - val_loss: 0.0258\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0386 - val_loss: 0.0231\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0335 - val_loss: 0.0291\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0382 - val_loss: 0.0426\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0473 - val_loss: 0.0645\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0730 - val_loss: 0.0770\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0818 - val_loss: 0.0752\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0823 - val_loss: 0.0488\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0513 - val_loss: 0.0348\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0232\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0252 - val_loss: 0.0188\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0217 - val_loss: 0.0160\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0182\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0255 - val_loss: 0.0204\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0356 - val_loss: 0.0293\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0526 - val_loss: 0.0276\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0556 - val_loss: 0.0254\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0473 - val_loss: 0.0157\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0310 - val_loss: 0.0129\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0105\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0173 - val_loss: 0.0139\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0187 - val_loss: 0.0240\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0271 - val_loss: 0.0520\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0537 - val_loss: 0.0937\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0909 - val_loss: 0.1222\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1207 - val_loss: 0.0860\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0868 - val_loss: 0.0649\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0765 - val_loss: 0.0407\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0547 - val_loss: 0.0299\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0481 - val_loss: 0.0223\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0171\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0291 - val_loss: 0.0152\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0229 - val_loss: 0.0132\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0211 - val_loss: 0.0144\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0200 - val_loss: 0.0157\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0209\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0406\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0471 - val_loss: 0.0572\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0670 - val_loss: 0.0633\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0711 - val_loss: 0.0666\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0767 - val_loss: 0.0500\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0563 - val_loss: 0.0413\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0299\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0353 - val_loss: 0.0255\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0328 - val_loss: 0.0226\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0296 - val_loss: 0.0229\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.0243\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0366 - val_loss: 0.0261\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0259\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0242\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0401 - val_loss: 0.0227\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0338 - val_loss: 0.0226\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0325 - val_loss: 0.0267\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0390\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0456 - val_loss: 0.0588\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0641 - val_loss: 0.0822\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0896 - val_loss: 0.0678\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0722 - val_loss: 0.0545\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0585 - val_loss: 0.0320\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0345 - val_loss: 0.0238\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0166\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0197 - val_loss: 0.0159\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0199 - val_loss: 0.0149\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0202\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0226\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0443 - val_loss: 0.0271\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0511 - val_loss: 0.0201\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0409 - val_loss: 0.0163\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0304 - val_loss: 0.0106\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0206 - val_loss: 0.0105\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 0.0471\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0487 - val_loss: 0.0965\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0952 - val_loss: 0.1098\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.1069 - val_loss: 0.1013\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1032 - val_loss: 0.0573\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0655 - val_loss: 0.0419\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0575 - val_loss: 0.0272\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0210\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0351 - val_loss: 0.0161\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0135\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0125\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0188 - val_loss: 0.0126\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0190 - val_loss: 0.0145\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0187\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0315 - val_loss: 0.0386\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0462 - val_loss: 0.0510\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0586 - val_loss: 0.0671\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0765 - val_loss: 0.0601\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0677 - val_loss: 0.0562\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0639 - val_loss: 0.0383\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0437 - val_loss: 0.0316\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0372 - val_loss: 0.0235\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0218\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0281 - val_loss: 0.0204\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0279 - val_loss: 0.0230\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0345 - val_loss: 0.0248\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0393 - val_loss: 0.0272\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0453 - val_loss: 0.0250\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0414 - val_loss: 0.0231\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0372 - val_loss: 0.0208\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0305 - val_loss: 0.0224\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0301 - val_loss: 0.0282\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0462\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0517 - val_loss: 0.0667\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0725 - val_loss: 0.0838\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0902 - val_loss: 0.0584\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0624 - val_loss: 0.0443\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0470 - val_loss: 0.0254\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0280 - val_loss: 0.0198\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0141\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0146\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0143\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0235 - val_loss: 0.0200\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0343 - val_loss: 0.0216\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0429 - val_loss: 0.0240\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0456 - val_loss: 0.0172\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0350 - val_loss: 0.0140\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0099\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0110\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0167 - val_loss: 0.0149\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0195 - val_loss: 0.0323\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0347 - val_loss: 0.0661\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0665 - val_loss: 0.1137\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1110 - val_loss: 0.0968\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0961 - val_loss: 0.0802\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0854 - val_loss: 0.0450\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0561 - val_loss: 0.0337\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0487 - val_loss: 0.0221\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0177\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0289 - val_loss: 0.0137\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0220 - val_loss: 0.0124\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0195 - val_loss: 0.0118\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0131\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0187 - val_loss: 0.0155\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0359 - val_loss: 0.0453\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0528 - val_loss: 0.0549\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0628 - val_loss: 0.0671\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0757 - val_loss: 0.0538\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0606 - val_loss: 0.0481\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0542 - val_loss: 0.0322\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0316 - val_loss: 0.0207\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0205\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0259 - val_loss: 0.0197\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0272 - val_loss: 0.0238\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0355 - val_loss: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0474 - val_loss: 0.0246\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0413 - val_loss: 0.0224\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0354 - val_loss: 0.0194\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0278 - val_loss: 0.0274\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.0469\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0518 - val_loss: 0.0670\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0730 - val_loss: 0.0826\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0885 - val_loss: 0.0552\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0593 - val_loss: 0.0415\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0439 - val_loss: 0.0234\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0184\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0204 - val_loss: 0.0130\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0166 - val_loss: 0.0137\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0221 - val_loss: 0.0185\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0199\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0394 - val_loss: 0.0222\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0422 - val_loss: 0.0163\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0330 - val_loss: 0.0136\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0099\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0162\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0206 - val_loss: 0.0362\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0381 - val_loss: 0.0713\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0715 - val_loss: 0.1147\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1118 - val_loss: 0.0896\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0900 - val_loss: 0.0725\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0786 - val_loss: 0.0405\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0518 - val_loss: 0.0306\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0443 - val_loss: 0.0200\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0317 - val_loss: 0.0163\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0182 - val_loss: 0.0113\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0167 - val_loss: 0.0132\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0184 - val_loss: 0.0156\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0305\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0467\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0539 - val_loss: 0.0545\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0623 - val_loss: 0.0653\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0731 - val_loss: 0.0506\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0570 - val_loss: 0.0450\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0501 - val_loss: 0.0299\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0340 - val_loss: 0.0257\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0195\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 280us/step - loss: 0.0231 - val_loss: 0.0196\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0238 - val_loss: 0.0188\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0250 - val_loss: 0.0234\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0259\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0304\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0502 - val_loss: 0.0261\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0443 - val_loss: 0.0233\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0188\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0278 - val_loss: 0.0197\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0257 - val_loss: 0.0234\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0277 - val_loss: 0.0393\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0435 - val_loss: 0.0594\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0651 - val_loss: 0.0808\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0868 - val_loss: 0.0589\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0635 - val_loss: 0.0461\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0487 - val_loss: 0.0255\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0283 - val_loss: 0.0196\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0191 - val_loss: 0.0160\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0265 - val_loss: 0.0175\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0211\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0170\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0149\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0277 - val_loss: 0.0107\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0117\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0178 - val_loss: 0.0149\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0197 - val_loss: 0.0314\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0618\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0627 - val_loss: 0.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1038 - val_loss: 0.0910\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0910 - val_loss: 0.0768\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0815 - val_loss: 0.0423\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0526 - val_loss: 0.0318\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0445 - val_loss: 0.0201\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0313 - val_loss: 0.0164\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0257 - val_loss: 0.0124\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0196 - val_loss: 0.0116\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0174 - val_loss: 0.0145\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0278\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0431\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0497 - val_loss: 0.0513\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0589 - val_loss: 0.0636\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0711 - val_loss: 0.0509\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0572 - val_loss: 0.0464\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0307\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0346 - val_loss: 0.0263\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0194\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0223 - val_loss: 0.0190\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0219 - val_loss: 0.0174\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0215 - val_loss: 0.0212\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0241\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0317\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0501 - val_loss: 0.0298\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0510 - val_loss: 0.0278\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0451 - val_loss: 0.0205\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0320 - val_loss: 0.0188\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0258 - val_loss: 0.0184\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0230 - val_loss: 0.0268\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0303 - val_loss: 0.0414\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0458 - val_loss: 0.0687\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0745 - val_loss: 0.0668\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0726 - val_loss: 0.0604\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0641 - val_loss: 0.0338\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0372 - val_loss: 0.0251\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0270 - val_loss: 0.0153\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0183 - val_loss: 0.0138\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0139\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0253 - val_loss: 0.0186\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0335 - val_loss: 0.0177\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0175\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0328 - val_loss: 0.0128\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0248 - val_loss: 0.0123\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0214\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0250 - val_loss: 0.0402\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0427 - val_loss: 0.0821\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0806 - val_loss: 0.0946\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0934 - val_loss: 0.0930\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0939 - val_loss: 0.0524\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0599 - val_loss: 0.0392\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0504 - val_loss: 0.0234\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0347 - val_loss: 0.0186\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0283 - val_loss: 0.0132\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0104\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0346\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0405 - val_loss: 0.0438\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0509 - val_loss: 0.0594\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0666 - val_loss: 0.0531\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0599 - val_loss: 0.0522\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0575 - val_loss: 0.0351\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0393 - val_loss: 0.0300\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0328 - val_loss: 0.0210\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0197\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0217 - val_loss: 0.0165\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0215 - val_loss: 0.0196\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0249 - val_loss: 0.0271\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0493 - val_loss: 0.0367\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0595 - val_loss: 0.0280\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0470 - val_loss: 0.0231\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0171\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0242 - val_loss: 0.0178\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0213\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0245 - val_loss: 0.0365\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0400 - val_loss: 0.0543\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0601 - val_loss: 0.0732\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0791 - val_loss: 0.0535\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0587 - val_loss: 0.0429\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0458 - val_loss: 0.0240\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0210 - val_loss: 0.0126\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0110\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0172 - val_loss: 0.0141\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0224 - val_loss: 0.0149\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0185\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0335 - val_loss: 0.0161\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0315 - val_loss: 0.0156\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0219 - val_loss: 0.0145\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0209 - val_loss: 0.0194\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0399\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0417 - val_loss: 0.0681\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0684 - val_loss: 0.1006\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0979 - val_loss: 0.0765\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0781 - val_loss: 0.0636\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0700 - val_loss: 0.0360\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0464 - val_loss: 0.0275\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0384 - val_loss: 0.0174\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0145\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0216 - val_loss: 0.0110\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0109\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0154\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0277 - val_loss: 0.0303\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0363 - val_loss: 0.0458\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0521 - val_loss: 0.0504\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0652 - val_loss: 0.0444\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0498 - val_loss: 0.0399\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0436 - val_loss: 0.0267\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0298 - val_loss: 0.0236\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0256 - val_loss: 0.0178\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0200 - val_loss: 0.0182\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0197 - val_loss: 0.0166\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0232 - val_loss: 0.0227\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.0326\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0447 - val_loss: 0.0355\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0568 - val_loss: 0.0371\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0602 - val_loss: 0.0253\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0417 - val_loss: 0.0199\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0148\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0202 - val_loss: 0.0162\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0235 - val_loss: 0.0373\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0409 - val_loss: 0.0551\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0613 - val_loss: 0.0718\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0778 - val_loss: 0.0503\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0556 - val_loss: 0.0398\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0426 - val_loss: 0.0221\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0255 - val_loss: 0.0176\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0117\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0212 - val_loss: 0.0141\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0261 - val_loss: 0.0176\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0317 - val_loss: 0.0156\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0155\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0274 - val_loss: 0.0126\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0157\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0267 - val_loss: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0467 - val_loss: 0.0723\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0723 - val_loss: 0.0984\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0960 - val_loss: 0.0697\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0724 - val_loss: 0.0565\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0638 - val_loss: 0.0320\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0423 - val_loss: 0.0245\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0157\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0133\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0195 - val_loss: 0.0104\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0161\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0207 - val_loss: 0.0244\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0291 - val_loss: 0.0319\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0379 - val_loss: 0.0474\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0537 - val_loss: 0.0499\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0569 - val_loss: 0.0562\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0621 - val_loss: 0.0413\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0461 - val_loss: 0.0368\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0248\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0275 - val_loss: 0.0223\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0171\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0189 - val_loss: 0.0178\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0188 - val_loss: 0.0164\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0230 - val_loss: 0.0285\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0297 - val_loss: 0.0313\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0431\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0497 - val_loss: 0.0463\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0653 - val_loss: 0.0499\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0793 - val_loss: 0.0291\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0514 - val_loss: 0.0191\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0106\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0166 - val_loss: 0.0081\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0156 - val_loss: 0.0296\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0537\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0605 - val_loss: 0.0818\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0885 - val_loss: 0.0596\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0656 - val_loss: 0.0465\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0491 - val_loss: 0.0236\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0177\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0195 - val_loss: 0.0108\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0144 - val_loss: 0.0092\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0124\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0221 - val_loss: 0.0134\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0276 - val_loss: 0.0155\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.0121\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0260 - val_loss: 0.0098\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0064\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0051\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0038\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0352\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0397 - val_loss: 0.1170\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1246 - val_loss: 0.1721\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.1830 - val_loss: 0.0685\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0753 - val_loss: 0.0357\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0392 - val_loss: 0.0136\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0158 - val_loss: 0.0082\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0074 - val_loss: 0.0091\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0225 - val_loss: 0.0291\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0431 - val_loss: 0.0413\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0614 - val_loss: 0.0546\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0721 - val_loss: 0.0452\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0566 - val_loss: 0.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0529 - val_loss: 0.0395\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0439 - val_loss: 0.0438\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0477 - val_loss: 0.0362\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0407 - val_loss: 0.0349\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0392 - val_loss: 0.0248\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0302 - val_loss: 0.0229\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0224 - val_loss: 0.0167\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0217 - val_loss: 0.0134\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0150\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0133\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0205 - val_loss: 0.0161\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0154\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0200\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0265 - val_loss: 0.0212\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0298\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0345 - val_loss: 0.0337\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0465\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0471 - val_loss: 0.0467\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0469 - val_loss: 0.0559\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0534 - val_loss: 0.0502\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0520 - val_loss: 0.0550\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0637 - val_loss: 0.0409\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0562 - val_loss: 0.0342\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0482 - val_loss: 0.0206\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0162\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0219 - val_loss: 0.0115\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0113\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.0256\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0283 - val_loss: 0.0327\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0469\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0455\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0505 - val_loss: 0.0484\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0519 - val_loss: 0.0342\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0379 - val_loss: 0.0308\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0215\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0209\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0233 - val_loss: 0.0181\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0247\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0416 - val_loss: 0.0272\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0477 - val_loss: 0.0198\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0362 - val_loss: 0.0151\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0248 - val_loss: 0.0104\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0162 - val_loss: 0.0099\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0183\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.0324\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0359 - val_loss: 0.0644\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0693 - val_loss: 0.0728\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0795 - val_loss: 0.0698\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0734 - val_loss: 0.0358\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0390 - val_loss: 0.0251\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.0136\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0083\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0183 - val_loss: 0.0155\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0274 - val_loss: 0.0164\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0174\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0329 - val_loss: 0.0122\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0242 - val_loss: 0.0107\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0092\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0182 - val_loss: 0.0275\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0303 - val_loss: 0.0626\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0622 - val_loss: 0.0853\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0858 - val_loss: 0.0927\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0930 - val_loss: 0.0511\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0566 - val_loss: 0.0371\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0443 - val_loss: 0.0205\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0162\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0231 - val_loss: 0.0112\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0173 - val_loss: 0.0104\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0150 - val_loss: 0.0141\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0185 - val_loss: 0.0174\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0271\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0322 - val_loss: 0.0346\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0411 - val_loss: 0.0504\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0564 - val_loss: 0.0493\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0558 - val_loss: 0.0530\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0575 - val_loss: 0.0366\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0321\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0214\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0215 - val_loss: 0.0161\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0239 - val_loss: 0.0191\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0295 - val_loss: 0.0244\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0199\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0186\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0313 - val_loss: 0.0120\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0214 - val_loss: 0.0115\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.0100\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.0398\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0558\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0563 - val_loss: 0.0764\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0756 - val_loss: 0.0595\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0642 - val_loss: 0.0524\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0606 - val_loss: 0.0305\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0409 - val_loss: 0.0237\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0146\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0123\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0092\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0145\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.0228\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0267 - val_loss: 0.0303\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0358 - val_loss: 0.0466\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0521 - val_loss: 0.0490\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0554 - val_loss: 0.0551\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0595 - val_loss: 0.0386\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0339\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0220\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0205\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0217 - val_loss: 0.0161\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0251 - val_loss: 0.0197\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0324 - val_loss: 0.0248\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0414 - val_loss: 0.0185\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0159\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0096\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0092\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0136 - val_loss: 0.0081\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0406\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0403 - val_loss: 0.0597\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0604 - val_loss: 0.0811\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0805 - val_loss: 0.0592\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0641 - val_loss: 0.0498\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0576 - val_loss: 0.0280\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0377 - val_loss: 0.0217\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0301 - val_loss: 0.0135\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0206 - val_loss: 0.0116\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0088\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0148 - val_loss: 0.0136\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0179 - val_loss: 0.0214\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0255 - val_loss: 0.0287\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0453\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0508 - val_loss: 0.0494\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0561 - val_loss: 0.0573\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0621 - val_loss: 0.0405\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0446 - val_loss: 0.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0372 - val_loss: 0.0226\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0208\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0161\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0209 - val_loss: 0.0192\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0178\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0307 - val_loss: 0.0208\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0353 - val_loss: 0.0150\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0134\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0229 - val_loss: 0.0086\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0089\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0132 - val_loss: 0.0084\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0219\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0245 - val_loss: 0.0448\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0446 - val_loss: 0.0627\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0636 - val_loss: 0.0806\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0799 - val_loss: 0.0559\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0606 - val_loss: 0.0464\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0540 - val_loss: 0.0265\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0362 - val_loss: 0.0208\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0131\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0113\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0086\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0215\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0290\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0459\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0514 - val_loss: 0.0494\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0561 - val_loss: 0.0564\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0610 - val_loss: 0.0391\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0431 - val_loss: 0.0340\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0216\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0243 - val_loss: 0.0201\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0220 - val_loss: 0.0156\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0207 - val_loss: 0.0189\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0175\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0201\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0344 - val_loss: 0.0143\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0127\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0218 - val_loss: 0.0083\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0088\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0166 - val_loss: 0.0235\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0478\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0475 - val_loss: 0.0642\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0651 - val_loss: 0.0791\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0788 - val_loss: 0.0527\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0579 - val_loss: 0.0430\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0507 - val_loss: 0.0245\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0192\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0272 - val_loss: 0.0123\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0190 - val_loss: 0.0107\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0157 - val_loss: 0.0083\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0115\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0300\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0357 - val_loss: 0.0469\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0524 - val_loss: 0.0492\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0558 - val_loss: 0.0551\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0594 - val_loss: 0.0376\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0414 - val_loss: 0.0326\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0208\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0238 - val_loss: 0.0198\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0156\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0216 - val_loss: 0.0188\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0271 - val_loss: 0.0166\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0183\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0315 - val_loss: 0.0126\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0245 - val_loss: 0.0114\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0193 - val_loss: 0.0077\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0125 - val_loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0164\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0182 - val_loss: 0.0267\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0293 - val_loss: 0.0530\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0526 - val_loss: 0.0661\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0671 - val_loss: 0.0763\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0765 - val_loss: 0.0484\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0389\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0469 - val_loss: 0.0223\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0314 - val_loss: 0.0176\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0178 - val_loss: 0.0101\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0148 - val_loss: 0.0080\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0276 - val_loss: 0.0316\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0374 - val_loss: 0.0488\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0543 - val_loss: 0.0491\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0556 - val_loss: 0.0532\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0571 - val_loss: 0.0354\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0390 - val_loss: 0.0306\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0197\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0192\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0221 - val_loss: 0.0153\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0186\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0158\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0292 - val_loss: 0.0168\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0290 - val_loss: 0.0113\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0219 - val_loss: 0.0104\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0173 - val_loss: 0.0073\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0130 - val_loss: 0.0088\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0134 - val_loss: 0.0187\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0204 - val_loss: 0.0309\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0335 - val_loss: 0.0591\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0584 - val_loss: 0.0670\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0681 - val_loss: 0.0720\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0731 - val_loss: 0.0436\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0501 - val_loss: 0.0345\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0427 - val_loss: 0.0199\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0159\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0229 - val_loss: 0.0105\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0164 - val_loss: 0.0095\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0077\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0119 - val_loss: 0.0088\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0198 - val_loss: 0.0255\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0296 - val_loss: 0.0338\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0399 - val_loss: 0.0509\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0565 - val_loss: 0.0486\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0548 - val_loss: 0.0506\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0328\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0363 - val_loss: 0.0284\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0300 - val_loss: 0.0186\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0221 - val_loss: 0.0186\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0150\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0230 - val_loss: 0.0181\n",
      "0.002618433441966772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.51263875,  0.80896986,  0.00595985,  0.20694405,  0.5027192 ],\n",
       "        [-0.22530574, -0.08534189,  0.05866665, -0.05954516,  0.20408928],\n",
       "        [-0.3991134 ,  0.1381345 ,  0.18508072, -0.0802011 ,  0.3857217 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.28211   , -0.37899697,  0.41298273,  0.33775887,  0.32688272],\n",
       "       dtype=float32),\n",
       " array([[ 0.448501  ,  0.21534765, -0.37219357, -0.10272112,  0.2606449 ,\n",
       "          0.62140864, -0.6213567 ,  0.23469952,  0.42477912, -0.4227617 ],\n",
       "        [-0.06083927,  0.52766275,  0.53080344,  0.27403927,  0.14151901,\n",
       "         -0.83799034,  0.44434944,  0.08110259, -0.42612296,  0.37949812],\n",
       "        [ 0.66655433,  0.13871539, -0.29017702,  0.24338292, -0.2667478 ,\n",
       "          0.2753393 , -0.31192723, -0.7764916 ,  0.46544275, -0.6585202 ],\n",
       "        [ 0.6014414 ,  0.42050758, -0.56431097, -0.50156593, -0.5535834 ,\n",
       "          0.4605099 , -0.40957552, -0.67721295, -0.09823111,  0.47671756],\n",
       "        [-0.02861236, -0.44147468, -0.29446372,  0.19847646,  0.01082743,\n",
       "          0.27157456,  0.09917583, -0.734237  ,  0.51892585, -0.1483266 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.43739158, -0.45235845, -0.44842857, -0.4515115 ,  0.45224553,\n",
       "         0.4394039 , -0.44906166, -0.4498206 ,  0.17349426, -0.45483977],\n",
       "       dtype=float32),\n",
       " array([[ 0.54818654],\n",
       "        [-0.845257  ],\n",
       "        [-0.76116025],\n",
       "        [-0.8829042 ],\n",
       "        [ 0.66754055],\n",
       "        [ 0.47243753],\n",
       "        [-0.77369255],\n",
       "        [-0.90597177],\n",
       "        [ 0.1577442 ],\n",
       "        [-0.8957572 ]], dtype=float32),\n",
       " array([0.4749385], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, RMSprop, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_rmsprop_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
