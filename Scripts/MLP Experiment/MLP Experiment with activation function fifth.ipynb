{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_linear(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_relu(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_sigmoid(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression_tanh(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 427us/step - loss: 15181.4297 - val_loss: 14319.8414\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12022.0383 - val_loss: 8497.6504\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4470.9665 - val_loss: 880.8587\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 174.0829 - val_loss: 50.2710\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 35.4476 - val_loss: 30.1191\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 25.3681 - val_loss: 28.2978\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 24.3312 - val_loss: 28.6218\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.3567 - val_loss: 28.0117\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.8285 - val_loss: 27.7724\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.7770 - val_loss: 28.0426\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.5973 - val_loss: 28.1304\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5101 - val_loss: 27.0470\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.1377 - val_loss: 26.9408\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1948 - val_loss: 27.1427\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 21.9614 - val_loss: 27.2371\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0724 - val_loss: 26.9491\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3204 - val_loss: 26.5343\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0929 - val_loss: 26.6201\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7722 - val_loss: 26.5950\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.0388 - val_loss: 26.3176\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.7672 - val_loss: 26.9549\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0211 - val_loss: 26.8501\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7239 - val_loss: 26.5023\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.8686 - val_loss: 26.2303\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7661 - val_loss: 26.1502\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8040 - val_loss: 26.5858\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1453 - val_loss: 26.5686\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9165 - val_loss: 26.1783\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6161 - val_loss: 26.2375\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5020 - val_loss: 27.0526\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5580 - val_loss: 25.8827\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5423 - val_loss: 26.4173\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6186 - val_loss: 25.6863\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7741 - val_loss: 25.7551\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2566 - val_loss: 26.1793\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6813 - val_loss: 25.7907\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5381 - val_loss: 26.4760\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5481 - val_loss: 26.5300\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5231 - val_loss: 25.7359\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.4247 - val_loss: 26.1171\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.3922 - val_loss: 25.5353\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.7194 - val_loss: 25.4484\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.1343 - val_loss: 25.4341\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.2332 - val_loss: 25.4219\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.0118 - val_loss: 25.0629\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 20.7431 - val_loss: 25.2815\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.5896 - val_loss: 24.8671\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.6275 - val_loss: 25.4511\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.2914 - val_loss: 25.0438\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.1415 - val_loss: 24.6014\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8039 - val_loss: 24.8459\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 19.4122 - val_loss: 24.8875\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.2538 - val_loss: 24.6231\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8635 - val_loss: 24.7587\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.9287 - val_loss: 24.5410\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.5187 - val_loss: 25.2775\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.4580 - val_loss: 23.3720\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4848 - val_loss: 23.4362\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.4980 - val_loss: 23.1001\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0880 - val_loss: 22.6758\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8703 - val_loss: 22.7121\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.8169 - val_loss: 23.3703\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.6402 - val_loss: 22.3579\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7373 - val_loss: 21.6000\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 131us/step - loss: 17.5121 - val_loss: 22.4203\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.9007 - val_loss: 21.3062\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5308 - val_loss: 21.7375\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3030 - val_loss: 21.9538\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6103 - val_loss: 20.5202\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1921 - val_loss: 20.9762\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8604 - val_loss: 20.4699\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0457 - val_loss: 21.0324\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8498 - val_loss: 21.2650\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2081 - val_loss: 19.7310\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.7603 - val_loss: 19.6141\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4930 - val_loss: 19.7632\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3302 - val_loss: 20.1822\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.7069 - val_loss: 20.4802\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5433 - val_loss: 19.9845\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.0802 - val_loss: 18.5821\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.7996 - val_loss: 19.9861\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2039 - val_loss: 18.5241\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.9166 - val_loss: 19.5268\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1353 - val_loss: 18.2546\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.6910 - val_loss: 18.7522\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.5537 - val_loss: 19.6335\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1403 - val_loss: 19.3240\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8623 - val_loss: 18.5474\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4938 - val_loss: 18.7540\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2186 - val_loss: 18.9035\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.0290 - val_loss: 18.3141\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.8195 - val_loss: 18.9568\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.4984 - val_loss: 17.8243\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.2458 - val_loss: 19.0816\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.6292 - val_loss: 20.6101\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.4995 - val_loss: 18.2949\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5276 - val_loss: 18.9147\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4501 - val_loss: 17.9753\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2934 - val_loss: 18.1362\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.2820 - val_loss: 17.7939\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.9253 - val_loss: 17.8543\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.3699 - val_loss: 17.5389\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.4807 - val_loss: 17.9119\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1234 - val_loss: 21.2368\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.6197 - val_loss: 18.4661\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1855 - val_loss: 17.8663\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.1487 - val_loss: 18.7636\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0827 - val_loss: 18.4060\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0193 - val_loss: 18.8687\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.0449 - val_loss: 17.8319\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.6960 - val_loss: 16.8643\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 14.9692 - val_loss: 17.9081\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8183 - val_loss: 17.4639\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8158 - val_loss: 17.8437\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.8808 - val_loss: 18.1264\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7871 - val_loss: 17.4914\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9575 - val_loss: 21.2264\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5423 - val_loss: 18.0672\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.9988 - val_loss: 20.0007\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.9975 - val_loss: 16.6778\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 14.0462 - val_loss: 17.0044\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.5611 - val_loss: 17.7266\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 14.1647 - val_loss: 17.9392\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 14.0083 - val_loss: 18.4345\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8459 - val_loss: 17.7741\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 15.1848 - val_loss: 19.6763\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 15.3775 - val_loss: 16.7474\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.8780 - val_loss: 18.5248\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9287 - val_loss: 16.3961\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8924 - val_loss: 17.4133\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.7648 - val_loss: 16.8626\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2496 - val_loss: 19.6444\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.0463 - val_loss: 17.7540\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6630 - val_loss: 17.6184\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.8193 - val_loss: 17.7818\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8897 - val_loss: 17.8823\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5058 - val_loss: 16.3588\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.87 - 0s 94us/step - loss: 14.0951 - val_loss: 18.1753\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9240 - val_loss: 19.0272\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9502 - val_loss: 18.3412\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1625 - val_loss: 16.4724\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7730 - val_loss: 16.4262\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5196 - val_loss: 17.4919\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5203 - val_loss: 21.6959\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.9350 - val_loss: 18.3647\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.4172 - val_loss: 16.8601\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6426 - val_loss: 15.8427\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.0052 - val_loss: 15.8707\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9084 - val_loss: 17.7778\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.3220 - val_loss: 17.2059\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3133 - val_loss: 16.1328\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.0274 - val_loss: 15.8583\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9984 - val_loss: 16.8862\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7926 - val_loss: 15.7882\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.9447 - val_loss: 16.7321\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7881 - val_loss: 15.8030\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.4122 - val_loss: 18.2160\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.3400 - val_loss: 16.4925\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6950 - val_loss: 17.7616\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9530 - val_loss: 15.3841\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6879 - val_loss: 14.8986\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9622 - val_loss: 15.3320\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.1881 - val_loss: 15.1418\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2650 - val_loss: 17.7096\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.5647 - val_loss: 16.1260\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.6204 - val_loss: 16.4922\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.6155 - val_loss: 15.5825\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.4455 - val_loss: 18.0786\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.7082 - val_loss: 15.3521\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.0716 - val_loss: 15.8715\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9519 - val_loss: 15.6362\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 12.5087 - val_loss: 14.2970\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3275 - val_loss: 14.5099\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.8173 - val_loss: 14.5180\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.5192 - val_loss: 17.3602\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.9334 - val_loss: 15.7383\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1577 - val_loss: 14.3242\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7898 - val_loss: 13.9858\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9282 - val_loss: 15.0551\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2604 - val_loss: 15.4430\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8231 - val_loss: 14.2316\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2812 - val_loss: 14.4000\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 11.3257 - val_loss: 14.9465\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.3541 - val_loss: 14.8902\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5463 - val_loss: 17.5949\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.1475 - val_loss: 14.8739\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4300 - val_loss: 14.2007\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.0357 - val_loss: 15.4972\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.6151 - val_loss: 13.8044\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.0736 - val_loss: 15.7588\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8490 - val_loss: 13.9122\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 12.1042 - val_loss: 14.5788\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.1706 - val_loss: 14.6555\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 11.2705 - val_loss: 13.4880\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.5659 - val_loss: 14.3908\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.6878 - val_loss: 15.9061\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1590 - val_loss: 15.7996\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0410 - val_loss: 14.7685\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4549 - val_loss: 14.8892\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.9803 - val_loss: 13.9658\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4248 - val_loss: 14.4232\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.8369 - val_loss: 15.2678\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.2286 - val_loss: 14.1749\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9899 - val_loss: 13.3260\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1423 - val_loss: 14.2092\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.1289 - val_loss: 13.3023\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6282 - val_loss: 12.9304\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7542 - val_loss: 13.3408\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 11.22 - 0s 84us/step - loss: 10.7771 - val_loss: 13.0509\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.6895 - val_loss: 14.6233\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.8416 - val_loss: 12.7979\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2782 - val_loss: 14.3950\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.7342 - val_loss: 13.9378\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4523 - val_loss: 13.1484\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5693 - val_loss: 12.5920\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5325 - val_loss: 13.1566\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6631 - val_loss: 13.0251\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6575 - val_loss: 14.1229\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.0633 - val_loss: 14.5795\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6085 - val_loss: 15.4930\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5944 - val_loss: 13.3865\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8627 - val_loss: 13.5607\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5655 - val_loss: 13.0489\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4004 - val_loss: 13.6534\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7211 - val_loss: 16.2133\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4294 - val_loss: 13.4108\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3910 - val_loss: 12.3148\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4814 - val_loss: 12.3357\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8147 - val_loss: 12.5682\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0741 - val_loss: 12.2916\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.6503 - val_loss: 12.6844\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.4586 - val_loss: 12.3504\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3500 - val_loss: 13.7802\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8165 - val_loss: 13.1001\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6040 - val_loss: 13.3862\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1543 - val_loss: 14.7082\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1670 - val_loss: 12.3618\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.9637 - val_loss: 12.6694\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1127 - val_loss: 12.8311\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1398 - val_loss: 13.1046\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3264 - val_loss: 12.8864\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.0725 - val_loss: 11.8894\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7550 - val_loss: 13.5945\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9605 - val_loss: 14.2624\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8863 - val_loss: 12.6232\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6893 - val_loss: 14.1397\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.4769 - val_loss: 12.7772\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0686 - val_loss: 12.4881\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1186 - val_loss: 12.5513\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1001 - val_loss: 12.9933\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7506 - val_loss: 12.3439\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9354 - val_loss: 11.7222\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7606 - val_loss: 13.1858\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6567 - val_loss: 12.2905\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5138 - val_loss: 12.0490\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4277 - val_loss: 12.8945\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8498 - val_loss: 12.9413\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9151 - val_loss: 12.5027\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9805 - val_loss: 13.2509\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8098 - val_loss: 12.2105\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4623 - val_loss: 11.5710\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3645 - val_loss: 12.0496\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8004 - val_loss: 12.4167\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5774 - val_loss: 11.8689\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6725 - val_loss: 12.1572\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1682 - val_loss: 12.3592\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2374 - val_loss: 12.9310\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.9121 - val_loss: 12.2986\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4561 - val_loss: 11.5709\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5242 - val_loss: 11.5644\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0619 - val_loss: 12.2940\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1660 - val_loss: 12.0404\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8011 - val_loss: 12.3025\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8833 - val_loss: 11.8262\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1419 - val_loss: 11.4022\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8924 - val_loss: 13.4501\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6819 - val_loss: 12.4796\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5947 - val_loss: 12.1028\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3914 - val_loss: 13.1699\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8951 - val_loss: 12.2935\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5272 - val_loss: 11.8961\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9949 - val_loss: 12.8768\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5173 - val_loss: 12.6542\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4404 - val_loss: 11.3365\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4379 - val_loss: 11.3398\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8322 - val_loss: 11.2290\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5453 - val_loss: 12.0237\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.0370 - val_loss: 12.1064\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.6988 - val_loss: 12.1386\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.6724 - val_loss: 11.7055\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.0266 - val_loss: 12.5823\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3040 - val_loss: 12.5948\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7724 - val_loss: 12.5049\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.7017 - val_loss: 11.3037\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.2168 - val_loss: 11.6813\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2059 - val_loss: 12.3863\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9335 - val_loss: 11.7529\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3389 - val_loss: 11.9153\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7741 - val_loss: 11.4053\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2190 - val_loss: 12.3037\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5246 - val_loss: 12.3253\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9064 - val_loss: 11.4282\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6029 - val_loss: 11.4724\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3049 - val_loss: 11.7038\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3685 - val_loss: 11.4131\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0655 - val_loss: 13.4389\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3814 - val_loss: 13.0748\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2744 - val_loss: 11.4934\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9199 - val_loss: 12.2952\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2733 - val_loss: 12.6530\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4752 - val_loss: 11.9049\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1170 - val_loss: 13.7853\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1915 - val_loss: 11.6437\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4813 - val_loss: 11.4798\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8487 - val_loss: 11.6969\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0289 - val_loss: 13.0003\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2029 - val_loss: 11.2350\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3197 - val_loss: 11.2837\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6573 - val_loss: 13.0729\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5373 - val_loss: 13.4086\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0572 - val_loss: 12.6582\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2768 - val_loss: 11.7117\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4891 - val_loss: 11.3042\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1693 - val_loss: 12.9374\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.7790 - val_loss: 11.4378\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3629 - val_loss: 13.3155\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6160 - val_loss: 10.9188\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1232 - val_loss: 11.6374\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4888 - val_loss: 13.1317\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8160 - val_loss: 11.8597\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.5028 - val_loss: 12.4292\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3014 - val_loss: 11.2785\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2280 - val_loss: 11.1608\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.8732 - val_loss: 11.4854\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3404 - val_loss: 13.0747\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3649 - val_loss: 12.4022\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3442 - val_loss: 11.0107\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5705 - val_loss: 12.1440\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2175 - val_loss: 12.3170\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1562 - val_loss: 11.7370\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4971 - val_loss: 11.5767\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3446 - val_loss: 11.8942\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2128 - val_loss: 11.6103\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3859 - val_loss: 11.7234\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7667 - val_loss: 11.9798\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4405 - val_loss: 10.8989\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4999 - val_loss: 11.4228\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4467 - val_loss: 12.4550\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7244 - val_loss: 12.0376\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3418 - val_loss: 11.2301\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2324 - val_loss: 13.1819\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5865 - val_loss: 11.6304\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3977 - val_loss: 13.1536\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1354 - val_loss: 11.5180\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3526 - val_loss: 10.8726\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3515 - val_loss: 13.7626\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5557 - val_loss: 12.9668\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4154 - val_loss: 11.1144\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4757 - val_loss: 11.2778\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6778 - val_loss: 11.3496\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1402 - val_loss: 11.4967\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2049 - val_loss: 11.5696\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6644 - val_loss: 11.7006\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2276 - val_loss: 11.2354\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7495 - val_loss: 10.7836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4007 - val_loss: 11.9295\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9924 - val_loss: 11.4980\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1783 - val_loss: 11.9081\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4541 - val_loss: 11.3381\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0249 - val_loss: 13.0937\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4183 - val_loss: 11.2837\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.5508 - val_loss: 12.2404\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5346 - val_loss: 12.0701\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5741 - val_loss: 12.1016\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5542 - val_loss: 11.3703\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3735 - val_loss: 11.8300\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5446 - val_loss: 11.8299\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1342 - val_loss: 11.8377\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1384 - val_loss: 10.9014\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0882 - val_loss: 11.4758\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1825 - val_loss: 12.3621\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7615 - val_loss: 12.0005\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3920 - val_loss: 10.8342\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3123 - val_loss: 11.1683\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2115 - val_loss: 11.7492\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4330 - val_loss: 11.0024\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2334 - val_loss: 12.9194\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6569 - val_loss: 12.2120\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8575 - val_loss: 10.7844\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1746 - val_loss: 11.4749\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3132 - val_loss: 10.8168\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.1361 - val_loss: 10.9227\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.1131 - val_loss: 12.9948\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2601 - val_loss: 12.3760\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5644 - val_loss: 11.2906\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3391 - val_loss: 11.5712\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4513 - val_loss: 11.1750\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3395 - val_loss: 12.1103\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0706 - val_loss: 11.6048\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2227 - val_loss: 11.3821\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2456 - val_loss: 11.4032\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9813 - val_loss: 11.1765\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1339 - val_loss: 13.9911\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.7451 - val_loss: 11.1216\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1316 - val_loss: 11.5087\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4102 - val_loss: 10.9433\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2136 - val_loss: 11.2111\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5941 - val_loss: 11.2962\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4118 - val_loss: 11.5548\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3519 - val_loss: 11.3842\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.3025 - val_loss: 11.2604\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6400 - val_loss: 12.9116\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.2659 - val_loss: 11.1869\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 115us/step - loss: 9.4782 - val_loss: 12.6444\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.2661 - val_loss: 11.8279\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1637 - val_loss: 11.4164\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.3790 - val_loss: 10.8931\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4282 - val_loss: 11.2635\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6390 - val_loss: 13.4530\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1458 - val_loss: 10.9696\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8753 - val_loss: 13.6401\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2595 - val_loss: 11.9265\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9826 - val_loss: 11.1658\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9950 - val_loss: 11.1449\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.2663 - val_loss: 10.8387\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1703 - val_loss: 11.3455\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0762 - val_loss: 11.2846\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9097 - val_loss: 12.4004\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3072 - val_loss: 12.6005\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3788 - val_loss: 11.0311\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 9.5122 - val_loss: 11.2976\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 8.9476 - val_loss: 11.4999\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.5165 - val_loss: 13.0328\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2899 - val_loss: 12.2641\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1940 - val_loss: 11.2080\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8752 - val_loss: 13.1066\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 9.2237 - val_loss: 10.9663\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.0286 - val_loss: 12.2273\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 9.1084 - val_loss: 11.0591\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.3038 - val_loss: 10.9640\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1310 - val_loss: 11.0754\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9923 - val_loss: 12.6076\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2363 - val_loss: 11.1838\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0804 - val_loss: 11.1034\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0251 - val_loss: 12.4775\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2770 - val_loss: 11.7259\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2481 - val_loss: 11.7729\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2339 - val_loss: 11.0918\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2881 - val_loss: 10.9365\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 9.6215 - val_loss: 11.1892\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.6864 - val_loss: 11.5401\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4072 - val_loss: 13.4812\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 9.5820 - val_loss: 11.3889\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1524 - val_loss: 11.6913\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 9.5681 - val_loss: 11.5798\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2588 - val_loss: 11.7759\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1682 - val_loss: 10.9898\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2744 - val_loss: 12.4051\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3572 - val_loss: 11.1200\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1694 - val_loss: 12.3155\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6488 - val_loss: 12.2999\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9613 - val_loss: 10.7178\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2587 - val_loss: 11.0614\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2948 - val_loss: 11.7164\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3408 - val_loss: 10.9441\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9890 - val_loss: 11.1374\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1479 - val_loss: 11.0922\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2073 - val_loss: 11.0121\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0931 - val_loss: 10.9251\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.8160 - val_loss: 11.0929\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2363 - val_loss: 11.0030\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3121 - val_loss: 12.0203\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.6268 - val_loss: 11.5267\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5199 - val_loss: 10.7760\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3315 - val_loss: 11.7733\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9833 - val_loss: 10.7243\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0619 - val_loss: 11.0664\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4309 - val_loss: 11.4759\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0562 - val_loss: 11.9672\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5713 - val_loss: 11.5485\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1515 - val_loss: 11.7770\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2543 - val_loss: 11.0895\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2779 - val_loss: 16.2829\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2045 - val_loss: 12.6319\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0181 - val_loss: 10.9974\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4749 - val_loss: 10.9236\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3214 - val_loss: 10.8348\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5794 - val_loss: 10.9043\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1610 - val_loss: 11.4855\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4075 - val_loss: 11.6006\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1097 - val_loss: 10.6548\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2465 - val_loss: 13.0281\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2005 - val_loss: 10.8339\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2911 - val_loss: 13.1758\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2331 - val_loss: 11.1366\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0628 - val_loss: 12.9153\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7869 - val_loss: 11.4615\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1271 - val_loss: 12.8680\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2162 - val_loss: 11.8054\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2009 - val_loss: 13.4275\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9958 - val_loss: 11.2694\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3849 - val_loss: 10.7884\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3592 - val_loss: 11.1842\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0575 - val_loss: 11.4250\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0706 - val_loss: 14.3545\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.1898 - val_loss: 10.7771\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9462 - val_loss: 10.7126\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8460 - val_loss: 11.5597\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2401 - val_loss: 11.6301\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3958 - val_loss: 11.6798\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8865 - val_loss: 11.7348\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9659 - val_loss: 10.9783\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4807 - val_loss: 11.2523\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5566 - val_loss: 14.7274\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8846 - val_loss: 11.3190\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9597 - val_loss: 12.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8064 - val_loss: 11.7109\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3172 - val_loss: 10.8025\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8336 - val_loss: 11.0611\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0418 - val_loss: 11.4302\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1806 - val_loss: 11.2916\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0875 - val_loss: 11.3096\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9919 - val_loss: 11.5447\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2044 - val_loss: 12.6051\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9167 - val_loss: 11.4377\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2079 - val_loss: 11.1039\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6672 - val_loss: 10.5918\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2173 - val_loss: 11.0653\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0626 - val_loss: 11.5413\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9145 - val_loss: 11.5815\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4517 - val_loss: 12.0395\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0435 - val_loss: 10.7271\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1519 - val_loss: 11.8502\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5222 - val_loss: 11.0159\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0659 - val_loss: 11.3600\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4903 - val_loss: 11.6785\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5717 - val_loss: 10.5667\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9031 - val_loss: 10.9470\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2222 - val_loss: 11.7649\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5033 - val_loss: 12.0179\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1899 - val_loss: 13.8449\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5444 - val_loss: 11.4596\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1418 - val_loss: 11.2342\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1479 - val_loss: 11.2563\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 128us/step - loss: 9.5973 - val_loss: 11.4071\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6677 - val_loss: 11.1352\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9143 - val_loss: 11.7415\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7536 - val_loss: 12.2581\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2098 - val_loss: 11.5845\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1791 - val_loss: 10.9913\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1272 - val_loss: 11.3050\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2221 - val_loss: 11.0991\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3704 - val_loss: 11.5730\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9426 - val_loss: 11.9498\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8323 - val_loss: 11.0290\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0685 - val_loss: 10.7026\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3701 - val_loss: 11.4773\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3519 - val_loss: 11.0724\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1923 - val_loss: 10.9569\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3712 - val_loss: 10.9723\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9305 - val_loss: 10.6878\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9748 - val_loss: 12.1433\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3447 - val_loss: 14.2028\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3606 - val_loss: 11.2482\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0043 - val_loss: 10.8977\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9941 - val_loss: 13.5665\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7087 - val_loss: 11.1017\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3980 - val_loss: 11.1717\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5738 - val_loss: 10.6573\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2300 - val_loss: 10.6266\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8175 - val_loss: 11.8656\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 9.5310 - val_loss: 10.8528\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.0797 - val_loss: 11.0991\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9338 - val_loss: 13.3063\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0030 - val_loss: 11.8149\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.2144 - val_loss: 11.0007\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1804 - val_loss: 10.8834\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9783 - val_loss: 11.6912\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9744 - val_loss: 12.2367\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3732 - val_loss: 11.4583\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1663 - val_loss: 11.0633\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.1294 - val_loss: 11.1218\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0062 - val_loss: 10.7768\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0394 - val_loss: 11.0276\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0575 - val_loss: 11.4685\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1080 - val_loss: 11.0670\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0764 - val_loss: 12.3473\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3473 - val_loss: 11.9857\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9610 - val_loss: 11.1324\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8388 - val_loss: 11.7834\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2246 - val_loss: 12.3924\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.4503 - val_loss: 11.5123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6034 - val_loss: 11.0115\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9802 - val_loss: 11.2974\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9203 - val_loss: 10.6881\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0120 - val_loss: 11.2998\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1224 - val_loss: 10.9146\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9832 - val_loss: 11.6387\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2414 - val_loss: 11.4597\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9218 - val_loss: 10.6833\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0203 - val_loss: 10.8733\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3877 - val_loss: 11.5592\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8204 - val_loss: 11.8710\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.2878 - val_loss: 12.2784\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2507 - val_loss: 10.9644\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0637 - val_loss: 10.9171\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9985 - val_loss: 12.4133\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0582 - val_loss: 11.7475\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1137 - val_loss: 10.7383\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2142 - val_loss: 12.1091\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0061 - val_loss: 11.1945\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1636 - val_loss: 10.9175\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2164 - val_loss: 11.6086\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5772 - val_loss: 10.6964\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2741 - val_loss: 11.0081\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9241 - val_loss: 11.3043\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0262 - val_loss: 12.1982\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.2077 - val_loss: 11.4646\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.1668 - val_loss: 11.3535\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.5800 - val_loss: 10.9486\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2372 - val_loss: 12.0763\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2260 - val_loss: 11.7522\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9527 - val_loss: 11.0831\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.4114 - val_loss: 12.5855\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5965 - val_loss: 10.5673\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2335 - val_loss: 11.6945\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0637 - val_loss: 11.9925\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0408 - val_loss: 11.2913\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7509 - val_loss: 12.2100\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7132 - val_loss: 11.7073\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1516 - val_loss: 11.1510\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0690 - val_loss: 11.2599\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5866 - val_loss: 11.0239\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3491 - val_loss: 12.7346\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.5812 - val_loss: 10.7003\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0211 - val_loss: 11.7205\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0249 - val_loss: 10.7976\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6684 - val_loss: 13.7071\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3185 - val_loss: 10.6520\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0209 - val_loss: 10.6054\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0847 - val_loss: 11.6144\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2306 - val_loss: 11.4643\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4055 - val_loss: 11.1594\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1952 - val_loss: 11.7307\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7668 - val_loss: 11.1650\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3769 - val_loss: 10.5388\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9134 - val_loss: 11.0727\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1174 - val_loss: 11.0121\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8694 - val_loss: 10.8475\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9935 - val_loss: 10.7803\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0881 - val_loss: 11.0343\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0456 - val_loss: 11.2076\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3542 - val_loss: 11.1368\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3330 - val_loss: 13.2404\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0261 - val_loss: 10.6636\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5450 - val_loss: 10.8603\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4333 - val_loss: 12.0512\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8678 - val_loss: 11.1689\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8366 - val_loss: 11.2143\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7513 - val_loss: 10.8940\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9685 - val_loss: 11.7351\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3922 - val_loss: 10.6616\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7201 - val_loss: 11.6439\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2280 - val_loss: 11.2128\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8391 - val_loss: 10.8657\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8378 - val_loss: 11.1122\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2267 - val_loss: 12.0247\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0627 - val_loss: 10.8830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8063 - val_loss: 11.9169\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0643 - val_loss: 11.9360\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8088 - val_loss: 12.6539\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3995 - val_loss: 11.5855\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0256 - val_loss: 11.1552\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2130 - val_loss: 10.7362\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3531 - val_loss: 11.3843\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4499 - val_loss: 11.1329\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2049 - val_loss: 11.5314\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2231 - val_loss: 11.8244\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0837 - val_loss: 10.4135\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0206 - val_loss: 10.8488\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6040 - val_loss: 10.9049\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3835 - val_loss: 11.5044\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9138 - val_loss: 10.8828\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9097 - val_loss: 11.6759\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9323 - val_loss: 10.5275\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9442 - val_loss: 10.8324\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8313 - val_loss: 11.6876\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7674 - val_loss: 10.6969\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1793 - val_loss: 10.4594\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2037 - val_loss: 10.8402\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8228 - val_loss: 12.8110\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2778 - val_loss: 11.2466\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1510 - val_loss: 10.8172\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0041 - val_loss: 11.2909\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5918 - val_loss: 11.2514\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1926 - val_loss: 11.4417\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0826 - val_loss: 10.7663\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0056 - val_loss: 11.1275\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4319 - val_loss: 11.9443\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6244 - val_loss: 10.5011\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0238 - val_loss: 11.3977\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9501 - val_loss: 12.0398\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4854 - val_loss: 11.3551\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1384 - val_loss: 11.8071\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8211 - val_loss: 11.6710\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1687 - val_loss: 10.9499\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8563 - val_loss: 12.2198\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3043 - val_loss: 11.8516\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1455 - val_loss: 12.4809\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6771 - val_loss: 11.7290\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7859 - val_loss: 11.3695\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7234 - val_loss: 12.7368\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4514 - val_loss: 11.0113\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2920 - val_loss: 12.9386\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1911 - val_loss: 11.6702\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9610 - val_loss: 10.8002\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7032 - val_loss: 12.8701\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3484 - val_loss: 12.5338\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3098 - val_loss: 10.8334\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8651 - val_loss: 11.2821\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8073 - val_loss: 10.9343\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9032 - val_loss: 11.7955\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9579 - val_loss: 12.5596\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5547 - val_loss: 11.3991\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0067 - val_loss: 10.5804\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8067 - val_loss: 12.2551\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2025 - val_loss: 12.3419\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3939 - val_loss: 11.7103\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2895 - val_loss: 11.1182\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1209 - val_loss: 11.4424\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7186 - val_loss: 10.7181\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9090 - val_loss: 11.0850\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2788 - val_loss: 11.7947\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2725 - val_loss: 11.1551\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8444 - val_loss: 10.6337\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6271 - val_loss: 11.1066\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4816 - val_loss: 11.7530\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8584 - val_loss: 12.2726\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7356 - val_loss: 10.6144\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7935 - val_loss: 10.7265\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7790 - val_loss: 11.3737\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6683 - val_loss: 12.3828\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0831 - val_loss: 11.0370\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6941 - val_loss: 12.6305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0167 - val_loss: 10.7716\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6005 - val_loss: 10.5015\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7958 - val_loss: 11.1376\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9126 - val_loss: 11.4955\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2829 - val_loss: 10.8482\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8674 - val_loss: 12.3031\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9477 - val_loss: 10.7069\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8977 - val_loss: 10.4319\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5566 - val_loss: 12.7834\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1745 - val_loss: 11.4361\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2222 - val_loss: 11.0796\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1763 - val_loss: 11.0673\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9345 - val_loss: 12.9898\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4293 - val_loss: 10.7987\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9024 - val_loss: 10.3580\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8631 - val_loss: 11.3072\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3399 - val_loss: 10.7301\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4230 - val_loss: 11.4079\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0328 - val_loss: 12.9856\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1246 - val_loss: 10.6019\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5187 - val_loss: 10.9058\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0988 - val_loss: 10.5589\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1851 - val_loss: 11.0073\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3468 - val_loss: 11.0543\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3009 - val_loss: 10.8777\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0274 - val_loss: 10.8600\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1747 - val_loss: 10.9851\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3625 - val_loss: 11.1974\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8479 - val_loss: 11.5261\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7355 - val_loss: 11.3661\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2363 - val_loss: 12.8143\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2693 - val_loss: 10.6175\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9905 - val_loss: 10.2883\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3729 - val_loss: 11.3031\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6856 - val_loss: 10.6839\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.6724 - val_loss: 12.5800\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5465 - val_loss: 12.3020\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5153 - val_loss: 10.7698\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8708 - val_loss: 10.4120\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7760 - val_loss: 10.5886\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7249 - val_loss: 11.5784\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2207 - val_loss: 11.1898\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8451 - val_loss: 10.6057\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0969 - val_loss: 10.8631\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7350 - val_loss: 11.6032\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2817 - val_loss: 11.3366\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8669 - val_loss: 11.0524\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3656 - val_loss: 11.4781\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4170 - val_loss: 10.8696\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.8702 - val_loss: 12.7850\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1121 - val_loss: 11.0673\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2674 - val_loss: 10.6434\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8558 - val_loss: 10.3272\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.1181 - val_loss: 11.7501\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.1315 - val_loss: 10.8718\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.2029 - val_loss: 11.3434\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1590 - val_loss: 10.4230\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8327 - val_loss: 10.8350\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6572 - val_loss: 11.4447\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1342 - val_loss: 11.2070\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1516 - val_loss: 10.4464\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4361 - val_loss: 14.1669\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6943 - val_loss: 11.7328\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3529 - val_loss: 10.1957\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3345 - val_loss: 11.2125\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5888 - val_loss: 10.4152\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8047 - val_loss: 11.3093\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1706 - val_loss: 10.3274\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0621 - val_loss: 10.0608\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8209 - val_loss: 10.9735\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0523 - val_loss: 13.0114\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1435 - val_loss: 10.3453\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8577 - val_loss: 12.2644\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1143 - val_loss: 11.0649\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8728 - val_loss: 10.9540\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7331 - val_loss: 10.7058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6071 - val_loss: 12.0120\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6770 - val_loss: 10.6401\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1920 - val_loss: 12.2536\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0216 - val_loss: 10.2450\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5658 - val_loss: 10.5270\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3654 - val_loss: 10.3877\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0132 - val_loss: 10.6601\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9360 - val_loss: 10.2950\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6826 - val_loss: 11.6526\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8896 - val_loss: 10.6885\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9022 - val_loss: 10.4119\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5072 - val_loss: 11.8731\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0440 - val_loss: 10.9904\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7914 - val_loss: 10.7893\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0844 - val_loss: 10.5540\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9239 - val_loss: 10.7191\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8943 - val_loss: 10.5600\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9788 - val_loss: 10.4581\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6961 - val_loss: 10.4855\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9907 - val_loss: 10.3452\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3246 - val_loss: 12.9276\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9412 - val_loss: 11.3197\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6566 - val_loss: 10.4618\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2336 - val_loss: 10.2835\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8966 - val_loss: 10.8439\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7216 - val_loss: 10.2471\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9039 - val_loss: 10.5367\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9209 - val_loss: 10.4247\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.5764 - val_loss: 11.1800\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.658 - 0s 81us/step - loss: 8.7594 - val_loss: 10.1999\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9337 - val_loss: 10.7095\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9308 - val_loss: 10.7584\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7325 - val_loss: 10.3952\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6420 - val_loss: 13.0679\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9105 - val_loss: 10.8243\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1718 - val_loss: 11.0649\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7659 - val_loss: 11.5654\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3030 - val_loss: 12.9119\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0900 - val_loss: 10.8973\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9303 - val_loss: 11.0388\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3804 - val_loss: 11.4508\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9209 - val_loss: 11.9395\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0726 - val_loss: 10.8665\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0847 - val_loss: 10.4932\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0720 - val_loss: 10.3186\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7202 - val_loss: 10.0088\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8630 - val_loss: 11.2670\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9015 - val_loss: 10.7950\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6486 - val_loss: 10.6605\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0901 - val_loss: 11.9024\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7968 - val_loss: 10.6065\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9475 - val_loss: 10.7828\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4564 - val_loss: 10.2400\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7125 - val_loss: 10.0554\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0089 - val_loss: 10.4131\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6422 - val_loss: 11.1288\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9617 - val_loss: 10.8042\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7603 - val_loss: 10.6381\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8410 - val_loss: 10.9391\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9698 - val_loss: 10.7346\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9551 - val_loss: 10.1265\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0978 - val_loss: 11.1191\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9452 - val_loss: 10.6918\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3363 - val_loss: 12.6722\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7980 - val_loss: 10.2558\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9267 - val_loss: 10.6125\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7886 - val_loss: 10.2252\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3670 - val_loss: 10.8981\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1924 - val_loss: 10.1397\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9332 - val_loss: 12.9166\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6645 - val_loss: 10.1748\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7411 - val_loss: 10.2695\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9239 - val_loss: 11.0340\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.5246 - val_loss: 10.3260\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9283 - val_loss: 10.6850\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9208 - val_loss: 10.5859\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7681 - val_loss: 10.6677\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6014 - val_loss: 10.2682\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0254 - val_loss: 10.2481\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7511 - val_loss: 10.1478\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5946 - val_loss: 10.2054\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8400 - val_loss: 11.3193\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3674 - val_loss: 10.5698\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3836 - val_loss: 10.3372\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9210 - val_loss: 10.7225\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2166 - val_loss: 12.0284\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0732 - val_loss: 10.4903\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8479 - val_loss: 10.7413\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7644 - val_loss: 10.3015\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7361 - val_loss: 10.7310\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0771 - val_loss: 11.1364\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5240 - val_loss: 10.5695\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8032 - val_loss: 10.5605\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3883 - val_loss: 11.4407\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7300 - val_loss: 10.2669\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7901 - val_loss: 10.6928\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6911 - val_loss: 11.5401\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4125 - val_loss: 10.3936\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4415 - val_loss: 11.0236\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7602 - val_loss: 10.1045\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3766 - val_loss: 10.9815\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0210 - val_loss: 10.3234\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7303 - val_loss: 10.5720\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8530 - val_loss: 10.8450\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7797 - val_loss: 10.3778\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7986 - val_loss: 10.5719\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8165 - val_loss: 11.2974\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8527 - val_loss: 10.1785\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1616 - val_loss: 10.9425\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6322 - val_loss: 10.2118\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.8217 - val_loss: 11.3856\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7179 - val_loss: 10.9877\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6060 - val_loss: 14.0690\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8608 - val_loss: 10.0003\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1518 - val_loss: 11.0789\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9962 - val_loss: 9.9907\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5910 - val_loss: 10.4851\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.3851 - val_loss: 10.3808\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8999 - val_loss: 10.7938\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9267 - val_loss: 10.7648\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0899 - val_loss: 10.9618\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7215 - val_loss: 10.7227\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6549 - val_loss: 10.1880\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7997 - val_loss: 9.8177\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0971 - val_loss: 11.7130\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9890 - val_loss: 11.6343\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3683 - val_loss: 10.3974\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0663 - val_loss: 10.4371\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1094 - val_loss: 10.2526\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7537 - val_loss: 10.1849\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9703 - val_loss: 10.8981\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0031 - val_loss: 9.9638\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4185 - val_loss: 11.0358\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7132 - val_loss: 11.5385\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8105 - val_loss: 10.3644\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7136 - val_loss: 10.4635\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6589 - val_loss: 10.0905\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4809 - val_loss: 10.7668\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1307 - val_loss: 11.4514\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7920 - val_loss: 11.1109\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9481 - val_loss: 10.0965\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9120 - val_loss: 11.6754\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0364 - val_loss: 10.4581\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6836 - val_loss: 11.5294\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2292 - val_loss: 10.5253\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0660 - val_loss: 11.2556\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9567 - val_loss: 10.7099\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7254 - val_loss: 9.9964\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9910 - val_loss: 11.4736\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.6903 - val_loss: 10.2896\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7939 - val_loss: 11.8989\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3579 - val_loss: 11.3788\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5848 - val_loss: 10.1917\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7337 - val_loss: 10.0614\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7464 - val_loss: 10.3316\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2775 - val_loss: 11.1975\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.0871 - val_loss: 10.2101\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9084 - val_loss: 10.1232\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3275 - val_loss: 12.0707\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7672 - val_loss: 10.0414\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9068 - val_loss: 12.3538\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4487 - val_loss: 10.2325\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6330 - val_loss: 10.3910\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8528 - val_loss: 11.0860\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3014 - val_loss: 11.1242\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.6554 - val_loss: 9.8301\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7932 - val_loss: 10.1681\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9129 - val_loss: 10.2214\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.4292 - val_loss: 10.0283\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8678 - val_loss: 11.3681\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6870 - val_loss: 10.0452\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8378 - val_loss: 10.0242\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8365 - val_loss: 9.9406\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7016 - val_loss: 10.6180\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9951 - val_loss: 10.1982\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6187 - val_loss: 10.4224\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9474 - val_loss: 11.1369\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0299 - val_loss: 10.6749\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5153 - val_loss: 12.1908\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9732 - val_loss: 9.8925\n",
      "8.810405023857555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-3.9293177 ,  0.19434448,  1.5833381 , -3.7679641 , -1.1117964 ],\n",
       "        [ 0.34215468,  0.25556788, -0.3653869 ,  0.10949246, -0.13052316],\n",
       "        [-0.56560266,  0.37892106, -0.2603686 ,  0.09333552, -0.38091692],\n",
       "        [ 0.16801071, -0.09366929, -0.07857995,  0.08532921,  0.1286498 ],\n",
       "        [-0.45890555,  0.18266131,  0.15687558, -2.2467766 , -1.2367002 ]],\n",
       "       dtype=float32),\n",
       " array([-4.825783  ,  0.21218878,  1.256269  , -5.2095475 , -3.1770606 ],\n",
       "       dtype=float32),\n",
       " array([[ 2.222594  , -2.414922  ,  2.08969   ,  1.4184452 ,  2.1564856 ,\n",
       "          1.5767916 ,  2.3679087 ,  1.8407524 , -1.4496205 ,  2.4631839 ],\n",
       "        [ 0.7141877 , -0.59554464,  1.0852578 ,  0.7927337 ,  1.2204171 ,\n",
       "          1.4010733 ,  0.9252656 ,  0.89417356, -1.1906831 ,  1.0570639 ],\n",
       "        [ 0.25556594, -1.1544007 ,  1.1331152 ,  1.0467371 ,  0.6917381 ,\n",
       "          0.16497959,  1.2627496 ,  0.7112823 , -0.7310253 ,  0.35499611],\n",
       "        [ 1.820605  , -2.0428133 ,  2.096184  ,  2.1389275 ,  1.5011934 ,\n",
       "          1.5529569 ,  1.9245901 ,  1.6236421 , -2.1587732 ,  1.002151  ],\n",
       "        [ 1.646608  , -2.123714  ,  1.5311731 ,  1.9289542 ,  2.3678508 ,\n",
       "          1.3964337 ,  1.509181  ,  1.5659429 , -1.7713999 ,  2.0114224 ]],\n",
       "       dtype=float32),\n",
       " array([-1.5848109,  1.6269993, -1.6740661, -1.6697932, -1.5896076,\n",
       "        -1.6570672, -1.6859938, -1.6803857,  1.7822086, -1.7835823],\n",
       "       dtype=float32),\n",
       " array([[-2.3674462],\n",
       "        [ 2.095738 ],\n",
       "        [-1.8312899],\n",
       "        [-1.7860243],\n",
       "        [-2.2239795],\n",
       "        [-1.7251353],\n",
       "        [-1.8432122],\n",
       "        [-1.8376456],\n",
       "        [ 1.5633501],\n",
       "        [-1.6466638]], dtype=float32),\n",
       " array([1.5701271], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_linear(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_linear_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 195us/step - loss: 9349.0057 - val_loss: 2083.8301\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 664.0884 - val_loss: 323.9227\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 237.0154 - val_loss: 181.8394\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 143.7633 - val_loss: 113.5768\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 102.2284 - val_loss: 92.7365\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 80.0469 - val_loss: 69.8631\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 69.30 - 0s 88us/step - loss: 66.2304 - val_loss: 59.6373\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 51.3505 - val_loss: 49.5771\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 43.0848 - val_loss: 42.9456\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 37.0544 - val_loss: 38.1550\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 33.8986 - val_loss: 35.4664\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 30.3117 - val_loss: 32.8110\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 27.8667 - val_loss: 30.8243\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 25.9628 - val_loss: 30.4046\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 24.8550 - val_loss: 29.5013\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.3870 - val_loss: 28.6616\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.2962 - val_loss: 29.5700\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.3147 - val_loss: 27.7044\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.4603 - val_loss: 28.0083\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5052 - val_loss: 28.2874\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5318 - val_loss: 27.8520\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9766 - val_loss: 28.7371\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.1350 - val_loss: 27.7740\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.3824 - val_loss: 27.5040\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.5934 - val_loss: 28.6735\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.0927 - val_loss: 27.2107\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6305 - val_loss: 27.7540\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.1105 - val_loss: 27.4880\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 21.2149 - val_loss: 27.9859\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.4267 - val_loss: 26.9921\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.8384 - val_loss: 27.1616\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.7920 - val_loss: 28.0033\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.0698 - val_loss: 27.1103\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.0643 - val_loss: 27.5507\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.1454 - val_loss: 27.3387\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.8049 - val_loss: 27.5890\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.7186 - val_loss: 28.0861\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2430 - val_loss: 26.5798\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 20.4141 - val_loss: 27.0503\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.2255 - val_loss: 25.8415\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.1687 - val_loss: 26.6207\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.3656 - val_loss: 26.3995\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.3785 - val_loss: 26.2100\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.7087 - val_loss: 25.4150\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.6875 - val_loss: 24.9996\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.8204 - val_loss: 27.0349\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.8227 - val_loss: 25.5309\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.2192 - val_loss: 26.0260\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5655 - val_loss: 25.4697\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.8297 - val_loss: 25.2922\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.5473 - val_loss: 24.6917\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.8757 - val_loss: 25.9492\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.5669 - val_loss: 24.6538\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.4551 - val_loss: 24.6610\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.9716 - val_loss: 24.6275\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.2091 - val_loss: 24.6759\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 19.1324 - val_loss: 25.7959\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.2468 - val_loss: 25.6458\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.2520 - val_loss: 24.4457\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.1607 - val_loss: 23.7631\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.7233 - val_loss: 24.7757\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.9806 - val_loss: 26.5005\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.5473 - val_loss: 24.0080\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.4711 - val_loss: 27.7678\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.2757 - val_loss: 24.8220\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.8534 - val_loss: 24.4921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.8683 - val_loss: 26.2041\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.6875 - val_loss: 24.4314\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.5488 - val_loss: 24.6168\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.0322 - val_loss: 24.5925\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.3543 - val_loss: 25.6978\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.6506 - val_loss: 26.5610\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.5558 - val_loss: 24.3298\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 20.4311 - val_loss: 24.9007\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 20.4591 - val_loss: 25.7941\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.2900 - val_loss: 25.5759\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.3858 - val_loss: 24.4487\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.1793 - val_loss: 24.1419\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.1863 - val_loss: 24.9035\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7475 - val_loss: 24.4330\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8912 - val_loss: 24.6503\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.1968 - val_loss: 25.5835\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 19.8470 - val_loss: 23.8065\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8853 - val_loss: 24.3557\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8194 - val_loss: 23.8534\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4952 - val_loss: 25.1446\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.1427 - val_loss: 23.9213\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.7591 - val_loss: 24.5930\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.6634 - val_loss: 22.7733\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 19.0865 - val_loss: 22.7343\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.7977 - val_loss: 23.6184\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.7293 - val_loss: 23.1246\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.7101 - val_loss: 22.4075\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0473 - val_loss: 23.1355\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1709 - val_loss: 22.1180\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0821 - val_loss: 22.6204\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4456 - val_loss: 22.5478\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9819 - val_loss: 24.3301\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1395 - val_loss: 23.2514\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.0231 - val_loss: 23.0886\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1667 - val_loss: 22.6483\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.3837 - val_loss: 22.7856\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0360 - val_loss: 22.7825\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2502 - val_loss: 23.1371\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.1937 - val_loss: 23.2324\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0090 - val_loss: 21.7194\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3493 - val_loss: 23.0020\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.9167 - val_loss: 21.9829\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.7547 - val_loss: 21.0867\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.1911 - val_loss: 21.0407\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7524 - val_loss: 22.1844\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.7154 - val_loss: 21.6605\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.5225 - val_loss: 21.7582\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8686 - val_loss: 22.1037\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4747 - val_loss: 21.6584\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7159 - val_loss: 21.9764\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7527 - val_loss: 21.8139\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3889 - val_loss: 22.5689\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7809 - val_loss: 21.2221\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4345 - val_loss: 21.5495\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.5995 - val_loss: 21.5329\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8328 - val_loss: 23.5067\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1303 - val_loss: 21.1017\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4776 - val_loss: 21.3141\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3170 - val_loss: 21.9273\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5160 - val_loss: 23.4155\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6550 - val_loss: 20.4462\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.9652 - val_loss: 21.7012\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 17.5776 - val_loss: 24.7743\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9958 - val_loss: 21.6868\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.2803 - val_loss: 21.2457\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.4312 - val_loss: 21.4482\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2173 - val_loss: 22.8780\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6543 - val_loss: 21.5898\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7270 - val_loss: 21.8384\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4026 - val_loss: 20.6102\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.4901 - val_loss: 21.5426\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.3820 - val_loss: 21.7010\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.9361 - val_loss: 21.8685\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7277 - val_loss: 20.4977\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 17.5824 - val_loss: 23.0257\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.0750 - val_loss: 21.8246\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.8282 - val_loss: 21.9310\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.4238 - val_loss: 20.6569\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4624 - val_loss: 22.9550\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4941 - val_loss: 20.7706\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8075 - val_loss: 23.2813\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.1232 - val_loss: 21.5155\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0688 - val_loss: 22.2381\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7453 - val_loss: 22.1644\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7085 - val_loss: 21.5414\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5779 - val_loss: 21.3917\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8310 - val_loss: 21.1381\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6216 - val_loss: 22.1595\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7135 - val_loss: 22.2770\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3836 - val_loss: 22.2087\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3902 - val_loss: 21.7929\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5037 - val_loss: 22.9174\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4749 - val_loss: 22.2766\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0115 - val_loss: 22.2151\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0129 - val_loss: 21.6673\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6546 - val_loss: 20.9240\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9462 - val_loss: 23.3815\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8593 - val_loss: 21.4085\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6032 - val_loss: 21.9495\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6303 - val_loss: 22.4330\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6901 - val_loss: 20.6607\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.1414 - val_loss: 20.9563\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.1111 - val_loss: 21.6737\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.3834 - val_loss: 21.7376\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8958 - val_loss: 22.6822\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1428 - val_loss: 21.5463\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4850 - val_loss: 20.9318\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5338 - val_loss: 20.6866\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2370 - val_loss: 20.7721\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3678 - val_loss: 22.3510\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6335 - val_loss: 22.2270\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3418 - val_loss: 21.2105\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5551 - val_loss: 21.3203\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4723 - val_loss: 23.5848\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4196 - val_loss: 22.1215\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6280 - val_loss: 20.5959\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3036 - val_loss: 21.8990\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.0700 - val_loss: 21.9501\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3081 - val_loss: 21.2401\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2141 - val_loss: 21.2085\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8901 - val_loss: 23.8715\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6606 - val_loss: 22.7725\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1841 - val_loss: 23.8812\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6222 - val_loss: 21.1997\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2687 - val_loss: 22.2304\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.6314 - val_loss: 22.7558\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.9224 - val_loss: 21.7156\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9126 - val_loss: 21.8858\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5875 - val_loss: 21.3677\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2826 - val_loss: 21.4591\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2554 - val_loss: 20.9058\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7802 - val_loss: 21.1162\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2605 - val_loss: 24.3808\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3046 - val_loss: 22.4591\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3506 - val_loss: 21.6938\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3611 - val_loss: 23.5574\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2499 - val_loss: 21.7997\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5558 - val_loss: 21.5200\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 17.4168 - val_loss: 21.5160\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.2947 - val_loss: 24.2073\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.1290 - val_loss: 22.7042\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6042 - val_loss: 22.8398\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9757 - val_loss: 23.1358\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9871 - val_loss: 22.0062\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5524 - val_loss: 21.8032\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2361 - val_loss: 22.2385\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3397 - val_loss: 21.7750\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3807 - val_loss: 21.6541\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5461 - val_loss: 23.3820\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5448 - val_loss: 23.0239\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8643 - val_loss: 20.9072\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5537 - val_loss: 23.7740\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5736 - val_loss: 23.6157\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.8051 - val_loss: 21.0812\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.5506 - val_loss: 22.6660\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7244 - val_loss: 21.2072\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9507 - val_loss: 22.5116\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2441 - val_loss: 22.7270\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5728 - val_loss: 21.4795\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6281 - val_loss: 21.7805\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6052 - val_loss: 21.6506\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8696 - val_loss: 20.9479\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8472 - val_loss: 21.1459\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3555 - val_loss: 21.0778\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4980 - val_loss: 22.1892\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4789 - val_loss: 21.2361\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.2856 - val_loss: 22.1567\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4647 - val_loss: 24.0502\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5670 - val_loss: 21.8585\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7508 - val_loss: 21.4093\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9185 - val_loss: 21.5826\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3461 - val_loss: 22.3456\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4668 - val_loss: 22.6720\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3923 - val_loss: 22.2601\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5205 - val_loss: 21.7646\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.8563 - val_loss: 22.1795\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6596 - val_loss: 21.0870\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0836 - val_loss: 21.6671\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.9739 - val_loss: 21.7630\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1796 - val_loss: 22.2275\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7407 - val_loss: 21.3330\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6957 - val_loss: 23.2465\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7973 - val_loss: 23.0797\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2704 - val_loss: 20.9341\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2776 - val_loss: 21.2915\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2693 - val_loss: 20.8143\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4009 - val_loss: 21.0519\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8761 - val_loss: 21.2318\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.0150 - val_loss: 21.7879\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2992 - val_loss: 22.1392\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3068 - val_loss: 22.2603\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8971 - val_loss: 21.7646\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6533 - val_loss: 20.9714\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9347 - val_loss: 21.9976\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8211 - val_loss: 22.9178\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4767 - val_loss: 21.0723\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5414 - val_loss: 22.2171\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4348 - val_loss: 21.4491\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7831 - val_loss: 22.0183\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3562 - val_loss: 24.3924\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.9338 - val_loss: 22.2827\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0707 - val_loss: 21.0518\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5979 - val_loss: 22.9427\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3883 - val_loss: 22.2455\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3091 - val_loss: 22.2001\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0055 - val_loss: 23.0002\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3028 - val_loss: 21.9862\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2946 - val_loss: 21.1813\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4793 - val_loss: 21.8971\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3880 - val_loss: 21.9982\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4338 - val_loss: 21.5796\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5535 - val_loss: 21.5072\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9827 - val_loss: 20.7956\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0509 - val_loss: 21.5001\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2023 - val_loss: 20.8291\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6726 - val_loss: 21.7497\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6234 - val_loss: 23.1909\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9430 - val_loss: 22.4915\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8249 - val_loss: 23.8461\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0120 - val_loss: 22.0067\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5596 - val_loss: 21.9400\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2648 - val_loss: 21.5468\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.5748 - val_loss: 21.9477\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4257 - val_loss: 21.3603\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2520 - val_loss: 21.4962\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 19.3074 - val_loss: 22.4010\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9261 - val_loss: 22.8435\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7111 - val_loss: 22.4608\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7923 - val_loss: 21.9785\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2019 - val_loss: 23.6589\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6124 - val_loss: 21.7041\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2035 - val_loss: 22.3420\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7410 - val_loss: 23.3871\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3123 - val_loss: 24.4056\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5514 - val_loss: 22.3418\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.8708 - val_loss: 22.2686\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4581 - val_loss: 22.4080\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.1781 - val_loss: 22.5984\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2875 - val_loss: 22.5441\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4945 - val_loss: 21.4940\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0489 - val_loss: 21.7996\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2166 - val_loss: 23.1608\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.3837 - val_loss: 25.1053\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6164 - val_loss: 21.8560\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3658 - val_loss: 22.9909\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.6469 - val_loss: 22.2810\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1123 - val_loss: 23.1159\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.4379 - val_loss: 21.7288\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.9453 - val_loss: 20.9463\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.5173 - val_loss: 22.2203\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.3153 - val_loss: 23.1038\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.5249 - val_loss: 21.0780\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.7612 - val_loss: 23.8346\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2743 - val_loss: 21.3607\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5741 - val_loss: 21.7452\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8816 - val_loss: 21.8643\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7397 - val_loss: 21.7327\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3651 - val_loss: 22.5678\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3685 - val_loss: 21.2828\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.9619 - val_loss: 26.0483\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.9889 - val_loss: 22.2672\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7406 - val_loss: 21.2440\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.9743 - val_loss: 21.8258\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8105 - val_loss: 24.2690\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9091 - val_loss: 21.0274\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7407 - val_loss: 22.4412\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7358 - val_loss: 21.5268\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0407 - val_loss: 22.6225\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6386 - val_loss: 22.3592\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6781 - val_loss: 23.2928\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1410 - val_loss: 23.1670\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7153 - val_loss: 24.0323\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4018 - val_loss: 21.4995\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1213 - val_loss: 21.6777\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.8367 - val_loss: 21.1109\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9686 - val_loss: 21.2465\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7388 - val_loss: 23.0132\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4277 - val_loss: 21.3953\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1335 - val_loss: 22.2143\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7223 - val_loss: 22.9593\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4208 - val_loss: 21.8372\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1537 - val_loss: 21.7858\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5130 - val_loss: 21.7070\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0396 - val_loss: 22.3259\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3514 - val_loss: 22.2068\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1617 - val_loss: 22.0112\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5883 - val_loss: 21.3870\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5038 - val_loss: 21.7048\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1382 - val_loss: 21.3895\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8036 - val_loss: 22.9257\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6532 - val_loss: 23.9038\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4833 - val_loss: 22.3249\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9305 - val_loss: 22.9468\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2576 - val_loss: 21.9627\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2429 - val_loss: 22.0188\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2482 - val_loss: 22.8810\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.1691 - val_loss: 22.6476\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9492 - val_loss: 22.4053\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.4545 - val_loss: 23.3577\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2663 - val_loss: 21.5391\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4320 - val_loss: 21.9602\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.8842 - val_loss: 23.0798\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1675 - val_loss: 22.8801\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4347 - val_loss: 22.5594\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5709 - val_loss: 22.0034\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6729 - val_loss: 23.6805\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.8754 - val_loss: 21.6469\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7488 - val_loss: 22.2560\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2326 - val_loss: 22.0157\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2931 - val_loss: 22.6693\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5868 - val_loss: 21.6098\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3791 - val_loss: 21.6628\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5461 - val_loss: 23.5934\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1346 - val_loss: 22.0193\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8691 - val_loss: 21.7537\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4091 - val_loss: 21.8040\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.8145 - val_loss: 22.3219\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.4274 - val_loss: 21.2819\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4025 - val_loss: 23.1952\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5372 - val_loss: 22.5417\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3836 - val_loss: 21.4056\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4269 - val_loss: 21.6582\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8614 - val_loss: 22.4540\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5504 - val_loss: 20.6499\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5535 - val_loss: 23.3313\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3995 - val_loss: 21.9768\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3018 - val_loss: 21.2540\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4663 - val_loss: 23.9331\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2671 - val_loss: 22.0437\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8717 - val_loss: 21.1239\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0171 - val_loss: 21.1280\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1884 - val_loss: 20.7655\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1024 - val_loss: 22.1820\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6689 - val_loss: 21.7086\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4076 - val_loss: 21.6525\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9239 - val_loss: 21.4634\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3339 - val_loss: 23.5903\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4180 - val_loss: 22.6157\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1758 - val_loss: 21.5807\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4345 - val_loss: 20.9852\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3219 - val_loss: 21.7541\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1438 - val_loss: 23.9370\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.8570 - val_loss: 20.9059\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2840 - val_loss: 24.2204\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5385 - val_loss: 22.1438\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4827 - val_loss: 21.8756\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1657 - val_loss: 23.5422\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4341 - val_loss: 22.0128\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6191 - val_loss: 23.3285\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.9378 - val_loss: 21.7821\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.4704 - val_loss: 24.0877\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6628 - val_loss: 23.6398\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.1399 - val_loss: 22.1090\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2885 - val_loss: 21.9558\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3415 - val_loss: 21.9261\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4364 - val_loss: 21.4492\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1129 - val_loss: 23.0760\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2334 - val_loss: 23.7242\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.5535 - val_loss: 21.5421\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4489 - val_loss: 21.2879\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0755 - val_loss: 23.3497\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4497 - val_loss: 21.5110\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0357 - val_loss: 21.9534\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1750 - val_loss: 22.6537\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.8790 - val_loss: 22.3014\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7905 - val_loss: 21.1440\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9640 - val_loss: 21.3403\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1807 - val_loss: 24.5321\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5575 - val_loss: 21.4340\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3863 - val_loss: 22.4686\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3710 - val_loss: 23.0275\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3314 - val_loss: 23.1987\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4539 - val_loss: 21.0084\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1750 - val_loss: 22.2397\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7411 - val_loss: 21.7899\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2027 - val_loss: 22.4199\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5594 - val_loss: 22.7123\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 17.5697 - val_loss: 22.1260\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0312 - val_loss: 21.5972\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4130 - val_loss: 21.4197\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5069 - val_loss: 22.8928\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.9991 - val_loss: 22.2908\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5428 - val_loss: 21.5349\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5134 - val_loss: 21.3656\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6253 - val_loss: 21.3983\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1808 - val_loss: 21.8890\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2880 - val_loss: 21.6029\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9898 - val_loss: 22.3856\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6736 - val_loss: 22.8685\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6011 - val_loss: 21.7740\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8691 - val_loss: 22.0531\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3962 - val_loss: 21.4160\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3440 - val_loss: 22.1406\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.8769 - val_loss: 22.1280\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0112 - val_loss: 21.2041\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5268 - val_loss: 21.6149\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5392 - val_loss: 23.4865\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1521 - val_loss: 21.8899\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.0413 - val_loss: 21.8829\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4872 - val_loss: 23.0717\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4421 - val_loss: 21.6428\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4470 - val_loss: 22.9661\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4898 - val_loss: 22.6080\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6016 - val_loss: 21.7481\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1913 - val_loss: 21.3534\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0313 - val_loss: 21.1100\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5216 - val_loss: 21.5286\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0174 - val_loss: 22.7339\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1209 - val_loss: 23.8486\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3678 - val_loss: 22.2771\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6610 - val_loss: 21.8061\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6765 - val_loss: 21.5303\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6115 - val_loss: 21.5482\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7840 - val_loss: 21.9010\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6743 - val_loss: 24.0152\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2184 - val_loss: 21.3581\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5009 - val_loss: 22.6866\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.7592 - val_loss: 23.8127\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.1296 - val_loss: 21.4541\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.0284 - val_loss: 21.3373\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.7193 - val_loss: 21.4033\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.5328 - val_loss: 22.7214\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 18.2775 - val_loss: 24.5828\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 18.4866 - val_loss: 21.9792\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6186 - val_loss: 22.5546\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1353 - val_loss: 23.5136\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5063 - val_loss: 21.2511\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3106 - val_loss: 21.9380\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5542 - val_loss: 22.2785\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6153 - val_loss: 22.3524\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0531 - val_loss: 22.0188\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6191 - val_loss: 22.2197\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.9375 - val_loss: 21.5543\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9378 - val_loss: 21.7161\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0719 - val_loss: 22.3020\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4036 - val_loss: 22.6166\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.5418 - val_loss: 21.8161\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9368 - val_loss: 21.2734\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6859 - val_loss: 21.3198\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5481 - val_loss: 22.8375\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3588 - val_loss: 21.8790\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9209 - val_loss: 22.8571\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2942 - val_loss: 21.4950\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1263 - val_loss: 21.5998\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2678 - val_loss: 21.6868\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1743 - val_loss: 21.9808\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1687 - val_loss: 23.1571\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5992 - val_loss: 23.6309\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7476 - val_loss: 22.0021\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5712 - val_loss: 21.8456\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0988 - val_loss: 21.8306\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2910 - val_loss: 21.5236\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2682 - val_loss: 20.6991\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4687 - val_loss: 22.9147\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0858 - val_loss: 23.6231\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6232 - val_loss: 21.5286\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.0747 - val_loss: 23.2136\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5446 - val_loss: 21.4781\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8384 - val_loss: 22.8317\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.8584 - val_loss: 23.2729\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4867 - val_loss: 21.8725\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3345 - val_loss: 22.4504\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2831 - val_loss: 21.9491\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7629 - val_loss: 22.8603\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.7274 - val_loss: 22.3110\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6947 - val_loss: 21.0313\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.3590 - val_loss: 22.6022\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4949 - val_loss: 21.9355\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1795 - val_loss: 21.2630\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4151 - val_loss: 21.7503\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.0593 - val_loss: 22.6514\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9806 - val_loss: 22.1454\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3373 - val_loss: 22.3802\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8156 - val_loss: 22.0228\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2105 - val_loss: 22.0824\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6343 - val_loss: 22.1182\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3090 - val_loss: 21.5316\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3000 - val_loss: 22.8962\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4288 - val_loss: 22.8513\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5705 - val_loss: 22.4156\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0665 - val_loss: 22.5803\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3674 - val_loss: 24.8539\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5851 - val_loss: 21.2271\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0720 - val_loss: 21.1535\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3876 - val_loss: 22.8946\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.2784 - val_loss: 21.5152\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4756 - val_loss: 23.7126\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.1914 - val_loss: 22.7154\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3966 - val_loss: 21.9489\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1899 - val_loss: 21.8698\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4690 - val_loss: 22.6283\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6119 - val_loss: 24.0136\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.4053 - val_loss: 23.5810\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6143 - val_loss: 21.1188\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4425 - val_loss: 22.1578\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4891 - val_loss: 21.3295\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3622 - val_loss: 21.5968\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4504 - val_loss: 22.0375\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9957 - val_loss: 21.5182\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.2076 - val_loss: 23.0178\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2823 - val_loss: 24.0374\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0429 - val_loss: 21.4844\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4918 - val_loss: 20.9668\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0661 - val_loss: 23.3605\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6721 - val_loss: 22.9624\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5102 - val_loss: 23.4179\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5810 - val_loss: 22.9753\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4179 - val_loss: 20.9752\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3331 - val_loss: 22.1839\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5621 - val_loss: 21.6499\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9605 - val_loss: 22.2935\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0604 - val_loss: 23.6829\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.6387 - val_loss: 21.8538\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4977 - val_loss: 21.8246\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8569 - val_loss: 23.2653\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.7467 - val_loss: 21.8534\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.5941 - val_loss: 21.4908\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9883 - val_loss: 24.3548\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6539 - val_loss: 21.8190\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5330 - val_loss: 23.4233\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2192 - val_loss: 21.7128\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3986 - val_loss: 21.9790\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4231 - val_loss: 22.5347\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1454 - val_loss: 22.2604\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 17.58 - 0s 85us/step - loss: 16.9523 - val_loss: 21.7689\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.1389 - val_loss: 20.7062\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0385 - val_loss: 22.3801\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3575 - val_loss: 23.3268\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0676 - val_loss: 23.1761\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5690 - val_loss: 23.4951\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3077 - val_loss: 22.7975\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4879 - val_loss: 21.4904\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3267 - val_loss: 21.1676\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6784 - val_loss: 21.2410\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2858 - val_loss: 21.2774\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3178 - val_loss: 20.9906\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8455 - val_loss: 21.5821\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3162 - val_loss: 22.0177\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4857 - val_loss: 21.8869\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4271 - val_loss: 21.4188\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1804 - val_loss: 21.2915\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.1130 - val_loss: 20.9600\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5960 - val_loss: 22.3200\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6445 - val_loss: 24.5614\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0868 - val_loss: 25.1051\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.9588 - val_loss: 21.4783\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.0476 - val_loss: 21.7162\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2824 - val_loss: 21.7383\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0140 - val_loss: 21.8555\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0117 - val_loss: 21.5069\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4618 - val_loss: 22.1409\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5652 - val_loss: 21.5290\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1600 - val_loss: 22.3468\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3591 - val_loss: 23.5047\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9824 - val_loss: 23.1732\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4952 - val_loss: 24.8029\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3783 - val_loss: 21.6910\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4783 - val_loss: 21.5136\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2309 - val_loss: 22.1187\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.8697 - val_loss: 22.6284\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.7509 - val_loss: 21.2886\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4058 - val_loss: 22.8747\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1778 - val_loss: 22.5593\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1154 - val_loss: 23.5880\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1388 - val_loss: 21.4507\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3916 - val_loss: 21.3109\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9624 - val_loss: 23.0374\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6665 - val_loss: 22.8124\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.2693 - val_loss: 23.0253\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9659 - val_loss: 21.8814\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5172 - val_loss: 21.4514\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5456 - val_loss: 22.6087\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2170 - val_loss: 22.2152\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.4771 - val_loss: 21.5541\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.3318 - val_loss: 22.2196\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6496 - val_loss: 22.2058\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4792 - val_loss: 22.3995\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.2466 - val_loss: 22.0419\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3161 - val_loss: 21.5777\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3176 - val_loss: 22.2930\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0674 - val_loss: 22.1617\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9816 - val_loss: 21.4818\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4165 - val_loss: 21.4536\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5621 - val_loss: 21.5036\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1012 - val_loss: 22.3805\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5758 - val_loss: 22.3693\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4436 - val_loss: 21.3658\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2588 - val_loss: 21.6820\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3458 - val_loss: 21.9167\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9408 - val_loss: 22.7935\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5293 - val_loss: 21.8007\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4974 - val_loss: 21.4296\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 117us/step - loss: 17.6922 - val_loss: 21.9829\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.7223 - val_loss: 21.6326\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.1856 - val_loss: 21.2415\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1732 - val_loss: 21.6117\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.0316 - val_loss: 21.7847\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.1239 - val_loss: 22.5566\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.8720 - val_loss: 21.5257\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.1567 - val_loss: 22.5396\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2804 - val_loss: 22.4431\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8910 - val_loss: 22.5451\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.1941 - val_loss: 21.9363\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7325 - val_loss: 21.6246\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5804 - val_loss: 22.4426\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3045 - val_loss: 22.8320\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5744 - val_loss: 22.4781\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9866 - val_loss: 22.9042\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4469 - val_loss: 22.4947\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7311 - val_loss: 21.5468\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2219 - val_loss: 22.9417\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5979 - val_loss: 23.3046\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5174 - val_loss: 22.3279\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.5582 - val_loss: 25.1835\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.9701 - val_loss: 23.1052\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1513 - val_loss: 21.5486\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.2498 - val_loss: 21.7658\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9306 - val_loss: 21.2069\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8802 - val_loss: 23.0815\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3278 - val_loss: 22.5653\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6008 - val_loss: 22.7351\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7457 - val_loss: 22.9857\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.9920 - val_loss: 22.5423\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1266 - val_loss: 22.1114\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2592 - val_loss: 22.3050\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3486 - val_loss: 21.8923\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.4224 - val_loss: 23.1158\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1013 - val_loss: 22.5289\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.0107 - val_loss: 21.6811\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8821 - val_loss: 22.3465\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6897 - val_loss: 23.5817\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8076 - val_loss: 22.5377\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7752 - val_loss: 22.8201\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6648 - val_loss: 22.4654\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3196 - val_loss: 21.8910\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.3500 - val_loss: 24.5551\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4352 - val_loss: 23.4283\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.1013 - val_loss: 23.7606\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6365 - val_loss: 21.6094\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2209 - val_loss: 20.9770\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0635 - val_loss: 21.4654\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2756 - val_loss: 21.1997\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 17.4359 - val_loss: 21.4875\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1977 - val_loss: 21.7481\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3383 - val_loss: 21.3921\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9044 - val_loss: 21.6532\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1174 - val_loss: 23.0099\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6104 - val_loss: 22.4770\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3341 - val_loss: 22.8046\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6810 - val_loss: 22.0509\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9977 - val_loss: 21.6320\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7832 - val_loss: 22.3058\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9966 - val_loss: 21.7722\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1478 - val_loss: 22.1202\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2842 - val_loss: 22.2711\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3567 - val_loss: 21.3728\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1200 - val_loss: 22.1182\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3321 - val_loss: 22.6470\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9769 - val_loss: 22.5477\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1570 - val_loss: 22.0625\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4976 - val_loss: 23.4219\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9980 - val_loss: 24.9234\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5361 - val_loss: 21.3105\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3075 - val_loss: 23.2198\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3314 - val_loss: 22.0716\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7370 - val_loss: 22.9157\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.8793 - val_loss: 21.6908\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2525 - val_loss: 22.6394\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9224 - val_loss: 22.1518\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.1099 - val_loss: 21.8123\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5346 - val_loss: 22.1062\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1722 - val_loss: 22.6264\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6007 - val_loss: 23.3981\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0910 - val_loss: 21.1705\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4215 - val_loss: 22.9666\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0771 - val_loss: 21.4478\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8987 - val_loss: 21.7371\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6374 - val_loss: 22.0903\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.1581 - val_loss: 22.7495\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9907 - val_loss: 22.8563\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.6140 - val_loss: 21.4579\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5554 - val_loss: 21.7755\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2651 - val_loss: 23.3673\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0238 - val_loss: 22.5335\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4682 - val_loss: 22.6772\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.0667 - val_loss: 22.2444\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4539 - val_loss: 22.7941\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3844 - val_loss: 21.8108\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5315 - val_loss: 22.4050\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.2633 - val_loss: 22.6151\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3568 - val_loss: 22.2523\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1623 - val_loss: 21.4823\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0717 - val_loss: 23.5544\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8731 - val_loss: 23.1719\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6884 - val_loss: 21.4895\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.4447 - val_loss: 21.6755\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.0195 - val_loss: 23.8065\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4787 - val_loss: 22.5478\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8252 - val_loss: 21.7112\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8510 - val_loss: 22.6248\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4396 - val_loss: 21.2131\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9754 - val_loss: 21.4888\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3316 - val_loss: 23.0297\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.8225 - val_loss: 21.8361\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4963 - val_loss: 22.4250\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4752 - val_loss: 23.7636\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9018 - val_loss: 23.0063\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1690 - val_loss: 22.1402\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0940 - val_loss: 22.7569\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.5039 - val_loss: 21.8132\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0981 - val_loss: 21.2325\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.2617 - val_loss: 24.5639\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9360 - val_loss: 22.1834\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5267 - val_loss: 22.3978\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1330 - val_loss: 20.9262\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2470 - val_loss: 21.1894\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3517 - val_loss: 24.3220\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5814 - val_loss: 24.4524\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9247 - val_loss: 22.7855\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.1379 - val_loss: 21.8974\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.3623 - val_loss: 23.1609\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6293 - val_loss: 22.1961\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9293 - val_loss: 22.4649\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3826 - val_loss: 21.5755\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8331 - val_loss: 21.0136\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2626 - val_loss: 21.5751\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0859 - val_loss: 21.9007\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4451 - val_loss: 21.9948\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.9292 - val_loss: 22.2229\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2402 - val_loss: 22.1276\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1962 - val_loss: 21.9793\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0194 - val_loss: 23.4111\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0979 - val_loss: 23.6036\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3021 - val_loss: 21.1886\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3330 - val_loss: 22.0843\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2154 - val_loss: 21.0703\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8339 - val_loss: 21.4612\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3717 - val_loss: 21.4045\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6534 - val_loss: 21.7339\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2953 - val_loss: 21.6539\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5684 - val_loss: 22.0725\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.4665 - val_loss: 21.7712\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.2839 - val_loss: 23.5026\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3265 - val_loss: 22.2969\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5333 - val_loss: 21.5669\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5790 - val_loss: 22.8729\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.5101 - val_loss: 21.2862\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8041 - val_loss: 22.9857\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5559 - val_loss: 23.2557\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6258 - val_loss: 22.1841\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.4098 - val_loss: 21.8249\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4053 - val_loss: 22.6970\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.1403 - val_loss: 22.5694\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2480 - val_loss: 22.5333\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.1878 - val_loss: 23.4281\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.4312 - val_loss: 22.8795\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.5049 - val_loss: 21.5454\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3960 - val_loss: 21.0278\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6346 - val_loss: 21.4676\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5152 - val_loss: 22.0056\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9891 - val_loss: 22.1494\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9372 - val_loss: 22.4026\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.6164 - val_loss: 22.2391\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6469 - val_loss: 22.0367\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0829 - val_loss: 23.6855\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.5777 - val_loss: 21.7716\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6051 - val_loss: 22.1052\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 106us/step - loss: 17.3130 - val_loss: 23.1616\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5065 - val_loss: 22.7309\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 17.3968 - val_loss: 22.9624\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.4025 - val_loss: 23.9313\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 18.8071 - val_loss: 23.1870\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.6573 - val_loss: 21.9908\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 17.3887 - val_loss: 21.8929\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.7135 - val_loss: 22.8533\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1618 - val_loss: 23.1269\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.2783 - val_loss: 21.7003\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.4205 - val_loss: 22.0206\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3845 - val_loss: 24.4782\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.4651 - val_loss: 23.6005\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7783 - val_loss: 20.9682\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4340 - val_loss: 22.9600\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7230 - val_loss: 23.1600\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2688 - val_loss: 21.8304\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4363 - val_loss: 22.4851\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3055 - val_loss: 21.9189\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3402 - val_loss: 24.4384\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0071 - val_loss: 22.0368\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9641 - val_loss: 22.1944\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 18.0139 - val_loss: 22.5982\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0677 - val_loss: 22.3910\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.9349 - val_loss: 22.9966\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9501 - val_loss: 22.0085\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.9762 - val_loss: 21.8163\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5125 - val_loss: 21.4014\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5151 - val_loss: 21.7269\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8379 - val_loss: 22.1909\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4898 - val_loss: 22.0861\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1268 - val_loss: 21.8977\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8027 - val_loss: 21.7688\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3826 - val_loss: 22.6324\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4831 - val_loss: 22.7162\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1678 - val_loss: 21.3007\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4410 - val_loss: 21.8918\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.6083 - val_loss: 25.3046\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8714 - val_loss: 21.0136\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5264 - val_loss: 21.8648\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1623 - val_loss: 21.2853\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5309 - val_loss: 22.3148\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1406 - val_loss: 21.8493\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2492 - val_loss: 21.9957\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1909 - val_loss: 22.0691\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3575 - val_loss: 22.2978\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0916 - val_loss: 21.8539\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0791 - val_loss: 22.3124\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5652 - val_loss: 21.7493\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1939 - val_loss: 21.7228\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0344 - val_loss: 24.9561\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9062 - val_loss: 21.1113\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3478 - val_loss: 21.1132\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9961 - val_loss: 21.2951\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3148 - val_loss: 22.0160\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.7281 - val_loss: 22.3441\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4826 - val_loss: 21.0645\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4191 - val_loss: 22.2231\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4202 - val_loss: 21.8421\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0771 - val_loss: 20.8954\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3763 - val_loss: 23.1992\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9048 - val_loss: 21.9326\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8086 - val_loss: 22.2738\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1118 - val_loss: 23.2647\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3014 - val_loss: 21.8453\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3657 - val_loss: 22.0362\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1546 - val_loss: 21.6906\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5637 - val_loss: 22.7056\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1234 - val_loss: 21.8492\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3048 - val_loss: 21.8240\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1220 - val_loss: 22.2290\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.4522 - val_loss: 25.4552\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.9613 - val_loss: 22.5086\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2653 - val_loss: 21.4136\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2368 - val_loss: 22.4786\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.0188 - val_loss: 21.8224\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3246 - val_loss: 22.9366\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2599 - val_loss: 21.0232\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3461 - val_loss: 21.4724\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3440 - val_loss: 21.6783\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5849 - val_loss: 21.9913\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6709 - val_loss: 21.5428\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6370 - val_loss: 21.8373\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9996 - val_loss: 22.7178\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3138 - val_loss: 21.2133\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7108 - val_loss: 22.1278\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4560 - val_loss: 23.5991\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2693 - val_loss: 21.9331\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.8670 - val_loss: 21.2595\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.0110 - val_loss: 22.9561\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3084 - val_loss: 21.0864\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3707 - val_loss: 21.9323\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4853 - val_loss: 21.9406\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1785 - val_loss: 22.3030\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4346 - val_loss: 22.8996\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7420 - val_loss: 21.3019\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.8306 - val_loss: 22.2237\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.3395 - val_loss: 21.4185\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.6160 - val_loss: 21.8604\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0810 - val_loss: 24.3986\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.7267 - val_loss: 21.7212\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.2031 - val_loss: 22.4295\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0570 - val_loss: 21.4280\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.1087 - val_loss: 21.4634\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.1692 - val_loss: 22.3424\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.1310 - val_loss: 22.4352\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3359 - val_loss: 22.5932\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.4461 - val_loss: 22.6622\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.9559 - val_loss: 21.1283\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0628 - val_loss: 21.8836\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6728 - val_loss: 21.7077\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.3893 - val_loss: 21.9168\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4554 - val_loss: 21.6227\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.8298 - val_loss: 22.2279\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2148 - val_loss: 21.7605\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.9706 - val_loss: 21.5436\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.1844 - val_loss: 21.9316\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8742 - val_loss: 21.1256\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2728 - val_loss: 22.7479\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2159 - val_loss: 22.0063\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.9964 - val_loss: 22.1236\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.5737 - val_loss: 21.4538\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3751 - val_loss: 21.3974\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4788 - val_loss: 21.6617\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3622 - val_loss: 23.0652\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.7952 - val_loss: 22.1871\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1619 - val_loss: 21.2218\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6138 - val_loss: 22.4885\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.5009 - val_loss: 23.8077\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.7882 - val_loss: 21.8770\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1879 - val_loss: 21.9419\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0854 - val_loss: 23.7770\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.1940 - val_loss: 21.1135\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.0070 - val_loss: 21.9007\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0967 - val_loss: 21.4691\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.5592 - val_loss: 23.1847\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4533 - val_loss: 22.8793\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.3224 - val_loss: 22.3195\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8242 - val_loss: 22.8563\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.2497 - val_loss: 23.5219\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4220 - val_loss: 23.4922\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8945 - val_loss: 24.8571\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.3708 - val_loss: 21.4530\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.3183 - val_loss: 22.0257\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.5580 - val_loss: 22.6299\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3572 - val_loss: 22.2486\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.1749 - val_loss: 21.4694\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.1093 - val_loss: 21.1422\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3156 - val_loss: 21.2730\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 16.9290 - val_loss: 21.4342\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.4525 - val_loss: 21.8751\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0943 - val_loss: 21.9546\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2296 - val_loss: 21.4259\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2970 - val_loss: 21.7901\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.8974 - val_loss: 21.8578\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0428 - val_loss: 21.8293\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 16.6931 - val_loss: 22.7810\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3585 - val_loss: 21.7922\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.4182 - val_loss: 21.8401\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8077 - val_loss: 21.3342\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.0981 - val_loss: 22.5515\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.8793 - val_loss: 22.6852\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.6441 - val_loss: 22.3296\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.4032 - val_loss: 25.1065\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.4128 - val_loss: 22.4891\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.5503 - val_loss: 21.9487\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.0715 - val_loss: 21.9123\n",
      "16.17969278740672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-6.9873160e-01,  1.5001279e-01, -1.4628013e+00, -3.5770342e-01,\n",
       "          2.0507312e-01],\n",
       "        [-4.9871728e-02,  1.9290209e-01,  7.3607022e-01, -6.2675193e-02,\n",
       "         -5.4032618e-01],\n",
       "        [-6.2658209e-01, -8.7140542e-01,  4.6801928e-01,  2.5363505e+00,\n",
       "         -2.0122204e+00],\n",
       "        [-2.1121231e-01,  1.4494795e-01,  1.7510287e-01,  3.2499935e-02,\n",
       "          7.8973666e-02],\n",
       "        [-2.6619565e-01, -5.9680152e-01,  1.3265331e+00,  2.3448378e-02,\n",
       "          8.8104000e-04]], dtype=float32),\n",
       " array([3.0221555 , 3.4456012 , 0.93795013, 2.8648953 , 3.3526647 ],\n",
       "       dtype=float32),\n",
       " array([[-0.26704103, -0.24707033, -0.09471258,  0.9856984 ,  1.2312359 ,\n",
       "         -0.5247978 , -0.95006806,  0.01280636, -0.468651  ,  1.068053  ],\n",
       "        [-0.59096086, -0.20532243, -0.7789056 ,  1.881537  ,  1.1882198 ,\n",
       "         -0.6440584 , -0.5324607 , -0.38427982, -0.06075155,  1.2582499 ],\n",
       "        [-0.640467  , -0.8248334 , -0.42673445,  1.0341029 ,  0.12141625,\n",
       "         -0.39100662, -0.02124108, -0.35239923, -0.7532337 ,  0.47012842],\n",
       "        [-0.07386572, -0.07458302, -0.08632782,  1.6634537 ,  1.6365421 ,\n",
       "         -0.2641647 , -0.29307702, -0.33808675, -0.18278351,  1.9504379 ],\n",
       "        [-0.42208385, -0.8521322 , -0.52153635,  1.9155527 ,  1.061408  ,\n",
       "         -0.06023137, -0.20473014, -0.4171309 , -0.49105066,  1.6818084 ]],\n",
       "       dtype=float32),\n",
       " array([-0.6196205 , -0.59765047, -0.679708  ,  3.933985  ,  3.8488686 ,\n",
       "        -0.49327967, -0.466859  ,  0.        , -0.55484045,  3.9180932 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.34687364],\n",
       "        [ 0.16646363],\n",
       "        [ 0.29221377],\n",
       "        [ 1.7949554 ],\n",
       "        [ 1.4488212 ],\n",
       "        [ 0.4635317 ],\n",
       "        [ 0.30423597],\n",
       "        [ 0.26349372],\n",
       "        [-0.15290564],\n",
       "        [ 1.8950063 ]], dtype=float32),\n",
       " array([3.8758476], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_relu(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_relu_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 224us/step - loss: 13575.4897 - val_loss: 11370.3389\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9716.2938 - val_loss: 8311.4513\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 7268.6015 - val_loss: 6408.1200\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 5692.4656 - val_loss: 5101.2922\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4567.5529 - val_loss: 4132.4897\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 3717.0152 - val_loss: 3382.6445\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 3050.4461 - val_loss: 2790.4414\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 2519.3639 - val_loss: 2311.5063\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 2088.4289 - val_loss: 1921.7956\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 1736.4395 - val_loss: 1601.3014\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 1446.6637 - val_loss: 1336.1337\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 1206.5575 - val_loss: 1117.1845\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 1007.8053 - val_loss: 934.3036\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 842.3684 - val_loss: 781.9453\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 704.6314 - val_loss: 655.0740\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 589.8829 - val_loss: 549.5505\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 494.2840 - val_loss: 461.7684\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 414.9252 - val_loss: 388.2964\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 348.9123 - val_loss: 326.9922\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 294.1112 - val_loss: 276.1491\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 248.6392 - val_loss: 234.2867\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 211.1614 - val_loss: 199.5146\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 180.3523 - val_loss: 170.4306\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 154.8481 - val_loss: 146.7975\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 134.0008 - val_loss: 127.4722\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 117.0880 - val_loss: 111.3013\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 103.1090 - val_loss: 98.3673\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 91.8952 - val_loss: 87.6810\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 82.7405 - val_loss: 79.1271\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 75.3642 - val_loss: 72.2327\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 69.4810 - val_loss: 66.5105\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 64.7396 - val_loss: 61.9439\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 60.9476 - val_loss: 58.3017\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 57.9488 - val_loss: 55.3474\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 55.5497 - val_loss: 53.0589\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 53.7286 - val_loss: 51.0385\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 52.2290 - val_loss: 49.5715\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 51.1017 - val_loss: 48.3735\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 50.1940 - val_loss: 47.4846\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 49.5179 - val_loss: 46.7423\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 48.9818 - val_loss: 46.1523\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 48.5815 - val_loss: 45.6686\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 48.2608 - val_loss: 45.3271\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 48.0418 - val_loss: 44.9892\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.8454 - val_loss: 44.7826\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 47.7081 - val_loss: 44.5974\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 47.5923 - val_loss: 44.4466\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 47.4896 - val_loss: 44.3143\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.3794 - val_loss: 44.1394\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.1495 - val_loss: 43.8221\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 46.7133 - val_loss: 43.2951\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 46.1988 - val_loss: 42.4005\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 44.3474 - val_loss: 40.6029\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 38.0354 - val_loss: 34.7620\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 30.4693 - val_loss: 30.4592\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 26.0579 - val_loss: 27.3507\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.1370 - val_loss: 24.9678\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.4015 - val_loss: 23.7576\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 20.1895 - val_loss: 22.4606\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.1490 - val_loss: 21.6578\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.3709 - val_loss: 21.0699\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8110 - val_loss: 20.5242\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.2398 - val_loss: 20.2341\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.8547 - val_loss: 19.7797\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.5503 - val_loss: 19.6905\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.1480 - val_loss: 19.0659\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.9068 - val_loss: 18.9217\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.6012 - val_loss: 18.7422\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4531 - val_loss: 18.5162\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.3021 - val_loss: 18.5573\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1915 - val_loss: 18.1919\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.0651 - val_loss: 18.3198\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9384 - val_loss: 18.1905\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8049 - val_loss: 18.1837\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.8167 - val_loss: 18.1674\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6830 - val_loss: 17.9441\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.6087 - val_loss: 18.0059\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5323 - val_loss: 17.8629\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6043 - val_loss: 17.8038\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4683 - val_loss: 17.9829\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4710 - val_loss: 17.7667\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4115 - val_loss: 18.1178\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.5183 - val_loss: 18.0764\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3623 - val_loss: 18.0668\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.3813 - val_loss: 17.9346\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3538 - val_loss: 17.8000\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2855 - val_loss: 17.7075\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.2132 - val_loss: 17.8252\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2174 - val_loss: 18.0139\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.2732 - val_loss: 17.7248\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1162 - val_loss: 17.6084\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1382 - val_loss: 17.7064\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0478 - val_loss: 17.6811\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0862 - val_loss: 17.6205\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9770 - val_loss: 17.5614\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8336 - val_loss: 17.6613\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7456 - val_loss: 17.2755\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5540 - val_loss: 17.3239\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4737 - val_loss: 17.0340\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3958 - val_loss: 17.0864\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.3942 - val_loss: 16.9758\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.3518 - val_loss: 16.9903\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.3027 - val_loss: 16.8392\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1812 - val_loss: 16.7383\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.1327 - val_loss: 16.7241\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0889 - val_loss: 16.5366\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.37 - 0s 88us/step - loss: 13.0550 - val_loss: 16.6272\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0923 - val_loss: 16.6984\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.0131 - val_loss: 16.6822\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.0205 - val_loss: 16.6945\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9541 - val_loss: 16.4671\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9757 - val_loss: 16.6668\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9223 - val_loss: 16.8881\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.8813 - val_loss: 16.4795\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9531 - val_loss: 16.6067\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9431 - val_loss: 16.5965\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8568 - val_loss: 16.2870\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8221 - val_loss: 16.4400\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9215 - val_loss: 16.3727\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7453 - val_loss: 16.3118\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7062 - val_loss: 16.1474\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.8641 - val_loss: 16.2438\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.7146 - val_loss: 16.2734\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.6523 - val_loss: 16.2566\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.6061 - val_loss: 16.2189\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.6345 - val_loss: 16.1729\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.6298 - val_loss: 15.5085\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.2576 - val_loss: 13.3059\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8530 - val_loss: 12.0442\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9970 - val_loss: 11.4227\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2822 - val_loss: 11.2599\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9187 - val_loss: 11.1622\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.3258 - val_loss: 10.6452\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.2138 - val_loss: 10.2460\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 7.8980 - val_loss: 10.1263\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 7.8966 - val_loss: 10.0983\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.6646 - val_loss: 9.6072\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.4118 - val_loss: 10.0169\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 7.2862 - val_loss: 9.5507\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2434 - val_loss: 9.7225\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 7.2874 - val_loss: 10.1388\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 7.3447 - val_loss: 8.9122\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 7.0629 - val_loss: 9.1515\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.8834 - val_loss: 8.5647\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.9300 - val_loss: 8.8738\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.7808 - val_loss: 8.4981\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.7756 - val_loss: 8.4035\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.6852 - val_loss: 8.6040\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.6885 - val_loss: 8.7803\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.6257 - val_loss: 8.1783\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5366 - val_loss: 7.9920\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.5472 - val_loss: 8.3476\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.6182 - val_loss: 8.2447\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 6.3824 - val_loss: 8.3420\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3739 - val_loss: 8.1570\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4640 - val_loss: 8.5738\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.4775 - val_loss: 8.2676\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.5205 - val_loss: 8.7316\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.5447 - val_loss: 8.0661\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.3444 - val_loss: 8.1425\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.2717 - val_loss: 7.9203\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.2187 - val_loss: 8.2626\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.4624 - val_loss: 8.1278\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2233 - val_loss: 8.0403\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 6.1108 - val_loss: 8.1024\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2272 - val_loss: 8.0512\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.3148 - val_loss: 8.6842\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.2347 - val_loss: 7.7859\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.2725 - val_loss: 8.0450\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1128 - val_loss: 7.7797\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0453 - val_loss: 7.9495\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 6.3117 - val_loss: 8.2078\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 6.1212 - val_loss: 8.1501\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 6.1324 - val_loss: 7.9135\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 6.0582 - val_loss: 7.7625\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 6.0630 - val_loss: 7.7400\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.4200 - val_loss: 8.2722\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 6.1414 - val_loss: 7.7372\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 6.0876 - val_loss: 7.6478\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 6.0285 - val_loss: 7.8051\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 6.0843 - val_loss: 7.6785\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 5.9229 - val_loss: 7.6510\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 6.0378 - val_loss: 7.9286\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.9695 - val_loss: 7.7904\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 6.1518 - val_loss: 7.6087\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1730 - val_loss: 8.3333\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.1673 - val_loss: 7.7537\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.2544 - val_loss: 8.7388\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0184 - val_loss: 7.7234\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9983 - val_loss: 7.6929\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7960 - val_loss: 7.8518\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.9799 - val_loss: 7.6096\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 6.0443 - val_loss: 7.8921\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 5.7845 - val_loss: 7.5634\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.7974 - val_loss: 7.7942\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0358 - val_loss: 8.2263\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8192 - val_loss: 7.6352\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7789 - val_loss: 7.6469\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7069 - val_loss: 7.9630\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.8632 - val_loss: 7.8394\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5803 - val_loss: 8.4637\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.8475 - val_loss: 7.8931\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 5.6827 - val_loss: 8.2486\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5560 - val_loss: 7.4732\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6999 - val_loss: 7.8199\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5229 - val_loss: 7.9125\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6976 - val_loss: 7.5035\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.6354 - val_loss: 9.3129\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.7405 - val_loss: 7.9319\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6.0039 - val_loss: 7.6201\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7141 - val_loss: 7.6556\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6562 - val_loss: 7.5621\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6345 - val_loss: 7.8603\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5141 - val_loss: 7.4556\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.4172 - val_loss: 8.2198\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5973 - val_loss: 7.3095\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 6.0718 - val_loss: 8.1308\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6886 - val_loss: 7.4797\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4163 - val_loss: 7.6372\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.7100 - val_loss: 7.4743\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6131 - val_loss: 7.5329\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5485 - val_loss: 8.4684\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.7330 - val_loss: 7.3354\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4835 - val_loss: 7.2429\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5067 - val_loss: 7.8623\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4471 - val_loss: 7.9824\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5754 - val_loss: 7.9952\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5397 - val_loss: 7.9402\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7610 - val_loss: 7.3518\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.6094 - val_loss: 8.3912\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.6400 - val_loss: 8.3134\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4499 - val_loss: 7.2021\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5177 - val_loss: 7.2568\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4265 - val_loss: 7.0857\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.6390 - val_loss: 7.2486\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.7231 - val_loss: 7.2008\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4076 - val_loss: 7.3039\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3980 - val_loss: 7.6805\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4371 - val_loss: 7.0855\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5096 - val_loss: 7.9003\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.7295 - val_loss: 7.4314\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7278 - val_loss: 7.2521\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4634 - val_loss: 7.3905\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4313 - val_loss: 7.4285\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5623 - val_loss: 7.2426\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3404 - val_loss: 7.8810\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5872 - val_loss: 7.6409\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5353 - val_loss: 7.3344\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.4518 - val_loss: 7.5482\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4481 - val_loss: 7.8151\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.5105 - val_loss: 7.3566\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3680 - val_loss: 7.2001\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.4265 - val_loss: 7.2243\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3628 - val_loss: 7.1448\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.5140 - val_loss: 8.2236\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.5092 - val_loss: 7.3259\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3458 - val_loss: 8.4542\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3038 - val_loss: 8.2674\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.8279 - val_loss: 7.7217\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.3700 - val_loss: 7.3065\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3989 - val_loss: 7.0953\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4586 - val_loss: 7.2504\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2946 - val_loss: 6.9705\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2553 - val_loss: 7.9772\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5622 - val_loss: 7.5054\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4984 - val_loss: 7.0568\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.2784 - val_loss: 7.2060\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4529 - val_loss: 7.4381\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.4371 - val_loss: 7.3821\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2334 - val_loss: 7.1861\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3174 - val_loss: 7.8510\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4129 - val_loss: 6.9615\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4695 - val_loss: 7.2264\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4233 - val_loss: 7.0447\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3398 - val_loss: 6.7612\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.3163 - val_loss: 6.9500\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2218 - val_loss: 7.2437\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3589 - val_loss: 7.3972\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3359 - val_loss: 7.3471\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3070 - val_loss: 7.1049\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.4716 - val_loss: 7.2227\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.4904 - val_loss: 7.3241\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3159 - val_loss: 7.4606\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2530 - val_loss: 7.0804\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.7493 - val_loss: 7.6784\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.4665 - val_loss: 7.1131\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.2689 - val_loss: 7.8288\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3256 - val_loss: 7.1969\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3045 - val_loss: 7.1948\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.5413 - val_loss: 7.3668\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2924 - val_loss: 7.1140\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.2891 - val_loss: 6.9054\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.2161 - val_loss: 7.0414\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3477 - val_loss: 6.8512\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1746 - val_loss: 8.0568\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.5069 - val_loss: 7.1471\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.4890 - val_loss: 7.1959\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3510 - val_loss: 7.5051\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3061 - val_loss: 7.6202\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3646 - val_loss: 7.8938\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.3755 - val_loss: 7.4250\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3274 - val_loss: 7.2252\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1758 - val_loss: 8.6152\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3713 - val_loss: 6.9277\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 5.1623 - val_loss: 6.7833\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3586 - val_loss: 7.4161\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2096 - val_loss: 7.1108\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1404 - val_loss: 7.1446\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3104 - val_loss: 6.9323\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2833 - val_loss: 7.0145\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.1410 - val_loss: 6.9296\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.5826 - val_loss: 7.1106\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.3387 - val_loss: 7.3331\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2663 - val_loss: 7.1259\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 5.5807 - val_loss: 6.9874\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2807 - val_loss: 6.7830\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1672 - val_loss: 6.7742\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 6.0114 - val_loss: 7.8946\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.6105 - val_loss: 6.7655\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.3507 - val_loss: 6.9159\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.5407 - val_loss: 7.0969\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.2118 - val_loss: 7.1060\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1770 - val_loss: 7.1374\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.2917 - val_loss: 6.9006\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.3113 - val_loss: 7.1049\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 5.1493 - val_loss: 6.6815\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3668 - val_loss: 7.2852\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0894 - val_loss: 6.6125\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1295 - val_loss: 7.0290\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1423 - val_loss: 6.8230\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.3616 - val_loss: 6.6819\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.0468 - val_loss: 6.8106\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.9308 - val_loss: 6.8800\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 5.1756 - val_loss: 6.4550\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 5.0872 - val_loss: 6.2850\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.0261 - val_loss: 6.5473\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.0954 - val_loss: 6.4639\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.9623 - val_loss: 6.6118\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9454 - val_loss: 6.3477\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.1640 - val_loss: 6.1359\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.0533 - val_loss: 6.2812\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.8719 - val_loss: 6.4630\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9667 - val_loss: 7.6913\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.9561 - val_loss: 6.1978\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.8460 - val_loss: 6.2748\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.8928 - val_loss: 6.2579\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 5.0429 - val_loss: 6.4175\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 5.3949 - val_loss: 6.2351\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 5.0555 - val_loss: 6.0228\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.8433 - val_loss: 6.0782\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.7887 - val_loss: 5.9611\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.6817 - val_loss: 6.0345\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.8650 - val_loss: 7.3091\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 5.1562 - val_loss: 6.0590\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.7853 - val_loss: 5.9680\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 4.9042 - val_loss: 5.7644\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 5.1657 - val_loss: 6.6939\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 5.2057 - val_loss: 6.1812\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.9629 - val_loss: 7.2531\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.9903 - val_loss: 5.8406\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.8995 - val_loss: 6.0288\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7450 - val_loss: 5.7751\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5842 - val_loss: 5.7650\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7866 - val_loss: 5.8785\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.7852 - val_loss: 6.0313\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.8807 - val_loss: 5.9343\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.8867 - val_loss: 5.7663\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7706 - val_loss: 5.9935\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7117 - val_loss: 6.2621\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7412 - val_loss: 5.8930\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6293 - val_loss: 5.8549\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.7940 - val_loss: 5.6536\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6006 - val_loss: 7.4971\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.8071 - val_loss: 6.2145\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.9670 - val_loss: 5.7664\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.8920 - val_loss: 5.5444\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6738 - val_loss: 5.6134\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7179 - val_loss: 6.2096\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.9661 - val_loss: 5.9711\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.8528 - val_loss: 5.7008\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.6667 - val_loss: 5.6565\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5775 - val_loss: 5.5832\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6253 - val_loss: 6.0947\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.6532 - val_loss: 5.6200\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6938 - val_loss: 5.6013\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5679 - val_loss: 5.5420\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7531 - val_loss: 5.7738\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.8434 - val_loss: 5.9338\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6912 - val_loss: 6.5671\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7508 - val_loss: 5.8553\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.8048 - val_loss: 6.2009\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5327 - val_loss: 6.2315\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 5.2038 - val_loss: 5.6286\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7670 - val_loss: 5.7128\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7604 - val_loss: 5.8856\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.7881 - val_loss: 5.4943\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6279 - val_loss: 6.4637\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7469 - val_loss: 5.3792\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6762 - val_loss: 5.4620\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6383 - val_loss: 5.6047\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6519 - val_loss: 6.7338\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.9421 - val_loss: 5.8755\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7670 - val_loss: 6.4784\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 4.8461 - val_loss: 5.5417\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6269 - val_loss: 6.6803\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7368 - val_loss: 5.5577\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.7773 - val_loss: 5.5952\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7895 - val_loss: 5.6313\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5528 - val_loss: 5.9053\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6892 - val_loss: 5.7793\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6716 - val_loss: 5.4257\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7289 - val_loss: 6.0533\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.4888 - val_loss: 6.0347\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.7043 - val_loss: 5.7402\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7386 - val_loss: 6.0706\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6674 - val_loss: 5.3184\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5593 - val_loss: 5.4691\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.5274 - val_loss: 5.6963\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.4794 - val_loss: 5.8157\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.7116 - val_loss: 5.4514\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6239 - val_loss: 5.4657\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.7125 - val_loss: 5.5544\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5989 - val_loss: 5.6355\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5701 - val_loss: 5.6188\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5849 - val_loss: 5.5786\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.4026 - val_loss: 5.5165\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6509 - val_loss: 5.4900\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 5.0378 - val_loss: 6.6627\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.8037 - val_loss: 5.6211\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5146 - val_loss: 5.9109\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6531 - val_loss: 5.9275\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6543 - val_loss: 5.9794\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5734 - val_loss: 6.0729\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3998 - val_loss: 5.9690\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4793 - val_loss: 5.8472\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4235 - val_loss: 5.7453\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.5774 - val_loss: 5.7672\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5604 - val_loss: 5.7595\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5392 - val_loss: 6.5095\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.7765 - val_loss: 5.3275\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.8334 - val_loss: 5.5961\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.7191 - val_loss: 6.6961\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.6060 - val_loss: 5.7418\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4880 - val_loss: 5.3057\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.3905 - val_loss: 5.6464\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6976 - val_loss: 5.7830\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5351 - val_loss: 5.5318\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.4337 - val_loss: 5.8055\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.3766 - val_loss: 5.8125\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 3.696 - 0s 90us/step - loss: 4.6287 - val_loss: 5.3427\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5875 - val_loss: 5.6300\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4680 - val_loss: 7.3471\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6592 - val_loss: 6.0656\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4695 - val_loss: 6.1039\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5853 - val_loss: 5.2995\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.4653 - val_loss: 5.6085\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4901 - val_loss: 5.4901\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.6654 - val_loss: 6.1117\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4820 - val_loss: 5.5388\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5468 - val_loss: 6.8754\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.4828 - val_loss: 5.4923\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4082 - val_loss: 5.2982\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3273 - val_loss: 6.2058\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.6099 - val_loss: 6.0135\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.4106 - val_loss: 5.3310\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.4826 - val_loss: 5.2786\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.5130 - val_loss: 5.7292\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.3368 - val_loss: 5.6800\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.5194 - val_loss: 5.9717\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4829 - val_loss: 6.2208\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.7033 - val_loss: 5.2102\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4440 - val_loss: 5.4664\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.4136 - val_loss: 5.3450\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3171 - val_loss: 5.7015\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.4555 - val_loss: 5.3923\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.4896 - val_loss: 5.9395\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.5667 - val_loss: 5.5781\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4159 - val_loss: 6.6371\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.5099 - val_loss: 5.3083\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.3289 - val_loss: 5.6286\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.3204 - val_loss: 5.5404\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4342 - val_loss: 5.5629\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4635 - val_loss: 5.9412\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6449 - val_loss: 5.5703\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4686 - val_loss: 5.2899\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3773 - val_loss: 5.4463\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.5631 - val_loss: 5.8829\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.5172 - val_loss: 5.4253\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4592 - val_loss: 5.3661\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.6458 - val_loss: 6.9804\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4824 - val_loss: 5.4192\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4626 - val_loss: 5.2971\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.3511 - val_loss: 5.4869\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.3856 - val_loss: 6.5430\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.4960 - val_loss: 5.4210\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.5306 - val_loss: 5.8816\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5886 - val_loss: 5.5393\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.6210 - val_loss: 6.1676\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.3606 - val_loss: 5.5609\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.3281 - val_loss: 5.1591\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.4214 - val_loss: 5.3565\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.4228 - val_loss: 5.7927\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.3233 - val_loss: 5.6113\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.7441 - val_loss: 5.5372\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.3841 - val_loss: 5.6491\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3661 - val_loss: 5.5176\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4236 - val_loss: 6.1427\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.3368 - val_loss: 5.6643\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.6429 - val_loss: 7.0190\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5162 - val_loss: 5.7132\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 4.3458 - val_loss: 5.5828\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.3803 - val_loss: 5.4945\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4541 - val_loss: 5.9060\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3692 - val_loss: 5.2434\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.4256 - val_loss: 6.5087\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.3609 - val_loss: 6.0171\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4285 - val_loss: 5.1645\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5024 - val_loss: 5.2301\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3573 - val_loss: 5.4236\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2791 - val_loss: 5.4461\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.3180 - val_loss: 5.5866\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.3401 - val_loss: 5.0768\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.4219 - val_loss: 5.1054\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 4.4480 - val_loss: 5.5619\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.2933 - val_loss: 5.0606\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.3534 - val_loss: 6.2296\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.5814 - val_loss: 5.5694\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.4294 - val_loss: 5.7800\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.6184 - val_loss: 5.5841\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2622 - val_loss: 5.2431\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.2777 - val_loss: 5.6024\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3788 - val_loss: 5.3069\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3213 - val_loss: 5.6215\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2875 - val_loss: 5.2816\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.5858 - val_loss: 6.7523\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 112us/step - loss: 4.7161 - val_loss: 5.6743\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.2945 - val_loss: 5.2962\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.2945 - val_loss: 6.3470\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 4.1657 - val_loss: 5.0174\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.4126 - val_loss: 5.1280\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 4.2877 - val_loss: 5.0799\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 4.4411 - val_loss: 5.6599\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 4.5901 - val_loss: 6.4193\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 4.3489 - val_loss: 5.1571\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 4.2573 - val_loss: 5.3125\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.0943 - val_loss: 5.0911\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.2064 - val_loss: 5.2045\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.3752 - val_loss: 5.5645\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.2046 - val_loss: 5.4313\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3477 - val_loss: 4.8259\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3509 - val_loss: 5.1198\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3331 - val_loss: 5.0696\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.5039 - val_loss: 6.0112\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4082 - val_loss: 5.0983\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.3147 - val_loss: 6.3539\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.3714 - val_loss: 5.6645\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.5541 - val_loss: 5.6345\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.3072 - val_loss: 5.0962\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.4455 - val_loss: 4.9224\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.4136 - val_loss: 5.4614\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.6031 - val_loss: 6.8831\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.3057 - val_loss: 5.0087\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.2237 - val_loss: 5.0365\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.1951 - val_loss: 5.2006\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.0601 - val_loss: 4.9342\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.3791 - val_loss: 5.0660\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2865 - val_loss: 4.9197\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.1374 - val_loss: 5.0494\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.1688 - val_loss: 5.0686\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.2990 - val_loss: 5.1782\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.4870 - val_loss: 5.0725\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.1414 - val_loss: 5.0181\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 4.1199 - val_loss: 5.3119\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 4.3834 - val_loss: 5.5348\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.2727 - val_loss: 5.7862\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.1442 - val_loss: 5.1021\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.1704 - val_loss: 5.1078\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.3653 - val_loss: 5.9318\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.2106 - val_loss: 5.4989\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.2663 - val_loss: 4.8312\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.0932 - val_loss: 5.2994\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.1015 - val_loss: 4.9278\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3545 - val_loss: 4.8734\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.1531 - val_loss: 6.1848\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.1257 - val_loss: 4.8894\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2030 - val_loss: 5.1712\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.1624 - val_loss: 4.8932\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.3449 - val_loss: 5.3253\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.1781 - val_loss: 5.4473\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.3259 - val_loss: 4.8203\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.2056 - val_loss: 4.9978\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.2126 - val_loss: 4.8841\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.3595 - val_loss: 5.0368\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.4619 - val_loss: 6.0532\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5568 - val_loss: 4.8646\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2499 - val_loss: 5.2577\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.2776 - val_loss: 4.7683\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.0403 - val_loss: 4.9476\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2073 - val_loss: 5.0233\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.1540 - val_loss: 5.2722\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.1147 - val_loss: 5.1871\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.1807 - val_loss: 5.2400\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2815 - val_loss: 5.0229\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 4.1318 - val_loss: 4.9664\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 4.2907 - val_loss: 5.4855\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2463 - val_loss: 5.0228\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2327 - val_loss: 6.7587\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.4685 - val_loss: 4.8830\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.0988 - val_loss: 4.9132\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.0364 - val_loss: 5.0015\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.2664 - val_loss: 5.0634\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.3287 - val_loss: 5.7216\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2085 - val_loss: 5.0244\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2514 - val_loss: 4.9221\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.7119 - val_loss: 6.1728\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.3564 - val_loss: 5.1411\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2913 - val_loss: 5.1303\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.2488 - val_loss: 6.2055\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.1258 - val_loss: 5.3818\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2819 - val_loss: 5.0633\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2235 - val_loss: 5.0109\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2044 - val_loss: 6.0681\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 4.2360 - val_loss: 4.7997\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.3572 - val_loss: 5.1964\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 4.4619 - val_loss: 5.2307\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 138us/step - loss: 4.3086 - val_loss: 5.3929\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 110us/step - loss: 4.1213 - val_loss: 4.6074\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.1113 - val_loss: 4.8883\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.1559 - val_loss: 5.2027\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.4015 - val_loss: 4.8662\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.6557 - val_loss: 5.7153\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.2995 - val_loss: 5.0975\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.2917 - val_loss: 5.0561\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 4.3584 - val_loss: 5.8697\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 4.1877 - val_loss: 5.5050\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.1176 - val_loss: 5.3144\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.0639 - val_loss: 5.6819\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.2789 - val_loss: 5.2174\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.3389 - val_loss: 6.2170\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.2757 - val_loss: 5.0194\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 4.3249 - val_loss: 4.7835\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.4917 - val_loss: 5.9312\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.1742 - val_loss: 4.8180\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2572 - val_loss: 5.2327\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 4.0578 - val_loss: 5.2577\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.1316 - val_loss: 4.7308\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.0957 - val_loss: 5.2454\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.2776 - val_loss: 5.1620\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.4061 - val_loss: 4.8415\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.1397 - val_loss: 5.2111\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.0706 - val_loss: 4.9135\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2256 - val_loss: 4.6075\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3149 - val_loss: 4.8544\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 145us/step - loss: 4.0245 - val_loss: 4.8746\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.0697 - val_loss: 4.8130\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1555 - val_loss: 4.7488\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2227 - val_loss: 5.1900\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.5146 - val_loss: 5.0317\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.1515 - val_loss: 4.6584\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.1950 - val_loss: 4.7937\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.0926 - val_loss: 4.9729\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.1715 - val_loss: 4.7845\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2862 - val_loss: 5.4018\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.1686 - val_loss: 5.1362\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.2538 - val_loss: 5.9948\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.2170 - val_loss: 4.9848\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2373 - val_loss: 4.8615\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5239 - val_loss: 5.8449\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.4346 - val_loss: 5.7402\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.3009 - val_loss: 4.8411\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.0958 - val_loss: 5.1780\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.1653 - val_loss: 5.0110\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.0389 - val_loss: 4.9494\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.1187 - val_loss: 4.8539\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.1378 - val_loss: 5.2014\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 4.1395 - val_loss: 4.7528\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.2400 - val_loss: 4.9684\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.1517 - val_loss: 5.2149\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 4.2072 - val_loss: 5.0933\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 4.1698 - val_loss: 5.0857\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.2776 - val_loss: 5.4241\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 4.1834 - val_loss: 4.6055\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 4.1434 - val_loss: 4.8890\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 4.2636 - val_loss: 4.7625\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 4.2026 - val_loss: 6.3885\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.2243 - val_loss: 4.8209\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1282 - val_loss: 4.8122\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1914 - val_loss: 4.8125\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1761 - val_loss: 4.9943\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.1114 - val_loss: 5.3503\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2382 - val_loss: 4.8292\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.4128 - val_loss: 4.7747\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.3460 - val_loss: 5.4919\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.1649 - val_loss: 4.9645\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2608 - val_loss: 5.0037\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.0796 - val_loss: 4.6635\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4442 - val_loss: 4.9251\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2390 - val_loss: 5.0709\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.2121 - val_loss: 6.3498\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.0971 - val_loss: 4.6035\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1904 - val_loss: 5.5407\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.1346 - val_loss: 4.9944\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.4619 - val_loss: 5.4119\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0953 - val_loss: 5.3079\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2489 - val_loss: 5.1407\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.1372 - val_loss: 5.2849\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.3581 - val_loss: 4.9878\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2777 - val_loss: 5.4662\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.1758 - val_loss: 5.2215\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2367 - val_loss: 4.9436\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.2208 - val_loss: 4.8508\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 4.2182 - val_loss: 5.9991\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.3690 - val_loss: 5.1715\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3276 - val_loss: 5.6571\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2523 - val_loss: 4.9108\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1499 - val_loss: 5.1947\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2683 - val_loss: 4.9941\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2207 - val_loss: 5.6961\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1001 - val_loss: 5.5368\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0404 - val_loss: 4.7556\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2163 - val_loss: 4.6687\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0631 - val_loss: 4.8402\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1297 - val_loss: 5.1507\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.1524 - val_loss: 4.9608\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0344 - val_loss: 4.7052\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.2377 - val_loss: 5.4159\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2007 - val_loss: 5.0406\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.2446 - val_loss: 4.8740\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1360 - val_loss: 4.8419\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0691 - val_loss: 4.7340\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0963 - val_loss: 5.0954\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0627 - val_loss: 4.9348\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0839 - val_loss: 4.7215\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1705 - val_loss: 4.7223\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0648 - val_loss: 4.8488\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2465 - val_loss: 4.8001\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 3.9919 - val_loss: 4.6667\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0564 - val_loss: 4.8587\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 4.0928 - val_loss: 4.7954\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.2756 - val_loss: 4.7504\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1839 - val_loss: 4.7615\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2265 - val_loss: 5.1945\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1271 - val_loss: 4.5555\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9923 - val_loss: 5.0129\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1215 - val_loss: 6.4470\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 125us/step - loss: 4.2567 - val_loss: 6.6577\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 4.2647 - val_loss: 6.4344\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 4.5414 - val_loss: 4.6915\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 97us/step - loss: 4.1794 - val_loss: 4.8402\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.1246 - val_loss: 5.2624\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2040 - val_loss: 4.6465\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 3.9827 - val_loss: 5.5250\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 121us/step - loss: 4.0868 - val_loss: 4.6009\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.3358 - val_loss: 4.8691\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.2396 - val_loss: 4.8656\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.3977 - val_loss: 4.6880\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0156 - val_loss: 5.2172\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.2902 - val_loss: 4.7933\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.2020 - val_loss: 5.6296\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.5066 - val_loss: 4.9264\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1067 - val_loss: 4.7832\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1645 - val_loss: 5.0949\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1347 - val_loss: 5.4353\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.5140 - val_loss: 4.9864\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0651 - val_loss: 5.3673\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1770 - val_loss: 5.3560\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.1650 - val_loss: 4.9030\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.1190 - val_loss: 4.9695\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2821 - val_loss: 5.8300\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2212 - val_loss: 5.4795\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8984 - val_loss: 4.8961\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1220 - val_loss: 5.5753\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2537 - val_loss: 5.1828\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1377 - val_loss: 6.3843\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.9645 - val_loss: 4.8044\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2826 - val_loss: 5.1060\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0946 - val_loss: 4.9021\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1111 - val_loss: 5.2011\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2474 - val_loss: 4.8492\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.9572 - val_loss: 5.1936\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.1122 - val_loss: 4.9827\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0634 - val_loss: 5.9038\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.4487 - val_loss: 4.7187\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1427 - val_loss: 5.3663\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9941 - val_loss: 5.0574\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0894 - val_loss: 4.8832\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9054 - val_loss: 4.9123\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0975 - val_loss: 5.6960\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0131 - val_loss: 5.5174\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1272 - val_loss: 4.7243\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.1868 - val_loss: 4.8085\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0172 - val_loss: 5.1562\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0204 - val_loss: 4.9923\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9540 - val_loss: 5.0524\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0438 - val_loss: 4.8028\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0587 - val_loss: 5.2281\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1692 - val_loss: 5.2249\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9659 - val_loss: 5.0925\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1130 - val_loss: 4.8817\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9499 - val_loss: 5.2296\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0713 - val_loss: 4.9866\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1028 - val_loss: 6.3393\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 4.0674 - val_loss: 4.9125\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 3.9931 - val_loss: 5.8894\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1359 - val_loss: 5.7756\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0538 - val_loss: 5.1077\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8800 - val_loss: 5.0250\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0255 - val_loss: 5.0224\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9128 - val_loss: 5.3364\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0294 - val_loss: 4.8478\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.0323 - val_loss: 4.8611\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0250 - val_loss: 5.3734\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9753 - val_loss: 4.8675\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0118 - val_loss: 5.4296\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3991 - val_loss: 4.9648\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0650 - val_loss: 5.5818\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1741 - val_loss: 5.4111\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0561 - val_loss: 5.5212\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.3721 - val_loss: 5.5437\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9351 - val_loss: 5.0518\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0458 - val_loss: 5.1564\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2938 - val_loss: 5.1751\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.2618 - val_loss: 5.4084\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0528 - val_loss: 5.3094\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.1446 - val_loss: 5.1212\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0356 - val_loss: 5.9217\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8250 - val_loss: 4.7476\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 4.2660 - val_loss: 4.9897\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0416 - val_loss: 5.0879\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9572 - val_loss: 5.3680\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1266 - val_loss: 7.0692\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0285 - val_loss: 5.7040\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9382 - val_loss: 5.1633\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0335 - val_loss: 4.9338\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.3379 - val_loss: 5.6453\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9441 - val_loss: 5.5477\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1406 - val_loss: 5.0063\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0132 - val_loss: 5.0239\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0352 - val_loss: 6.4377\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.9484 - val_loss: 5.7755\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0972 - val_loss: 5.2048\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0020 - val_loss: 5.3464\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0713 - val_loss: 5.3964\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2831 - val_loss: 5.3212\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9353 - val_loss: 5.6025\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1543 - val_loss: 5.0253\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1939 - val_loss: 5.7626\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8914 - val_loss: 5.7416\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0913 - val_loss: 5.3267\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0841 - val_loss: 5.3667\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 4.2801 - val_loss: 5.4581\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 4.0958 - val_loss: 5.9998\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 4.0310 - val_loss: 5.3959\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 3.9921 - val_loss: 5.8399\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 3.9149 - val_loss: 6.3303\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 3.9573 - val_loss: 6.9795\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 3.9399 - val_loss: 5.6232\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 4.1240 - val_loss: 5.3529\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4.0971 - val_loss: 4.8676\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1670 - val_loss: 6.2345\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8747 - val_loss: 4.8606\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8437 - val_loss: 5.3266\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1980 - val_loss: 4.9448\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0440 - val_loss: 5.5640\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.3707 - val_loss: 5.6689\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3.9611 - val_loss: 4.8541\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 3.996 - 0s 87us/step - loss: 4.0107 - val_loss: 5.8873\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2361 - val_loss: 6.0117\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9021 - val_loss: 5.4717\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0154 - val_loss: 5.4578\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9554 - val_loss: 4.9057\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.0228 - val_loss: 4.7338\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0402 - val_loss: 5.2856\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 4.5912 - val_loss: 6.0139\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2075 - val_loss: 5.7801\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9412 - val_loss: 5.0983\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.8824 - val_loss: 6.9576\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9489 - val_loss: 5.3345\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8724 - val_loss: 5.2713\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.7840 - val_loss: 5.0507\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 3.8456 - val_loss: 4.9962\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.1455 - val_loss: 6.3575\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8819 - val_loss: 4.9377\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0326 - val_loss: 5.2173\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8194 - val_loss: 5.0334\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8918 - val_loss: 5.5182\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1108 - val_loss: 5.0372\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9495 - val_loss: 5.2528\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1089 - val_loss: 5.2536\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.8310 - val_loss: 5.9885\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0433 - val_loss: 5.1525\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0426 - val_loss: 5.6907\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1296 - val_loss: 6.3533\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.9246 - val_loss: 5.0112\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9364 - val_loss: 5.2293\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0235 - val_loss: 5.0065\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9744 - val_loss: 5.3122\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9923 - val_loss: 4.8115\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9386 - val_loss: 5.5448\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1031 - val_loss: 5.5317\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.1683 - val_loss: 5.4954\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0843 - val_loss: 5.7889\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9305 - val_loss: 5.1204\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8271 - val_loss: 5.0444\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9745 - val_loss: 5.5551\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.0793 - val_loss: 5.0271\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0020 - val_loss: 5.5026\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9614 - val_loss: 5.5146\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4.2321 - val_loss: 5.0888\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.8990 - val_loss: 4.9269\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0936 - val_loss: 5.7634\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9885 - val_loss: 5.5456\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3.9890 - val_loss: 5.2034\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.2313 - val_loss: 5.5545\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2798 - val_loss: 5.2845\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1042 - val_loss: 5.4781\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.7777 - val_loss: 5.2861\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8691 - val_loss: 5.5660\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8098 - val_loss: 5.6468\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 3.9229 - val_loss: 5.8558\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9309 - val_loss: 5.4378\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9363 - val_loss: 5.0021\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0246 - val_loss: 5.3450\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3.8114 - val_loss: 5.3022\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9595 - val_loss: 5.6999\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1291 - val_loss: 5.8822\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9156 - val_loss: 5.5100\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1416 - val_loss: 4.8581\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0207 - val_loss: 5.3891\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8605 - val_loss: 5.0674\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3.9102 - val_loss: 5.0542\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.3030 - val_loss: 6.0900\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 4.0837 - val_loss: 5.8685\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8687 - val_loss: 5.4709\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.0254 - val_loss: 5.0700\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.2051 - val_loss: 5.7294\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8309 - val_loss: 5.8903\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.0360 - val_loss: 5.2939\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9505 - val_loss: 5.0854\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9361 - val_loss: 5.2282\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9000 - val_loss: 4.9836\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0676 - val_loss: 5.1283\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8844 - val_loss: 5.2936\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0390 - val_loss: 5.2024\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.2039 - val_loss: 4.9918\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 3.8872 - val_loss: 5.4219\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8904 - val_loss: 6.7770\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.1812 - val_loss: 6.5629\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 4.3887 - val_loss: 5.0622\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8844 - val_loss: 5.4069\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0678 - val_loss: 5.1451\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0770 - val_loss: 5.5546\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.9210 - val_loss: 5.1736\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8610 - val_loss: 5.7796\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.8271 - val_loss: 6.1605\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9276 - val_loss: 5.0756\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8863 - val_loss: 5.2668\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8982 - val_loss: 5.6334\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9885 - val_loss: 6.5065\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.8861 - val_loss: 5.6177\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 4.0586 - val_loss: 4.9282\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 3.8245 - val_loss: 5.1574\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0477 - val_loss: 5.4620\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8921 - val_loss: 5.1518\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9457 - val_loss: 5.2667\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9036 - val_loss: 5.0564\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.8422 - val_loss: 4.9090\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1802 - val_loss: 5.2331\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9257 - val_loss: 5.3712\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.9579 - val_loss: 5.2182\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.8389 - val_loss: 5.0544\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.9262 - val_loss: 5.7361\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9486 - val_loss: 5.2174\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 4.1143 - val_loss: 5.6249\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0211 - val_loss: 5.3983\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9454 - val_loss: 5.1274\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8003 - val_loss: 5.8751\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8578 - val_loss: 5.7667\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8387 - val_loss: 5.1293\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 3.9534 - val_loss: 5.3133\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.7836 - val_loss: 5.2182\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8357 - val_loss: 5.7758\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.2172 - val_loss: 5.4212\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8916 - val_loss: 5.0464\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9044 - val_loss: 5.8627\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9223 - val_loss: 6.1467\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 4.1038 - val_loss: 4.8696\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.8930 - val_loss: 6.3223\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 3.9467 - val_loss: 5.8641\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 4.0341 - val_loss: 5.0312\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3.8047 - val_loss: 5.9182\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.1043 - val_loss: 5.9484\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.8635 - val_loss: 5.9505\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 4.0570 - val_loss: 5.7905\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 3.8033 - val_loss: 5.2457\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 3.9649 - val_loss: 5.2979\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3.9453 - val_loss: 4.9581\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 3.9504 - val_loss: 5.2094\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4.0765 - val_loss: 5.0012\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 4.2911 - val_loss: 5.6584\n",
      "3.389035431684646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.4499823 , -0.6032244 , -1.6675066 , -1.8055677 , -5.289867  ],\n",
       "        [-1.313119  , -0.98834544, -0.1783103 ,  0.88390696,  0.12180699],\n",
       "        [-3.9577403 , -0.61197567, -0.07918966,  0.04764467, -0.20561747],\n",
       "        [ 0.345189  ,  0.26159862,  0.12791581,  0.27076417,  0.09014586],\n",
       "        [ 0.6441812 , -0.53684974, -4.9618025 , -0.26548967, -0.50958484]],\n",
       "       dtype=float32),\n",
       " array([-1.1258736 ,  3.0917513 , -1.1874661 ,  0.19185622, -2.706063  ],\n",
       "       dtype=float32),\n",
       " array([[ 3.834655  , -1.3020366 , -0.6857818 , 13.584686  , -0.5748337 ,\n",
       "          1.4964862 , 20.162653  , -0.32345614, -4.3567634 , 20.040857  ],\n",
       "        [-3.2767158 ,  0.7274077 ,  1.1485547 ,  1.0802006 ,  0.87847495,\n",
       "         -0.1519382 ,  0.199678  ,  1.5249951 ,  4.2322187 ,  0.03666813],\n",
       "        [ 0.8269084 , 26.03941   , -2.0812976 , -0.26940414, -0.04900074,\n",
       "          1.4969497 , -1.3719857 , -0.33731174,  0.7006002 ,  2.4536626 ],\n",
       "        [-2.075264  , -0.56781775, -0.6655047 ,  1.7298068 ,  0.71349394,\n",
       "          1.2354484 , -0.7452235 ,  2.275156  , -0.46301493,  1.9472277 ],\n",
       "        [-4.06707   , -1.7991422 , -2.219045  , -2.9268572 ,  2.2736044 ,\n",
       "          1.5867504 ,  1.4023879 , -3.8959613 ,  5.6627784 ,  3.3728938 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.3552213,  4.456573 ,  3.996991 ,  3.7538326, -2.5630205,\n",
       "        -3.1392968,  4.7350373, -1.0025432,  2.1200292,  1.5403599],\n",
       "       dtype=float32),\n",
       " array([[ 7.1955037],\n",
       "        [15.364633 ],\n",
       "        [12.153454 ],\n",
       "        [14.532493 ],\n",
       "        [14.04389  ],\n",
       "        [13.180105 ],\n",
       "        [13.9149065],\n",
       "        [14.27292  ],\n",
       "        [14.036821 ],\n",
       "        [14.4217825]], dtype=float32),\n",
       " array([13.732886], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_sigmoid(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sigmoid_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 225us/step - loss: 13242.7009 - val_loss: 10651.0083\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8908.9615 - val_loss: 7505.3239\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 6483.4409 - val_loss: 5635.2014\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 4941.2140 - val_loss: 4365.0943\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 3855.8018 - val_loss: 3439.0533\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 3049.7153 - val_loss: 2737.6503\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 2432.7522 - val_loss: 2194.3276\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 1951.5233 - val_loss: 1767.1473\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 1571.9501 - val_loss: 1426.5344\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 1269.3209 - val_loss: 1154.7908\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 1027.1873 - val_loss: 936.6169\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 832.4684 - val_loss: 761.1988\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 675.9574 - val_loss: 619.2099\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 549.6422 - val_loss: 504.8498\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 448.0603 - val_loss: 412.1942\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 366.0102 - val_loss: 338.0583\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 300.3137 - val_loss: 277.9280\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 247.3683 - val_loss: 229.8944\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 205.1017 - val_loss: 191.1584\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 171.1955 - val_loss: 160.4433\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 144.4017 - val_loss: 135.5293\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 122.9905 - val_loss: 115.9001\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 106.1760 - val_loss: 100.1635\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 92.8204 - val_loss: 88.0072\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 82.4569 - val_loss: 78.1898\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 74.2681 - val_loss: 70.5972\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 67.9351 - val_loss: 64.6441\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 62.9967 - val_loss: 60.0091\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 59.2076 - val_loss: 56.3665\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 56.2792 - val_loss: 53.5558\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 54.0611 - val_loss: 51.3156\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 52.3600 - val_loss: 49.5854\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 51.0468 - val_loss: 48.3517\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 50.1152 - val_loss: 47.3030\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 49.3685 - val_loss: 46.5337\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 48.8368 - val_loss: 45.9329\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 48.4223 - val_loss: 45.5034\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 48.1361 - val_loss: 45.1214\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 47.9189 - val_loss: 44.8367\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 47.7648 - val_loss: 44.6174\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.6496 - val_loss: 44.4861\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.5712 - val_loss: 44.3466\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 47.4999 - val_loss: 44.2727\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 47.4611 - val_loss: 44.1857\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 47.4290 - val_loss: 44.1449\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.4055 - val_loss: 44.0823\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.3901 - val_loss: 44.0570\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.3690 - val_loss: 44.0192\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 47.3558 - val_loss: 44.0008\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3477 - val_loss: 43.9847\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 47.3214 - val_loss: 43.9466\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.2747 - val_loss: 43.8829\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 47.1221 - val_loss: 43.6997\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 46.2928 - val_loss: 42.7676\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 42.8865 - val_loss: 37.6305\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 40.4428 - val_loss: 37.4707\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 38.8223 - val_loss: 36.6286\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 33.7170 - val_loss: 30.7757\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 28.8417 - val_loss: 27.2491\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 24.2370 - val_loss: 25.3184\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0729 - val_loss: 24.4299\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.8129 - val_loss: 24.3375\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.0190 - val_loss: 22.7535\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 19.4309 - val_loss: 22.2329\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.8006 - val_loss: 21.7686\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.3520 - val_loss: 21.4510\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.0496 - val_loss: 21.1246\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.5202 - val_loss: 20.5554\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.3183 - val_loss: 20.4448\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.9032 - val_loss: 20.6413\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.8273 - val_loss: 20.3208\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.5059 - val_loss: 20.2267\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.3597 - val_loss: 19.8368\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.2450 - val_loss: 19.8345\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.0408 - val_loss: 19.6773\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.8205 - val_loss: 19.3050\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.5873 - val_loss: 19.2498\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 15.4748 - val_loss: 19.2398\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.3024 - val_loss: 18.9894\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1675 - val_loss: 18.9187\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1282 - val_loss: 18.8129\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.0573 - val_loss: 18.7791\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9523 - val_loss: 18.7971\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9965 - val_loss: 18.6717\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9199 - val_loss: 18.5814\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7990 - val_loss: 18.4042\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8782 - val_loss: 18.4762\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9003 - val_loss: 18.5122\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7763 - val_loss: 18.4539\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.6805 - val_loss: 18.3398\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5978 - val_loss: 18.5560\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6781 - val_loss: 18.3672\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.6047 - val_loss: 18.6492\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.6402 - val_loss: 18.2435\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.5910 - val_loss: 18.3345\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.6816 - val_loss: 18.4102\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.5890 - val_loss: 18.3453\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4236 - val_loss: 18.2570\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4744 - val_loss: 18.3702\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3738 - val_loss: 18.2266\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3292 - val_loss: 18.2051\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3935 - val_loss: 18.0591\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.3391 - val_loss: 17.9395\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.2683 - val_loss: 18.1109\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.3215 - val_loss: 18.0561\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1624 - val_loss: 17.8671\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1949 - val_loss: 17.7799\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1456 - val_loss: 18.3216\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1392 - val_loss: 17.7967\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0681 - val_loss: 17.8168\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1357 - val_loss: 17.7506\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0246 - val_loss: 17.8594\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1138 - val_loss: 17.8681\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0899 - val_loss: 17.9747\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.0381 - val_loss: 17.9505\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9878 - val_loss: 17.8268\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9477 - val_loss: 17.8614\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9909 - val_loss: 17.6319\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9514 - val_loss: 18.1615\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.1395 - val_loss: 17.7069\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.2015 - val_loss: 17.8257\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0977 - val_loss: 17.6777\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9587 - val_loss: 17.7970\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9445 - val_loss: 17.9848\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 14.49 - 0s 86us/step - loss: 14.0178 - val_loss: 17.8606\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9247 - val_loss: 17.8491\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8618 - val_loss: 17.6411\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9347 - val_loss: 17.9583\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9672 - val_loss: 17.6586\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8990 - val_loss: 17.7756\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9414 - val_loss: 17.7378\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.9235 - val_loss: 17.6370\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8902 - val_loss: 17.8194\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8755 - val_loss: 17.5657\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9021 - val_loss: 17.7740\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9616 - val_loss: 17.9829\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9517 - val_loss: 17.7015\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8903 - val_loss: 17.7541\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9769 - val_loss: 17.6974\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8891 - val_loss: 17.7043\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9036 - val_loss: 17.7333\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9631 - val_loss: 17.7544\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9442 - val_loss: 17.5723\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.67 - 0s 86us/step - loss: 13.9449 - val_loss: 17.7304\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8804 - val_loss: 17.7415\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8339 - val_loss: 17.6910\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8659 - val_loss: 17.7338\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8638 - val_loss: 17.4931\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8689 - val_loss: 17.6841\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9079 - val_loss: 17.6756\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8539 - val_loss: 17.4838\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9419 - val_loss: 17.7697\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9561 - val_loss: 17.5366\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8630 - val_loss: 17.7622\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8583 - val_loss: 17.4971\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8820 - val_loss: 17.4752\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9738 - val_loss: 17.8646\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8674 - val_loss: 17.7706\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8351 - val_loss: 17.5633\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8219 - val_loss: 17.6857\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8245 - val_loss: 17.5360\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8105 - val_loss: 17.5858\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8018 - val_loss: 17.6404\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7846 - val_loss: 17.6736\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8236 - val_loss: 17.7522\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8541 - val_loss: 17.4536\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8475 - val_loss: 17.8220\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8117 - val_loss: 17.5496\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7711 - val_loss: 17.6433\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7695 - val_loss: 17.7099\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8476 - val_loss: 17.7273\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8059 - val_loss: 17.5619\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8077 - val_loss: 17.7452\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7976 - val_loss: 17.5506\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8243 - val_loss: 17.7598\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8975 - val_loss: 17.9550\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9543 - val_loss: 17.6672\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8001 - val_loss: 17.7184\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7793 - val_loss: 17.5199\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8272 - val_loss: 17.7166\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7822 - val_loss: 17.5123\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8042 - val_loss: 17.5175\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7975 - val_loss: 17.5292\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8147 - val_loss: 18.1454\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8605 - val_loss: 17.5921\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8376 - val_loss: 17.4522\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7699 - val_loss: 17.5495\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8210 - val_loss: 17.7900\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7802 - val_loss: 17.6753\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 13.7680 - val_loss: 17.4990\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.8420 - val_loss: 17.5618\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.8720 - val_loss: 17.5633\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 13.8142 - val_loss: 17.5974\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8223 - val_loss: 17.4010\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.8399 - val_loss: 17.4993\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8175 - val_loss: 17.7724\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 13.8383 - val_loss: 17.5092\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.8330 - val_loss: 17.6472\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.7788 - val_loss: 17.6214\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7790 - val_loss: 17.8493\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.7820 - val_loss: 17.4919\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.9680 - val_loss: 17.9378\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8011 - val_loss: 17.5853\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8198 - val_loss: 17.5084\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8059 - val_loss: 17.3752\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8699 - val_loss: 17.4680\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.9133 - val_loss: 17.5736\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7686 - val_loss: 17.6073\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7672 - val_loss: 17.6360\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7704 - val_loss: 17.5105\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7183 - val_loss: 17.5978\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7806 - val_loss: 17.4770\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7830 - val_loss: 17.3647\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7932 - val_loss: 17.4788\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7562 - val_loss: 17.4894\n",
      "Epoch 216/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7368 - val_loss: 17.3039\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7342 - val_loss: 17.3939\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8111 - val_loss: 17.6890\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8526 - val_loss: 17.4816\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7719 - val_loss: 17.4068\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8309 - val_loss: 17.7560\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8285 - val_loss: 17.3269\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7687 - val_loss: 17.5263\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7253 - val_loss: 17.5634\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8216 - val_loss: 17.2583\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7360 - val_loss: 17.6764\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6714 - val_loss: 17.5498\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7916 - val_loss: 17.4102\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7289 - val_loss: 17.3130\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7403 - val_loss: 17.4898\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7603 - val_loss: 17.6490\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7534 - val_loss: 17.4722\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8086 - val_loss: 17.4965\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8136 - val_loss: 17.7463\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7251 - val_loss: 17.5304\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7115 - val_loss: 17.3858\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6764 - val_loss: 17.5756\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7730 - val_loss: 17.5711\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8119 - val_loss: 17.3983\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8103 - val_loss: 17.6326\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8308 - val_loss: 17.2877\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7636 - val_loss: 17.4727\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7393 - val_loss: 17.3413\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8089 - val_loss: 17.2672\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6867 - val_loss: 17.8265\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7317 - val_loss: 17.3744\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7084 - val_loss: 17.5415\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8152 - val_loss: 17.5296\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6817 - val_loss: 17.6049\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7334 - val_loss: 17.4011\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.9364 - val_loss: 17.5263\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6991 - val_loss: 17.3749\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8262 - val_loss: 17.4916\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8604 - val_loss: 17.6641\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8400 - val_loss: 17.7878\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7432 - val_loss: 17.2877\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8451 - val_loss: 17.4741\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8334 - val_loss: 17.3249\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7470 - val_loss: 17.4061\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7388 - val_loss: 17.3123\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6948 - val_loss: 17.4263\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7516 - val_loss: 17.5426\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7774 - val_loss: 17.3576\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8216 - val_loss: 17.3686\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7646 - val_loss: 17.5107\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7382 - val_loss: 17.2987\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6875 - val_loss: 17.5994\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8114 - val_loss: 17.5361\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7995 - val_loss: 17.3971\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7201 - val_loss: 17.2763\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7238 - val_loss: 17.3988\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7672 - val_loss: 17.4979\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7750 - val_loss: 17.2259\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7302 - val_loss: 17.4457\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7595 - val_loss: 17.4933\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7021 - val_loss: 17.4665\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7940 - val_loss: 17.4436\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7732 - val_loss: 17.3086\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8108 - val_loss: 17.7062\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.7008 - val_loss: 17.3235\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7805 - val_loss: 17.1068\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7435 - val_loss: 17.4426\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6696 - val_loss: 17.3138\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7038 - val_loss: 17.5373\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7374 - val_loss: 17.4234\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7615 - val_loss: 17.3265\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7091 - val_loss: 17.3315\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7310 - val_loss: 17.2390\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6809 - val_loss: 17.4478\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7523 - val_loss: 17.3096\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6988 - val_loss: 17.1375\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7762 - val_loss: 17.3500\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7255 - val_loss: 17.7785\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7552 - val_loss: 17.7640\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.7890 - val_loss: 17.7236\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7921 - val_loss: 17.4363\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7185 - val_loss: 17.2844\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7058 - val_loss: 17.2859\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6975 - val_loss: 17.3725\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7543 - val_loss: 17.3696\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7579 - val_loss: 17.6417\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7955 - val_loss: 17.5350\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8372 - val_loss: 17.3908\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6912 - val_loss: 17.2985\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7408 - val_loss: 17.3364\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6741 - val_loss: 17.1938\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6826 - val_loss: 17.6693\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8900 - val_loss: 17.3338\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7576 - val_loss: 17.4925\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7460 - val_loss: 17.4208\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.8142 - val_loss: 17.2424\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7603 - val_loss: 17.2678\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.8320 - val_loss: 17.4103\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7885 - val_loss: 17.3693\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6598 - val_loss: 17.6065\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.9098 - val_loss: 17.2820\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7656 - val_loss: 17.2457\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8317 - val_loss: 17.6256\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8084 - val_loss: 17.3576\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7283 - val_loss: 17.3439\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7082 - val_loss: 17.6276\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7741 - val_loss: 17.5188\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7433 - val_loss: 17.4021\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6915 - val_loss: 17.2684\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8628 - val_loss: 17.4098\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7859 - val_loss: 17.5218\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7429 - val_loss: 17.2260\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6891 - val_loss: 17.2980\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6742 - val_loss: 17.3047\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7665 - val_loss: 17.2217\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7184 - val_loss: 17.3885\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7189 - val_loss: 17.3271\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6938 - val_loss: 17.3199\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7201 - val_loss: 17.4603\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7246 - val_loss: 17.2580\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7214 - val_loss: 17.4729\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8323 - val_loss: 17.5152\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6943 - val_loss: 17.4299\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8250 - val_loss: 17.3823\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6646 - val_loss: 17.3784\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7171 - val_loss: 17.2794\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7291 - val_loss: 17.0974\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.7145 - val_loss: 17.3458\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6885 - val_loss: 17.5480\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7742 - val_loss: 17.4433\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7665 - val_loss: 17.3070\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6839 - val_loss: 17.3018\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6240 - val_loss: 17.4567\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7197 - val_loss: 17.2954\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7766 - val_loss: 17.3286\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7222 - val_loss: 17.1404\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6487 - val_loss: 17.4044\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6830 - val_loss: 17.4846\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7849 - val_loss: 17.2059\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7408 - val_loss: 17.6596\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8248 - val_loss: 17.2023\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6372 - val_loss: 17.1437\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7684 - val_loss: 17.5101\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7811 - val_loss: 17.4110\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7190 - val_loss: 17.4207\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7219 - val_loss: 17.4716\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7263 - val_loss: 17.3609\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6986 - val_loss: 17.1966\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.6749 - val_loss: 17.1357\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.6899 - val_loss: 17.3838\n",
      "Epoch 366/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6407 - val_loss: 17.1049\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7893 - val_loss: 17.7323\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.8839 - val_loss: 17.2954\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8232 - val_loss: 17.1776\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8104 - val_loss: 17.2829\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.8087 - val_loss: 17.1862\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7127 - val_loss: 17.4427\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6972 - val_loss: 17.1721\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7367 - val_loss: 17.6210\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7111 - val_loss: 17.2184\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.8075 - val_loss: 17.3640\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7751 - val_loss: 17.2688\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7546 - val_loss: 17.5704\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6964 - val_loss: 17.1875\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6798 - val_loss: 17.3823\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7401 - val_loss: 17.3173\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7053 - val_loss: 17.2552\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6700 - val_loss: 17.2028\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7124 - val_loss: 17.3956\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7822 - val_loss: 17.3201\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6286 - val_loss: 17.2511\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7106 - val_loss: 17.3257\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7550 - val_loss: 17.3239\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7188 - val_loss: 17.5032\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7406 - val_loss: 17.1905\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7056 - val_loss: 17.0859\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6643 - val_loss: 17.1406\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7177 - val_loss: 17.4728\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6960 - val_loss: 17.1411\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6919 - val_loss: 17.0581\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7384 - val_loss: 17.0350\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6778 - val_loss: 17.4681\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7054 - val_loss: 17.1175\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7052 - val_loss: 17.3648\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7199 - val_loss: 17.0720\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.1284 - val_loss: 17.3550\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7598 - val_loss: 17.1015\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6689 - val_loss: 17.3303\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6780 - val_loss: 17.3059\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6972 - val_loss: 17.1210\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7900 - val_loss: 17.4121\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7234 - val_loss: 17.4015\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7600 - val_loss: 17.1980\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6998 - val_loss: 17.3549\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7025 - val_loss: 17.1595\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5751 - val_loss: 17.1634\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.7518 - val_loss: 16.9936\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6630 - val_loss: 17.1987\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6184 - val_loss: 17.1693\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5710 - val_loss: 17.0475\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7301 - val_loss: 17.1927\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6459 - val_loss: 17.0161\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6541 - val_loss: 17.1716\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6175 - val_loss: 17.1938\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8041 - val_loss: 17.1379\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.8301 - val_loss: 17.2920\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7719 - val_loss: 17.0420\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6858 - val_loss: 17.2982\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6719 - val_loss: 17.1231\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6354 - val_loss: 17.2345\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6332 - val_loss: 17.3754\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6181 - val_loss: 17.1296\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6491 - val_loss: 17.1449\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6217 - val_loss: 17.2164\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6975 - val_loss: 17.1628\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7129 - val_loss: 17.2140\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7706 - val_loss: 17.0833\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6807 - val_loss: 17.0320\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6870 - val_loss: 17.0849\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6065 - val_loss: 17.1676\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5842 - val_loss: 17.1177\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7060 - val_loss: 17.2894\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6723 - val_loss: 17.2028\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6523 - val_loss: 17.0466\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7236 - val_loss: 17.1436\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6542 - val_loss: 17.3398\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.7719 - val_loss: 17.2911\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6826 - val_loss: 17.1192\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6673 - val_loss: 17.1780\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7064 - val_loss: 17.0889\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7324 - val_loss: 17.0850\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7668 - val_loss: 17.0627\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6279 - val_loss: 17.1759\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7086 - val_loss: 17.1837\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6394 - val_loss: 17.2385\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7474 - val_loss: 17.0777\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7051 - val_loss: 17.0420\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7182 - val_loss: 17.2879\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7006 - val_loss: 17.1515\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6377 - val_loss: 17.0924\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6528 - val_loss: 17.0448\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.6408 - val_loss: 17.2173\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7089 - val_loss: 17.0053\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6865 - val_loss: 17.1768\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7085 - val_loss: 17.0770\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6004 - val_loss: 17.3364\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6592 - val_loss: 17.1903\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6423 - val_loss: 17.0079\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7517 - val_loss: 17.1260\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5923 - val_loss: 17.0073\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6062 - val_loss: 17.0287\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6902 - val_loss: 17.1946\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6691 - val_loss: 17.0356\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6567 - val_loss: 17.1669\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5876 - val_loss: 17.0507\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6488 - val_loss: 17.0850\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5960 - val_loss: 17.0699\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6611 - val_loss: 17.1627\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6510 - val_loss: 17.1440\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6703 - val_loss: 17.1958\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7462 - val_loss: 16.9945\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5939 - val_loss: 17.2086\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7388 - val_loss: 17.2421\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7899 - val_loss: 17.3674\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8520 - val_loss: 17.2631\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7268 - val_loss: 17.1892\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6459 - val_loss: 17.1586\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7306 - val_loss: 17.0710\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6850 - val_loss: 17.2522\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7267 - val_loss: 17.1329\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6672 - val_loss: 17.0008\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6030 - val_loss: 17.1232\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6520 - val_loss: 17.4553\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7461 - val_loss: 17.0840\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7116 - val_loss: 17.2652\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6601 - val_loss: 17.0574\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6586 - val_loss: 17.2510\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6137 - val_loss: 17.1807\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6916 - val_loss: 17.2171\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7058 - val_loss: 17.2367\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7251 - val_loss: 17.1131\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7135 - val_loss: 17.1087\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6071 - val_loss: 17.1421\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6556 - val_loss: 17.1664\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6058 - val_loss: 17.2425\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6322 - val_loss: 17.3055\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6495 - val_loss: 17.1070\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7017 - val_loss: 17.3754\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.8182 - val_loss: 17.1030\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6890 - val_loss: 17.2481\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6622 - val_loss: 17.1525\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6444 - val_loss: 17.0642\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.6172 - val_loss: 17.1801\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6579 - val_loss: 17.0478\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6590 - val_loss: 17.2338\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7044 - val_loss: 17.4331\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6672 - val_loss: 17.0992\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6828 - val_loss: 17.3230\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.9765 - val_loss: 17.2629\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6630 - val_loss: 17.1359\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6562 - val_loss: 17.2975\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7015 - val_loss: 17.2359\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5905 - val_loss: 17.0713\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6220 - val_loss: 17.1080\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6093 - val_loss: 17.0900\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5968 - val_loss: 17.2993\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6577 - val_loss: 17.0465\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6658 - val_loss: 17.1271\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6641 - val_loss: 17.3201\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6474 - val_loss: 17.1193\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6094 - val_loss: 17.0345\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6608 - val_loss: 17.0810\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5789 - val_loss: 17.0769\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7579 - val_loss: 17.1671\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6734 - val_loss: 17.0875\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6840 - val_loss: 17.2172\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7667 - val_loss: 17.3118\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6619 - val_loss: 17.3082\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7070 - val_loss: 17.1352\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7888 - val_loss: 17.1546\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5989 - val_loss: 17.0789\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6273 - val_loss: 17.0589\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.6163 - val_loss: 17.1353\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.7092 - val_loss: 17.2570\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.6084 - val_loss: 17.2885\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.6488 - val_loss: 17.1224\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6955 - val_loss: 17.0715\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6347 - val_loss: 17.3256\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 13.6933 - val_loss: 16.9708\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 13.7856 - val_loss: 17.1115\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.6788 - val_loss: 17.1979\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6685 - val_loss: 17.3103\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7056 - val_loss: 17.1522\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6769 - val_loss: 17.4298\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6795 - val_loss: 17.1389\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.5758 - val_loss: 17.2268\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6260 - val_loss: 17.1633\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6486 - val_loss: 17.1009\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6402 - val_loss: 17.0451\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7186 - val_loss: 17.0541\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.6898 - val_loss: 17.0972\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6568 - val_loss: 17.1968\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6779 - val_loss: 17.4364\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7884 - val_loss: 17.2672\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7612 - val_loss: 17.2903\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6546 - val_loss: 17.2262\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6538 - val_loss: 17.2524\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.7515 - val_loss: 17.4655\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6590 - val_loss: 17.2557\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6889 - val_loss: 17.3627\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.7733 - val_loss: 17.2359\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.7209 - val_loss: 17.3587\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6089 - val_loss: 17.3413\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6082 - val_loss: 17.0776\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5990 - val_loss: 17.2419\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6264 - val_loss: 17.1242\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6723 - val_loss: 17.1167\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6177 - val_loss: 17.1475\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6431 - val_loss: 17.1190\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6309 - val_loss: 17.1281\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5622 - val_loss: 17.3228\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.6371 - val_loss: 17.0805\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6419 - val_loss: 17.0931\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6352 - val_loss: 17.4399\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6340 - val_loss: 17.2295\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6152 - val_loss: 17.2567\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5739 - val_loss: 17.1204\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7456 - val_loss: 17.4982\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6723 - val_loss: 17.1076\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6215 - val_loss: 17.2460\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5902 - val_loss: 17.1397\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.5628 - val_loss: 17.2199\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5835 - val_loss: 17.0923\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6049 - val_loss: 17.1139\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5767 - val_loss: 17.1838\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5756 - val_loss: 17.1428\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5302 - val_loss: 17.0874\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5696 - val_loss: 17.0440\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5956 - val_loss: 17.1227\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7140 - val_loss: 17.2602\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7186 - val_loss: 17.2728\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6616 - val_loss: 17.2497\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.7018 - val_loss: 17.1981\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6659 - val_loss: 17.3216\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.7007 - val_loss: 17.1875\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6584 - val_loss: 17.1975\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6444 - val_loss: 17.2188\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6338 - val_loss: 16.9687\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5957 - val_loss: 17.0199\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6343 - val_loss: 17.2121\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5775 - val_loss: 17.1234\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6323 - val_loss: 17.0328\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6249 - val_loss: 17.1530\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5973 - val_loss: 16.9707\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6739 - val_loss: 17.3217\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5954 - val_loss: 16.9849\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 13.5454 - val_loss: 17.4215\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5403 - val_loss: 17.1431\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6372 - val_loss: 17.1500\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5885 - val_loss: 16.9995\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5252 - val_loss: 17.0136\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5415 - val_loss: 17.1721\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5297 - val_loss: 17.1627\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6834 - val_loss: 17.4698\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6104 - val_loss: 17.7217\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6608 - val_loss: 17.1218\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5412 - val_loss: 17.4030\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5544 - val_loss: 17.2042\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5823 - val_loss: 17.1875\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6481 - val_loss: 17.1795\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.6962 - val_loss: 17.0752\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.6604 - val_loss: 17.1318\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5619 - val_loss: 17.0398\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6610 - val_loss: 17.1201\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.6315 - val_loss: 17.2213\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.6755 - val_loss: 17.1353\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.6535 - val_loss: 17.1646\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5885 - val_loss: 17.0871\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6196 - val_loss: 17.2274\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.5105 - val_loss: 17.0239\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5326 - val_loss: 17.1584\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5833 - val_loss: 17.1379\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6031 - val_loss: 17.0363\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5359 - val_loss: 17.1852\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.5187 - val_loss: 17.2874\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.6274 - val_loss: 17.1336\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.5479 - val_loss: 17.2535\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.5357 - val_loss: 17.4874\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5254 - val_loss: 17.2987\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.5526 - val_loss: 17.0362\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5336 - val_loss: 17.0115\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8998 - val_loss: 15.0056\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4380 - val_loss: 15.0868\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2577 - val_loss: 15.0341\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.1385 - val_loss: 15.5335\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7472 - val_loss: 14.6680\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2896 - val_loss: 15.4811\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0527 - val_loss: 15.1966\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1592 - val_loss: 14.7678\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1788 - val_loss: 15.3681\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.8939 - val_loss: 14.6047\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.9253 - val_loss: 14.4860\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.1584 - val_loss: 14.9210\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9315 - val_loss: 14.5389\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.8442 - val_loss: 14.4168\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.8350 - val_loss: 14.5951\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.6571 - val_loss: 14.4032\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.8088 - val_loss: 14.6722\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.0868 - val_loss: 15.5346\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.0144 - val_loss: 14.5036\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5952 - val_loss: 14.6680\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5781 - val_loss: 14.4467\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0823 - val_loss: 14.3667\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.5113 - val_loss: 14.5603\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5440 - val_loss: 14.4833\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.5770 - val_loss: 14.1392\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.6858 - val_loss: 14.7808\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.9683 - val_loss: 15.1513\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.9366 - val_loss: 14.6728\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5457 - val_loss: 14.2769\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5774 - val_loss: 14.5273\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5353 - val_loss: 14.3875\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5687 - val_loss: 14.3716\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.5285 - val_loss: 14.8161\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6256 - val_loss: 13.9920\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4825 - val_loss: 14.1762\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4728 - val_loss: 14.8009\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.4601 - val_loss: 14.0428\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 10.59 - 0s 88us/step - loss: 10.5402 - val_loss: 14.0521\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3715 - val_loss: 14.1571\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3407 - val_loss: 13.9718\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.4645 - val_loss: 14.1814\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4756 - val_loss: 14.0729\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3375 - val_loss: 13.9633\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3222 - val_loss: 13.8784\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3296 - val_loss: 14.1214\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.3297 - val_loss: 14.4831\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5393 - val_loss: 13.8872\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2604 - val_loss: 13.9969\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2462 - val_loss: 13.9575\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4063 - val_loss: 13.9284\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5096 - val_loss: 13.7353\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2673 - val_loss: 13.8086\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2571 - val_loss: 13.7962\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3099 - val_loss: 13.6755\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.2441 - val_loss: 13.9319\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1832 - val_loss: 13.6953\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2684 - val_loss: 14.1584\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4969 - val_loss: 14.0264\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5711 - val_loss: 14.0623\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3050 - val_loss: 14.0250\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1839 - val_loss: 13.7543\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2436 - val_loss: 14.0469\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2304 - val_loss: 13.5308\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3003 - val_loss: 13.7903\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.2914 - val_loss: 13.7946\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.2061 - val_loss: 14.2978\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1274 - val_loss: 13.6027\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2157 - val_loss: 13.7583\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.1673 - val_loss: 13.6668\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.1946 - val_loss: 14.0336\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.2025 - val_loss: 13.5141\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.1080 - val_loss: 13.6571\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.1075 - val_loss: 13.7971\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2691 - val_loss: 14.0567\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0838 - val_loss: 13.6862\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3446 - val_loss: 14.0372\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5846 - val_loss: 14.0251\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3714 - val_loss: 13.9609\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1665 - val_loss: 13.8550\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7475 - val_loss: 13.4534\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7098 - val_loss: 13.9390\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1806 - val_loss: 13.6977\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1422 - val_loss: 13.7017\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0313 - val_loss: 13.4449\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1098 - val_loss: 14.5833\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3028 - val_loss: 13.4283\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0210 - val_loss: 13.9458\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1189 - val_loss: 13.4666\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 10.1632 - val_loss: 13.7703\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0477 - val_loss: 13.5540\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0317 - val_loss: 13.5002\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1118 - val_loss: 13.4844\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9901 - val_loss: 13.5905\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0759 - val_loss: 13.7308\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1398 - val_loss: 13.5722\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0199 - val_loss: 13.9148\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1828 - val_loss: 13.3773\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0450 - val_loss: 13.6996\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1426 - val_loss: 14.2949\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1260 - val_loss: 13.5365\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2490 - val_loss: 13.5863\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9893 - val_loss: 13.7287\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1513 - val_loss: 14.4897\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1290 - val_loss: 13.4691\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9570 - val_loss: 13.8582\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1004 - val_loss: 13.4668\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1158 - val_loss: 13.4201\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0333 - val_loss: 13.7489\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0377 - val_loss: 13.4176\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1273 - val_loss: 13.5357\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0474 - val_loss: 13.5214\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0291 - val_loss: 13.9026\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1573 - val_loss: 13.4222\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1518 - val_loss: 13.5573\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1116 - val_loss: 13.4997\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.2320 - val_loss: 13.6154\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0384 - val_loss: 13.8110\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0565 - val_loss: 13.9420\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0552 - val_loss: 13.5769\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.1861 - val_loss: 14.1768\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1515 - val_loss: 13.5604\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0330 - val_loss: 13.9212\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0360 - val_loss: 13.5881\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0726 - val_loss: 13.3088\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9916 - val_loss: 13.5060\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8868 - val_loss: 13.5195\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0307 - val_loss: 13.7384\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0745 - val_loss: 13.5155\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1264 - val_loss: 13.3695\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9978 - val_loss: 13.3140\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9961 - val_loss: 13.3996\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9771 - val_loss: 13.6050\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2874 - val_loss: 13.7960\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0695 - val_loss: 13.4283\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9980 - val_loss: 13.4918\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0366 - val_loss: 13.5223\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1213 - val_loss: 13.4955\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0800 - val_loss: 13.3321\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0378 - val_loss: 13.5430\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1259 - val_loss: 13.6518\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9449 - val_loss: 13.3951\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9765 - val_loss: 13.5019\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0023 - val_loss: 13.3222\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9128 - val_loss: 13.4224\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1369 - val_loss: 13.7658\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.5598 - val_loss: 13.9556\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0636 - val_loss: 13.7162\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0051 - val_loss: 13.7557\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3407 - val_loss: 13.5967\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2514 - val_loss: 13.8007\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0098 - val_loss: 13.7317\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9746 - val_loss: 13.2967\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9616 - val_loss: 13.6372\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9348 - val_loss: 13.5538\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9485 - val_loss: 13.6873\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0565 - val_loss: 13.8415\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1538 - val_loss: 13.2672\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9675 - val_loss: 13.3828\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9781 - val_loss: 13.7729\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1163 - val_loss: 13.5125\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0312 - val_loss: 13.7002\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9601 - val_loss: 13.4889\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9158 - val_loss: 13.8613\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0225 - val_loss: 13.5447\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9854 - val_loss: 13.4803\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0527 - val_loss: 13.8893\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1144 - val_loss: 13.5869\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9770 - val_loss: 13.7568\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9220 - val_loss: 13.9606\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9371 - val_loss: 13.6194\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9505 - val_loss: 13.3622\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8648 - val_loss: 13.4030\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9569 - val_loss: 13.5588\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0459 - val_loss: 13.9252\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0530 - val_loss: 13.7744\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0575 - val_loss: 13.6740\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9708 - val_loss: 13.5342\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9771 - val_loss: 13.3504\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 10.23 - 0s 87us/step - loss: 9.9567 - val_loss: 13.3151\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9346 - val_loss: 13.6063\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2638 - val_loss: 13.6673\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1096 - val_loss: 13.1922\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8736 - val_loss: 13.5683\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0511 - val_loss: 13.4536\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9370 - val_loss: 14.1895\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2140 - val_loss: 14.3776\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1501 - val_loss: 13.8932\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0510 - val_loss: 13.4426\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0174 - val_loss: 13.3484\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9655 - val_loss: 13.8546\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9160 - val_loss: 13.4459\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9150 - val_loss: 13.4481\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9053 - val_loss: 13.8111\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0145 - val_loss: 13.5140\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0653 - val_loss: 13.4618\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9441 - val_loss: 13.5081\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9144 - val_loss: 13.6295\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0606 - val_loss: 14.0680\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0254 - val_loss: 13.4062\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9098 - val_loss: 13.3597\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9897 - val_loss: 13.7645\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9180 - val_loss: 13.6731\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0491 - val_loss: 14.0141\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1322 - val_loss: 13.4574\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0126 - val_loss: 13.4500\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0112 - val_loss: 13.2828\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8635 - val_loss: 13.6078\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1284 - val_loss: 13.1516\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9855 - val_loss: 13.3722\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0144 - val_loss: 13.4597\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9927 - val_loss: 13.6424\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9437 - val_loss: 13.3034\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0517 - val_loss: 13.8693\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9885 - val_loss: 13.4469\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8922 - val_loss: 13.3365\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0632 - val_loss: 13.4518\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9605 - val_loss: 13.4588\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9833 - val_loss: 13.3956\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8776 - val_loss: 13.4914\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9682 - val_loss: 13.6577\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3773 - val_loss: 13.3620\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.4038 - val_loss: 14.1208\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0952 - val_loss: 13.3202\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9002 - val_loss: 13.4386\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0456 - val_loss: 13.2944\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9286 - val_loss: 13.4152\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9887 - val_loss: 13.3863\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0952 - val_loss: 13.2808\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0703 - val_loss: 13.3721\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0409 - val_loss: 13.3848\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9891 - val_loss: 13.2694\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0448 - val_loss: 13.4633\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9249 - val_loss: 13.5249\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0785 - val_loss: 13.3148\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2297 - val_loss: 13.5834\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1248 - val_loss: 13.5673\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9273 - val_loss: 13.1509\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.9724 - val_loss: 13.5903\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.9414 - val_loss: 13.6079\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.1099 - val_loss: 13.9115\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.8953 - val_loss: 13.3939\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.8957 - val_loss: 13.2685\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.8584 - val_loss: 13.1761\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.9656 - val_loss: 13.0980\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.0009 - val_loss: 13.4366\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.9747 - val_loss: 13.0771\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7694 - val_loss: 13.1757\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8259 - val_loss: 13.1958\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7588 - val_loss: 13.1423\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7942 - val_loss: 13.1407\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9577 - val_loss: 13.0753\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9017 - val_loss: 13.3153\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8317 - val_loss: 13.2800\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8827 - val_loss: 13.2472\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0847 - val_loss: 13.4717\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8005 - val_loss: 14.0909\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1551 - val_loss: 14.8487\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0178 - val_loss: 13.2774\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9549 - val_loss: 13.4493\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9007 - val_loss: 13.2242\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8726 - val_loss: 13.1623\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0448 - val_loss: 13.4273\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8203 - val_loss: 13.4059\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9060 - val_loss: 13.1695\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8379 - val_loss: 13.0873\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7914 - val_loss: 13.8677\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9726 - val_loss: 12.9600\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8515 - val_loss: 13.2877\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7465 - val_loss: 13.0071\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2752 - val_loss: 13.6134\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6386 - val_loss: 14.6706\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3774 - val_loss: 13.6018\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9372 - val_loss: 13.3963\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8623 - val_loss: 13.1207\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8137 - val_loss: 13.1621\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7919 - val_loss: 13.1776\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8857 - val_loss: 13.3223\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8013 - val_loss: 13.0691\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8321 - val_loss: 13.1551\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9149 - val_loss: 13.2126\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0024 - val_loss: 13.0250\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8342 - val_loss: 13.1239\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8333 - val_loss: 13.1753\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9429 - val_loss: 13.0945\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9050 - val_loss: 13.2637\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8017 - val_loss: 13.0223\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9104 - val_loss: 13.0141\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9436 - val_loss: 13.1079\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8945 - val_loss: 13.3203\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7708 - val_loss: 13.4327\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8862 - val_loss: 13.3420\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8214 - val_loss: 13.7809\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9952 - val_loss: 14.0245\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.8884 - 0s 86us/step - loss: 9.9009 - val_loss: 13.0065\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8446 - val_loss: 13.5834\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8760 - val_loss: 13.0132\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9040 - val_loss: 13.3450\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8323 - val_loss: 13.3767\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9390 - val_loss: 13.3896\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0031 - val_loss: 13.3277\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8431 - val_loss: 13.0634\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8112 - val_loss: 13.1947\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9006 - val_loss: 13.0008\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8066 - val_loss: 13.3343\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7767 - val_loss: 12.9780\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8575 - val_loss: 13.0853\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8259 - val_loss: 12.9727\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8932 - val_loss: 13.3517\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8228 - val_loss: 13.3599\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2047 - val_loss: 13.1414\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9996 - val_loss: 13.3407\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9457 - val_loss: 13.1918\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.0478 - val_loss: 13.2555\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0001 - val_loss: 13.0699\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8577 - val_loss: 13.3237\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0996 - val_loss: 13.2619\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0909 - val_loss: 13.2553\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8730 - val_loss: 12.9514\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7910 - val_loss: 13.7660\n",
      "Epoch 966/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9710 - val_loss: 13.1540\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7793 - val_loss: 13.0303\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7335 - val_loss: 13.1251\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7855 - val_loss: 13.6873\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8243 - val_loss: 13.8806\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9112 - val_loss: 13.0205\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.2940 - val_loss: 13.1962\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0319 - val_loss: 13.0805\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7902 - val_loss: 13.1093\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7634 - val_loss: 13.5116\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8776 - val_loss: 12.9710\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7741 - val_loss: 13.0617\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8558 - val_loss: 13.0702\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7605 - val_loss: 13.0462\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7699 - val_loss: 13.0231\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7774 - val_loss: 13.6195\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7924 - val_loss: 13.1114\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7836 - val_loss: 13.1641\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1306 - val_loss: 13.8028\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8530 - val_loss: 13.2818\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7976 - val_loss: 13.0685\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.9578 - val_loss: 12.9988\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7906 - val_loss: 13.2632\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0900 - val_loss: 13.1850\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7367 - val_loss: 13.0979\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7315 - val_loss: 13.2580\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7903 - val_loss: 13.3828\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8928 - val_loss: 13.0057\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9646 - val_loss: 13.4178\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1387 - val_loss: 13.0210\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7823 - val_loss: 13.0034\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7224 - val_loss: 13.1129\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8560 - val_loss: 13.2852\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.9127 - val_loss: 13.2615\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8812 - val_loss: 13.8345\n",
      "11.006013937756023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.811891  , -0.19100763, -1.6472718 , -5.6467724 , -0.6736696 ],\n",
       "        [-0.41259205, -0.84766024, -2.2492795 , -0.15298864, -2.644314  ],\n",
       "        [-0.50958574, -3.6086032 , -3.3061728 , -0.48678327, -0.98489153],\n",
       "        [ 0.48166114,  0.26646465,  0.5526344 ,  0.3458153 ,  0.34682986],\n",
       "        [-0.64954734,  0.3517098 ,  0.6753315 , -0.5994751 , -1.8011643 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.8413658 , -0.92573786, -1.5823224 , -1.6575754 ,  0.17513597],\n",
       "       dtype=float32),\n",
       " array([[  0.2698168 ,  -8.119445  ,  -0.50465095,  -1.2352878 ,\n",
       "           0.5043376 ,  -0.5035528 ,   0.50583005,  -3.7141747 ,\n",
       "          -0.5129782 ,  -0.505595  ],\n",
       "        [  0.3239123 ,  -0.1987677 ,  -0.10578597,   1.0514723 ,\n",
       "           0.10826877,  -0.10665236,   0.10535426,  -0.16914673,\n",
       "          -0.12313108,  -0.10528868],\n",
       "        [  2.0163848 , -13.313239  ,  -3.3376703 ,  -1.0247176 ,\n",
       "           3.1271975 ,  -3.15403   ,   3.4844866 , -12.846012  ,\n",
       "          -4.2315946 ,  -3.8812735 ],\n",
       "        [  0.65231174,   1.8952713 ,  -0.35488814,   2.2210557 ,\n",
       "           0.3597551 ,  -0.35803574,   0.35314742,   1.4944997 ,\n",
       "          -0.35136005,  -0.34867427],\n",
       "        [  0.17074965,  -0.33659706, -11.137866  , -18.476313  ,\n",
       "           8.641324  , -11.131095  ,   9.781434  ,  -0.37827638,\n",
       "         -17.010418  , -14.746731  ]], dtype=float32),\n",
       " array([-0.7916199, -1.2630374, -3.1823697, -3.7759378,  3.6410801,\n",
       "        -3.5044744,  3.7323492, -2.0247304, -1.2565414, -2.5702403],\n",
       "       dtype=float32),\n",
       " array([[ 10.296319],\n",
       "        [-11.895683],\n",
       "        [-12.597821],\n",
       "        [-10.394725],\n",
       "        [ 12.138254],\n",
       "        [-12.515832],\n",
       "        [ 12.249703],\n",
       "        [-11.839007],\n",
       "        [-12.639159],\n",
       "        [-12.261585]], dtype=float32),\n",
       " array([11.542388], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression_tanh(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_tanh_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 677us/step - loss: 500.3748 - val_loss: 268.7774\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 157.8863 - val_loss: 57.4476\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 48.4680 - val_loss: 26.1447\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 27.6027 - val_loss: 19.7741\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 21.3732 - val_loss: 18.3590\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.5507 - val_loss: 16.8400\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.6203 - val_loss: 16.5908\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 17.6634 - val_loss: 15.3776\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.7083 - val_loss: 14.3328\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.6503 - val_loss: 13.3256\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.1110 - val_loss: 13.0182\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 12.9771 - val_loss: 13.2686\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 12.0090 - val_loss: 13.2386\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.1047 - val_loss: 12.9058\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.6729 - val_loss: 12.4051\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.2334 - val_loss: 12.0592\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.5345 - val_loss: 11.7367\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.4323 - val_loss: 11.7588\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.2392 - val_loss: 11.4870\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1988 - val_loss: 11.1969\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.2874 - val_loss: 11.0997\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.4016 - val_loss: 10.7522\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.0722 - val_loss: 10.8374\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.8200 - val_loss: 10.7236\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6518 - val_loss: 10.4055\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.6792 - val_loss: 10.2930\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.7123 - val_loss: 10.2330\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7122 - val_loss: 10.1175\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.6713 - val_loss: 10.3521\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.5115 - val_loss: 10.0494\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.6676 - val_loss: 10.4737\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4450 - val_loss: 10.0751\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.6316 - val_loss: 9.8944\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.3653 - val_loss: 9.9646\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5090 - val_loss: 10.2854\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3618 - val_loss: 9.9952\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.3961 - val_loss: 10.2906\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2379 - val_loss: 10.2490\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.3181 - val_loss: 9.9866\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3970 - val_loss: 10.1354\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.2646 - val_loss: 10.1915\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1383 - val_loss: 10.1148\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0885 - val_loss: 9.9053\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 8.1474 - val_loss: 10.1461\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0982 - val_loss: 9.9464\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2663 - val_loss: 9.9326\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1608 - val_loss: 9.9861\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0799 - val_loss: 10.2572\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0159 - val_loss: 10.0778\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8536 - val_loss: 10.5591\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1013 - val_loss: 10.1763\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.0289 - val_loss: 9.9306\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9255 - val_loss: 10.2306\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0728 - val_loss: 10.2887\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.1071 - val_loss: 10.2835\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8341 - val_loss: 10.1699\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8558 - val_loss: 9.7211\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.9659 - val_loss: 10.5141\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.7576 - val_loss: 10.3013\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6557 - val_loss: 10.1477\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6969 - val_loss: 10.6009\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.5655 - val_loss: 10.1444\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5431 - val_loss: 10.3864\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5146 - val_loss: 10.2135\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5094 - val_loss: 10.4032\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.5023 - val_loss: 10.6686\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.4660 - val_loss: 10.3226\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6087 - val_loss: 10.7384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3265 - val_loss: 10.4808\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4876 - val_loss: 10.6102\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.4257 - val_loss: 10.7069\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3925 - val_loss: 10.5013\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6220 - val_loss: 11.2493\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3983 - val_loss: 10.5404\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3455 - val_loss: 10.2880\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5615 - val_loss: 11.2013\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4672 - val_loss: 10.9513\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4014 - val_loss: 10.7609\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3116 - val_loss: 10.8817\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.2690 - val_loss: 10.3353\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2624 - val_loss: 10.7556\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.1713 - val_loss: 10.6881\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2584 - val_loss: 10.7156\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2558 - val_loss: 10.3632\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4719 - val_loss: 10.4795\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2185 - val_loss: 10.3488\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1290 - val_loss: 10.7365\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2370 - val_loss: 10.5407\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2963 - val_loss: 10.4965\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5368 - val_loss: 10.3620\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.9317 - val_loss: 10.5659\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.6342 - val_loss: 10.5194\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4105 - val_loss: 10.5133\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3929 - val_loss: 10.5978\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5815 - val_loss: 10.3112\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0904 - val_loss: 10.5362\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1125 - val_loss: 10.3604\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1587 - val_loss: 10.1792\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1508 - val_loss: 10.0900\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2432 - val_loss: 10.2221\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2561 - val_loss: 10.2456\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3643 - val_loss: 10.1659\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8587 - val_loss: 10.1103\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4284 - val_loss: 10.1769\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6613 - val_loss: 9.9175\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.9543 - val_loss: 10.2493\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.8063 - val_loss: 10.0793\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.8080 - val_loss: 10.1166\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2019 - val_loss: 10.1041\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0781 - val_loss: 9.8568\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1003 - val_loss: 10.1430\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0947 - val_loss: 10.3586\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2235 - val_loss: 9.9208\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1597 - val_loss: 10.3942\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1077 - val_loss: 9.7348\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1075 - val_loss: 10.0180\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1672 - val_loss: 10.0861\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0379 - val_loss: 10.1118\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0819 - val_loss: 10.1933\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2016 - val_loss: 10.1097\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1129 - val_loss: 9.9420\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9847 - val_loss: 9.7408\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0538 - val_loss: 9.7749\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1385 - val_loss: 9.7298\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0743 - val_loss: 9.9980\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0187 - val_loss: 9.7554\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1516 - val_loss: 10.0325\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6293 - val_loss: 9.5467\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5986 - val_loss: 10.1163\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1758 - val_loss: 9.9180\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0664 - val_loss: 9.8868\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2806 - val_loss: 9.4832\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4607 - val_loss: 10.2471\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0030 - val_loss: 9.4772\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0700 - val_loss: 9.8741\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9097 - val_loss: 9.5290\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9258 - val_loss: 9.6499\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8304 - val_loss: 9.6337\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4075 - val_loss: 9.4605\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9463 - val_loss: 9.4406\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1412 - val_loss: 9.5464\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8087 - val_loss: 9.5406\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7835 - val_loss: 9.6188\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9388 - val_loss: 9.8478\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9226 - val_loss: 9.4767\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8573 - val_loss: 9.8553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7004 - val_loss: 9.6421\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8200 - val_loss: 9.2582\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8051 - val_loss: 9.4428\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7561 - val_loss: 9.1250\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6069 - val_loss: 9.3001\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.6678 - val_loss: 9.4046\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.6114 - val_loss: 9.6004\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5973 - val_loss: 9.3076\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7311 - val_loss: 9.2276\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6851 - val_loss: 9.2675\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5621 - val_loss: 8.9051\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0394 - val_loss: 9.4897\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7649 - val_loss: 8.9412\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6461 - val_loss: 9.0412\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4729 - val_loss: 9.0286\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5761 - val_loss: 8.9049\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4711 - val_loss: 9.1568\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4326 - val_loss: 8.6678\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4306 - val_loss: 8.8757\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5512 - val_loss: 8.8656\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5741 - val_loss: 8.9434\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7239 - val_loss: 8.8582\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6361 - val_loss: 8.9346\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.5544 - val_loss: 8.6095\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3553 - val_loss: 8.8208\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3320 - val_loss: 8.6699\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2878 - val_loss: 8.6082\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3496 - val_loss: 8.9239\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3618 - val_loss: 8.5917\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3501 - val_loss: 8.8520\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3304 - val_loss: 8.6026\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2983 - val_loss: 8.7388\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2780 - val_loss: 8.5251\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1918 - val_loss: 8.5341\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1418 - val_loss: 8.5798\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.2286 - val_loss: 8.4285\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1404 - val_loss: 8.6398\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1432 - val_loss: 8.4496\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.2057 - val_loss: 8.4623\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.1894 - val_loss: 8.5757\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.3251 - val_loss: 8.3318\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.1271 - val_loss: 8.5678\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1844 - val_loss: 8.5146\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2687 - val_loss: 8.5576\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1938 - val_loss: 8.4641\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0489 - val_loss: 8.2512\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0696 - val_loss: 8.1903\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1032 - val_loss: 8.1723\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1116 - val_loss: 8.1506\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.1508 - val_loss: 8.0932\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0351 - val_loss: 8.1788\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1959 - val_loss: 8.3103\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2020 - val_loss: 8.1821\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1504 - val_loss: 7.9478\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1574 - val_loss: 7.9522\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0687 - val_loss: 8.3180\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0067 - val_loss: 8.0512\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0840 - val_loss: 8.0605\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.0437 - val_loss: 8.2339\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0668 - val_loss: 8.2445\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0985 - val_loss: 8.1698\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9852 - val_loss: 8.0649\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0856 - val_loss: 8.0520\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0760 - val_loss: 7.8737\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0771 - val_loss: 8.2633\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2247 - val_loss: 8.0956\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1728 - val_loss: 8.4078\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2891 - val_loss: 8.0057\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1107 - val_loss: 7.8701\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.0684 - val_loss: 8.1543\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9996 - val_loss: 8.1533\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0435 - val_loss: 8.1328\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0132 - val_loss: 8.0743\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8872 - val_loss: 7.9898\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9935 - val_loss: 8.0805\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9907 - val_loss: 8.1377\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9786 - val_loss: 7.9567\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9420 - val_loss: 8.1505\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9496 - val_loss: 8.2383\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9375 - val_loss: 8.2905\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1059 - val_loss: 7.9700\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0771 - val_loss: 8.0404\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0527 - val_loss: 8.1273\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9396 - val_loss: 8.1635\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1304 - val_loss: 8.2082\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9388 - val_loss: 8.0098\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8807 - val_loss: 8.0475\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0479 - val_loss: 7.8129\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2348 - val_loss: 8.0803\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1939 - val_loss: 8.4643\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9833 - val_loss: 7.8896\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9119 - val_loss: 7.8854\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0469 - val_loss: 8.0573\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9782 - val_loss: 7.8369\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8963 - val_loss: 8.0777\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8936 - val_loss: 8.3020\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9941 - val_loss: 8.0073\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9181 - val_loss: 7.9935\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8926 - val_loss: 8.1439\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9791 - val_loss: 7.7615\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9262 - val_loss: 8.0113\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0340 - val_loss: 8.2588\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4583 - val_loss: 8.0037\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1044 - val_loss: 8.4804\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0975 - val_loss: 8.1881\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.0140 - val_loss: 7.9782\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1351 - val_loss: 7.8544\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9245 - val_loss: 7.8251\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0435 - val_loss: 8.0920\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1250 - val_loss: 8.3658\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0662 - val_loss: 8.1238\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1331 - val_loss: 7.9177\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.1131 - val_loss: 8.2362\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9409 - val_loss: 7.9786\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9206 - val_loss: 8.3035\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8066 - val_loss: 8.1482\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9911 - val_loss: 7.7802\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9687 - val_loss: 8.0812\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8765 - val_loss: 8.0168\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8671 - val_loss: 8.0360\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0408 - val_loss: 8.0614\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9891 - val_loss: 8.0226\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9956 - val_loss: 8.0796\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9768 - val_loss: 7.8494\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8251 - val_loss: 8.0009\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9146 - val_loss: 8.1195\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0136 - val_loss: 8.1005\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8508 - val_loss: 7.9854\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0435 - val_loss: 7.7389\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1174 - val_loss: 8.0707\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2362 - val_loss: 8.3378\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1390 - val_loss: 7.9189\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1197 - val_loss: 8.3313\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9921 - val_loss: 8.1092\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.0986 - val_loss: 8.1719\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9183 - val_loss: 8.0980\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8758 - val_loss: 8.0831\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9107 - val_loss: 8.3070\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9278 - val_loss: 7.8613\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8785 - val_loss: 7.8137\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0295 - val_loss: 8.0984\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4174 - val_loss: 8.1512\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0339 - val_loss: 8.0278\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7982 - val_loss: 8.3542\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9058 - val_loss: 8.0908\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8999 - val_loss: 8.3516\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9500 - val_loss: 7.9775\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9810 - val_loss: 8.1933\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8360 - val_loss: 8.1216\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9071 - val_loss: 8.1847\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9894 - val_loss: 8.0581\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9115 - val_loss: 7.9386\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9892 - val_loss: 8.1481\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0834 - val_loss: 8.1948\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1190 - val_loss: 7.9771\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.8239 - val_loss: 7.9511\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0023 - val_loss: 8.0015\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0749 - val_loss: 7.9737\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8826 - val_loss: 8.0127\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8868 - val_loss: 8.1738\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1207 - val_loss: 8.2501\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7645 - val_loss: 7.9898\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7442 - val_loss: 7.9011\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8123 - val_loss: 8.0376\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8371 - val_loss: 8.0777\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8047 - val_loss: 8.1454\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7408 - val_loss: 8.1123\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8955 - val_loss: 7.9736\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.9225 - val_loss: 7.9255\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7768 - val_loss: 8.0801\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8937 - val_loss: 8.3578\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7617 - val_loss: 8.1026\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8679 - val_loss: 7.9816\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7618 - val_loss: 7.9807\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8323 - val_loss: 8.1502\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7457 - val_loss: 8.2542\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0689 - val_loss: 8.1528\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0596 - val_loss: 8.3096\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9664 - val_loss: 8.0878\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3638 - val_loss: 7.9468\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8091 - val_loss: 8.3618\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7671 - val_loss: 8.4333\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0312 - val_loss: 8.2082\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8673 - val_loss: 7.9310\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8365 - val_loss: 8.0870\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7825 - val_loss: 7.8543\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9970 - val_loss: 8.0467\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7697 - val_loss: 8.0462\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8367 - val_loss: 8.2127\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8191 - val_loss: 7.8949\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8178 - val_loss: 7.9508\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7050 - val_loss: 8.3460\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7760 - val_loss: 8.3164\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7386 - val_loss: 8.0750\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8595 - val_loss: 8.1889\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7709 - val_loss: 8.4590\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8854 - val_loss: 8.0997\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9027 - val_loss: 8.0718\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8220 - val_loss: 7.9581\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9656 - val_loss: 8.2975\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8119 - val_loss: 8.0381\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8011 - val_loss: 8.0879\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7990 - val_loss: 8.1209\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6963 - val_loss: 8.0638\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7030 - val_loss: 8.1462\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7784 - val_loss: 8.0730\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0951 - val_loss: 8.2481\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2005 - val_loss: 7.9560\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1913 - val_loss: 8.4024\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8522 - val_loss: 8.1359\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7496 - val_loss: 8.2302\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6854 - val_loss: 8.0272\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7378 - val_loss: 7.8394\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7247 - val_loss: 8.1030\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7673 - val_loss: 8.3680\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6814 - val_loss: 8.0268\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7992 - val_loss: 7.8854\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1318 - val_loss: 7.9806\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8798 - val_loss: 8.2189\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7485 - val_loss: 8.1241\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8924 - val_loss: 8.3744\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9041 - val_loss: 8.0374\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7226 - val_loss: 8.0161\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7911 - val_loss: 8.2200\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7658 - val_loss: 8.4664\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9073 - val_loss: 8.0766\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7745 - val_loss: 8.0969\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8301 - val_loss: 8.2743\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7759 - val_loss: 7.9029\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7498 - val_loss: 8.1557\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9058 - val_loss: 7.9959\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8726 - val_loss: 8.3156\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9825 - val_loss: 7.8753\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 5.8485 - val_loss: 8.2804\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7421 - val_loss: 8.1520\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7691 - val_loss: 8.3245\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8811 - val_loss: 8.1204\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6923 - val_loss: 8.0271\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8077 - val_loss: 8.2159\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7908 - val_loss: 7.8246\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8611 - val_loss: 8.1937\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.7096 - val_loss: 8.0939\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7243 - val_loss: 8.1556\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7931 - val_loss: 8.0862\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7998 - val_loss: 8.0537\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7561 - val_loss: 8.0763\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7473 - val_loss: 8.1240\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7545 - val_loss: 8.2519\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7585 - val_loss: 8.3750\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7362 - val_loss: 8.2292\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8460 - val_loss: 8.2815\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8667 - val_loss: 7.9717\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8442 - val_loss: 7.8835\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8743 - val_loss: 8.2758\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7312 - val_loss: 8.2074\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6120 - val_loss: 8.1949\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6927 - val_loss: 8.1914\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7750 - val_loss: 8.2183\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8090 - val_loss: 7.9141\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6757 - val_loss: 8.0955\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7901 - val_loss: 8.0726\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7121 - val_loss: 8.2704\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7392 - val_loss: 8.4078\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8224 - val_loss: 8.2100\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8564 - val_loss: 7.9003\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8854 - val_loss: 8.1236\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9428 - val_loss: 8.3660\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8802 - val_loss: 8.2202\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7982 - val_loss: 8.5444\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8103 - val_loss: 8.0427\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7150 - val_loss: 8.3273\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8105 - val_loss: 8.2607\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7370 - val_loss: 8.1475\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7204 - val_loss: 8.1497\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7304 - val_loss: 8.0508\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6841 - val_loss: 8.2524\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6247 - val_loss: 8.3208\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7337 - val_loss: 8.2164\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7093 - val_loss: 8.1545\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8520 - val_loss: 8.3712\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7032 - val_loss: 8.1842\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7579 - val_loss: 8.1665\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9672 - val_loss: 8.7004\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9513 - val_loss: 8.0600\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7095 - val_loss: 8.4443\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0132 - val_loss: 8.4296\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8918 - val_loss: 7.9783\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4722 - val_loss: 8.2232\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7954 - val_loss: 8.1425\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0134 - val_loss: 8.3286\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6458 - val_loss: 8.2445\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7780 - val_loss: 8.3275\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7398 - val_loss: 8.2990\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8918 - val_loss: 8.3468\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0150 - val_loss: 8.3613\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1204 - val_loss: 8.9518\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1951 - val_loss: 8.2391\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6657 - val_loss: 8.4852\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7382 - val_loss: 8.1175\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6766 - val_loss: 8.4071\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6294 - val_loss: 8.0712\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7363 - val_loss: 8.2822\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6313 - val_loss: 8.4267\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7429 - val_loss: 8.2551\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6812 - val_loss: 8.2527\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6083 - val_loss: 8.1472\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7295 - val_loss: 8.3774\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6607 - val_loss: 8.2088\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9466 - val_loss: 8.2264\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0404 - val_loss: 8.2257\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6587 - val_loss: 8.3495\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.6367 - val_loss: 8.0841\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7932 - val_loss: 8.3841\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7995 - val_loss: 8.0489\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.7361 - val_loss: 8.2274\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6943 - val_loss: 8.1220\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6558 - val_loss: 8.0042\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6476 - val_loss: 8.1640\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6167 - val_loss: 8.2067\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7331 - val_loss: 8.2516\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6078 - val_loss: 8.3921\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7801 - val_loss: 8.0433\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6501 - val_loss: 8.0252\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7614 - val_loss: 7.8428\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7576 - val_loss: 8.5118\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6958 - val_loss: 8.1937\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7424 - val_loss: 8.3246\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6890 - val_loss: 8.3035\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7649 - val_loss: 8.3460\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7378 - val_loss: 8.2489\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8556 - val_loss: 8.3516\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7091 - val_loss: 8.2196\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.7922 - val_loss: 8.0903\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6097 - val_loss: 8.1053\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6899 - val_loss: 8.0886\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6393 - val_loss: 7.9101\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6493 - val_loss: 8.1395\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7203 - val_loss: 8.2218\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7724 - val_loss: 8.0616\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7397 - val_loss: 8.1628\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7739 - val_loss: 8.1892\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6599 - val_loss: 8.1083\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7629 - val_loss: 8.3070\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6124 - val_loss: 8.5153\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7872 - val_loss: 8.2910\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7959 - val_loss: 7.8243\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6701 - val_loss: 8.3170\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8318 - val_loss: 8.3701\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9805 - val_loss: 8.4527\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6753 - val_loss: 8.1421\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5833 - val_loss: 8.7624\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7552 - val_loss: 8.1677\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7200 - val_loss: 8.2611\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7641 - val_loss: 8.1809\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7579 - val_loss: 8.3659\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8219 - val_loss: 8.1246\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7269 - val_loss: 8.2184\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6970 - val_loss: 8.1768\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6771 - val_loss: 8.2600\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5762 - val_loss: 8.1985\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5743 - val_loss: 8.0050\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6561 - val_loss: 8.0761\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6943 - val_loss: 8.0750\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6289 - val_loss: 8.0663\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6904 - val_loss: 8.4135\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7908 - val_loss: 8.2471\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7946 - val_loss: 8.3463\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7019 - val_loss: 8.0289\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5929 - val_loss: 7.8214\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7616 - val_loss: 8.0317\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6266 - val_loss: 8.1605\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6898 - val_loss: 8.3908\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8982 - val_loss: 8.1626\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8277 - val_loss: 7.9370\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7971 - val_loss: 8.2469\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7917 - val_loss: 8.5540\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9694 - val_loss: 8.5412\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1751 - val_loss: 8.7994\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0715 - val_loss: 8.3464\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9229 - val_loss: 8.0421\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6033 - val_loss: 8.2887\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5753 - val_loss: 7.9873\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7716 - val_loss: 8.1897\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9175 - val_loss: 8.1528\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8811 - val_loss: 8.2018\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6588 - val_loss: 8.1874\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5811 - val_loss: 8.2912\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6959 - val_loss: 8.1036\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6013 - val_loss: 8.0875\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 94us/step - loss: 5.6704 - val_loss: 8.0971\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6203 - val_loss: 8.1821\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5923 - val_loss: 8.2821\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.6542 - val_loss: 8.1074\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6225 - val_loss: 8.3059\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5839 - val_loss: 8.2589\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5894 - val_loss: 7.9492\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5607 - val_loss: 7.9531\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5973 - val_loss: 8.1435\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9029 - val_loss: 8.2238\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7062 - val_loss: 7.9612\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6060 - val_loss: 8.3231\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6510 - val_loss: 8.3510\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5859 - val_loss: 8.1749\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5530 - val_loss: 8.1201\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5754 - val_loss: 8.1663\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6768 - val_loss: 8.2277\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9330 - val_loss: 8.2933\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7444 - val_loss: 8.3362\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6148 - val_loss: 8.1765\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6466 - val_loss: 8.1929\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5922 - val_loss: 8.1914\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6829 - val_loss: 8.4129\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6261 - val_loss: 8.0552\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5906 - val_loss: 8.4615\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7340 - val_loss: 8.0742\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7713 - val_loss: 8.0203\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6554 - val_loss: 8.4939\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6060 - val_loss: 8.3594\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5438 - val_loss: 8.2140\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5757 - val_loss: 8.2064\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5416 - val_loss: 8.2271\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5363 - val_loss: 8.1566\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5858 - val_loss: 8.3593\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8100 - val_loss: 8.0513\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7427 - val_loss: 8.4700\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6921 - val_loss: 8.1454\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3392 - val_loss: 8.5147\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0382 - val_loss: 8.0644\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6943 - val_loss: 8.2299\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5623 - val_loss: 8.1925\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6836 - val_loss: 8.4314\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6010 - val_loss: 8.0569\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6059 - val_loss: 8.5064\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6138 - val_loss: 8.2632\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6734 - val_loss: 8.2071\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5764 - val_loss: 8.2192\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5392 - val_loss: 8.1908\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5558 - val_loss: 7.9270\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7806 - val_loss: 8.1429\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8440 - val_loss: 8.1326\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4666 - val_loss: 8.4677\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6571 - val_loss: 8.0833\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5742 - val_loss: 8.3173\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5770 - val_loss: 8.0365\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5195 - val_loss: 8.3120\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6668 - val_loss: 8.0396\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4985 - val_loss: 8.3232\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6851 - val_loss: 8.0397\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6381 - val_loss: 8.1331\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9343 - val_loss: 8.6705\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8622 - val_loss: 8.0549\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6502 - val_loss: 8.1326\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7232 - val_loss: 8.0494\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5650 - val_loss: 8.3029\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8006 - val_loss: 8.0372\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7524 - val_loss: 8.2189\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9674 - val_loss: 8.2743\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5963 - val_loss: 8.1368\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6115 - val_loss: 8.3475\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5584 - val_loss: 8.2711\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5082 - val_loss: 8.1499\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5654 - val_loss: 8.2450\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6022 - val_loss: 7.9927\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5873 - val_loss: 8.3305\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5213 - val_loss: 8.1547\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5865 - val_loss: 8.1398\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9029 - val_loss: 8.0019\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 97us/step - loss: 5.7435 - val_loss: 8.2027\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5891 - val_loss: 7.9939\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.7489 - val_loss: 8.1678\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5398 - val_loss: 7.9363\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5749 - val_loss: 8.2479\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6031 - val_loss: 8.1472\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7183 - val_loss: 8.4736\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0452 - val_loss: 7.9330\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1817 - val_loss: 8.4373\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6191 - val_loss: 8.3715\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8240 - val_loss: 8.4013\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5458 - val_loss: 8.4343\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.7168 - val_loss: 8.1047\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6991 - val_loss: 8.5840\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5619 - val_loss: 8.0445\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.5285 - val_loss: 8.1502\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5551 - val_loss: 8.1512\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8216 - val_loss: 8.1287\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.5102 - val_loss: 8.1194\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4823 - val_loss: 8.0380\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6657 - val_loss: 8.0909\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6639 - val_loss: 8.0762\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7381 - val_loss: 8.1301\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7433 - val_loss: 8.4053\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5887 - val_loss: 8.1331\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6983 - val_loss: 8.2038\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6490 - val_loss: 7.9377\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4973 - val_loss: 7.9838\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4929 - val_loss: 7.9667\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4396 - val_loss: 8.2815\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4546 - val_loss: 8.1803\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5302 - val_loss: 8.0543\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6709 - val_loss: 7.9311\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4665 - val_loss: 8.2799\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5389 - val_loss: 8.1676\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5520 - val_loss: 8.1531\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5126 - val_loss: 7.8036\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4543 - val_loss: 8.0847\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4912 - val_loss: 8.0444\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4483 - val_loss: 7.8895\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5222 - val_loss: 7.9188\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6274 - val_loss: 8.2904\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7222 - val_loss: 8.3589\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7731 - val_loss: 7.8784\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5653 - val_loss: 8.1107\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6551 - val_loss: 7.8925\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6674 - val_loss: 8.3294\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.7649 - val_loss: 8.2040\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5805 - val_loss: 8.1569\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4800 - val_loss: 7.9629\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7833 - val_loss: 8.1787\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7192 - val_loss: 8.5494\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6136 - val_loss: 7.9986\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5149 - val_loss: 8.0935\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4761 - val_loss: 7.9759\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4591 - val_loss: 8.0738\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5768 - val_loss: 8.1635\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5293 - val_loss: 8.2940\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5467 - val_loss: 8.1717\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5441 - val_loss: 8.1008\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4728 - val_loss: 7.7220\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5153 - val_loss: 8.0892\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4195 - val_loss: 7.9304\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6280 - val_loss: 7.8890\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3939 - val_loss: 8.0404\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3888 - val_loss: 7.9579\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5092 - val_loss: 7.8256\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5143 - val_loss: 7.8550\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5736 - val_loss: 8.0188\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5826 - val_loss: 8.3976\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4924 - val_loss: 7.8592\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5199 - val_loss: 8.0121\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4052 - val_loss: 8.3940\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4748 - val_loss: 8.3290\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4810 - val_loss: 8.0058\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5422 - val_loss: 8.0524\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6671 - val_loss: 7.9446\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8022 - val_loss: 7.8063\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 5.9548 - val_loss: 7.7016\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8814 - val_loss: 8.2666\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6934 - val_loss: 8.0411\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6075 - val_loss: 8.4650\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5145 - val_loss: 8.2352\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4342 - val_loss: 8.1087\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6026 - val_loss: 7.9366\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9231 - val_loss: 7.9239\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6774 - val_loss: 8.0615\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5207 - val_loss: 8.2139\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6222 - val_loss: 7.8082\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6297 - val_loss: 8.2034\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5145 - val_loss: 8.2815\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7986 - val_loss: 7.6978\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6641 - val_loss: 8.2768\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5332 - val_loss: 8.0007\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5627 - val_loss: 7.8234\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5781 - val_loss: 8.1545\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4621 - val_loss: 8.0632\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5586 - val_loss: 8.0296\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4750 - val_loss: 8.2129\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3848 - val_loss: 8.0224\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5374 - val_loss: 7.8556\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6009 - val_loss: 8.2272\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4714 - val_loss: 7.9889\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4584 - val_loss: 8.0213\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5379 - val_loss: 8.2045\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5328 - val_loss: 7.9257\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6033 - val_loss: 8.0166\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4712 - val_loss: 8.1243\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4635 - val_loss: 8.0283\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7605 - val_loss: 8.0873\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4892 - val_loss: 8.2693\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4261 - val_loss: 7.9114\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3972 - val_loss: 7.9761\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4054 - val_loss: 8.0320\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4758 - val_loss: 8.3931\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7578 - val_loss: 7.8628\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5911 - val_loss: 8.2902\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6696 - val_loss: 8.0105\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6103 - val_loss: 8.0897\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4921 - val_loss: 8.1325\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4242 - val_loss: 8.3546\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4254 - val_loss: 8.0799\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5260 - val_loss: 7.8217\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7246 - val_loss: 7.7162\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4932 - val_loss: 8.2414\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4814 - val_loss: 8.0134\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4875 - val_loss: 8.0611\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3938 - val_loss: 8.1599\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3335 - val_loss: 7.9054\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3701 - val_loss: 8.1741\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3982 - val_loss: 7.9540\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3601 - val_loss: 7.9756\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5482 - val_loss: 8.0729\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4892 - val_loss: 7.9613\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4190 - val_loss: 7.9742\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4323 - val_loss: 7.8853\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3678 - val_loss: 7.9365\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4598 - val_loss: 8.0455\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4570 - val_loss: 8.2989\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3921 - val_loss: 7.9890\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6526 - val_loss: 7.8158\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9872 - val_loss: 8.1891\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2658 - val_loss: 8.0421\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.8153 - val_loss: 7.9433\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6768 - val_loss: 8.0971\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7767 - val_loss: 8.4508\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4155 - val_loss: 7.9455\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3885 - val_loss: 8.0664\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4682 - val_loss: 7.8714\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5745 - val_loss: 7.9607\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7953 - val_loss: 8.1251\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8340 - val_loss: 8.0908\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6453 - val_loss: 7.8083\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5002 - val_loss: 8.1707\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5435 - val_loss: 8.2224\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5593 - val_loss: 7.7483\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 106us/step - loss: 5.4253 - val_loss: 8.0429\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5524 - val_loss: 7.8949\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4284 - val_loss: 8.1670\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4031 - val_loss: 7.9040\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3824 - val_loss: 8.5230\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4391 - val_loss: 7.9832\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3654 - val_loss: 7.9788\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4501 - val_loss: 8.0171\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4540 - val_loss: 8.1888\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4621 - val_loss: 8.0717\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3815 - val_loss: 8.1198\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5110 - val_loss: 7.9517\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3025 - val_loss: 7.7972\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.3509 - val_loss: 7.9938\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5096 - val_loss: 8.3282\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3530 - val_loss: 7.8842\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5036 - val_loss: 8.2149\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5681 - val_loss: 7.9295\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.13 - 0s 98us/step - loss: 5.5852 - val_loss: 8.2220\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4940 - val_loss: 8.2034\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4663 - val_loss: 8.0429\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7159 - val_loss: 8.2150\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6510 - val_loss: 7.8634\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4323 - val_loss: 7.8868\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4147 - val_loss: 7.9812\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4568 - val_loss: 7.8213\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3744 - val_loss: 8.0047\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4773 - val_loss: 8.1568\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3781 - val_loss: 7.9241\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5915 - val_loss: 8.1063\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7318 - val_loss: 7.9351\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7320 - val_loss: 8.0514\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7006 - val_loss: 8.2023\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3695 - val_loss: 7.9018\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3127 - val_loss: 7.8914\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3146 - val_loss: 7.9929\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3609 - val_loss: 8.2038\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4088 - val_loss: 8.0515\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3617 - val_loss: 8.1181\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4426 - val_loss: 8.0511\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.772 - 0s 91us/step - loss: 5.3775 - val_loss: 8.2038\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5989 - val_loss: 7.9669\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4273 - val_loss: 8.3721\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3607 - val_loss: 7.9954\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4379 - val_loss: 8.0026\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4309 - val_loss: 8.2953\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5058 - val_loss: 7.9987\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4476 - val_loss: 8.1025\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3899 - val_loss: 7.8256\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3590 - val_loss: 7.9364\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2844 - val_loss: 8.3535\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4181 - val_loss: 8.1284\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5549 - val_loss: 8.0397\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6688 - val_loss: 8.2362\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3056 - val_loss: 8.1475\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8782 - val_loss: 7.9470\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4092 - val_loss: 8.3229\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4588 - val_loss: 8.2755\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4020 - val_loss: 7.8288\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3734 - val_loss: 7.8246\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4389 - val_loss: 8.3066\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5731 - val_loss: 8.0189\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7246 - val_loss: 8.2395\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6136 - val_loss: 7.8829\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3476 - val_loss: 7.9742\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4009 - val_loss: 7.8288\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6087 - val_loss: 8.0986\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6939 - val_loss: 7.9882\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4284 - val_loss: 8.0178\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5203 - val_loss: 7.9430\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5082 - val_loss: 8.2011\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2764 - val_loss: 8.0919\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3322 - val_loss: 7.9705\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4922 - val_loss: 7.9178\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3694 - val_loss: 8.0692\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4382 - val_loss: 8.0132\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2995 - val_loss: 7.9201\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.4394 - val_loss: 7.9433\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4079 - val_loss: 7.8961\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3427 - val_loss: 8.2727\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4458 - val_loss: 7.9121\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4045 - val_loss: 8.1542\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3052 - val_loss: 7.9957\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3240 - val_loss: 8.1683\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3420 - val_loss: 8.0013\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4104 - val_loss: 7.8981\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3549 - val_loss: 7.9708\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3021 - val_loss: 7.8571\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4084 - val_loss: 8.1164\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4005 - val_loss: 7.9947\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7174 - val_loss: 8.4643\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8784 - val_loss: 8.0365\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5944 - val_loss: 8.1044\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2367 - val_loss: 8.1455\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3662 - val_loss: 8.0465\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4524 - val_loss: 7.9376\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3426 - val_loss: 8.1291\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3445 - val_loss: 8.0453\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3525 - val_loss: 8.3818\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3639 - val_loss: 7.9157\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4928 - val_loss: 7.9893\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3715 - val_loss: 8.0591\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3652 - val_loss: 8.2319\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4362 - val_loss: 8.2399\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2467 - val_loss: 8.0204\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3403 - val_loss: 7.9582\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3714 - val_loss: 8.3391\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3301 - val_loss: 8.2764\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3031 - val_loss: 7.9990\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2545 - val_loss: 8.1631\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2853 - val_loss: 8.0256\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2957 - val_loss: 7.9535\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3773 - val_loss: 8.0874\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3395 - val_loss: 8.0544\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3888 - val_loss: 8.1347\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5672 - val_loss: 8.2227\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3336 - val_loss: 7.9990\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3441 - val_loss: 8.0161\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3202 - val_loss: 8.2901\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3031 - val_loss: 8.0754\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3089 - val_loss: 8.0242\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3907 - val_loss: 8.0665\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4179 - val_loss: 8.2575\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3013 - val_loss: 8.0852\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3111 - val_loss: 8.0881\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3109 - val_loss: 8.6166\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4344 - val_loss: 8.0937\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2879 - val_loss: 8.3518\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4826 - val_loss: 8.4609\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3447 - val_loss: 8.3005\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3755 - val_loss: 7.9693\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3671 - val_loss: 8.0317\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3032 - val_loss: 8.2133\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2724 - val_loss: 8.1784\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4975 - val_loss: 8.3079\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3520 - val_loss: 8.4214\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.4147 - val_loss: 8.2152\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3377 - val_loss: 7.9907\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3381 - val_loss: 8.1747\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4480 - val_loss: 8.0542\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.4780 - val_loss: 7.9354\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4679 - val_loss: 8.2284\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3321 - val_loss: 8.3220\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4854 - val_loss: 8.3122\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2955 - val_loss: 8.1920\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3083 - val_loss: 8.0209\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3346 - val_loss: 8.0771\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3920 - val_loss: 8.2330\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2889 - val_loss: 8.2282\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3260 - val_loss: 8.0727\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3796 - val_loss: 7.9331\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3125 - val_loss: 8.1250\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2589 - val_loss: 8.1094\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3116 - val_loss: 7.9739\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3141 - val_loss: 8.3221\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.3375 - val_loss: 8.1133\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3745 - val_loss: 8.2611\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3554 - val_loss: 7.9725\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3389 - val_loss: 8.2663\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2623 - val_loss: 8.0282\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3346 - val_loss: 8.2373\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2387 - val_loss: 8.2644\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3138 - val_loss: 8.2242\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3254 - val_loss: 8.1903\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3100 - val_loss: 8.0650\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2990 - val_loss: 8.1723\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4127 - val_loss: 7.9618\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2994 - val_loss: 8.0647\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4145 - val_loss: 8.3663\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3575 - val_loss: 7.9413\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3605 - val_loss: 8.3357\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3833 - val_loss: 8.0856\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2651 - val_loss: 8.2698\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.3020 - val_loss: 7.9990\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3741 - val_loss: 7.9179\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3124 - val_loss: 8.1929\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4204 - val_loss: 8.1490\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4624 - val_loss: 8.1908\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3312 - val_loss: 8.1432\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2568 - val_loss: 7.8849\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2856 - val_loss: 7.9350\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2189 - val_loss: 7.9461\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2807 - val_loss: 8.2019\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3585 - val_loss: 8.0951\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5181 - val_loss: 8.2336\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3281 - val_loss: 8.1060\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4268 - val_loss: 7.9211\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3853 - val_loss: 8.2742\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5306 - val_loss: 8.2399\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4855 - val_loss: 8.3623\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6750 - val_loss: 8.1825\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3748 - val_loss: 8.2308\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2234 - val_loss: 8.2770\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4083 - val_loss: 8.0027\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0718 - val_loss: 8.0108\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3981 - val_loss: 8.1686\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3206 - val_loss: 8.5593\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4860 - val_loss: 7.9369\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5188 - val_loss: 8.1939\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.4286 - val_loss: 8.0065\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3696 - val_loss: 8.0749\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3462 - val_loss: 8.0653\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4290 - val_loss: 8.3329\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4496 - val_loss: 7.8140\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3383 - val_loss: 8.1432\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3936 - val_loss: 8.1312\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4465 - val_loss: 8.4969\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3504 - val_loss: 8.0057\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3329 - val_loss: 8.4532\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5456 - val_loss: 8.2552\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4544 - val_loss: 8.2922\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2340 - val_loss: 8.3933\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3884 - val_loss: 8.6352\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2134 - val_loss: 8.2550\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2763 - val_loss: 8.4656\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3374 - val_loss: 8.1650\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4594 - val_loss: 8.0416\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2896 - val_loss: 8.2526\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3241 - val_loss: 7.8827\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4512 - val_loss: 8.4648\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2774 - val_loss: 8.0878\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2755 - val_loss: 8.2685\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1880 - val_loss: 7.7798\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2804 - val_loss: 8.2429\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3482 - val_loss: 8.1132\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.961 - 0s 98us/step - loss: 5.2747 - val_loss: 8.2728\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4693 - val_loss: 7.8848\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5279 - val_loss: 8.2095\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2652 - val_loss: 7.8669\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3635 - val_loss: 8.4380\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4185 - val_loss: 8.0752\n",
      "7.022216707973157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 7.8396505e-01, -7.0646778e-02, -3.6483979e+00,  7.7198374e-01,\n",
       "         -4.1958174e-01],\n",
       "        [ 8.6152369e-01, -2.1799493e+00,  7.2000825e-01, -2.7529651e-01,\n",
       "          2.5904194e-01],\n",
       "        [ 1.2116531e+00, -5.9480852e-01, -6.4959057e-02, -2.0551500e-01,\n",
       "          4.6306905e-01],\n",
       "        [-2.9359292e-03,  1.9477630e+00,  2.6826727e-01, -9.4536908e-02,\n",
       "          4.0557703e-01],\n",
       "        [ 4.6087334e-01, -1.3469018e+00,  4.7335518e-03,  3.8572592e-01,\n",
       "         -1.3947444e-01],\n",
       "        [ 4.5578077e-01, -1.3517122e+00, -1.7410306e+00, -5.8969748e-01,\n",
       "          2.1967623e-01],\n",
       "        [-1.5459347e-01, -1.5943466e+00,  4.5279264e-01, -1.3606008e+00,\n",
       "          9.2665529e-01]], dtype=float32),\n",
       " array([ 1.221022  ,  2.0641363 , -1.9928219 , -0.9194853 , -0.04051967],\n",
       "       dtype=float32),\n",
       " array([[-0.45565432,  0.7982162 ,  0.62819386,  0.45449808, -0.42913687,\n",
       "         -0.2766273 ,  0.23487231, -0.42321536,  0.90295565, -0.21211888],\n",
       "        [ 0.13471723,  0.08703529,  0.078076  ,  0.42094532, -0.887983  ,\n",
       "         -0.27711377,  0.8798402 ,  0.22808848,  0.9333757 , -0.50119585],\n",
       "        [ 0.35130522,  0.6615928 ,  0.47701156,  0.5041984 , -0.2007953 ,\n",
       "         -0.6400208 ,  0.13648508, -0.23961595,  0.38091654,  0.0120385 ],\n",
       "        [-0.9668311 , -0.20819904,  0.7794625 ,  0.49790478, -0.23962113,\n",
       "         -0.32421646,  0.47282362,  0.20055583,  0.8063382 , -0.27518317],\n",
       "        [-0.40610486,  0.20376198,  0.06964159,  0.69463354, -0.97654414,\n",
       "          0.09366069,  0.1161743 , -0.13141336,  0.87195   , -0.80494237]],\n",
       "       dtype=float32),\n",
       " array([ 1.7720957, -1.8736813, -1.8711358, -1.871927 ,  1.8871622,\n",
       "         1.8565781, -1.8716406,  1.8529902, -1.863223 ,  1.8237479],\n",
       "       dtype=float32),\n",
       " array([[ 1.2251536],\n",
       "        [-1.1251214],\n",
       "        [-1.1740503],\n",
       "        [-1.1777627],\n",
       "        [ 1.0405722],\n",
       "        [ 1.286631 ],\n",
       "        [-0.9687831],\n",
       "        [ 1.0624756],\n",
       "        [-1.5450519],\n",
       "        [ 1.3828154]], dtype=float32),\n",
       " array([1.8189834], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_linear(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_linear_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 779us/step - loss: 471.5712 - val_loss: 233.6012\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 135.7744 - val_loss: 47.4547\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 50.5506 - val_loss: 36.1821\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 28.7248 - val_loss: 24.0332\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 19.5426 - val_loss: 20.1412\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.5581 - val_loss: 14.1720\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 14.7343 - val_loss: 15.3239\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.9328 - val_loss: 11.9221\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.5162 - val_loss: 12.0462\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 12.4379 - val_loss: 10.9795\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.5860 - val_loss: 11.0999\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.2357 - val_loss: 10.7059\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.1548 - val_loss: 10.9299\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.7654 - val_loss: 10.4559\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 10.9393 - val_loss: 9.7064\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.9588 - val_loss: 10.1727\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.9802 - val_loss: 9.2679\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.0633 - val_loss: 9.3413\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.4776 - val_loss: 9.2239\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1582 - val_loss: 8.3306\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.3347 - val_loss: 8.8581\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.0604 - val_loss: 8.2640\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 9.4642 - val_loss: 8.5452\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0978 - val_loss: 8.0125\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1079 - val_loss: 8.8971\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.3691 - val_loss: 7.8886\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.7600 - val_loss: 8.7526\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.4955 - val_loss: 7.8425\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4915 - val_loss: 8.1852\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4072 - val_loss: 8.1522\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4731 - val_loss: 7.8432\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 8.4564 - val_loss: 8.1008\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4282 - val_loss: 7.7879\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.4153 - val_loss: 8.3624\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.5951 - val_loss: 7.7350\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2688 - val_loss: 8.0820\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.3010 - val_loss: 7.5944\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2263 - val_loss: 7.9676\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9669 - val_loss: 7.5832\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.9723 - val_loss: 8.0342\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1511 - val_loss: 7.6376\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9667 - val_loss: 7.5928\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4298 - val_loss: 7.6179\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9439 - val_loss: 7.6378\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7797 - val_loss: 8.1367\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.9427 - val_loss: 7.8428\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1109 - val_loss: 7.9260\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8530 - val_loss: 7.7654\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.6918 - val_loss: 8.0473\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7662 - val_loss: 7.8253\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.0622 - val_loss: 7.4838\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7476 - val_loss: 7.7377\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6610 - val_loss: 7.5447\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.6830 - val_loss: 7.7095\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7464 - val_loss: 7.6303\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6271 - val_loss: 7.4709\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.7606 - val_loss: 7.7446\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8337 - val_loss: 7.5861\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6025 - val_loss: 7.5192\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.6656 - val_loss: 7.4218\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.5578 - val_loss: 7.3418\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8340 - val_loss: 7.7285\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1955 - val_loss: 7.3321\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7439 - val_loss: 7.6546\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6275 - val_loss: 7.3752\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5984 - val_loss: 7.9877\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5144 - val_loss: 7.3210\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5165 - val_loss: 7.5847\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 7.7289 - val_loss: 7.4726\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.5250 - val_loss: 7.4570\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4565 - val_loss: 7.3459\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.4927 - val_loss: 7.5216\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5104 - val_loss: 7.4210\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.4894 - val_loss: 7.5914\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5342 - val_loss: 7.3427\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6487 - val_loss: 7.7003\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.5411 - val_loss: 7.7040\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4096 - val_loss: 7.2555\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.6281 - val_loss: 7.3429\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.6973 - val_loss: 7.5217\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3566 - val_loss: 7.5783\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.6657 - val_loss: 7.0227\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3391 - val_loss: 7.8345\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4939 - val_loss: 7.1600\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3831 - val_loss: 7.3909\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5145 - val_loss: 7.1969\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.6927 - val_loss: 7.7056\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4808 - val_loss: 7.4155\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4555 - val_loss: 7.3339\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4487 - val_loss: 7.4535\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7318 - val_loss: 7.6124\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6461 - val_loss: 7.4988\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3984 - val_loss: 7.2656\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3571 - val_loss: 7.5318\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.8510 - val_loss: 7.5365\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6744 - val_loss: 7.2570\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5251 - val_loss: 7.4592\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5373 - val_loss: 7.6764\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3931 - val_loss: 7.3585\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3043 - val_loss: 7.7505\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4263 - val_loss: 7.4053\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4972 - val_loss: 7.3309\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2586 - val_loss: 7.4323\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2807 - val_loss: 7.5182\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.2893 - val_loss: 7.3051\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2624 - val_loss: 7.1911\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1664 - val_loss: 7.9806\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3288 - val_loss: 7.0903\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2417 - val_loss: 7.5932\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4182 - val_loss: 7.1558\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.2904 - val_loss: 7.3903\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4128 - val_loss: 7.3320\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5444 - val_loss: 7.5785\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1867 - val_loss: 7.3900\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2020 - val_loss: 7.3211\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1975 - val_loss: 7.3826\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1380 - val_loss: 7.3685\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5309 - val_loss: 7.3859\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7097 - val_loss: 7.4715\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.4080 - val_loss: 7.6768\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3541 - val_loss: 7.1788\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1110 - val_loss: 8.2656\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.1266 - val_loss: 7.0629\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2649 - val_loss: 7.6019\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1356 - val_loss: 7.1599\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2086 - val_loss: 8.1786\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4095 - val_loss: 7.2063\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3198 - val_loss: 7.7398\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4588 - val_loss: 7.1532\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0967 - val_loss: 7.5086\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3294 - val_loss: 7.0899\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3525 - val_loss: 7.4988\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1032 - val_loss: 7.4575\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1458 - val_loss: 7.4604\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1016 - val_loss: 7.5022\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1632 - val_loss: 7.1539\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1900 - val_loss: 7.3978\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0466 - val_loss: 7.1194\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2199 - val_loss: 7.2681\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1678 - val_loss: 7.3931\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0521 - val_loss: 7.1878\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2254 - val_loss: 7.3939\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0416 - val_loss: 7.6165\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1451 - val_loss: 7.1782\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0977 - val_loss: 7.7427\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2276 - val_loss: 7.0360\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 7.0733 - val_loss: 7.5459\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1566 - val_loss: 7.0594\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1099 - val_loss: 7.5337\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0254 - val_loss: 7.2354\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1179 - val_loss: 7.4951\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0975 - val_loss: 7.1750\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0575 - val_loss: 7.4833\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1912 - val_loss: 7.2507\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0844 - val_loss: 7.5532\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0769 - val_loss: 7.1475\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1744 - val_loss: 7.2464\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1020 - val_loss: 7.4809\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3237 - val_loss: 7.2513\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0989 - val_loss: 7.1181\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1085 - val_loss: 7.3311\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0231 - val_loss: 7.6597\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2032 - val_loss: 7.2630\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0443 - val_loss: 7.3210\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0350 - val_loss: 7.4114\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9941 - val_loss: 7.1585\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0817 - val_loss: 7.5594\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9723 - val_loss: 7.0480\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1769 - val_loss: 7.6493\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0316 - val_loss: 7.3214\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9946 - val_loss: 7.2065\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9841 - val_loss: 7.5473\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.0161 - val_loss: 7.1225\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1419 - val_loss: 7.6117\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2025 - val_loss: 7.0146\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0867 - val_loss: 7.2282\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0483 - val_loss: 7.5280\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0373 - val_loss: 7.4015\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0594 - val_loss: 7.3644\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0565 - val_loss: 7.3226\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9726 - val_loss: 7.1815\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0118 - val_loss: 7.2980\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1796 - val_loss: 7.8269\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4550 - val_loss: 7.0184\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.8684 - val_loss: 8.0747\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.7915 - val_loss: 7.1056\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.0509 - val_loss: 7.8532\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.6652 - val_loss: 7.1077\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.7833 - val_loss: 8.4946\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5685 - val_loss: 7.1459\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3158 - val_loss: 7.4503\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2946 - val_loss: 7.1434\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2646 - val_loss: 7.3542\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0981 - val_loss: 7.8061\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1961 - val_loss: 7.1294\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.6103 - val_loss: 7.9694\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2920 - val_loss: 7.1296\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.3264 - val_loss: 7.6193\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1620 - val_loss: 7.4862\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0858 - val_loss: 7.1972\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.9345 - val_loss: 7.5352\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9351 - val_loss: 7.2315\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9812 - val_loss: 7.4165\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1568 - val_loss: 8.0729\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2594 - val_loss: 7.0185\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0507 - val_loss: 7.4231\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9391 - val_loss: 7.2417\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9618 - val_loss: 7.2513\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9699 - val_loss: 7.3609\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9759 - val_loss: 7.1458\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9892 - val_loss: 7.4741\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5922 - val_loss: 7.8173\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7649 - val_loss: 7.1733\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1093 - val_loss: 7.2578\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9502 - val_loss: 7.3909\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0140 - val_loss: 7.1107\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9488 - val_loss: 7.4090\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0811 - val_loss: 7.3920\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2189 - val_loss: 7.4771\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.3226 - val_loss: 7.3257\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.0274 - val_loss: 7.1626\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0817 - val_loss: 7.3209\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.0074 - val_loss: 7.2522\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.1196 - val_loss: 7.4611\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 124us/step - loss: 6.9448 - val_loss: 7.3076\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.9915 - val_loss: 7.2321\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9970 - val_loss: 7.3864\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9701 - val_loss: 7.4030\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9052 - val_loss: 7.3262\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9896 - val_loss: 7.3772\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2363 - val_loss: 7.2101\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5209 - val_loss: 7.4105\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.0792 - val_loss: 7.0580\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8887 - val_loss: 7.5221\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0512 - val_loss: 7.1344\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9099 - val_loss: 7.9194\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0775 - val_loss: 7.3663\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1298 - val_loss: 7.2654\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4089 - val_loss: 7.8544\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1419 - val_loss: 7.2226\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0105 - val_loss: 7.5216\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1417 - val_loss: 7.3525\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 6.8354 - val_loss: 7.5374\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8646 - val_loss: 7.2845\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1191 - val_loss: 7.9478\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0355 - val_loss: 7.5105\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7764 - val_loss: 7.5663\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9185 - val_loss: 7.0394\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8467 - val_loss: 7.4663\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8442 - val_loss: 7.1557\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8882 - val_loss: 8.2474\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.4819 - val_loss: 7.2670\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3930 - val_loss: 7.7744\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8114 - val_loss: 7.4274\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9964 - val_loss: 7.3974\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8294 - val_loss: 7.3291\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.0494 - val_loss: 7.4099\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0165 - val_loss: 7.6933\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8116 - val_loss: 7.3507\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8455 - val_loss: 7.6163\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9939 - val_loss: 7.2718\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7828 - val_loss: 8.0804\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8131 - val_loss: 7.3085\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8870 - val_loss: 7.8735\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9332 - val_loss: 7.2454\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8271 - val_loss: 7.7062\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9735 - val_loss: 7.3296\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8391 - val_loss: 7.3118\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9086 - val_loss: 7.4880\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8123 - val_loss: 7.7488\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6849 - val_loss: 7.4242\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0688 - val_loss: 7.9769\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7941 - val_loss: 7.4219\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7594 - val_loss: 7.4127\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.8121 - val_loss: 7.5797\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9377 - val_loss: 7.7702\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7312 - val_loss: 7.4747\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8279 - val_loss: 7.8004\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0088 - val_loss: 7.3285\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7373 - val_loss: 7.6882\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7364 - val_loss: 7.4937\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8008 - val_loss: 7.7622\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8347 - val_loss: 7.5573\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9935 - val_loss: 8.1515\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7489 - val_loss: 7.2986\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7173 - val_loss: 7.5835\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6653 - val_loss: 7.4797\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7136 - val_loss: 7.6237\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8763 - val_loss: 7.6437\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1560 - val_loss: 8.0885\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8474 - val_loss: 7.4454\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7454 - val_loss: 7.8203\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6660 - val_loss: 7.4848\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0551 - val_loss: 8.3520\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7793 - val_loss: 7.3817\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6509 - val_loss: 7.6876\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6776 - val_loss: 7.4978\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6329 - val_loss: 7.6894\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5976 - val_loss: 7.5093\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7226 - val_loss: 7.4702\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 7.0274 - val_loss: 7.4423\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9367 - val_loss: 7.7311\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 7.0644 - val_loss: 7.7176\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.8115 - val_loss: 7.6890\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6507 - val_loss: 7.5323\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6594 - val_loss: 7.6966\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8389 - val_loss: 8.4441\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7888 - val_loss: 7.4679\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8783 - val_loss: 8.1251\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7158 - val_loss: 7.5895\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7358 - val_loss: 7.4856\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6757 - val_loss: 7.7046\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7149 - val_loss: 7.4510\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7809 - val_loss: 7.5946\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8774 - val_loss: 7.9802\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7560 - val_loss: 7.7182\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7155 - val_loss: 7.4906\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.8231 - val_loss: 7.9834\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7796 - val_loss: 7.9486\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6563 - val_loss: 7.5520\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.5543 - val_loss: 7.9919\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7193 - val_loss: 7.3918\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8222 - val_loss: 7.6807\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.8470 - val_loss: 7.6562\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8114 - val_loss: 7.7178\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5905 - val_loss: 7.4786\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 8.802 - 0s 109us/step - loss: 6.6380 - val_loss: 7.9521\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.260 - 0s 120us/step - loss: 6.6091 - val_loss: 7.5116\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6650 - val_loss: 7.6051\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6061 - val_loss: 7.9954\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.6496 - val_loss: 7.8874\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5434 - val_loss: 7.4869\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.126 - 0s 109us/step - loss: 6.5870 - val_loss: 7.5777\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6894 - val_loss: 8.1569\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.7165 - val_loss: 7.4561\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8004 - val_loss: 7.4482\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.0894 - val_loss: 8.6422\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7057 - val_loss: 7.7650\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7912 - val_loss: 8.1986\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9851 - val_loss: 7.8980\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7148 - val_loss: 7.5960\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6072 - val_loss: 7.6436\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5330 - val_loss: 7.6271\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7776 - val_loss: 8.0359\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7901 - val_loss: 7.7544\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5968 - val_loss: 7.5850\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7781 - val_loss: 8.2106\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6208 - val_loss: 7.5471\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6422 - val_loss: 7.7561\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8020 - val_loss: 7.4392\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5910 - val_loss: 7.6032\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.8084 - val_loss: 8.3317\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.7567 - val_loss: 7.5480\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7768 - val_loss: 7.4180\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7121 - val_loss: 7.6501\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6327 - val_loss: 7.7937\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9633 - val_loss: 7.5613\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5199 - val_loss: 7.9873\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7038 - val_loss: 8.0104\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7648 - val_loss: 7.5812\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5638 - val_loss: 7.6939\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5431 - val_loss: 7.6249\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6659 - val_loss: 7.6701\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8539 - val_loss: 7.7220\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.1941 - val_loss: 8.7480\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8036 - val_loss: 7.5650\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0684 - val_loss: 7.9795\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9726 - val_loss: 7.8118\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5669 - val_loss: 7.7742\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5085 - val_loss: 7.6416\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5526 - val_loss: 7.6697\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4745 - val_loss: 7.6191\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5643 - val_loss: 7.5409\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5600 - val_loss: 7.6617\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.5788 - val_loss: 7.8038\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5707 - val_loss: 7.7738\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4866 - val_loss: 7.8490\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6204 - val_loss: 7.5908\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5351 - val_loss: 8.1922\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 6.5059 - val_loss: 7.4184\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6116 - val_loss: 7.8293\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7021 - val_loss: 7.5891\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7333 - val_loss: 7.9251\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9260 - val_loss: 8.3364\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7819 - val_loss: 7.6755\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5286 - val_loss: 7.8451\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7542 - val_loss: 7.6247\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5250 - val_loss: 8.3800\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7129 - val_loss: 7.8137\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5872 - val_loss: 7.9987\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6959 - val_loss: 8.2445\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6153 - val_loss: 7.5484\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.5753 - val_loss: 8.0114\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5706 - val_loss: 7.4369\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.0023 - val_loss: 8.0816\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4736 - val_loss: 7.4787\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6456 - val_loss: 8.1563\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6570 - val_loss: 7.5292\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4285 - val_loss: 8.2925\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5136 - val_loss: 7.3626\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6928 - val_loss: 7.9056\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4954 - val_loss: 7.5894\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6276 - val_loss: 7.7690\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8109 - val_loss: 8.1689\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5968 - val_loss: 7.7153\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4742 - val_loss: 8.0640\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6188 - val_loss: 7.4635\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6299 - val_loss: 7.9707\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6844 - val_loss: 8.0081\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6528 - val_loss: 7.6408\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5814 - val_loss: 7.8357\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5246 - val_loss: 7.6999\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5782 - val_loss: 8.0264\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5203 - val_loss: 7.6038\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4969 - val_loss: 7.6585\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4687 - val_loss: 7.6357\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5028 - val_loss: 7.8521\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5947 - val_loss: 7.4980\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7974 - val_loss: 7.5109\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5000 - val_loss: 8.3032\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6148 - val_loss: 7.5685\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5585 - val_loss: 7.9238\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5804 - val_loss: 7.5979\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6305 - val_loss: 8.0772\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6578 - val_loss: 8.2335\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5848 - val_loss: 7.5415\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4790 - val_loss: 8.3864\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9298 - val_loss: 7.5065\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9312 - val_loss: 8.8123\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7267 - val_loss: 7.6005\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5273 - val_loss: 7.8724\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5675 - val_loss: 7.8543\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5644 - val_loss: 8.0394\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5129 - val_loss: 7.7900\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5210 - val_loss: 7.9230\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.6003 - val_loss: 7.6923\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6084 - val_loss: 8.0647\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.5544 - val_loss: 7.4320\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4591 - val_loss: 7.8721\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6364 - val_loss: 7.7225\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7883 - val_loss: 8.8672\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7733 - val_loss: 7.3856\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4621 - val_loss: 8.1237\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5220 - val_loss: 7.7228\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5114 - val_loss: 8.3176\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5383 - val_loss: 7.4823\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4091 - val_loss: 7.9541\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5332 - val_loss: 7.9398\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5289 - val_loss: 7.6606\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5530 - val_loss: 7.3941\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4697 - val_loss: 7.9423\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7287 - val_loss: 7.5006\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4994 - val_loss: 8.0876\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6829 - val_loss: 7.3768\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2320 - val_loss: 8.7773\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5572 - val_loss: 7.6775\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5115 - val_loss: 7.7444\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 94us/step - loss: 6.4029 - val_loss: 7.8989\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6989 - val_loss: 7.9823\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5053 - val_loss: 7.6750\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3928 - val_loss: 7.7132\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5908 - val_loss: 8.0715\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6282 - val_loss: 7.7893\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5507 - val_loss: 7.3914\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5250 - val_loss: 7.5374\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4026 - val_loss: 7.8561\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4522 - val_loss: 7.7765\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5094 - val_loss: 7.5249\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9651 - val_loss: 8.6398\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7934 - val_loss: 7.6767\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6192 - val_loss: 7.8790\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4950 - val_loss: 7.7641\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5234 - val_loss: 7.5706\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4615 - val_loss: 7.8268\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0896 - val_loss: 7.4272\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5054 - val_loss: 8.1653\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4864 - val_loss: 7.4617\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6939 - val_loss: 7.9391\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5674 - val_loss: 7.8848\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5955 - val_loss: 7.4570\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6543 - val_loss: 8.0459\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3883 - val_loss: 7.5663\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6194 - val_loss: 7.9385\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3454 - val_loss: 7.5389\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4915 - val_loss: 7.9709\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3984 - val_loss: 7.6269\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3404 - val_loss: 7.6029\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4243 - val_loss: 8.0737\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3718 - val_loss: 7.7237\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4976 - val_loss: 8.3238\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4408 - val_loss: 7.4962\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4135 - val_loss: 7.9910\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4839 - val_loss: 7.5886\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6681 - val_loss: 7.6393\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4892 - val_loss: 7.8114\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4457 - val_loss: 7.9904\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5791 - val_loss: 7.7782\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3644 - val_loss: 7.6463\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4350 - val_loss: 7.8534\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6423 - val_loss: 8.1215\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3292 - val_loss: 7.5287\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5463 - val_loss: 7.9601\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5631 - val_loss: 7.6117\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3781 - val_loss: 7.5678\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4423 - val_loss: 7.7158\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3649 - val_loss: 7.6194\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3810 - val_loss: 8.5366\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5763 - val_loss: 7.5655\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5086 - val_loss: 8.3191\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3915 - val_loss: 7.3868\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8518 - val_loss: 8.8626\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5648 - val_loss: 7.4202\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4200 - val_loss: 7.5969\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4291 - val_loss: 7.6231\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5306 - val_loss: 7.6107\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5689 - val_loss: 7.8621\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5015 - val_loss: 7.8664\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3757 - val_loss: 7.9130\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4360 - val_loss: 7.4719\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3420 - val_loss: 7.9491\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5702 - val_loss: 7.6674\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4588 - val_loss: 8.4132\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4346 - val_loss: 7.6217\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4387 - val_loss: 7.9562\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5484 - val_loss: 7.6564\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3645 - val_loss: 8.1802\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3551 - val_loss: 7.6879\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3932 - val_loss: 7.8533\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3108 - val_loss: 7.6759\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4288 - val_loss: 7.8178\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4053 - val_loss: 7.7218\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4958 - val_loss: 8.3767\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6137 - val_loss: 7.6544\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5772 - val_loss: 8.5125\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6595 - val_loss: 7.6682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4596 - val_loss: 7.8299\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3708 - val_loss: 7.6123\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5686 - val_loss: 7.4598\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4784 - val_loss: 8.1460\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4547 - val_loss: 7.6782\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5850 - val_loss: 8.7064\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5557 - val_loss: 7.5856\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4313 - val_loss: 7.7955\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3957 - val_loss: 7.8483\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3417 - val_loss: 7.8987\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4893 - val_loss: 8.0456\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6144 - val_loss: 7.7535\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5696 - val_loss: 7.5859\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4542 - val_loss: 8.1551\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9391 - val_loss: 7.5907\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5676 - val_loss: 8.4845\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8238 - val_loss: 7.9173\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3754 - val_loss: 8.0675\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5993 - val_loss: 7.5247\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6082 - val_loss: 7.8134\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4717 - val_loss: 7.8910\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3702 - val_loss: 7.6696\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.996 - 0s 98us/step - loss: 6.4541 - val_loss: 8.2427\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5141 - val_loss: 7.6856\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3500 - val_loss: 7.8105\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4210 - val_loss: 8.0218\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6713 - val_loss: 7.5413\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4312 - val_loss: 8.0964\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7288 - val_loss: 7.7668\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0041 - val_loss: 8.2312\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3399 - val_loss: 7.8606\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6613 - val_loss: 7.8416\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4737 - val_loss: 8.1763\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3235 - val_loss: 7.6600\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3446 - val_loss: 8.0034\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5012 - val_loss: 7.6443\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3660 - val_loss: 8.3846\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3706 - val_loss: 7.7106\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4109 - val_loss: 7.7045\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3618 - val_loss: 8.1094\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3064 - val_loss: 7.7296\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7809 - val_loss: 7.9546\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3348 - val_loss: 7.9311\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7865 - val_loss: 8.6183\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.1617 - val_loss: 7.6662\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8023 - val_loss: 8.4533\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5809 - val_loss: 7.9716\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4857 - val_loss: 7.6701\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0749 - val_loss: 8.6708\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9338 - val_loss: 7.8515\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7522 - val_loss: 8.0507\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4461 - val_loss: 7.9037\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4185 - val_loss: 8.1120\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7155 - val_loss: 7.7428\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3123 - val_loss: 7.9037\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4423 - val_loss: 7.6959\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3660 - val_loss: 8.2083\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2600 - val_loss: 7.7541\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3934 - val_loss: 8.0937\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4129 - val_loss: 7.6281\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4296 - val_loss: 7.9743\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3542 - val_loss: 7.6424\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4989 - val_loss: 7.9924\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2891 - val_loss: 7.8329\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2945 - val_loss: 7.7443\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6045 - val_loss: 7.5233\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4921 - val_loss: 7.8169\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4140 - val_loss: 7.9181\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3002 - val_loss: 8.8546\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5133 - val_loss: 7.6931\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5292 - val_loss: 8.6540\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7793 - val_loss: 7.5098\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7111 - val_loss: 8.2669\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.487 - 0s 98us/step - loss: 6.7777 - val_loss: 7.8114\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3557 - val_loss: 7.7564\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2999 - val_loss: 7.9835\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3475 - val_loss: 7.9447\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 96us/step - loss: 6.5053 - val_loss: 7.7939\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.2869 - val_loss: 7.9230\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4267 - val_loss: 8.3349\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.6251 - val_loss: 7.7772\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1751 - val_loss: 9.1795\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2872 - val_loss: 7.6835\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.8032 - val_loss: 8.3241\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4955 - val_loss: 7.6799\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6358 - val_loss: 8.6024\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7790 - val_loss: 7.7626\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3757 - val_loss: 8.0144\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2667 - val_loss: 7.7760\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3389 - val_loss: 8.2849\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3691 - val_loss: 7.7537\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5436 - val_loss: 8.4056\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3444 - val_loss: 7.8686\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5588 - val_loss: 7.9187\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3769 - val_loss: 7.7931\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4041 - val_loss: 8.1783\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9601 - val_loss: 7.7618\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2593 - val_loss: 8.0017\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3859 - val_loss: 7.5420\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4152 - val_loss: 8.1537\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8060 - val_loss: 7.9460\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.7068 - val_loss: 8.8903\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6626 - val_loss: 8.0600\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3063 - val_loss: 8.3145\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2552 - val_loss: 7.6821\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3228 - val_loss: 8.3840\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4365 - val_loss: 7.7532\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.7181 - val_loss: 9.5168\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0031 - val_loss: 7.6972\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3157 - val_loss: 7.9592\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3076 - val_loss: 7.7535\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3505 - val_loss: 8.0711\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3475 - val_loss: 8.0134\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5075 - val_loss: 7.8706\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3970 - val_loss: 8.0579\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3347 - val_loss: 7.6463\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7904 - val_loss: 8.6033\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4986 - val_loss: 7.9217\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4041 - val_loss: 7.7541\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3448 - val_loss: 8.3746\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5685 - val_loss: 7.6766\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3928 - val_loss: 7.8036\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3244 - val_loss: 7.8174\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3145 - val_loss: 8.0166\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2696 - val_loss: 8.1164\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5910 - val_loss: 7.6720\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.4771 - val_loss: 7.8778\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8476 - val_loss: 8.8846\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6023 - val_loss: 7.9627\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4233 - val_loss: 8.1521\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3665 - val_loss: 7.9013\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5550 - val_loss: 7.7626\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4263 - val_loss: 8.7591\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6025 - val_loss: 7.7906\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6067 - val_loss: 8.5237\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3862 - val_loss: 7.8003\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.7372 - val_loss: 8.9740\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8554 - val_loss: 7.6668\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2400 - val_loss: 8.4409\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4061 - val_loss: 7.9065\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3663 - val_loss: 8.1405\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4882 - val_loss: 8.1044\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3030 - val_loss: 8.0264\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3797 - val_loss: 7.8603\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3416 - val_loss: 8.0759\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4587 - val_loss: 7.8363\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4760 - val_loss: 7.9356\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2268 - val_loss: 8.2080\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1886 - val_loss: 7.8120\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2976 - val_loss: 8.2246\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6251 - val_loss: 7.9175\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2648 - val_loss: 7.9996\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3945 - val_loss: 7.6305\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.1689 - val_loss: 8.6055\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4422 - val_loss: 7.6842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8562 - val_loss: 8.4322\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2706 - val_loss: 7.7024\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4763 - val_loss: 8.3078\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4020 - val_loss: 8.0774\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3914 - val_loss: 8.5425\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7346 - val_loss: 7.7386\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6504 - val_loss: 9.1078\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4494 - val_loss: 7.6630\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5652 - val_loss: 9.9762\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0045 - val_loss: 7.7123\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6224 - val_loss: 8.8569\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5555 - val_loss: 7.8248\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3136 - val_loss: 8.5160\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3170 - val_loss: 7.6415\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2560 - val_loss: 7.7323\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2926 - val_loss: 8.1714\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4508 - val_loss: 8.3850\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5309 - val_loss: 7.9094\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6164 - val_loss: 8.2873\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4691 - val_loss: 7.7909\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3725 - val_loss: 7.8525\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2971 - val_loss: 8.2554\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3187 - val_loss: 7.9036\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2831 - val_loss: 7.9742\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3454 - val_loss: 7.9843\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2228 - val_loss: 8.0929\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4136 - val_loss: 7.6615\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3794 - val_loss: 8.6286\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4407 - val_loss: 8.1275\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3107 - val_loss: 8.2787\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2543 - val_loss: 7.7129\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3180 - val_loss: 7.9318\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2971 - val_loss: 7.8246\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5389 - val_loss: 7.7934\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4672 - val_loss: 8.3549\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.2497 - val_loss: 7.8999\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4119 - val_loss: 9.0171\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8346 - val_loss: 7.7613\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1847 - val_loss: 9.8757\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8976 - val_loss: 7.7156\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3326 - val_loss: 8.0734\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5646 - val_loss: 8.1467\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4687 - val_loss: 7.9847\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4639 - val_loss: 8.0717\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3201 - val_loss: 7.8608\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3728 - val_loss: 7.7537\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4326 - val_loss: 8.5907\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6584 - val_loss: 8.1668\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2635 - val_loss: 8.0578\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2242 - val_loss: 8.0020\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2756 - val_loss: 8.4005\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5296 - val_loss: 7.8676\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3067 - val_loss: 8.0346\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3702 - val_loss: 7.6845\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3359 - val_loss: 7.6994\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2880 - val_loss: 8.2301\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4612 - val_loss: 8.4420\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3594 - val_loss: 7.8487\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2607 - val_loss: 7.8362\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2413 - val_loss: 7.8023\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4299 - val_loss: 7.7628\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4815 - val_loss: 8.1984\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2282 - val_loss: 8.0122\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4506 - val_loss: 8.3003\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2580 - val_loss: 7.9856\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4756 - val_loss: 8.2875\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2744 - val_loss: 7.8892\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4119 - val_loss: 8.2068\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3222 - val_loss: 7.8683\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5105 - val_loss: 8.2218\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2434 - val_loss: 8.0027\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2176 - val_loss: 7.9781\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2973 - val_loss: 8.3423\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3111 - val_loss: 8.1275\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5420 - val_loss: 7.4999\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5393 - val_loss: 8.6160\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.4844 - val_loss: 7.7143\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0605 - val_loss: 8.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9878 - val_loss: 7.8511\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4080 - val_loss: 7.7843\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7056 - val_loss: 7.6143\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3530 - val_loss: 8.1665\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3156 - val_loss: 7.9008\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6378 - val_loss: 7.9197\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3297 - val_loss: 8.1425\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2775 - val_loss: 7.9325\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2303 - val_loss: 7.9590\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2461 - val_loss: 7.7606\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3025 - val_loss: 8.0388\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3541 - val_loss: 7.9844\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2424 - val_loss: 7.9464\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4483 - val_loss: 8.5839\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6468 - val_loss: 7.9675\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3719 - val_loss: 8.0504\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2517 - val_loss: 7.9026\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2058 - val_loss: 8.2480\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2426 - val_loss: 8.0125\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2400 - val_loss: 8.1370\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4282 - val_loss: 7.8796\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2426 - val_loss: 8.4026\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4146 - val_loss: 8.0707\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1856 - val_loss: 8.1855\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3830 - val_loss: 7.6678\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4150 - val_loss: 8.1002\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3504 - val_loss: 8.0220\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5638 - val_loss: 7.6407\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6841 - val_loss: 8.3289\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3653 - val_loss: 7.8945\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3907 - val_loss: 8.1844\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2193 - val_loss: 7.9645\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.4974 - val_loss: 8.2146\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3806 - val_loss: 7.7656\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5541 - val_loss: 7.7409\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2933 - val_loss: 8.8885\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4417 - val_loss: 7.7481\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2913 - val_loss: 8.2151\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3028 - val_loss: 7.6680\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3053 - val_loss: 7.8458\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4024 - val_loss: 7.9037\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5425 - val_loss: 8.4504\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5789 - val_loss: 7.6270\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3129 - val_loss: 8.1636\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2556 - val_loss: 7.9652\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3397 - val_loss: 8.2534\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5680 - val_loss: 8.2061\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4401 - val_loss: 7.6826\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3368 - val_loss: 7.9565\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3247 - val_loss: 8.0105\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2385 - val_loss: 8.0488\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2655 - val_loss: 8.0152\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2040 - val_loss: 8.0011\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2871 - val_loss: 7.6524\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3210 - val_loss: 8.2026\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3693 - val_loss: 7.7799\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2931 - val_loss: 8.3746\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3708 - val_loss: 7.9191\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2170 - val_loss: 8.0892\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5178 - val_loss: 7.6639\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4836 - val_loss: 8.2856\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4382 - val_loss: 7.7463\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4137 - val_loss: 7.9457\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3045 - val_loss: 7.8831\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2061 - val_loss: 8.2138\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2787 - val_loss: 8.0326\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4813 - val_loss: 7.6547\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.876 - 0s 99us/step - loss: 6.2695 - val_loss: 7.8356\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2805 - val_loss: 8.0888\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4127 - val_loss: 8.1247\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3409 - val_loss: 8.5348\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4519 - val_loss: 7.8494\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4077 - val_loss: 7.8300\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1929 - val_loss: 8.9673\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4486 - val_loss: 7.8202\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5647 - val_loss: 9.1688\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6365 - val_loss: 7.7726\n",
      "Epoch 846/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.6747 - val_loss: 8.1817\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3773 - val_loss: 7.8726\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3844 - val_loss: 8.1758\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7734 - val_loss: 8.1971\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0182 - val_loss: 7.6814\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6126 - val_loss: 8.2094\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3634 - val_loss: 8.1108\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2682 - val_loss: 7.8008\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3845 - val_loss: 8.9435\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6808 - val_loss: 8.0918\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2024 - val_loss: 7.9151\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2186 - val_loss: 7.9379\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2135 - val_loss: 7.8239\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3952 - val_loss: 8.2619\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4993 - val_loss: 8.1403\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7877 - val_loss: 7.7793\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9033 - val_loss: 8.4974\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5823 - val_loss: 7.7133\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4582 - val_loss: 8.3628\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3007 - val_loss: 7.9621\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2681 - val_loss: 7.9066\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1701 - val_loss: 7.6864\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2424 - val_loss: 7.8961\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2618 - val_loss: 7.8210\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2973 - val_loss: 8.5805\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7801 - val_loss: 7.6001\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7382 - val_loss: 8.6304\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4550 - val_loss: 7.7619\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5074 - val_loss: 8.2571\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5310 - val_loss: 7.8931\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2232 - val_loss: 8.4798\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3047 - val_loss: 7.8036\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6413 - val_loss: 7.8077\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2706 - val_loss: 7.8913\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2421 - val_loss: 8.1662\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3788 - val_loss: 7.9953\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2168 - val_loss: 8.0788\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2484 - val_loss: 7.7459\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2190 - val_loss: 7.7748\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2134 - val_loss: 7.7343\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6153 - val_loss: 8.5180\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7116 - val_loss: 7.7911\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5994 - val_loss: 8.1159\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4620 - val_loss: 7.8123\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3307 - val_loss: 7.7940\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3112 - val_loss: 7.8565\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2838 - val_loss: 8.2576\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7314 - val_loss: 7.8206\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5380 - val_loss: 8.4458\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.3980 - val_loss: 7.8043\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2664 - val_loss: 8.0205\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3456 - val_loss: 7.8192\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5233 - val_loss: 8.3921\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5807 - val_loss: 7.9615\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8915 - val_loss: 8.3345\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6026 - val_loss: 7.6125\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2376 - val_loss: 8.0882\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2826 - val_loss: 7.8594\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2557 - val_loss: 8.0447\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.2669 - val_loss: 7.9385\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1691 - val_loss: 7.7120\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3060 - val_loss: 8.3008\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 6.3964 - val_loss: 8.0185\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2024 - val_loss: 7.8688\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2081 - val_loss: 8.0970\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3705 - val_loss: 7.7753\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.1820 - val_loss: 8.0224\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2906 - val_loss: 7.9349\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4484 - val_loss: 8.2363\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5912 - val_loss: 7.7752\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.7557 - val_loss: 8.5192\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.7243 - val_loss: 8.0154\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3961 - val_loss: 8.0994\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2766 - val_loss: 8.0432\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2547 - val_loss: 7.9022\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4627 - val_loss: 8.1837\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0515 - val_loss: 7.7225\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 6.2614 - val_loss: 8.1068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 6.3170 - val_loss: 7.6562\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2089 - val_loss: 7.7639\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2354 - val_loss: 8.1380\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4804 - val_loss: 7.6714\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3675 - val_loss: 8.2590\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 6.3767 - val_loss: 7.8117\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3845 - val_loss: 8.1702\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2606 - val_loss: 7.5039\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2243 - val_loss: 8.7636\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4511 - val_loss: 8.0386\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3134 - val_loss: 8.0636\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3720 - val_loss: 8.3007\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4125 - val_loss: 7.6838\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1763 - val_loss: 8.2000\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4380 - val_loss: 7.8169\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3449 - val_loss: 7.7349\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3146 - val_loss: 8.4695\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2655 - val_loss: 7.8854\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2737 - val_loss: 7.8705\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2004 - val_loss: 7.7921\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3082 - val_loss: 7.8379\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2572 - val_loss: 8.1003\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2978 - val_loss: 8.2656\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2780 - val_loss: 7.7422\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3591 - val_loss: 8.6345\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4778 - val_loss: 7.7178\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2268 - val_loss: 8.7617\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2876 - val_loss: 7.9162\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4653 - val_loss: 8.2270\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7792 - val_loss: 7.6616\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2825 - val_loss: 7.7355\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.5956 - val_loss: 7.8436\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1785 - val_loss: 7.9181\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2782 - val_loss: 8.0368\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3507 - val_loss: 7.8216\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.3395 - val_loss: 7.7983\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1823 - val_loss: 8.1024\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2467 - val_loss: 7.8220\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2910 - val_loss: 8.2368\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1884 - val_loss: 7.7251\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2458 - val_loss: 7.9702\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2129 - val_loss: 7.7287\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.2238 - val_loss: 8.2345\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2586 - val_loss: 7.9244\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1732 - val_loss: 7.8674\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2904 - val_loss: 8.1505\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3802 - val_loss: 7.9108\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2881 - val_loss: 7.6910\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3519 - val_loss: 8.3659\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3377 - val_loss: 7.9899\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3488 - val_loss: 7.5778\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2475 - val_loss: 8.1355\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4604 - val_loss: 7.7767\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5757 - val_loss: 7.8719\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0174 - val_loss: 8.6070\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1897 - val_loss: 7.7523\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0969 - val_loss: 8.1295\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5558 - val_loss: 7.7776\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2736 - val_loss: 8.1611\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6745 - val_loss: 7.7402\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1581 - val_loss: 8.5151\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2062 - val_loss: 7.9412\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2826 - val_loss: 9.2814\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6390 - val_loss: 7.6225\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4633 - val_loss: 9.1713\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6800 - val_loss: 7.9797\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5301 - val_loss: 8.9832\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5092 - val_loss: 7.7551\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3662 - val_loss: 7.8351\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3826 - val_loss: 8.0749\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7443 - val_loss: 7.7557\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5337 - val_loss: 8.4157\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6035 - val_loss: 7.7805\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3907 - val_loss: 7.7458\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4200 - val_loss: 7.7768\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.4021 - val_loss: 8.4260\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4550 - val_loss: 7.9370\n",
      "5.308871463193732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.53232044, -0.58687955,  0.39952472,  0.17230423,  0.5017748 ],\n",
       "        [ 0.9582751 ,  0.6359535 ,  0.41869873, -1.8547462 ,  0.2501738 ],\n",
       "        [ 0.05215393,  0.01839157, -0.86553407, -0.53786933, -0.45027575],\n",
       "        [-1.1254938 ,  0.21484661, -1.3041146 ,  0.5993762 , -1.3218354 ],\n",
       "        [-0.851446  , -0.01704559,  0.07102912, -0.37940705,  0.85400087],\n",
       "        [-0.1623543 ,  1.6085427 ,  0.33604884, -1.3272104 ,  0.9310007 ],\n",
       "        [-1.0627977 , -0.34666207,  1.078834  , -0.30213377,  0.62023973]],\n",
       "       dtype=float32),\n",
       " array([0.39717206, 2.0962946 , 0.3316032 , 1.4984368 , 1.320142  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.89418113, -0.18161769,  0.24381569,  0.8688638 , -0.10515603,\n",
       "          0.7298871 , -0.33471155, -0.3281004 , -0.18082145,  1.0777526 ],\n",
       "        [ 1.2876474 , -0.86524373,  0.69760394, -0.67396533,  1.1511638 ,\n",
       "         -0.63650674, -0.7862481 , -0.48302144,  0.18977526,  0.8333433 ],\n",
       "        [ 0.81513196, -1.3317782 ,  0.11486205,  0.42142197,  0.86790925,\n",
       "         -0.2726391 , -0.06375529, -0.9140161 , -0.00287051,  0.14143276],\n",
       "        [ 1.0739517 , -0.5791196 ,  1.0939369 , -1.0459169 ,  1.040832  ,\n",
       "         -0.42135754, -0.20299311, -0.3776978 ,  0.6845033 ,  0.9537954 ],\n",
       "        [ 1.0829477 , -0.2896085 , -0.24130438,  1.4022934 , -0.12831599,\n",
       "          0.58516645, -1.0579485 , -0.20076215,  0.6122777 ,  0.10622326]],\n",
       "       dtype=float32),\n",
       " array([ 0.87151605, -0.68604267,  0.75906044, -0.5569511 ,  0.7972874 ,\n",
       "         0.9981669 , -0.50360924, -0.64423084,  0.75591874,  0.7654461 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.2694309 ],\n",
       "        [ 0.12228813],\n",
       "        [ 0.56916237],\n",
       "        [ 0.9003656 ],\n",
       "        [ 0.7696419 ],\n",
       "        [-0.23365372],\n",
       "        [-0.18255349],\n",
       "        [ 0.14615901],\n",
       "        [ 0.3394461 ],\n",
       "        [ 0.5098096 ]], dtype=float32),\n",
       " array([0.94635826], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_relu(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_relu_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 788us/step - loss: 562.5902 - val_loss: 486.4482\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 397.2893 - val_loss: 361.7185\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 294.1268 - val_loss: 272.5330\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 222.0088 - val_loss: 211.2917\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 174.1178 - val_loss: 170.6436\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 143.0676 - val_loss: 143.2356\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 121.8108 - val_loss: 125.3491\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 108.4886 - val_loss: 112.5307\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 99.1687 - val_loss: 102.5651\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 91.5325 - val_loss: 93.4964\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 82.3839 - val_loss: 80.0624\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 73.2909 - val_loss: 74.7398\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 69.2283 - val_loss: 69.9235\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 65.8727 - val_loss: 65.8722\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 62.8730 - val_loss: 62.8593\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 60.7308 - val_loss: 60.2119\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 58.7369 - val_loss: 58.0632\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 56.9503 - val_loss: 56.3754\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 55.4403 - val_loss: 54.7191\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 53.9603 - val_loss: 53.2894\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 52.6262 - val_loss: 51.9976\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 51.4755 - val_loss: 50.7021\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 50.2661 - val_loss: 49.6121\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 49.2230 - val_loss: 48.5760\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 48.1865 - val_loss: 47.5964\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 47.2453 - val_loss: 46.6480\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 46.3558 - val_loss: 45.7962\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 45.5056 - val_loss: 45.0918\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 44.7146 - val_loss: 44.4053\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 43.9245 - val_loss: 43.6489\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 43.2016 - val_loss: 42.9362\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 42.4827 - val_loss: 42.2676\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 41.8360 - val_loss: 41.6516\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 41.2133 - val_loss: 41.1301\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 40.5987 - val_loss: 40.5799\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 25.57 - 0s 120us/step - loss: 40.0120 - val_loss: 40.0818\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 39.4463 - val_loss: 39.5619\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 38.9621 - val_loss: 39.0425\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 38.4253 - val_loss: 38.6468\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 37.9543 - val_loss: 38.2760\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 37.4474 - val_loss: 37.7920\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 36.9687 - val_loss: 37.3705\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 36.5104 - val_loss: 36.9533\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 36.1126 - val_loss: 36.5341\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 35.6442 - val_loss: 36.1689\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 35.1929 - val_loss: 35.6935\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 34.7034 - val_loss: 35.0511\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 34.1953 - val_loss: 34.5197\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 33.8802 - val_loss: 33.9833\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 33.3396 - val_loss: 33.6061\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 32.8582 - val_loss: 33.2347\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 32.4570 - val_loss: 32.8221\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 32.0351 - val_loss: 32.4356\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 31.6689 - val_loss: 32.0642\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 31.3337 - val_loss: 31.6609\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 30.9373 - val_loss: 31.2861\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 30.5281 - val_loss: 30.9645\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 30.1971 - val_loss: 30.6147\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 29.8615 - val_loss: 30.4868\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 29.4336 - val_loss: 30.3020\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 29.0834 - val_loss: 29.9937\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 28.8334 - val_loss: 29.2324\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 28.4026 - val_loss: 28.6643\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 28.0656 - val_loss: 28.0982\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 27.6300 - val_loss: 27.4356\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 27.3478 - val_loss: 27.0967\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 26.9950 - val_loss: 26.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 26.4619 - val_loss: 26.7821\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 26.2299 - val_loss: 26.5795\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 25.7169 - val_loss: 25.7317\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 25.2973 - val_loss: 25.5696\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 24.9314 - val_loss: 25.4408\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 24.5959 - val_loss: 25.2499\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 24.3237 - val_loss: 24.8705\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 24.0277 - val_loss: 24.6214\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 23.5463 - val_loss: 24.1670\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 22.4173 - val_loss: 22.1603\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.6939 - val_loss: 20.2498\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.6559 - val_loss: 19.4308\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.3308 - val_loss: 18.6415\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.3918 - val_loss: 18.2796\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7003 - val_loss: 17.5457\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.0952 - val_loss: 17.5331\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 14.5095 - val_loss: 17.0034\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.1562 - val_loss: 17.1966\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.7762 - val_loss: 17.1165\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.5241 - val_loss: 17.0538\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.2069 - val_loss: 16.6100\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.7260 - val_loss: 16.5380\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3387 - val_loss: 16.3751\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.9588 - val_loss: 15.9537\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.6261 - val_loss: 15.6941\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.2521 - val_loss: 15.4287\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.9423 - val_loss: 15.0826\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.6232 - val_loss: 14.6015\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.4917 - val_loss: 14.3363\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.2815 - val_loss: 14.4812\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.9430 - val_loss: 13.9319\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.8419 - val_loss: 14.0395\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 9.5433 - val_loss: 13.3418\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.4546 - val_loss: 13.1577\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.2690 - val_loss: 13.4016\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 9.0102 - val_loss: 12.8269\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 8.9016 - val_loss: 12.5967\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 8.6663 - val_loss: 12.4825\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 8.5285 - val_loss: 12.3594\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3162 - val_loss: 12.0827\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.3246 - val_loss: 11.9098\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1333 - val_loss: 12.2334\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2018 - val_loss: 11.5971\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.9078 - val_loss: 11.6199\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7883 - val_loss: 11.2739\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7354 - val_loss: 11.2953\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7968 - val_loss: 11.4183\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.6844 - val_loss: 11.2534\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6441 - val_loss: 11.3302\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.5879 - val_loss: 10.8941\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3709 - val_loss: 11.1871\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3164 - val_loss: 11.0234\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2099 - val_loss: 10.8926\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.2099 - val_loss: 11.0078\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1364 - val_loss: 10.7902\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1231 - val_loss: 10.4377\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0847 - val_loss: 10.8031\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1734 - val_loss: 10.5838\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9675 - val_loss: 10.5542\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9533 - val_loss: 10.4987\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8905 - val_loss: 10.6849\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.9167 - val_loss: 10.6329\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9148 - val_loss: 10.6748\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.8006 - val_loss: 10.6566\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7385 - val_loss: 10.6668\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7508 - val_loss: 10.5389\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6965 - val_loss: 10.7030\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8223 - val_loss: 10.5450\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7457 - val_loss: 10.3613\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6698 - val_loss: 10.5032\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6057 - val_loss: 10.2967\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6484 - val_loss: 10.5674\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7679 - val_loss: 10.4283\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.5660 - val_loss: 10.1841\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5198 - val_loss: 10.0578\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.4720 - val_loss: 10.1213\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5429 - val_loss: 10.1076\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 6.5693 - val_loss: 10.0140\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3583 - val_loss: 9.9782\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2767 - val_loss: 9.8670\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2260 - val_loss: 9.9175\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2586 - val_loss: 9.8326\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1918 - val_loss: 9.6663\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2332 - val_loss: 9.8434\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3367 - val_loss: 9.7482\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2065 - val_loss: 9.6789\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1905 - val_loss: 9.5932\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0801 - val_loss: 9.5906\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1029 - val_loss: 9.4478\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0938 - val_loss: 9.5524\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0847 - val_loss: 9.4498\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0311 - val_loss: 9.2403\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0056 - val_loss: 9.2826\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0755 - val_loss: 9.1319\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9682 - val_loss: 8.9388\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9696 - val_loss: 9.2132\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9595 - val_loss: 9.3118\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8798 - val_loss: 9.2376\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9493 - val_loss: 9.0641\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0850 - val_loss: 9.1802\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8304 - val_loss: 8.8129\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8493 - val_loss: 8.8585\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7805 - val_loss: 8.8496\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7687 - val_loss: 8.8630\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7673 - val_loss: 8.6879\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7827 - val_loss: 8.8366\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7530 - val_loss: 8.7945\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.7105 - val_loss: 8.7834\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7283 - val_loss: 8.7617\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7580 - val_loss: 8.5980\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7319 - val_loss: 8.7312\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7110 - val_loss: 8.5903\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8711 - val_loss: 8.6238\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7474 - val_loss: 8.6098\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6333 - val_loss: 8.5000\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5970 - val_loss: 8.6866\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6724 - val_loss: 8.7550\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6121 - val_loss: 8.4231\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5881 - val_loss: 8.5238\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6412 - val_loss: 8.5769\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6586 - val_loss: 8.4335\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6882 - val_loss: 8.5823\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5650 - val_loss: 8.5918\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5887 - val_loss: 8.4439\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5552 - val_loss: 8.6205\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5641 - val_loss: 8.6206\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5415 - val_loss: 8.5328\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4869 - val_loss: 8.4904\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5572 - val_loss: 8.5656\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5585 - val_loss: 8.5144\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6377 - val_loss: 8.4484\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6446 - val_loss: 8.6368\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5822 - val_loss: 8.4909\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4997 - val_loss: 8.6588\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6445 - val_loss: 8.4394\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5998 - val_loss: 8.5627\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5360 - val_loss: 8.5088\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5020 - val_loss: 8.4424\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5133 - val_loss: 8.4815\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5647 - val_loss: 8.6092\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5820 - val_loss: 8.4270\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4795 - val_loss: 8.7990\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4986 - val_loss: 8.3521\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4702 - val_loss: 8.2836\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4522 - val_loss: 8.3773\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4702 - val_loss: 8.4597\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4293 - val_loss: 8.3261\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.4165 - val_loss: 8.4121\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4430 - val_loss: 8.3338\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4578 - val_loss: 8.4142\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4480 - val_loss: 8.4077\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5208 - val_loss: 8.4614\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.4899 - val_loss: 8.4172\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4092 - val_loss: 8.2941\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4078 - val_loss: 8.2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.4094 - val_loss: 8.4923\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4129 - val_loss: 8.3885\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4986 - val_loss: 8.2805\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3737 - val_loss: 8.2392\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3804 - val_loss: 8.4083\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 5.4506 - val_loss: 8.1916\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3403 - val_loss: 8.2263\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3814 - val_loss: 8.4450\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3961 - val_loss: 8.4437\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3823 - val_loss: 8.2880\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3649 - val_loss: 8.1090\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3614 - val_loss: 8.1014\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3433 - val_loss: 8.2374\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3902 - val_loss: 8.1993\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3777 - val_loss: 8.2453\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3598 - val_loss: 8.4196\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3284 - val_loss: 8.1775\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3537 - val_loss: 8.0294\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3126 - val_loss: 8.1759\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3594 - val_loss: 8.1580\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3807 - val_loss: 8.1790\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3331 - val_loss: 8.1940\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4027 - val_loss: 8.1995\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3776 - val_loss: 8.1041\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3195 - val_loss: 8.3354\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3423 - val_loss: 8.3110\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3649 - val_loss: 8.1464\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3972 - val_loss: 8.2963\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2784 - val_loss: 8.1905\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2783 - val_loss: 8.2356\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2930 - val_loss: 8.1516\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3209 - val_loss: 8.1399\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3544 - val_loss: 8.1124\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4556 - val_loss: 8.1360\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3110 - val_loss: 8.0966\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2860 - val_loss: 7.9434\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4019 - val_loss: 8.3397\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3219 - val_loss: 8.2896\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3546 - val_loss: 8.0487\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6201 - val_loss: 8.2104\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3296 - val_loss: 8.0921\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4234 - val_loss: 8.2350\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.4474 - val_loss: 7.8682\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2938 - val_loss: 8.1096\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2932 - val_loss: 8.2370\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2386 - val_loss: 7.9928\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3846 - val_loss: 8.0627\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3166 - val_loss: 7.9815\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2057 - val_loss: 8.0530\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3247 - val_loss: 7.9574\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2870 - val_loss: 8.0344\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2617 - val_loss: 7.9645\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1801 - val_loss: 8.4105\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2782 - val_loss: 8.0537\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2215 - val_loss: 8.0884\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2182 - val_loss: 7.9668\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2725 - val_loss: 8.1025\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2553 - val_loss: 7.9657\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3113 - val_loss: 8.2049\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1788 - val_loss: 7.9539\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3680 - val_loss: 8.0218\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2712 - val_loss: 8.2055\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2217 - val_loss: 7.9575\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2367 - val_loss: 8.3230\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3522 - val_loss: 7.9217\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2097 - val_loss: 8.0392\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2084 - val_loss: 8.0330\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2064 - val_loss: 8.0019\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1993 - val_loss: 8.0468\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2220 - val_loss: 8.0001\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1679 - val_loss: 7.9279\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2022 - val_loss: 8.1137\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2524 - val_loss: 7.9171\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4495 - val_loss: 7.7799\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4932 - val_loss: 8.4940\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3193 - val_loss: 8.0230\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1938 - val_loss: 8.1517\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.2228 - val_loss: 7.9350\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2060 - val_loss: 7.9207\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1759 - val_loss: 7.9668\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2167 - val_loss: 7.9545\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4042 - val_loss: 8.0640\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2837 - val_loss: 7.8062\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2419 - val_loss: 8.0737\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3104 - val_loss: 7.8240\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3645 - val_loss: 8.0915\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2770 - val_loss: 7.8890\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3143 - val_loss: 8.1771\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1660 - val_loss: 7.8704\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1769 - val_loss: 8.0573\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2520 - val_loss: 8.0566\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2253 - val_loss: 8.1215\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1823 - val_loss: 8.1698\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1982 - val_loss: 7.8509\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1236 - val_loss: 8.1422\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1536 - val_loss: 8.0911\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1808 - val_loss: 8.0088\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1424 - val_loss: 8.0298\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1280 - val_loss: 8.0342\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1873 - val_loss: 7.9870\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2099 - val_loss: 8.1312\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3248 - val_loss: 7.9487\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2307 - val_loss: 8.1253\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1324 - val_loss: 7.9832\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1547 - val_loss: 8.0783\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1718 - val_loss: 7.9449\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1900 - val_loss: 8.0815\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3056 - val_loss: 8.1950\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2184 - val_loss: 7.8970\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1484 - val_loss: 8.0369\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1646 - val_loss: 8.0857\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1645 - val_loss: 7.9485\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1249 - val_loss: 8.2407\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1870 - val_loss: 8.0734\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3032 - val_loss: 8.1657\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3741 - val_loss: 8.1339\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4220 - val_loss: 7.9499\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3465 - val_loss: 8.2516\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2634 - val_loss: 7.9097\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1103 - val_loss: 8.3290\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1484 - val_loss: 8.1815\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3057 - val_loss: 8.0159\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1758 - val_loss: 8.0631\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1964 - val_loss: 8.0954\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2096 - val_loss: 8.2319\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2514 - val_loss: 7.8661\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1521 - val_loss: 7.8915\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1416 - val_loss: 8.0665\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1265 - val_loss: 7.9554\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2015 - val_loss: 8.0527\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1693 - val_loss: 7.9432\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1267 - val_loss: 8.2131\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1796 - val_loss: 7.9328\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1658 - val_loss: 7.9453\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2722 - val_loss: 8.1656\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1700 - val_loss: 8.1507\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1752 - val_loss: 7.9518\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1557 - val_loss: 8.4291\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1704 - val_loss: 8.0776\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1059 - val_loss: 8.1247\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0672 - val_loss: 8.1410\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1273 - val_loss: 8.0904\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.0980 - val_loss: 7.9790\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1318 - val_loss: 8.0485\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0811 - val_loss: 8.1632\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0919 - val_loss: 8.1708\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0948 - val_loss: 8.1823\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0936 - val_loss: 8.1686\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0795 - val_loss: 8.0581\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1080 - val_loss: 8.0892\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1231 - val_loss: 8.1348\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1190 - val_loss: 8.1280\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1111 - val_loss: 7.9822\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1795 - val_loss: 8.1574\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.1811 - val_loss: 8.2259\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3017 - val_loss: 8.2772\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2847 - val_loss: 8.1898\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0724 - val_loss: 8.2401\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1756 - val_loss: 8.1530\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1634 - val_loss: 8.2264\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0875 - val_loss: 8.3440\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1739 - val_loss: 8.2029\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1612 - val_loss: 8.3097\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0722 - val_loss: 8.2651\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1084 - val_loss: 8.4077\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1001 - val_loss: 8.0929\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0995 - val_loss: 8.2932\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0889 - val_loss: 8.4540\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0792 - val_loss: 8.3022\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1144 - val_loss: 8.3513\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1433 - val_loss: 8.4759\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0523 - val_loss: 8.5099\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0761 - val_loss: 8.2885\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1138 - val_loss: 8.5131\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0779 - val_loss: 8.4370\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0865 - val_loss: 8.3126\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0653 - val_loss: 8.4030\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0851 - val_loss: 8.2745\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0752 - val_loss: 8.3125\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1484 - val_loss: 8.3579\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0816 - val_loss: 8.1314\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0873 - val_loss: 8.3873\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0945 - val_loss: 8.1956\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.1889 - val_loss: 8.5300\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1203 - val_loss: 8.3230\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.1142 - val_loss: 8.4485\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2387 - val_loss: 8.3125\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1002 - val_loss: 8.5663\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1541 - val_loss: 8.3530\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0999 - val_loss: 8.4457\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1629 - val_loss: 8.2573\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1411 - val_loss: 8.3492\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0557 - val_loss: 8.3309\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0440 - val_loss: 8.2972\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0716 - val_loss: 8.1931\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0334 - val_loss: 8.2506\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0093 - val_loss: 8.2608\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.0475 - val_loss: 8.3540\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1208 - val_loss: 8.4906\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0392 - val_loss: 8.5473\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0794 - val_loss: 8.1990\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1000 - val_loss: 8.2935\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0546 - val_loss: 8.3761\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0013 - val_loss: 8.3466\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0119 - val_loss: 8.2643\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0574 - val_loss: 8.3269\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.9928 - val_loss: 8.2302\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0392 - val_loss: 8.2857\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0465 - val_loss: 8.2312\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9719 - val_loss: 8.3894\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0246 - val_loss: 8.3678\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0292 - val_loss: 8.2096\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0029 - val_loss: 8.2504\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0516 - val_loss: 8.2258\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0295 - val_loss: 8.4451\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0356 - val_loss: 8.3329\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0136 - val_loss: 8.3679\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0290 - val_loss: 8.2087\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0506 - val_loss: 8.2700\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.100 - 0s 116us/step - loss: 5.0885 - val_loss: 8.3900\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9958 - val_loss: 8.5193\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9991 - val_loss: 8.3423\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0131 - val_loss: 8.3861\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9564 - val_loss: 8.2829\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0143 - val_loss: 8.4468\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9813 - val_loss: 8.3316\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0207 - val_loss: 8.5004\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0749 - val_loss: 8.2288\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2499 - val_loss: 8.4468\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9378 - val_loss: 8.3437\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.1144 - val_loss: 8.4056\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 109us/step - loss: 4.9461 - val_loss: 8.0384\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0080 - val_loss: 8.3487\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9552 - val_loss: 8.4523\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9633 - val_loss: 8.2897\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.9475 - val_loss: 8.2685\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0449 - val_loss: 8.3092\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.9515 - val_loss: 8.3562\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9388 - val_loss: 8.4543\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.0182 - val_loss: 8.2415\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9688 - val_loss: 8.3315\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9389 - val_loss: 8.3016\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.9269 - val_loss: 8.3566\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 149us/step - loss: 5.1106 - val_loss: 8.3906\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 193us/step - loss: 4.8561 - val_loss: 8.7770\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.0434 - val_loss: 8.1738\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 157us/step - loss: 4.9908 - val_loss: 8.4364\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9470 - val_loss: 8.1963\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9413 - val_loss: 8.4273\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.9267 - val_loss: 8.4054\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9011 - val_loss: 8.4439\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.9260 - val_loss: 8.4396\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8920 - val_loss: 8.3875\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8942 - val_loss: 8.4467\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8922 - val_loss: 8.3604\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9059 - val_loss: 8.5058\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9141 - val_loss: 8.2392\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9142 - val_loss: 8.4024\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9208 - val_loss: 8.3178\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.8519 - val_loss: 8.2700\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9000 - val_loss: 8.3163\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.9514 - val_loss: 8.4299\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0231 - val_loss: 8.5033\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.0192 - val_loss: 8.5907\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8247 - val_loss: 8.6039\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 4.9323 - val_loss: 8.4512\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8740 - val_loss: 8.2930\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8761 - val_loss: 8.4258\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8773 - val_loss: 8.5841\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.8120 - val_loss: 8.6971\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8813 - val_loss: 8.4028\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9197 - val_loss: 8.3898\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8749 - val_loss: 8.2939\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.8509 - val_loss: 8.4374\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8276 - val_loss: 8.4926\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8675 - val_loss: 8.4449\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 4.8245 - val_loss: 8.4031\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8519 - val_loss: 8.4602\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8366 - val_loss: 8.6130\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8501 - val_loss: 8.5901\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8214 - val_loss: 8.4652\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.8892 - val_loss: 8.5195\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0712 - val_loss: 8.3950\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8161 - val_loss: 8.6060\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8232 - val_loss: 8.3789\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9945 - val_loss: 8.5350\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9446 - val_loss: 8.7493\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8503 - val_loss: 8.3562\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8675 - val_loss: 8.4787\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8551 - val_loss: 8.6497\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1167 - val_loss: 8.4586\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0672 - val_loss: 8.6279\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2820 - val_loss: 8.5344\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8462 - val_loss: 8.6586\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0801 - val_loss: 8.3577\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8212 - val_loss: 8.4482\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8062 - val_loss: 8.5254\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.8862 - val_loss: 8.5077\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 4.7958 - val_loss: 8.5303\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.8277 - val_loss: 8.5566\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.8003 - val_loss: 8.5136\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.8530 - val_loss: 8.5219\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.8295 - val_loss: 8.6784\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8217 - val_loss: 8.4036\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7999 - val_loss: 8.5926\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.8066 - val_loss: 8.6213\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7927 - val_loss: 8.4635\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8077 - val_loss: 8.4080\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 4.7748 - val_loss: 8.5148\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7938 - val_loss: 8.6486\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7741 - val_loss: 8.4319\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8086 - val_loss: 8.4856\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8837 - val_loss: 8.5547\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8041 - val_loss: 8.4573\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.8006 - val_loss: 8.4914\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7702 - val_loss: 8.5021\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8176 - val_loss: 8.5439\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7971 - val_loss: 8.4543\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8250 - val_loss: 8.5207\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7919 - val_loss: 8.4460\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7736 - val_loss: 8.5307\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7829 - val_loss: 8.6535\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.7950 - val_loss: 8.5186\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7518 - val_loss: 8.5755\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7707 - val_loss: 8.3873\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7603 - val_loss: 8.5951\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7635 - val_loss: 8.5753\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7885 - val_loss: 8.5373\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7632 - val_loss: 8.4952\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7760 - val_loss: 8.6947\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.7835 - val_loss: 8.6103\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7516 - val_loss: 8.6386\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8652 - val_loss: 8.6223\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7975 - val_loss: 8.5498\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7630 - val_loss: 8.5964\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7638 - val_loss: 8.3658\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7511 - val_loss: 8.4759\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7524 - val_loss: 8.5396\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9234 - val_loss: 8.5272\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7795 - val_loss: 8.7064\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7770 - val_loss: 8.5103\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.8096 - val_loss: 8.6788\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7725 - val_loss: 8.5422\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7665 - val_loss: 8.6796\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8236 - val_loss: 8.6816\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7453 - val_loss: 8.6369\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.8138 - val_loss: 8.6703\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8431 - val_loss: 8.5292\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7597 - val_loss: 8.6725\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.8246 - val_loss: 8.7433\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 4.8318 - val_loss: 8.4768\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9668 - val_loss: 8.5043\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9600 - val_loss: 8.6271\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.6997 - val_loss: 8.7153\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7781 - val_loss: 8.7206\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8299 - val_loss: 8.6068\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8254 - val_loss: 8.4135\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7450 - val_loss: 8.6645\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7976 - val_loss: 8.6051\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.8213 - val_loss: 8.5303\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7224 - val_loss: 8.5197\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7533 - val_loss: 8.7484\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7576 - val_loss: 8.5554\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7576 - val_loss: 8.4812\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7402 - val_loss: 8.6587\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7414 - val_loss: 8.8354\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7433 - val_loss: 8.7778\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7501 - val_loss: 8.5438\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7304 - val_loss: 8.7215\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7617 - val_loss: 8.6703\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 4.9358 - val_loss: 8.5280\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7227 - val_loss: 8.6283\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.7831 - val_loss: 8.7408\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7694 - val_loss: 8.6039\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.7493 - val_loss: 8.6329\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.6897 - val_loss: 8.6164\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7369 - val_loss: 8.5406\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.7843 - val_loss: 8.6781\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7101 - val_loss: 8.6607\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7016 - val_loss: 8.6889\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 4.7583 - val_loss: 8.6118\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7770 - val_loss: 8.5999\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7898 - val_loss: 8.7081\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.7624 - val_loss: 8.6407\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6785 - val_loss: 8.7269\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 4.7327 - val_loss: 8.7637\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7594 - val_loss: 8.8021\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7035 - val_loss: 8.5549\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.8336 - val_loss: 8.5389\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.8870 - val_loss: 8.7030\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7661 - val_loss: 8.6805\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7933 - val_loss: 8.6854\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7315 - val_loss: 8.6279\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7109 - val_loss: 8.5359\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6949 - val_loss: 8.6175\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7374 - val_loss: 8.7581\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7080 - val_loss: 8.7819\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7420 - val_loss: 8.7837\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7182 - val_loss: 8.5575\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7051 - val_loss: 8.4630\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.7771 - val_loss: 8.6192\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.8153 - val_loss: 8.7852\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8919 - val_loss: 8.6590\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9942 - val_loss: 8.7156\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8963 - val_loss: 8.9040\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7855 - val_loss: 8.9396\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7254 - val_loss: 8.5643\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7510 - val_loss: 8.5140\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6882 - val_loss: 8.7212\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6945 - val_loss: 8.6768\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7095 - val_loss: 8.7316\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6937 - val_loss: 8.7216\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7028 - val_loss: 8.6563\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.7011 - val_loss: 8.6299\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7474 - val_loss: 8.6174\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7030 - val_loss: 8.6473\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7579 - val_loss: 8.6288\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7633 - val_loss: 8.8662\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7747 - val_loss: 8.4826\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7317 - val_loss: 8.6312\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6779 - val_loss: 8.4668\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7860 - val_loss: 8.7373\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 4.7219 - val_loss: 8.6650\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6905 - val_loss: 8.6477\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7772 - val_loss: 8.8935\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6996 - val_loss: 8.6227\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 123us/step - loss: 4.6799 - val_loss: 8.6481\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7865 - val_loss: 8.6048\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6902 - val_loss: 8.6159\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6938 - val_loss: 8.7836\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7027 - val_loss: 8.6581\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 4.7329 - val_loss: 8.7279\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7300 - val_loss: 8.5907\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6824 - val_loss: 8.6726\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7141 - val_loss: 8.7447\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7489 - val_loss: 8.5972\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6597 - val_loss: 8.7706\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6792 - val_loss: 8.6827\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6823 - val_loss: 8.4945\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6772 - val_loss: 8.6356\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7148 - val_loss: 8.6529\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7211 - val_loss: 8.6658\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7491 - val_loss: 8.6470\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7710 - val_loss: 8.7304\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6893 - val_loss: 8.8217\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.7412 - val_loss: 8.7282\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6754 - val_loss: 8.5860\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.7219 - val_loss: 8.3795\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6605 - val_loss: 8.6515\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7119 - val_loss: 8.6680\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6813 - val_loss: 8.6552\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6658 - val_loss: 8.8138\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6840 - val_loss: 8.7783\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6934 - val_loss: 8.6781\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.7105 - val_loss: 8.6842\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6678 - val_loss: 8.7287\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6663 - val_loss: 8.7087\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6894 - val_loss: 8.6740\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6515 - val_loss: 8.6714\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7095 - val_loss: 8.7943\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6677 - val_loss: 8.6703\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6503 - val_loss: 8.6743\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6582 - val_loss: 8.6994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6778 - val_loss: 8.7133\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6974 - val_loss: 8.6423\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6771 - val_loss: 8.8512\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7058 - val_loss: 8.6352\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7454 - val_loss: 8.6285\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6650 - val_loss: 8.5122\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7027 - val_loss: 8.7912\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 4.7325 - val_loss: 8.6559\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 4.6849 - val_loss: 8.5675\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7615 - val_loss: 8.6987\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.7851 - val_loss: 8.7842\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.8288 - val_loss: 8.8106\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6133 - val_loss: 8.8852\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6716 - val_loss: 8.7680\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6485 - val_loss: 8.6055\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6915 - val_loss: 8.6349\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7587 - val_loss: 8.8575\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7505 - val_loss: 8.8671\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6749 - val_loss: 8.8419\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7809 - val_loss: 8.8185\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6818 - val_loss: 8.6725\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6487 - val_loss: 8.6383\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6420 - val_loss: 8.6689\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7107 - val_loss: 8.7210\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7219 - val_loss: 8.7105\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6520 - val_loss: 8.7808\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6918 - val_loss: 8.7233\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6870 - val_loss: 8.6663\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6565 - val_loss: 8.5888\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6345 - val_loss: 8.7603\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6825 - val_loss: 8.8010\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.7147 - val_loss: 8.7670\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7217 - val_loss: 8.6981\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7724 - val_loss: 8.7475\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7237 - val_loss: 8.5720\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.7758 - val_loss: 8.7782\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7257 - val_loss: 8.5164\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6477 - val_loss: 8.6933\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7157 - val_loss: 8.7171\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.7011 - val_loss: 8.7962\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6708 - val_loss: 8.6985\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6124 - val_loss: 8.7152\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6673 - val_loss: 8.7082\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6634 - val_loss: 8.6872\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6376 - val_loss: 8.6642\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6302 - val_loss: 8.7584\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6633 - val_loss: 8.7759\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.7266 - val_loss: 8.5943\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7624 - val_loss: 8.8812\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6438 - val_loss: 8.7513\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6789 - val_loss: 8.6416\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 4.6389 - val_loss: 8.7059\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6359 - val_loss: 8.7762\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6978 - val_loss: 8.6033\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6306 - val_loss: 8.7874\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6317 - val_loss: 8.7677\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8036 - val_loss: 8.7596\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6124 - val_loss: 8.8225\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6377 - val_loss: 8.6495\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6867 - val_loss: 8.7393\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6358 - val_loss: 8.7254\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6638 - val_loss: 8.8293\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6234 - val_loss: 8.7304\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6251 - val_loss: 8.7236\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7620 - val_loss: 8.7713\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6259 - val_loss: 8.8851\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6243 - val_loss: 8.7515\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6284 - val_loss: 8.7064\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6251 - val_loss: 8.6804\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6392 - val_loss: 8.7727\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6333 - val_loss: 8.8649\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6361 - val_loss: 8.7646\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6213 - val_loss: 8.7068\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6381 - val_loss: 8.7534\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6328 - val_loss: 8.8482\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6426 - val_loss: 8.7086\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6116 - val_loss: 8.7060\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 4.8001 - val_loss: 8.7989\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6677 - val_loss: 8.6554\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6236 - val_loss: 8.7177\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6252 - val_loss: 8.8389\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 4.6184 - val_loss: 8.8388\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6372 - val_loss: 8.7969\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6295 - val_loss: 8.7543\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6321 - val_loss: 8.8150\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6486 - val_loss: 8.6370\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5966 - val_loss: 8.8775\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.6061 - val_loss: 8.9189\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6264 - val_loss: 8.8218\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6495 - val_loss: 8.8092\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 4.7099 - val_loss: 8.8014\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.7057 - val_loss: 8.7668\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6406 - val_loss: 8.8795\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7599 - val_loss: 8.6585\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6908 - val_loss: 8.7742\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6152 - val_loss: 8.7207\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.7393 - val_loss: 8.7175\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6071 - val_loss: 8.9593\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6259 - val_loss: 8.9700\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6749 - val_loss: 8.8798\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9577 - val_loss: 8.5812\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.7261 - val_loss: 8.8257\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6898 - val_loss: 8.5161\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6379 - val_loss: 8.7939\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6313 - val_loss: 8.8088\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6496 - val_loss: 8.7217\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6161 - val_loss: 8.8331\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6237 - val_loss: 8.6434\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6965 - val_loss: 8.7072\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.7287 - val_loss: 8.5562\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.6845 - val_loss: 8.7551\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6497 - val_loss: 8.7694\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6643 - val_loss: 8.6609\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6378 - val_loss: 8.9190\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6139 - val_loss: 8.9116\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6454 - val_loss: 8.5967\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6057 - val_loss: 8.8011\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6047 - val_loss: 8.7096\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6164 - val_loss: 8.7493\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6727 - val_loss: 8.8978\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6089 - val_loss: 8.9095\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6145 - val_loss: 8.8134\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.6225 - val_loss: 8.8811\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6031 - val_loss: 8.8378\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5907 - val_loss: 8.7896\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6227 - val_loss: 8.6488\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 4.6678 - val_loss: 8.8214\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6878 - val_loss: 8.7892\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8547 - val_loss: 8.7086\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6922 - val_loss: 8.8639\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7388 - val_loss: 8.7678\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6985 - val_loss: 8.9362\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6013 - val_loss: 8.7859\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6560 - val_loss: 8.9227\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6142 - val_loss: 8.7455\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6289 - val_loss: 8.8266\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5971 - val_loss: 8.7647\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.6215 - val_loss: 8.8936\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6370 - val_loss: 8.6438\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6110 - val_loss: 8.8369\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6580 - val_loss: 8.7717\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.7243 - val_loss: 8.7514\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6413 - val_loss: 8.8319\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6306 - val_loss: 8.6834\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5973 - val_loss: 8.7989\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6877 - val_loss: 8.8047\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6191 - val_loss: 8.7456\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6430 - val_loss: 8.7619\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6812 - val_loss: 8.6900\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6245 - val_loss: 8.8573\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6390 - val_loss: 8.7287\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6250 - val_loss: 8.8452\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6669 - val_loss: 8.8252\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6111 - val_loss: 8.7470\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6355 - val_loss: 8.7572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6274 - val_loss: 8.7189\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6146 - val_loss: 8.6937\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5830 - val_loss: 8.7309\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6242 - val_loss: 8.5722\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6124 - val_loss: 8.6389\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6272 - val_loss: 8.7599\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6863 - val_loss: 8.9505\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8767 - val_loss: 8.8111\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6228 - val_loss: 8.8874\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6048 - val_loss: 8.8316\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6491 - val_loss: 8.8585\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6347 - val_loss: 8.8458\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5857 - val_loss: 8.7283\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6437 - val_loss: 8.7736\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5954 - val_loss: 8.8705\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.5457 - val_loss: 8.8085\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6282 - val_loss: 8.7973\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 4.6024 - val_loss: 8.7176\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6120 - val_loss: 8.9191\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6307 - val_loss: 8.7047\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6930 - val_loss: 8.8703\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6219 - val_loss: 8.8221\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6037 - val_loss: 8.7658\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5777 - val_loss: 8.7916\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.6255 - val_loss: 8.7452\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.6330 - val_loss: 8.6552\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6662 - val_loss: 8.8846\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6314 - val_loss: 8.8120\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6608 - val_loss: 8.8019\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5571 - val_loss: 8.7802\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6130 - val_loss: 8.8200\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7365 - val_loss: 8.9266\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7075 - val_loss: 8.9573\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5576 - val_loss: 8.6821\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.7276 - val_loss: 8.8806\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6185 - val_loss: 8.6710\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 4.6899 - val_loss: 8.7278\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6201 - val_loss: 8.7299\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6251 - val_loss: 8.7217\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6495 - val_loss: 8.8486\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6731 - val_loss: 8.7260\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6057 - val_loss: 9.0822\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6065 - val_loss: 8.7924\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6264 - val_loss: 8.8541\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6105 - val_loss: 8.7045\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5870 - val_loss: 8.6820\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6923 - val_loss: 8.7937\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5517 - val_loss: 8.6369\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6093 - val_loss: 8.7064\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.5587 - val_loss: 8.7928\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6130 - val_loss: 8.8932\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5697 - val_loss: 8.8327\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.5435 - val_loss: 8.7644\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6025 - val_loss: 8.7150\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5847 - val_loss: 8.7657\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5727 - val_loss: 8.7486\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6001 - val_loss: 8.8842\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5703 - val_loss: 8.6723\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5861 - val_loss: 8.7061\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5787 - val_loss: 8.6463\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6003 - val_loss: 8.8665\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6468 - val_loss: 8.7475\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6554 - val_loss: 8.6361\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5445 - val_loss: 8.8187\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5915 - val_loss: 8.7927\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5756 - val_loss: 8.7662\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5748 - val_loss: 8.7243\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.6043 - val_loss: 8.7541\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5726 - val_loss: 8.7937\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5980 - val_loss: 8.7939\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5914 - val_loss: 8.7750\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5933 - val_loss: 8.7531\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5900 - val_loss: 8.7801\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6090 - val_loss: 8.8938\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5819 - val_loss: 8.8588\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5950 - val_loss: 8.9104\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5820 - val_loss: 8.6885\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5990 - val_loss: 8.8163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6376 - val_loss: 8.8067\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.6195 - val_loss: 8.8038\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5903 - val_loss: 8.8884\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6319 - val_loss: 8.7818\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5674 - val_loss: 8.6690\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.881 - 0s 95us/step - loss: 4.5851 - val_loss: 8.7248\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5862 - val_loss: 8.8858\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5701 - val_loss: 8.7051\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.5804 - val_loss: 8.8492\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5631 - val_loss: 8.8132\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5563 - val_loss: 8.7336\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.6426 - val_loss: 8.8175\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5574 - val_loss: 8.7934\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5674 - val_loss: 8.7653\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5899 - val_loss: 8.9081\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5986 - val_loss: 8.7539\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5839 - val_loss: 8.8667\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5962 - val_loss: 8.6896\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6252 - val_loss: 8.5946\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6775 - val_loss: 8.9162\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5629 - val_loss: 8.9409\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5726 - val_loss: 8.9250\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.5536 - val_loss: 8.7406\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5951 - val_loss: 8.7432\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5883 - val_loss: 8.7372\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5475 - val_loss: 8.7767\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5648 - val_loss: 8.7899\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5542 - val_loss: 8.8670\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5707 - val_loss: 8.7874\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5488 - val_loss: 8.7985\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5699 - val_loss: 8.9555\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6224 - val_loss: 8.7208\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5569 - val_loss: 8.9018\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5735 - val_loss: 8.7559\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.6053 - val_loss: 8.8237\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5569 - val_loss: 8.6161\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 4.5941 - val_loss: 8.8348\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5827 - val_loss: 8.6556\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5993 - val_loss: 8.7252\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.6074 - val_loss: 8.8015\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5220 - val_loss: 8.7894\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.5440 - val_loss: 8.8533\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6182 - val_loss: 8.7836\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5399 - val_loss: 8.7572\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.5603 - val_loss: 8.9005\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 4.5573 - val_loss: 8.6991\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6020 - val_loss: 8.6964\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5364 - val_loss: 8.8782\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5698 - val_loss: 8.8495\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.6023 - val_loss: 8.8089\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.6515 - val_loss: 8.8238\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7005 - val_loss: 8.8275\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.6038 - val_loss: 8.9505\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.6404 - val_loss: 8.7623\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5953 - val_loss: 8.8118\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5759 - val_loss: 8.7376\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5662 - val_loss: 8.7380\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.7563 - val_loss: 8.9311\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.6521 - val_loss: 8.8755\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5568 - val_loss: 8.7249\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5879 - val_loss: 8.7492\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.5367 - val_loss: 8.8982\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.5778 - val_loss: 8.7822\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5890 - val_loss: 8.7089\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.5703 - val_loss: 8.8163\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.5377 - val_loss: 8.8662\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.5450 - val_loss: 8.9121\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 4.6625 - val_loss: 8.7528\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.5507 - val_loss: 8.8637\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5684 - val_loss: 8.7070\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5747 - val_loss: 8.7577\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.5470 - val_loss: 8.8110\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.5402 - val_loss: 8.8137\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 4.6094 - val_loss: 8.8214\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 211us/step - loss: 4.6846 - val_loss: 8.8455\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.6928 - val_loss: 8.8548\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.5366 - val_loss: 8.8620\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 87us/step - loss: 4.6635 - val_loss: 8.8625\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.5266 - val_loss: 8.8804\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.5697 - val_loss: 8.7742\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 4.5273 - val_loss: 8.8754\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.5307 - val_loss: 8.8573\n",
      "7.866986210063352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.888967  ,  0.24963434, -1.8840702 , -0.7922792 , -1.142299  ],\n",
       "        [-0.6400192 ,  1.0748415 , -1.1081294 ,  0.9746161 , -1.7024589 ],\n",
       "        [ 0.4886785 ,  0.05848885,  3.134974  , -2.2829292 , -1.4802653 ],\n",
       "        [-1.5796264 , -1.8094813 ,  2.5711396 , -3.7817187 , -0.07497106],\n",
       "        [-0.58117926,  0.5476945 ,  0.651195  ,  0.04548264, -0.75807357],\n",
       "        [ 1.1498816 ,  3.2590168 , -0.1013321 ,  0.27861935,  0.5381409 ],\n",
       "        [ 0.60065675, -0.41926327, -3.3119555 ,  0.10611278, -0.7128088 ]],\n",
       "       dtype=float32),\n",
       " array([0.9993308 , 0.17911163, 0.8320461 , 0.33863136, 1.3267918 ],\n",
       "       dtype=float32),\n",
       " array([[-0.21750154, -0.5083548 ,  1.4419355 , -0.83671844, -1.8347126 ,\n",
       "          0.9081314 ,  0.18256028,  2.272771  ,  0.33706826, -0.6974015 ],\n",
       "        [-1.606229  , -1.0703155 ,  0.51851195, -0.5597823 ,  3.1134708 ,\n",
       "         -0.7387621 , -1.1735978 ,  0.7468676 ,  1.546497  , -1.2376742 ],\n",
       "        [-1.033086  , -0.7762064 , -0.3126401 , -0.69000643,  2.312434  ,\n",
       "          2.4595945 ,  3.1366196 , -1.8816183 ,  2.49587   , -0.9767429 ],\n",
       "        [-1.1323999 , -1.6426419 , -1.9421703 , -1.3707237 ,  2.592547  ,\n",
       "          4.472818  , -0.6496791 , -0.9835288 ,  1.4667282 , -0.5555544 ],\n",
       "        [-1.8922372 , -0.98312765,  3.7816296 , -0.09003361,  0.04141055,\n",
       "         -2.288716  ,  0.813137  , -0.2636873 ,  0.3591098 , -1.3479977 ]],\n",
       "       dtype=float32),\n",
       " array([-0.27109337, -0.768663  ,  0.41758275, -0.6766489 , -3.0928395 ,\n",
       "        -1.1245911 ,  1.7303032 , -0.23652504,  0.8199989 , -0.8081762 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.73677707],\n",
       "        [ 0.5166198 ],\n",
       "        [ 9.024292  ],\n",
       "        [ 0.46667102],\n",
       "        [ 5.7792892 ],\n",
       "        [ 5.515099  ],\n",
       "        [-8.895172  ],\n",
       "        [ 6.7840114 ],\n",
       "        [ 5.5582047 ],\n",
       "        [ 0.47660193]], dtype=float32),\n",
       " array([4.5230174], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_sigmoid(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sigmoid_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 863us/step - loss: 521.8041 - val_loss: 410.2622\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 292.2786 - val_loss: 208.3092\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 141.1327 - val_loss: 104.0492\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 79.8268 - val_loss: 67.3619\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 62.1396 - val_loss: 60.0830\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.6303 - val_loss: 59.3591\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 62.3307 - val_loss: 59.3603\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 62.1434 - val_loss: 59.4088\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.7680 - val_loss: 59.6983\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.5603 - val_loss: 60.0027\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4267 - val_loss: 60.1141\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4142 - val_loss: 60.1930\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 61.5624 - val_loss: 60.0065\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4063 - val_loss: 60.2302\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 61.4236 - val_loss: 60.3159\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.4220 - val_loss: 60.4717\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 61.4378 - val_loss: 60.3688\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4385 - val_loss: 60.1762\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.4477 - val_loss: 60.2675\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4047 - val_loss: 60.2028\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 61.4180 - val_loss: 60.2715\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.5246 - val_loss: 60.0481\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 61.4079 - val_loss: 60.1655\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.4051 - val_loss: 60.2323\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.4359 - val_loss: 60.2235\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4105 - val_loss: 60.2654\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 61.4202 - val_loss: 60.1919\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 61.4080 - val_loss: 60.1801\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.4717 - val_loss: 59.9642\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4607 - val_loss: 60.0700\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.4307 - val_loss: 59.9897\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 61.3836 - val_loss: 60.1320\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3925 - val_loss: 60.2671\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 61.4058 - val_loss: 60.3227\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.3934 - val_loss: 60.2442\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.4131 - val_loss: 60.1325\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 61.4255 - val_loss: 60.2203\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3942 - val_loss: 60.1704\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 61.3878 - val_loss: 60.1498\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 61.3960 - val_loss: 60.1508\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3949 - val_loss: 60.1366\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.4033 - val_loss: 60.2775\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 61.4956 - val_loss: 60.0468\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 61.4112 - val_loss: 60.0239\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3604 - val_loss: 60.1353\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.4413 - val_loss: 60.3965\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.3973 - val_loss: 60.3171\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.3781 - val_loss: 60.1470\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.3485 - val_loss: 60.1561\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3538 - val_loss: 60.0352\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 118us/step - loss: 61.3400 - val_loss: 60.1139\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.3570 - val_loss: 60.1659\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.3764 - val_loss: 60.0254\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.3430 - val_loss: 60.2170\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.2914 - val_loss: 60.2604\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.2951 - val_loss: 60.3381\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.2470 - val_loss: 60.3445\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 61.2132 - val_loss: 60.3614\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.1958 - val_loss: 60.4814\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 61.1162 - val_loss: 60.4811\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 61.0632 - val_loss: 60.4676\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 61.0431 - val_loss: 60.5146\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0567 - val_loss: 60.4581\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 61.0528 - val_loss: 60.4302\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0454 - val_loss: 60.4759\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 61.0792 - val_loss: 60.4443\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0210 - val_loss: 60.5518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 61.0349 - val_loss: 60.6783\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 61.0320 - val_loss: 60.7162\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 61.0241 - val_loss: 60.7242\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 60.9335 - val_loss: 60.5868\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 57.1365 - val_loss: 47.8685\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 44.4368 - val_loss: 44.9113\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 41.9065 - val_loss: 41.8178\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 39.4241 - val_loss: 39.2365\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 37.4821 - val_loss: 37.3355\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 35.7087 - val_loss: 35.7973\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 33.9896 - val_loss: 34.1728\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 32.3980 - val_loss: 32.8761\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 31.0940 - val_loss: 31.7542\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 29.8032 - val_loss: 30.5082\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 28.6887 - val_loss: 29.4787\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 27.5286 - val_loss: 28.3359\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 26.4295 - val_loss: 27.2404\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 25.7186 - val_loss: 26.1470\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 24.6917 - val_loss: 25.2934\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 24.1709 - val_loss: 24.3524\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 23.4064 - val_loss: 23.7380\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 22.0746 - val_loss: 23.1132\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 21.3416 - val_loss: 22.8764\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 20.6361 - val_loss: 22.0222\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 20.1405 - val_loss: 21.3281\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 19.4189 - val_loss: 20.6455\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.9103 - val_loss: 20.0676\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 18.3878 - val_loss: 19.4758\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 17.9958 - val_loss: 19.0797\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 17.6093 - val_loss: 18.7345\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 17.2157 - val_loss: 18.4916\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.8569 - val_loss: 18.2784\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.5729 - val_loss: 18.0651\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 16.2402 - val_loss: 17.9776\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.8632 - val_loss: 17.5171\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.6119 - val_loss: 17.2041\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.2801 - val_loss: 16.9544\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 15.1075 - val_loss: 17.0082\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 14.7999 - val_loss: 16.8814\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.5935 - val_loss: 16.9415\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3212 - val_loss: 16.5440\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 14.1210 - val_loss: 16.1856\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.9520 - val_loss: 16.3659\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 13.8473 - val_loss: 16.2992\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.4865 - val_loss: 16.0318\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.4744 - val_loss: 15.8758\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.3443 - val_loss: 15.8616\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 13.4083 - val_loss: 16.6530\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 13.5512 - val_loss: 16.5282\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 13.0088 - val_loss: 16.3122\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.8607 - val_loss: 15.9921\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 12.4096 - val_loss: 15.5094\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.3299 - val_loss: 15.0135\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.1278 - val_loss: 15.0045\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 11.9154 - val_loss: 14.9136\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.8224 - val_loss: 14.7599\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.9897 - val_loss: 14.4891\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 11.7711 - val_loss: 14.5812\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 11.4817 - val_loss: 14.2339\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 11.2750 - val_loss: 14.8051\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 11.2761 - val_loss: 13.8907\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.9937 - val_loss: 13.8076\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.8147 - val_loss: 13.6204\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.8036 - val_loss: 13.5427\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 10.6055 - val_loss: 13.3902\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 10.5124 - val_loss: 13.3519\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.2268 - val_loss: 12.8419\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 10.2340 - val_loss: 12.9247\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.1867 - val_loss: 12.5575\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.0998 - val_loss: 12.5803\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.9397 - val_loss: 12.4399\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.9149 - val_loss: 13.3299\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.8932 - val_loss: 12.7610\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.4747 - val_loss: 12.6736\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.2984 - val_loss: 12.7245\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.8099 - val_loss: 12.2471\n",
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 8.4618 - val_loss: 11.6161\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 8.0654 - val_loss: 11.7063\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.8873 - val_loss: 11.2858\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7234 - val_loss: 11.8136\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7521 - val_loss: 11.1363\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4463 - val_loss: 11.0491\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2897 - val_loss: 11.0864\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.2486 - val_loss: 11.2682\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1280 - val_loss: 11.0343\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.9920 - val_loss: 11.0619\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0511 - val_loss: 10.7899\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.8030 - val_loss: 10.6513\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7635 - val_loss: 10.9387\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8283 - val_loss: 10.6901\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.8274 - val_loss: 10.7427\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6394 - val_loss: 10.9915\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5957 - val_loss: 10.9099\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6004 - val_loss: 10.9068\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.5335 - val_loss: 10.8227\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4526 - val_loss: 10.9613\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3952 - val_loss: 10.9623\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.3563 - val_loss: 11.7205\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6524 - val_loss: 11.0196\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4344 - val_loss: 11.5455\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5951 - val_loss: 10.5408\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4998 - val_loss: 10.5559\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3592 - val_loss: 10.5826\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.3686 - val_loss: 10.0036\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1883 - val_loss: 10.1001\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4016 - val_loss: 10.9004\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.0874 - val_loss: 10.9324\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.5597 - val_loss: 10.6529\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1612 - val_loss: 10.2564\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.2263 - val_loss: 9.9198\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2243 - val_loss: 10.3028\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2066 - val_loss: 9.9256\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1056 - val_loss: 9.5313\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.0907 - val_loss: 9.6195\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1572 - val_loss: 10.1048\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.1658 - val_loss: 9.6751\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1453 - val_loss: 9.8707\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1831 - val_loss: 9.8447\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0121 - val_loss: 9.5114\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0251 - val_loss: 9.6025\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9479 - val_loss: 9.6453\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9268 - val_loss: 9.5376\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9341 - val_loss: 9.5593\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9159 - val_loss: 9.4689\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9350 - val_loss: 9.5212\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9397 - val_loss: 9.3664\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.9330 - val_loss: 9.5006\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9508 - val_loss: 9.7213\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9529 - val_loss: 9.4891\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9280 - val_loss: 9.4441\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0090 - val_loss: 9.5944\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9052 - val_loss: 9.5112\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0062 - val_loss: 9.4448\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0522 - val_loss: 9.7166\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9376 - val_loss: 9.5548\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8915 - val_loss: 9.9229\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0572 - val_loss: 9.5489\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8956 - val_loss: 9.5188\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9324 - val_loss: 9.3700\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9285 - val_loss: 9.3986\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8919 - val_loss: 9.6532\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8585 - val_loss: 9.3745\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8579 - val_loss: 9.5685\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8797 - val_loss: 9.3711\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0963 - val_loss: 9.8082\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0363 - val_loss: 9.5241\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3478 - val_loss: 10.2818\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3607 - val_loss: 9.9254\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0160 - val_loss: 10.2903\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0957 - val_loss: 9.8163\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9470 - val_loss: 10.0202\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0398 - val_loss: 9.7044\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7573 - val_loss: 9.4936\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.9228 - val_loss: 9.4696\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7732 - val_loss: 9.2578\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7774 - val_loss: 9.3088\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7956 - val_loss: 9.4005\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.9206 - val_loss: 9.3636\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8125 - val_loss: 9.3011\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7634 - val_loss: 9.4693\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7399 - val_loss: 9.1327\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7520 - val_loss: 9.3741\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7890 - val_loss: 9.3209\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7937 - val_loss: 9.3759\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9192 - val_loss: 9.7170\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2989 - val_loss: 9.3990\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8792 - val_loss: 9.6189\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8984 - val_loss: 9.1459\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7639 - val_loss: 9.3683\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7217 - val_loss: 9.2744\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8697 - val_loss: 9.3746\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7702 - val_loss: 9.1147\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8067 - val_loss: 9.2963\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8905 - val_loss: 9.1892\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0654 - val_loss: 9.0696\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9730 - val_loss: 9.3670\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7327 - val_loss: 9.1348\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7380 - val_loss: 9.3655\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7131 - val_loss: 9.1767\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8305 - val_loss: 9.2511\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9217 - val_loss: 9.1352\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0351 - val_loss: 8.9605\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8332 - val_loss: 9.2096\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8048 - val_loss: 9.1432\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.7039 - val_loss: 9.3163\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8434 - val_loss: 9.1015\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8115 - val_loss: 9.3555\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7780 - val_loss: 8.9775\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9096 - val_loss: 9.3017\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9080 - val_loss: 8.9105\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1832 - val_loss: 9.4027\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9324 - val_loss: 8.9865\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9177 - val_loss: 9.2400\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8067 - val_loss: 9.1009\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6694 - val_loss: 9.1349\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8211 - val_loss: 8.9020\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7299 - val_loss: 9.4208\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7801 - val_loss: 9.1386\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6575 - val_loss: 9.4537\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.6517 - val_loss: 9.2267\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6397 - val_loss: 9.3751\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5729 - val_loss: 9.2283\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5845 - val_loss: 9.1818\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5789 - val_loss: 9.2569\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6702 - val_loss: 9.2459\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7942 - val_loss: 9.0884\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5881 - val_loss: 9.3798\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5217 - val_loss: 9.0999\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7122 - val_loss: 9.3964\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7689 - val_loss: 9.1627\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.5661 - val_loss: 9.3497\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5733 - val_loss: 9.2594\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5683 - val_loss: 9.3410\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6084 - val_loss: 9.4735\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5995 - val_loss: 9.2387\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6895 - val_loss: 9.4201\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6421 - val_loss: 9.5316\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6161 - val_loss: 9.4978\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4923 - val_loss: 9.2979\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5203 - val_loss: 9.3303\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5126 - val_loss: 9.5316\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5208 - val_loss: 9.3550\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4988 - val_loss: 9.4742\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6155 - val_loss: 9.3026\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5334 - val_loss: 9.5257\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7168 - val_loss: 9.2739\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5122 - val_loss: 9.2863\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5214 - val_loss: 9.2429\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6292 - val_loss: 9.3876\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6579 - val_loss: 9.3427\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6240 - val_loss: 9.4369\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.7062 - val_loss: 9.6505\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6900 - val_loss: 9.4716\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6854 - val_loss: 9.6156\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6194 - val_loss: 9.4996\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7051 - val_loss: 9.6629\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5307 - val_loss: 9.4946\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5023 - val_loss: 9.1750\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4925 - val_loss: 9.3947\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4854 - val_loss: 9.3220\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6323 - val_loss: 9.2596\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5270 - val_loss: 9.2940\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6970 - val_loss: 9.3771\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7334 - val_loss: 9.5003\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6180 - val_loss: 9.8105\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.6817 - val_loss: 9.7760\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6041 - val_loss: 9.7600\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5911 - val_loss: 9.9543\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5329 - val_loss: 9.7797\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4702 - val_loss: 9.1674\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5161 - val_loss: 9.3322\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4393 - val_loss: 9.2002\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5025 - val_loss: 9.4646\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5643 - val_loss: 9.3518\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5563 - val_loss: 9.2150\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4956 - val_loss: 9.1458\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4953 - val_loss: 9.1337\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5562 - val_loss: 9.1183\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5788 - val_loss: 9.2768\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.4612 - val_loss: 9.1448\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4076 - val_loss: 9.1515\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4825 - val_loss: 9.4664\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5619 - val_loss: 9.1428\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5609 - val_loss: 9.2678\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4775 - val_loss: 9.2234\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5114 - val_loss: 9.1887\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3921 - val_loss: 9.1899\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4537 - val_loss: 8.9947\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4223 - val_loss: 8.9754\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4629 - val_loss: 9.2677\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4576 - val_loss: 9.2109\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4889 - val_loss: 9.3112\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4111 - val_loss: 9.0430\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.5269 - val_loss: 9.1445\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4257 - val_loss: 9.0696\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5297 - val_loss: 9.0091\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4443 - val_loss: 9.3270\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4780 - val_loss: 9.1567\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5242 - val_loss: 8.9685\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5314 - val_loss: 9.4256\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5482 - val_loss: 9.1580\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5584 - val_loss: 9.1521\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6218 - val_loss: 9.1998\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5679 - val_loss: 9.2013\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4528 - val_loss: 9.1801\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5440 - val_loss: 9.2397\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4542 - val_loss: 9.1574\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4935 - val_loss: 9.2918\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5506 - val_loss: 9.0851\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3886 - val_loss: 9.1388\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5714 - val_loss: 9.1829\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4598 - val_loss: 9.1239\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4162 - val_loss: 8.9281\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4458 - val_loss: 9.1170\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3350 - val_loss: 8.9094\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5069 - val_loss: 9.0020\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5080 - val_loss: 9.0915\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3392 - val_loss: 9.1040\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4201 - val_loss: 9.2134\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4190 - val_loss: 8.9682\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3878 - val_loss: 9.0979\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4365 - val_loss: 9.0341\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3546 - val_loss: 8.9769\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4348 - val_loss: 8.8964\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3963 - val_loss: 8.9566\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3234 - val_loss: 8.9458\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3347 - val_loss: 9.1071\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3527 - val_loss: 8.9591\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4462 - val_loss: 8.8230\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.5148 - val_loss: 9.2270\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9988 - val_loss: 8.8679\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5029 - val_loss: 9.1565\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5328 - val_loss: 9.0413\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6968 - val_loss: 9.7394\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8010 - val_loss: 9.7697\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6014 - val_loss: 9.4594\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5937 - val_loss: 9.3493\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5613 - val_loss: 9.3239\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5297 - val_loss: 9.4603\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4702 - val_loss: 9.0107\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6197 - val_loss: 9.2663\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6886 - val_loss: 8.8354\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6495 - val_loss: 9.2872\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6059 - val_loss: 8.9268\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4516 - val_loss: 8.9665\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4547 - val_loss: 8.9952\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4064 - val_loss: 9.0169\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3367 - val_loss: 9.0858\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4977 - val_loss: 8.7896\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4935 - val_loss: 9.0644\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4109 - val_loss: 9.0778\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4008 - val_loss: 9.2430\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3459 - val_loss: 9.1349\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3972 - val_loss: 9.3243\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3943 - val_loss: 9.0303\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2637 - val_loss: 8.9999\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3261 - val_loss: 8.9959\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4532 - val_loss: 9.5227\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.384 - 0s 98us/step - loss: 5.4878 - val_loss: 9.0409\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4652 - val_loss: 9.6058\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4566 - val_loss: 9.5010\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5225 - val_loss: 9.2747\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4226 - val_loss: 8.9325\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3716 - val_loss: 8.9411\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2887 - val_loss: 9.0711\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3173 - val_loss: 8.8851\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3828 - val_loss: 9.1675\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4066 - val_loss: 8.8141\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3215 - val_loss: 9.1496\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3941 - val_loss: 8.9400\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4218 - val_loss: 9.2021\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2713 - val_loss: 8.9826\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2837 - val_loss: 8.9569\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3261 - val_loss: 9.0077\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2978 - val_loss: 9.0314\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2440 - val_loss: 9.1131\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2280 - val_loss: 8.9094\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5049 - val_loss: 8.8141\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4921 - val_loss: 8.9034\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2959 - val_loss: 9.0170\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2200 - val_loss: 8.9505\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3290 - val_loss: 9.1052\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5029 - val_loss: 9.0093\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4475 - val_loss: 9.1120\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6419 - val_loss: 8.8845\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4269 - val_loss: 9.0104\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6574 - val_loss: 8.9664\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6606 - val_loss: 9.3724\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4343 - val_loss: 8.9455\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2443 - val_loss: 8.7494\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2988 - val_loss: 9.1535\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3218 - val_loss: 8.7862\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3283 - val_loss: 8.8716\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2356 - val_loss: 8.8336\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3013 - val_loss: 9.2670\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3120 - val_loss: 8.9472\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3467 - val_loss: 9.0405\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3233 - val_loss: 8.8104\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2754 - val_loss: 9.0906\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3872 - val_loss: 8.9553\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4849 - val_loss: 8.9799\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2937 - val_loss: 8.7706\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2220 - val_loss: 9.1200\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2622 - val_loss: 8.8426\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3386 - val_loss: 9.2416\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3871 - val_loss: 8.7245\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2466 - val_loss: 9.3107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3971 - val_loss: 8.8271\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2872 - val_loss: 9.0707\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2497 - val_loss: 8.8368\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3084 - val_loss: 9.3108\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2746 - val_loss: 8.9231\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3225 - val_loss: 9.8890\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3799 - val_loss: 8.9919\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4214 - val_loss: 9.4417\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4755 - val_loss: 8.7962\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3160 - val_loss: 9.0698\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3367 - val_loss: 8.9795\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2945 - val_loss: 9.1033\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5153 - val_loss: 8.7408\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2980 - val_loss: 9.2160\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2174 - val_loss: 8.7938\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2268 - val_loss: 8.8940\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2410 - val_loss: 9.0051\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1614 - val_loss: 8.8563\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2468 - val_loss: 9.0568\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3077 - val_loss: 8.9563\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1676 - val_loss: 9.0703\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1685 - val_loss: 8.9984\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2085 - val_loss: 9.1800\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2735 - val_loss: 8.8149\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2999 - val_loss: 9.0628\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1561 - val_loss: 8.5684\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2406 - val_loss: 8.9374\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1560 - val_loss: 8.9038\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1614 - val_loss: 8.9838\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1664 - val_loss: 9.0326\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0991 - val_loss: 8.9321\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2973 - val_loss: 9.0060\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3863 - val_loss: 9.4159\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2998 - val_loss: 8.9353\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2963 - val_loss: 9.0478\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4411 - val_loss: 8.7793\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3328 - val_loss: 8.9338\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2110 - val_loss: 8.8528\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1576 - val_loss: 8.7804\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2031 - val_loss: 8.9560\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2148 - val_loss: 9.0868\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2037 - val_loss: 8.8213\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1988 - val_loss: 8.8669\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1960 - val_loss: 8.7808\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2721 - val_loss: 9.3097\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2798 - val_loss: 8.7879\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3113 - val_loss: 9.1795\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2402 - val_loss: 8.8078\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2729 - val_loss: 8.8755\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1431 - val_loss: 8.9180\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2108 - val_loss: 9.2063\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3862 - val_loss: 8.7181\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3001 - val_loss: 9.0758\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2007 - val_loss: 8.7891\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.2305 - val_loss: 8.6664\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1353 - val_loss: 8.8543\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2212 - val_loss: 9.4570\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1963 - val_loss: 8.9057\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3980 - val_loss: 9.2071\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1019 - val_loss: 8.6817\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2369 - val_loss: 9.0160\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2448 - val_loss: 9.0487\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2351 - val_loss: 9.1999\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2160 - val_loss: 9.2270\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1405 - val_loss: 8.8164\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1585 - val_loss: 8.8985\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1101 - val_loss: 8.9338\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2603 - val_loss: 8.7984\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2122 - val_loss: 9.2652\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1847 - val_loss: 8.7880\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1522 - val_loss: 9.0949\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1794 - val_loss: 8.7297\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1359 - val_loss: 8.9869\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1634 - val_loss: 8.8798\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2166 - val_loss: 8.9553\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0821 - val_loss: 8.8024\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0715 - val_loss: 9.1626\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2132 - val_loss: 9.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3367 - val_loss: 9.2790\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.2666 - val_loss: 8.9460\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1719 - val_loss: 9.0810\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2940 - val_loss: 8.8786\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1221 - val_loss: 9.0511\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.383 - 0s 106us/step - loss: 5.2435 - val_loss: 8.7682\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1567 - val_loss: 8.8146\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2437 - val_loss: 9.0791\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1960 - val_loss: 8.8331\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2699 - val_loss: 9.3644\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3062 - val_loss: 9.1063\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1513 - val_loss: 9.1509\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2159 - val_loss: 8.8203\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1410 - val_loss: 8.7936\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.1323 - val_loss: 8.7261\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0665 - val_loss: 9.2782\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2551 - val_loss: 8.7138\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2538 - val_loss: 9.1861\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1858 - val_loss: 8.6910\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1068 - val_loss: 8.9248\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.0860 - val_loss: 8.6723\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1221 - val_loss: 9.2881\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1655 - val_loss: 8.9436\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1035 - val_loss: 9.0832\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.0817 - val_loss: 8.9399\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2081 - val_loss: 8.9761\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 5.0839 - val_loss: 8.9242\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.1966 - val_loss: 8.6901\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 5.3501 - val_loss: 9.2694\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1698 - val_loss: 8.8793\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1972 - val_loss: 9.0718\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.1879 - val_loss: 8.6868\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.1814 - val_loss: 9.1520\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2324 - val_loss: 8.7316\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2455 - val_loss: 9.0812\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0934 - val_loss: 8.8971\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1782 - val_loss: 8.8135\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1848 - val_loss: 8.8485\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2290 - val_loss: 8.6650\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1495 - val_loss: 9.0198\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1718 - val_loss: 8.7449\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1404 - val_loss: 8.8612\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0878 - val_loss: 8.7008\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1760 - val_loss: 8.9324\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1658 - val_loss: 8.7918\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 112us/step - loss: 5.2115 - val_loss: 8.9375\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2002 - val_loss: 8.9313\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1365 - val_loss: 8.8692\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2962 - val_loss: 8.9877\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1679 - val_loss: 8.9155\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1311 - val_loss: 9.0477\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0809 - val_loss: 8.8710\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1527 - val_loss: 8.7706\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1177 - val_loss: 8.7576\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0924 - val_loss: 8.8601\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1983 - val_loss: 8.9068\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3568 - val_loss: 8.7501\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3069 - val_loss: 9.3214\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2432 - val_loss: 9.0548\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0630 - val_loss: 9.0469\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.0712 - val_loss: 9.0689\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2400 - val_loss: 8.8620\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1410 - val_loss: 9.2103\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0739 - val_loss: 8.9061\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1910 - val_loss: 9.3571\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2021 - val_loss: 8.8531\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1435 - val_loss: 9.2823\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2233 - val_loss: 8.8995\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3570 - val_loss: 9.5770\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0999 - val_loss: 8.7782\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1453 - val_loss: 9.0958\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1642 - val_loss: 8.7715\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1079 - val_loss: 9.0937\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0244 - val_loss: 8.8069\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0510 - val_loss: 9.0800\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1666 - val_loss: 8.7337\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1915 - val_loss: 9.4456\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.1138 - val_loss: 8.7629\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1687 - val_loss: 9.2377\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2129 - val_loss: 8.9080\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3450 - val_loss: 9.0609\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1805 - val_loss: 9.1091\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2316 - val_loss: 8.7506\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0819 - val_loss: 9.1789\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1236 - val_loss: 8.9317\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1253 - val_loss: 8.8787\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1421 - val_loss: 8.7205\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1537 - val_loss: 8.7260\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1723 - val_loss: 8.6856\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1420 - val_loss: 8.7214\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1413 - val_loss: 9.3275\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1720 - val_loss: 8.9653\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2046 - val_loss: 9.0040\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1373 - val_loss: 8.9653\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0509 - val_loss: 8.9518\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0465 - val_loss: 8.9833\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2577 - val_loss: 9.0082\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2511 - val_loss: 8.8546\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0959 - val_loss: 8.7752\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0245 - val_loss: 9.3633\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3255 - val_loss: 9.2579\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1393 - val_loss: 8.9572\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1573 - val_loss: 9.0628\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1899 - val_loss: 8.7925\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0957 - val_loss: 8.8242\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1664 - val_loss: 9.1435\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1368 - val_loss: 8.8876\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2211 - val_loss: 9.3648\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1805 - val_loss: 8.8430\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2104 - val_loss: 9.0498\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2280 - val_loss: 8.9432\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2537 - val_loss: 8.9541\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1488 - val_loss: 9.1484\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0664 - val_loss: 8.8457\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.0988 - val_loss: 8.7408\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1763 - val_loss: 9.3452\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0726 - val_loss: 8.8032\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0716 - val_loss: 9.2377\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0883 - val_loss: 8.9516\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1679 - val_loss: 9.1167\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0878 - val_loss: 8.8505\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0758 - val_loss: 8.8819\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0844 - val_loss: 8.7756\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9853 - val_loss: 9.2895\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1775 - val_loss: 9.3735\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3517 - val_loss: 8.8853\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0847 - val_loss: 9.2697\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1964 - val_loss: 9.4968\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1458 - val_loss: 9.0094\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.2714 - val_loss: 9.0951\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2448 - val_loss: 8.8405\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4933 - val_loss: 9.8769\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4071 - val_loss: 9.0660\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3435 - val_loss: 9.4387\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0603 - val_loss: 8.8775\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0024 - val_loss: 8.8306\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1151 - val_loss: 8.9268\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0516 - val_loss: 9.1200\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1372 - val_loss: 8.9585\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2111 - val_loss: 9.3459\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2211 - val_loss: 9.1602\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1134 - val_loss: 8.7351\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1493 - val_loss: 9.1835\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1899 - val_loss: 8.8407\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1577 - val_loss: 9.2282\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1638 - val_loss: 8.8414\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1409 - val_loss: 8.9944\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0752 - val_loss: 8.8908\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1133 - val_loss: 9.4750\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1913 - val_loss: 8.9379\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0863 - val_loss: 9.6486\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1226 - val_loss: 9.0121\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0399 - val_loss: 9.1144\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1882 - val_loss: 9.4729\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0561 - val_loss: 8.8856\n",
      "Epoch 688/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.3402 - val_loss: 9.5202\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2480 - val_loss: 8.9605\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2656 - val_loss: 9.1477\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1603 - val_loss: 9.1798\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1081 - val_loss: 9.0094\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0188 - val_loss: 9.0080\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0747 - val_loss: 8.9503\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9723 - val_loss: 9.0054\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0089 - val_loss: 9.1776\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0190 - val_loss: 9.1223\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0469 - val_loss: 8.9959\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0992 - val_loss: 8.9815\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0599 - val_loss: 9.2364\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0262 - val_loss: 8.9456\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0740 - val_loss: 8.9660\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2255 - val_loss: 9.1045\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1237 - val_loss: 9.1752\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0027 - val_loss: 9.4726\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2440 - val_loss: 9.2469\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.3891 - val_loss: 9.7108\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5753 - val_loss: 9.1938\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5483 - val_loss: 9.8160\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7345 - val_loss: 9.2821\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5873 - val_loss: 9.1732\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2719 - val_loss: 8.6702\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2154 - val_loss: 9.4056\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2615 - val_loss: 8.6994\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.0663 - val_loss: 8.8915\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0640 - val_loss: 8.8452\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.0312 - val_loss: 8.8729\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0527 - val_loss: 9.0031\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0524 - val_loss: 8.7574\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0239 - val_loss: 9.0941\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0106 - val_loss: 9.1660\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0437 - val_loss: 9.2538\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9808 - val_loss: 9.1015\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0142 - val_loss: 9.0339\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0283 - val_loss: 8.9353\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0648 - val_loss: 9.0694\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0631 - val_loss: 8.7636\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9920 - val_loss: 8.8923\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0202 - val_loss: 8.8584\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0661 - val_loss: 8.9478\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0517 - val_loss: 8.9824\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1123 - val_loss: 8.8616\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0661 - val_loss: 9.1966\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1575 - val_loss: 8.9673\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3779 - val_loss: 9.1480\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9790 - val_loss: 8.9767\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0274 - val_loss: 9.1484\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0090 - val_loss: 9.1078\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1526 - val_loss: 8.9106\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0189 - val_loss: 9.2765\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2543 - val_loss: 8.7462\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2990 - val_loss: 9.5681\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1311 - val_loss: 8.8668\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0820 - val_loss: 9.1189\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0718 - val_loss: 8.8946\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1668 - val_loss: 9.1102\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0119 - val_loss: 8.7669\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1041 - val_loss: 8.8900\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9991 - val_loss: 8.8168\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0060 - val_loss: 9.1621\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9747 - val_loss: 8.9031\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9984 - val_loss: 8.9498\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0614 - val_loss: 8.8684\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0232 - val_loss: 9.0473\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9699 - val_loss: 9.1602\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0442 - val_loss: 9.0026\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0703 - val_loss: 9.1337\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1523 - val_loss: 9.0333\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2564 - val_loss: 9.1775\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0974 - val_loss: 9.2031\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1127 - val_loss: 9.2383\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.0871 - val_loss: 9.2351\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0351 - val_loss: 9.0046\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0699 - val_loss: 8.9063\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1128 - val_loss: 9.0395\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.0516 - val_loss: 9.0057\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.1397 - val_loss: 8.8603\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0324 - val_loss: 9.1346\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0222 - val_loss: 8.7252\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2249 - val_loss: 9.3857\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1210 - val_loss: 8.8124\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2132 - val_loss: 9.3216\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4206 - val_loss: 8.7580\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3226 - val_loss: 9.0675\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1767 - val_loss: 8.9747\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0727 - val_loss: 8.9477\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1751 - val_loss: 8.7529\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1474 - val_loss: 8.7274\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1176 - val_loss: 8.7487\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1135 - val_loss: 8.9490\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.0562 - val_loss: 8.7457\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0594 - val_loss: 9.0647\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0262 - val_loss: 8.8561\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0509 - val_loss: 8.8256\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1471 - val_loss: 8.9095\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2579 - val_loss: 9.3067\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1435 - val_loss: 9.0631\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0405 - val_loss: 9.2147\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0524 - val_loss: 9.1329\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0431 - val_loss: 9.0456\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0333 - val_loss: 8.6411\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9531 - val_loss: 8.9493\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0518 - val_loss: 8.8714\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9845 - val_loss: 9.0288\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1081 - val_loss: 8.8502\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.0142 - val_loss: 9.3021\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9826 - val_loss: 8.9001\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0657 - val_loss: 9.6618\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2297 - val_loss: 8.9618\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3166 - val_loss: 9.4841\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2957 - val_loss: 8.9719\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0467 - val_loss: 9.8233\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0595 - val_loss: 8.9703\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0403 - val_loss: 9.5389\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2238 - val_loss: 8.7878\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1017 - val_loss: 8.9598\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0837 - val_loss: 8.9259\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1145 - val_loss: 8.8352\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0100 - val_loss: 8.8110\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9823 - val_loss: 8.6646\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0354 - val_loss: 9.2970\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9815 - val_loss: 9.2790\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.0654 - val_loss: 9.0079\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0023 - val_loss: 8.8145\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9222 - val_loss: 8.8633\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0128 - val_loss: 8.8779\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9457 - val_loss: 8.8114\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9655 - val_loss: 9.1659\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9973 - val_loss: 8.7610\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9426 - val_loss: 8.9173\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0303 - val_loss: 8.9878\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0454 - val_loss: 9.0996\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1617 - val_loss: 8.8961\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0920 - val_loss: 8.9508\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.0462 - val_loss: 8.7802\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9376 - val_loss: 9.0245\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9766 - val_loss: 9.0048\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1233 - val_loss: 9.3417\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5730 - val_loss: 8.9394\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6896 - val_loss: 9.6339\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2683 - val_loss: 9.2823\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0755 - val_loss: 9.2712\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1133 - val_loss: 8.9945\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1005 - val_loss: 9.2551\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1947 - val_loss: 8.7742\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.1155 - val_loss: 8.9933\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0793 - val_loss: 8.5839\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1751 - val_loss: 9.1403\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1161 - val_loss: 8.6978\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0825 - val_loss: 9.2042\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0412 - val_loss: 8.8887\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9681 - val_loss: 9.1043\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0000 - val_loss: 8.9228\n",
      "Epoch 844/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.0708 - val_loss: 9.0717\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0611 - val_loss: 8.9085\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0799 - val_loss: 9.0511\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0318 - val_loss: 9.0779\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0460 - val_loss: 8.9652\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0485 - val_loss: 8.9178\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9552 - val_loss: 8.8197\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9882 - val_loss: 9.0707\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0931 - val_loss: 8.8171\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 1.789 - 0s 98us/step - loss: 5.0851 - val_loss: 9.0412\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9967 - val_loss: 8.9432\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9733 - val_loss: 9.2476\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0499 - val_loss: 8.7824\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 4.9601 - val_loss: 9.0931\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0131 - val_loss: 8.9277\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1047 - val_loss: 8.9400\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0945 - val_loss: 9.1324\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.1559 - val_loss: 8.8119\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1898 - val_loss: 9.2630\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9675 - val_loss: 9.1298\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0285 - val_loss: 9.2044\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0145 - val_loss: 9.1411\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9485 - val_loss: 9.1620\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9420 - val_loss: 8.9825\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.0229 - val_loss: 9.0322\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9959 - val_loss: 8.6902\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1271 - val_loss: 9.0592\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9197 - val_loss: 9.0386\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9740 - val_loss: 8.8632\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9889 - val_loss: 9.1386\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9733 - val_loss: 9.1012\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0355 - val_loss: 9.2885\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1745 - val_loss: 8.8398\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9644 - val_loss: 9.1377\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.1020 - val_loss: 8.9546\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0610 - val_loss: 8.9421\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0381 - val_loss: 9.0059\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9393 - val_loss: 8.9572\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.180 - 0s 96us/step - loss: 5.0564 - val_loss: 8.8901\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9334 - val_loss: 8.9443\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9524 - val_loss: 8.9214\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2984 - val_loss: 9.0601\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4381 - val_loss: 9.0477\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1863 - val_loss: 9.4281\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1135 - val_loss: 9.0060\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0309 - val_loss: 9.0304\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9918 - val_loss: 9.1959\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0158 - val_loss: 8.9088\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0316 - val_loss: 9.2931\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0474 - val_loss: 8.7964\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0608 - val_loss: 9.0301\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8913 - val_loss: 8.8687\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9266 - val_loss: 9.1709\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9665 - val_loss: 9.1225\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2164 - val_loss: 9.2727\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1061 - val_loss: 8.7904\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 4.9915 - val_loss: 8.8194\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9587 - val_loss: 8.7812\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 4.9791 - val_loss: 8.7606\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0415 - val_loss: 8.7580\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9155 - val_loss: 8.8889\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1168 - val_loss: 8.7096\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0431 - val_loss: 8.9251\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9058 - val_loss: 8.9813\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9064 - val_loss: 8.8209\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0123 - val_loss: 8.9365\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9418 - val_loss: 8.8678\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0105 - val_loss: 9.2793\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0470 - val_loss: 8.7671\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0332 - val_loss: 8.8005\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 4.9243 - val_loss: 8.8883\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1715 - val_loss: 9.3956\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1752 - val_loss: 8.7513\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2047 - val_loss: 9.2196\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3083 - val_loss: 8.7805\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.0750 - val_loss: 8.8305\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0772 - val_loss: 8.5324\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 4.9754 - val_loss: 8.7554\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0901 - val_loss: 8.7683\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0726 - val_loss: 9.0351\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9694 - val_loss: 8.8094\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1491 - val_loss: 8.8573\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.9966 - val_loss: 8.9094\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9679 - val_loss: 8.9145\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1505 - val_loss: 9.1484\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.0622 - val_loss: 8.7869\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9863 - val_loss: 8.9925\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0968 - val_loss: 8.5363\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3171 - val_loss: 9.1125\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2196 - val_loss: 8.5847\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9694 - val_loss: 8.6884\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8900 - val_loss: 8.8847\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 4.9231 - val_loss: 8.7567\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9528 - val_loss: 8.6858\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9394 - val_loss: 8.6959\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 4.8955 - val_loss: 8.8086\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9404 - val_loss: 9.0807\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8820 - val_loss: 8.9210\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9092 - val_loss: 9.0229\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9149 - val_loss: 8.7353\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9503 - val_loss: 8.7954\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9484 - val_loss: 8.8285\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9328 - val_loss: 8.8871\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9771 - val_loss: 8.6431\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0084 - val_loss: 8.7644\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0909 - val_loss: 8.7546\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.0111 - val_loss: 9.0168\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1009 - val_loss: 8.7540\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.0623 - val_loss: 8.7848\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2094 - val_loss: 9.0276\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0954 - val_loss: 9.0159\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1201 - val_loss: 9.1098\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9486 - val_loss: 9.0243\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.0374 - val_loss: 8.9528\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1733 - val_loss: 9.1188\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.0311 - val_loss: 8.5993\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 4.9380 - val_loss: 8.6418\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9570 - val_loss: 8.5212\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 4.9137 - val_loss: 8.7409\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.0036 - val_loss: 8.9134\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9386 - val_loss: 9.1205\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9389 - val_loss: 8.6532\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9056 - val_loss: 8.7797\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0196 - val_loss: 8.9555\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9462 - val_loss: 8.6209\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9573 - val_loss: 8.6940\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.0391 - val_loss: 8.9996\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9091 - val_loss: 8.8038\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9949 - val_loss: 8.7072\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.8893 - val_loss: 8.7057\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0072 - val_loss: 8.5654\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0129 - val_loss: 8.7855\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.0436 - val_loss: 8.8180\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9745 - val_loss: 8.8227\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9158 - val_loss: 8.5809\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9952 - val_loss: 8.7676\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8939 - val_loss: 8.7764\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.8658 - val_loss: 8.7686\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9016 - val_loss: 8.8447\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9877 - val_loss: 8.6597\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3570 - val_loss: 9.3441\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2470 - val_loss: 9.0513\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1450 - val_loss: 9.2033\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 4.9831 - val_loss: 8.9968\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9751 - val_loss: 9.2360\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 4.9786 - val_loss: 9.1154\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0034 - val_loss: 8.8370\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0916 - val_loss: 9.0429\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 4.9621 - val_loss: 8.8371\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.0701 - val_loss: 8.6750\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9836 - val_loss: 8.7504\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 4.9209 - val_loss: 8.6685\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 4.9271 - val_loss: 8.7273\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9591 - val_loss: 8.7803\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 4.9411 - val_loss: 9.2502\n",
      "Epoch 999/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 92us/step - loss: 5.0738 - val_loss: 8.6573\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 4.9371 - val_loss: 8.9939\n",
      "6.303745310185319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.24589933, -0.4381972 , -1.6227452 , -0.603289  , -0.52485555],\n",
       "        [ 0.91198945, -1.4688308 , -0.3214242 , -0.79096806, -1.4117553 ],\n",
       "        [-1.1259958 , -0.22375403,  0.8041433 ,  0.29059538, -0.18910547],\n",
       "        [-0.58695287, -1.1370027 ,  0.17402044,  3.852136  ,  1.3392057 ],\n",
       "        [ 0.46357173, -0.01634329,  0.13015084,  0.10417926,  0.546555  ],\n",
       "        [ 2.3118691 , -0.71987253, -0.30418858, -1.1095387 ,  0.541116  ],\n",
       "        [-0.5996107 ,  0.5845429 ,  0.3385425 , -1.5930628 , -1.9905351 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.44093534,  0.72339076, -2.094088  , -0.9322232 , -1.6822913 ],\n",
       "       dtype=float32),\n",
       " array([[  1.7369509 ,   0.71561617,   0.40615484,  -1.7409168 ,\n",
       "           0.01267235,  -3.9111621 ,  -6.4561143 ,   0.13799948,\n",
       "         -12.427966  ,   4.881072  ],\n",
       "        [  0.9748949 ,   0.06858849,   0.29639632,  -0.531547  ,\n",
       "           3.8811436 ,  -0.07089885,  -0.01796756,   9.955484  ,\n",
       "          -1.7255751 ,  -0.04450022],\n",
       "        [  0.30254695,   1.4430655 ,  -1.4844733 ,  -0.27412352,\n",
       "           0.33726332,  -0.46674332,   0.6121103 ,   0.39500463,\n",
       "          -1.0995136 ,  -0.06516406],\n",
       "        [  1.5357022 ,   3.2644732 ,  -3.8257914 ,  -2.262143  ,\n",
       "          -0.2597409 ,  -4.9685984 ,  -1.6357383 ,  11.290551  ,\n",
       "          -0.3466697 ,  -0.34551316],\n",
       "        [  0.68533784,   1.1005069 ,  -0.49111933,  -0.72749025,\n",
       "          -0.05037245,   0.42288992,   4.030378  ,  -1.2918108 ,\n",
       "          -7.9800878 ,   4.6252413 ]], dtype=float32),\n",
       " array([ 3.231553  ,  2.5955164 , -1.70661   , -3.0403357 ,  0.8691323 ,\n",
       "        -1.2072474 , -0.66335446,  0.20217201,  0.9808637 ,  2.660877  ],\n",
       "       dtype=float32),\n",
       " array([[ 2.92302  ],\n",
       "        [ 3.0185637],\n",
       "        [ 9.007082 ],\n",
       "        [-3.1354394],\n",
       "        [ 3.2015045],\n",
       "        [-2.9510329],\n",
       "        [-2.9800391],\n",
       "        [ 3.0076895],\n",
       "        [-2.8087368],\n",
       "        [ 3.0153346]], dtype=float32),\n",
       " array([2.590535], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression_tanh(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_tanh_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.2003\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0911 - val_loss: 0.0093\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0426 - val_loss: 0.0142\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0305 - val_loss: 0.0109\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0168 - val_loss: 0.0073\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0158 - val_loss: 0.0072\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0125 - val_loss: 0.0062\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0049\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0079 - val_loss: 0.0037\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0074\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0103\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0050 - val_loss: 0.0080\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 118us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 118us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0075\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 111us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0074\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0064\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0065\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0053\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 102us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0063\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0045\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0054\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 115us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0057\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 121us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0012 - val_loss: 0.0044\n",
      "0.017513690516352654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.23961212, -0.10005765,  0.4337188 , -0.7782677 , -0.6052689 ],\n",
       "        [ 0.40180287,  0.8586173 , -0.72573864,  0.13209698,  0.42037785],\n",
       "        [-0.48923054, -0.00780849,  0.20838998,  0.7869779 ,  0.6560765 ],\n",
       "        [ 0.1757683 , -0.3669295 ,  0.67687535,  0.6000651 ,  0.7926839 ],\n",
       "        [-0.5199921 , -0.8445304 , -0.39495495,  0.1897551 ,  1.1849545 ],\n",
       "        [-0.18393384,  0.20032422, -0.90306413, -1.0262172 , -0.47639707],\n",
       "        [ 0.20471497,  1.045668  , -0.14460598,  0.37539184, -0.4446468 ],\n",
       "        [-0.1378106 , -0.25243625,  0.5125994 ,  0.34403026, -0.8605147 ],\n",
       "        [-0.4853744 ,  0.16694611,  0.469519  , -0.19028147, -1.0112673 ],\n",
       "        [ 0.9531317 ,  1.176241  , -0.10195202, -0.37183577,  0.38542664],\n",
       "        [-0.31505388,  0.32247886, -0.05885102,  0.23003154, -0.03723168],\n",
       "        [ 0.79285026, -0.08707581, -0.24562912, -0.27454564,  0.4054678 ],\n",
       "        [ 0.49495333, -0.2833381 , -0.79554164, -0.5960141 , -0.49090853],\n",
       "        [-0.7759226 , -0.7425841 , -0.07392242, -1.7033557 , -0.62436175],\n",
       "        [-0.38495204,  0.06454731, -0.4287306 ,  0.26382965, -0.2139635 ],\n",
       "        [ 0.55889475,  0.3463088 ,  0.5747544 ,  0.11678778,  0.52996194],\n",
       "        [ 0.00513783, -0.65777266,  0.56044304,  0.43878824,  0.1854341 ],\n",
       "        [-0.45754483,  0.4361372 ,  0.5349796 , -0.35877657, -0.54967505],\n",
       "        [-1.2328643 , -0.6450284 , -0.37611726, -0.37101647, -0.7371433 ],\n",
       "        [-0.61426747, -0.551788  , -0.16652735,  0.4211445 ,  0.689952  ],\n",
       "        [-0.50790626, -0.35963145,  0.0817001 ,  1.9934684 ,  0.5061957 ],\n",
       "        [-0.36002576, -0.3813755 , -0.06722651,  0.3943935 , -0.09455676]],\n",
       "       dtype=float32),\n",
       " array([-0.17439696, -0.08604547, -0.16280793,  0.7670787 ,  0.07175492],\n",
       "       dtype=float32),\n",
       " array([[-1.19181104e-01,  2.26631790e-01,  5.91421664e-01,\n",
       "         -1.60616398e-01, -7.51532257e-01,  5.51810741e-01,\n",
       "          2.86591172e-01, -2.41417915e-01, -2.23872378e-01,\n",
       "          5.63153505e-01],\n",
       "        [ 6.79989308e-02, -6.93194568e-02, -9.32252333e-02,\n",
       "          2.61675626e-01,  6.48681819e-02, -4.64624166e-01,\n",
       "          1.29769713e-01,  1.75531283e-01,  5.17578006e-01,\n",
       "         -4.49165434e-01],\n",
       "        [ 1.16132461e-01,  1.93190277e-01, -3.73406261e-01,\n",
       "         -4.00618613e-01,  4.75324363e-01, -4.23069775e-01,\n",
       "         -5.43869853e-01,  3.12016279e-01, -6.40833285e-04,\n",
       "         -3.11142534e-01],\n",
       "        [-1.88484639e-01,  9.16086286e-02,  5.18831432e-01,\n",
       "         -5.95888019e-01, -5.64615548e-01, -7.53859058e-02,\n",
       "         -2.93194145e-01, -5.29012561e-01, -6.52703643e-02,\n",
       "          4.83277231e-01],\n",
       "        [ 1.01935118e-01,  9.27467793e-02, -1.94213122e-01,\n",
       "          3.90369713e-01,  1.02643959e-01, -3.48127723e-01,\n",
       "          1.71649769e-01, -2.91055590e-01,  1.65646970e-01,\n",
       "         -4.36569989e-01]], dtype=float32),\n",
       " array([ 0.09655552,  0.11181812, -0.09062272,  0.17907871,  0.11118164,\n",
       "        -0.0369893 ,  0.1886934 ,  0.22040683,  0.02254923, -0.07598686],\n",
       "       dtype=float32),\n",
       " array([[ 0.01219617],\n",
       "        [-0.00480641],\n",
       "        [-0.08442123],\n",
       "        [ 0.28163502],\n",
       "        [ 0.3197627 ],\n",
       "        [-0.16734402],\n",
       "        [ 0.13329285],\n",
       "        [ 0.26135054],\n",
       "        [ 0.09706436],\n",
       "        [-0.15074234]], dtype=float32),\n",
       " array([0.19644487], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_linear(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_linear_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0138\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0202 - val_loss: 0.0150\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0130 - val_loss: 0.0087\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0137 - val_loss: 0.0043\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 129us/step - loss: 0.0146 - val_loss: 0.0081\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0125 - val_loss: 0.0054\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0071\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 272us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "0.01841886341571808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2553444 , -0.6048329 ,  0.13925914, -0.2901107 ,  0.97003555],\n",
       "        [-0.44323468, -0.45346352,  0.14030094,  0.5024598 ,  0.0510693 ],\n",
       "        [-0.38616627, -0.10870995, -0.54246926,  0.43301463, -0.65756726],\n",
       "        [ 0.14545336,  0.16296998,  0.01860991,  0.22750637, -0.26175448],\n",
       "        [-0.10918033,  0.11942675, -0.29830548,  0.14449613, -0.48625788],\n",
       "        [ 0.15462545, -0.40102383, -0.255068  ,  0.01886888,  0.96722656],\n",
       "        [ 0.09779498, -0.4672329 , -0.06711988,  0.20488538, -0.3621773 ],\n",
       "        [-0.4156864 , -0.67918634, -0.46295008,  0.6745928 ,  0.41088542],\n",
       "        [-0.23709333,  0.05634768, -0.37213194,  0.28506818,  0.00508556],\n",
       "        [ 0.15373012, -0.04981105, -0.21973981,  0.336623  ,  0.523039  ],\n",
       "        [-0.17774528,  0.00672319, -0.7691115 ,  0.6482836 , -0.1977602 ],\n",
       "        [-0.35601217, -0.6474001 , -0.51383847,  0.25640738,  0.20365772],\n",
       "        [-0.06519881, -0.12917477, -0.6707338 , -0.292353  ,  0.08296744],\n",
       "        [-0.2157051 , -0.6065147 , -0.6682185 ,  1.0632205 ,  1.3368343 ],\n",
       "        [-0.4341984 , -0.47345594, -0.5539041 ,  0.29703808,  0.2508555 ],\n",
       "        [-0.10049507, -0.43793017, -0.6704564 , -0.03501337,  0.6119804 ],\n",
       "        [-0.30108237, -0.05416621, -0.4757098 , -0.10803675, -0.15483642],\n",
       "        [-0.42097038, -0.5904578 , -0.663588  ,  1.024956  , -0.26190242],\n",
       "        [ 0.10239652,  0.05664233, -0.21294075, -0.4128163 ,  0.05470977],\n",
       "        [ 0.21387795,  0.07346434, -0.34855756,  0.339715  ,  0.01790154],\n",
       "        [ 0.23232332, -0.19296286, -0.01737051, -2.2629259 , -1.2836927 ],\n",
       "        [ 0.09000513, -0.52719355, -0.11021858,  0.38162476, -0.8489295 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.        , -0.307087  , -0.31717423, -0.4300136 , -0.30338046],\n",
       "       dtype=float32),\n",
       " array([[ 0.2774017 ,  0.47724432,  0.57057077,  0.4072855 ,  0.1678012 ,\n",
       "         -0.627478  ,  0.5479863 , -0.46208853, -0.60044765, -0.24729195],\n",
       "        [ 0.13473034, -0.05384496, -0.7570802 ,  0.01605305,  0.5807499 ,\n",
       "          0.02431387,  0.06612599,  0.24971014,  0.0540157 ,  0.20057456],\n",
       "        [ 0.3011181 , -0.0533157 ,  0.17743301,  0.720226  ,  0.25041878,\n",
       "          0.18324065, -0.25598902,  0.9271833 ,  0.4457404 ,  0.0335817 ],\n",
       "        [-0.9197534 , -0.42912573, -0.7348325 , -0.31592986,  0.33628353,\n",
       "         -0.07301992, -0.15292823, -0.27871463, -0.5464988 ,  0.6716755 ],\n",
       "        [ 0.00965235, -0.3691918 ,  0.36991572,  1.0651729 ,  0.12912945,\n",
       "         -0.09962124, -0.06425124, -0.08525766, -0.48081246, -0.57096136]],\n",
       "       dtype=float32),\n",
       " array([-0.11796969, -0.31604257, -0.17440863, -0.7740611 , -0.03667934,\n",
       "         0.        ,  0.        , -0.15610197,  0.        , -0.73448807],\n",
       "       dtype=float32),\n",
       " array([[ 0.07377659],\n",
       "        [-0.07525589],\n",
       "        [ 0.1785985 ],\n",
       "        [ 0.6231435 ],\n",
       "        [ 0.3164078 ],\n",
       "        [-0.41460988],\n",
       "        [ 0.43768674],\n",
       "        [-0.16986768],\n",
       "        [-0.6646351 ],\n",
       "        [ 0.6202191 ]], dtype=float32),\n",
       " array([0.04533989], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_relu(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_relu_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0507\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0451 - val_loss: 0.0288\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0459 - val_loss: 0.0278\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0418 - val_loss: 0.0508\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0410 - val_loss: 0.0296\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0483 - val_loss: 0.0355\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0401 - val_loss: 0.0248\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0403 - val_loss: 0.0306\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0252\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0384 - val_loss: 0.0294\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0375 - val_loss: 0.0264\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0379 - val_loss: 0.0292\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0264\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0280\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0377 - val_loss: 0.0279\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0296\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0381 - val_loss: 0.0276\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0386 - val_loss: 0.0271\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0375 - val_loss: 0.0291\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0382 - val_loss: 0.0256\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0366 - val_loss: 0.0308\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0385 - val_loss: 0.0248\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0395 - val_loss: 0.0272\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0259\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0265\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0260\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0300\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0378 - val_loss: 0.0255\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0375 - val_loss: 0.0271\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0297\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0250\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0391 - val_loss: 0.0261\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0296\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0397 - val_loss: 0.0255\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0403 - val_loss: 0.0254\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0380 - val_loss: 0.0308\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0249\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0388 - val_loss: 0.0288\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0389 - val_loss: 0.0304\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0253\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0382 - val_loss: 0.0264\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0314\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0395 - val_loss: 0.0254\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0384 - val_loss: 0.0289\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0364 - val_loss: 0.0249\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0388 - val_loss: 0.0281\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.041 - 0s 104us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0386 - val_loss: 0.0257\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0306\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0384 - val_loss: 0.0269\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0331\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0258\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0391 - val_loss: 0.0269\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0300\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0252\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0375 - val_loss: 0.0286\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0380 - val_loss: 0.0257\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.023 - 0s 107us/step - loss: 0.0367 - val_loss: 0.0330\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0380 - val_loss: 0.0250\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0378 - val_loss: 0.0285\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0373 - val_loss: 0.0268\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0384 - val_loss: 0.0294\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0249\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0383 - val_loss: 0.0279\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0287\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0285\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0304\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0389 - val_loss: 0.0257\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0387 - val_loss: 0.0310\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0376 - val_loss: 0.0255\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0290\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0373 - val_loss: 0.0254\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0265\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0365 - val_loss: 0.0306\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0381 - val_loss: 0.0267\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0304\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0266\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0282\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0379 - val_loss: 0.0271\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0385 - val_loss: 0.0303\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0379 - val_loss: 0.0252\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0285\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0275\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0374 - val_loss: 0.0268\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0255\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0379 - val_loss: 0.0274\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0378 - val_loss: 0.0305\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0365 - val_loss: 0.0251\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0390 - val_loss: 0.0263\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0383 - val_loss: 0.0310\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0381 - val_loss: 0.0262\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0271\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0375 - val_loss: 0.0267\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0382 - val_loss: 0.0259\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0308\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0252\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0257\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0263\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0391 - val_loss: 0.0249\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0410 - val_loss: 0.0321\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0364 - val_loss: 0.0248\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 808us/step - loss: 0.0392 - val_loss: 0.0265\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0389 - val_loss: 0.0325\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0249\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0384 - val_loss: 0.0282\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0256\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0282\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0282\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0289\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0290\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0294\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0375 - val_loss: 0.0273\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0383 - val_loss: 0.0253\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0366 - val_loss: 0.0319\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0388 - val_loss: 0.0284\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0252\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0377 - val_loss: 0.0270\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0373 - val_loss: 0.0326\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0366 - val_loss: 0.0250\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0400 - val_loss: 0.0249\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0367 - val_loss: 0.0330\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0383 - val_loss: 0.0268\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0251\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0372 - val_loss: 0.0296\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0268\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0252\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0378 - val_loss: 0.0274\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0296\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0374 - val_loss: 0.0266\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0262\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0372 - val_loss: 0.0297\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0376 - val_loss: 0.0263\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0287\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0379 - val_loss: 0.0274\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0394 - val_loss: 0.0309\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0395 - val_loss: 0.0248\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0393 - val_loss: 0.0302\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0375 - val_loss: 0.0262\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0302\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0262\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0276\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0307\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0259\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0290\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0376 - val_loss: 0.0292\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0367 - val_loss: 0.0304\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0271\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0248\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0377 - val_loss: 0.0288\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0276\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0374 - val_loss: 0.0275\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0255\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0289\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0375 - val_loss: 0.0259\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0292\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0288\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0376 - val_loss: 0.0267\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0258\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0296\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0374 - val_loss: 0.0284\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0260\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0299\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0280\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0375 - val_loss: 0.0258\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0383 - val_loss: 0.0258\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0299\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0264\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0374 - val_loss: 0.0284\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0258\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0375 - val_loss: 0.0278\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0381 - val_loss: 0.0313\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 102us/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0378 - val_loss: 0.0267\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0283\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0273\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0254\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0286\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0373 - val_loss: 0.0262\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0377 - val_loss: 0.0276\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0252\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0301\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0278\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0300\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0265\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0291\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0278\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0373 - val_loss: 0.0253\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0381 - val_loss: 0.0289\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0373 - val_loss: 0.0264\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0386 - val_loss: 0.0285\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0273\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0372 - val_loss: 0.0275\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0370 - val_loss: 0.0274\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0368 - val_loss: 0.0296\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0379 - val_loss: 0.0288\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0259\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0285\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0274\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0380 - val_loss: 0.0298\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0374 - val_loss: 0.0250\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0279\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0306\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0374 - val_loss: 0.0267\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0379 - val_loss: 0.0288\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0379 - val_loss: 0.0259\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0292\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0386 - val_loss: 0.0254\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0364 - val_loss: 0.0298\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0393 - val_loss: 0.0322\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0365 - val_loss: 0.0248\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0384 - val_loss: 0.0257\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0373 - val_loss: 0.0281\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0367 - val_loss: 0.0304\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0373 - val_loss: 0.0267\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0254\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0291\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0374 - val_loss: 0.0253\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0375 - val_loss: 0.0279\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0364 - val_loss: 0.0306\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0283\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0381 - val_loss: 0.0284\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0376 - val_loss: 0.0251\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0283\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0269\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0276\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0269\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0294\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0385 - val_loss: 0.0254\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0292\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0374 - val_loss: 0.0299\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0254\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0386 - val_loss: 0.0261\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0383 - val_loss: 0.0307\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0252\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0258\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0288\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0375 - val_loss: 0.0264\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0274\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0301\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0377 - val_loss: 0.0265\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0371 - val_loss: 0.0264\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0379 - val_loss: 0.0295\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0266\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0378 - val_loss: 0.0294\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0373 - val_loss: 0.0272\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0372 - val_loss: 0.0257\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0272\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0297\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0367 - val_loss: 0.0250\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0270\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0367 - val_loss: 0.0308\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0275\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0255\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0264\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0290\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0377 - val_loss: 0.0258\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0377 - val_loss: 0.0305\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0263\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0332\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0384 - val_loss: 0.0256\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 117us/step - loss: 0.0374 - val_loss: 0.0266\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0302\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0253\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0365 - val_loss: 0.0312\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0378 - val_loss: 0.0273\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0370 - val_loss: 0.0263\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0372 - val_loss: 0.0285\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0372 - val_loss: 0.0277\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0254\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0367 - val_loss: 0.0291\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0255\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0295\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0261\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0291\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0373 - val_loss: 0.0290\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0252\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0280\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0269\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0382 - val_loss: 0.0254\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0261\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0283\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0289\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0276\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0255\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0285\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0263\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0390 - val_loss: 0.0253\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0362 - val_loss: 0.0309\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0388 - val_loss: 0.0314\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0371 - val_loss: 0.0275\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0376 - val_loss: 0.0289\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0286\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0372 - val_loss: 0.0289\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0254\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0283\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0265\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0374 - val_loss: 0.0264\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0375 - val_loss: 0.0303\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0276\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0374 - val_loss: 0.0289\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0281\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0302\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0258\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0258\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0288\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0397 - val_loss: 0.0248\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0297\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0383 - val_loss: 0.0306\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0366 - val_loss: 0.0252\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0384 - val_loss: 0.0251\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0381 - val_loss: 0.0312\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0379 - val_loss: 0.0262\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0367 - val_loss: 0.0296\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0288\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0268\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0258\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0258\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0285\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0372 - val_loss: 0.0265\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0299\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0265\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0291\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0372 - val_loss: 0.0262\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0377 - val_loss: 0.0317\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0381 - val_loss: 0.0276\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0280\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0277\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.022 - 0s 111us/step - loss: 0.0374 - val_loss: 0.0261\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0383 - val_loss: 0.0288\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0283\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0279\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0273\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0279\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0279\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0375 - val_loss: 0.0276\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0302\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0379 - val_loss: 0.0275\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0368 - val_loss: 0.0280\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0383 - val_loss: 0.0286\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0376 - val_loss: 0.0251\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0383 - val_loss: 0.0286\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0375 - val_loss: 0.0275\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0256\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0302\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0270\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0281\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0373 - val_loss: 0.0267\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0262\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0259\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0308\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0268\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0372 - val_loss: 0.0252\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0287\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0278\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0259\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0374 - val_loss: 0.0295\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0261\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0256\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0374 - val_loss: 0.0287\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0258\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 130us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0270\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0268\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0324\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0377 - val_loss: 0.0260\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0262\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0366 - val_loss: 0.0256\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0274\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0261\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0269\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0372 - val_loss: 0.0280\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0288\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0381 - val_loss: 0.0303\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0372 - val_loss: 0.0261\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0287\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0375 - val_loss: 0.0276\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0374 - val_loss: 0.0286\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0282\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0372 - val_loss: 0.0281\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0267\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0294\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0252\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0377 - val_loss: 0.0273\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0373 - val_loss: 0.0278\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0367 - val_loss: 0.0260\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0372 - val_loss: 0.0271\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0269\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0367 - val_loss: 0.0294\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0380 - val_loss: 0.0284\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0248\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0376 - val_loss: 0.0274\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0380 - val_loss: 0.0316\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0263\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0376 - val_loss: 0.0254\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0373 - val_loss: 0.0279\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0260\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0368 - val_loss: 0.0293\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0275\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0377 - val_loss: 0.0278\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0377 - val_loss: 0.0253\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0377 - val_loss: 0.0310\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0269\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0257\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0286\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0289\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0258\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0275\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0270\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0272\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0266\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0281\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0282\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0266\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0388 - val_loss: 0.0250\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0381 - val_loss: 0.0332\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0263\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0253\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0274\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0327\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0383 - val_loss: 0.0279\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0395 - val_loss: 0.0248\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0383 - val_loss: 0.0293\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0376 - val_loss: 0.0286\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0258\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0258\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0382 - val_loss: 0.0317\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0381 - val_loss: 0.0260\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0381 - val_loss: 0.0253\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0294\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0383 - val_loss: 0.0289\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0365 - val_loss: 0.0250\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0377 - val_loss: 0.0268\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0277\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0372 - val_loss: 0.0259\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0380 - val_loss: 0.0302\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0256\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0277\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0385 - val_loss: 0.0297\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0286\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0282\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0296\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0367 - val_loss: 0.0253\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0382 - val_loss: 0.0260\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0370 - val_loss: 0.0314\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0375 - val_loss: 0.0267\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0252\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0379 - val_loss: 0.0278\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0261\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0372 - val_loss: 0.0282\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0261\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0376 - val_loss: 0.0269\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0367 - val_loss: 0.0289\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0385 - val_loss: 0.0295\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0379 - val_loss: 0.0249\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0379 - val_loss: 0.0271\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0373 - val_loss: 0.0326\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0380 - val_loss: 0.0269\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0372 - val_loss: 0.0256\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0382 - val_loss: 0.0279\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0366 - val_loss: 0.0250\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0379 - val_loss: 0.0263\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0333\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0266\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0384 - val_loss: 0.0251\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0300\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0281\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0259\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0254\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0282\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0295\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0257\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0265\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0282\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0372 - val_loss: 0.0284\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0368 - val_loss: 0.0262\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0254\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0281\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0273\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0367 - val_loss: 0.0282\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0273\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0264\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0369 - val_loss: 0.0271\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0371 - val_loss: 0.0291\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0371 - val_loss: 0.0270\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0377 - val_loss: 0.0285\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0272\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0258\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0375 - val_loss: 0.0283\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0272\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0372 - val_loss: 0.0270\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0371 - val_loss: 0.0290\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0372 - val_loss: 0.0272\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0380 - val_loss: 0.0321\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0253\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0379 - val_loss: 0.0252\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0379 - val_loss: 0.0307\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0269\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0253\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0370 - val_loss: 0.0282\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0377 - val_loss: 0.0289\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0253\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0285\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0375 - val_loss: 0.0298\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0259\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0376 - val_loss: 0.0265\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0374 - val_loss: 0.0291\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0374 - val_loss: 0.0281\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0365 - val_loss: 0.0253\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0385 - val_loss: 0.0258\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0308\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0269\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0267\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0367 - val_loss: 0.0291\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0373 - val_loss: 0.0282\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0367 - val_loss: 0.0257\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0373 - val_loss: 0.0263\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0376 - val_loss: 0.0282\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0251\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0263\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0302\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0257\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0284\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0283\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0373 - val_loss: 0.0283\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0282\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0367 - val_loss: 0.0281\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0376 - val_loss: 0.0296\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0374 - val_loss: 0.0256\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0369 - val_loss: 0.0278\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0383 - val_loss: 0.0289\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0280\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0365 - val_loss: 0.0251\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0376 - val_loss: 0.0263\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0371 - val_loss: 0.0307\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0375 - val_loss: 0.0264\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0259\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0371 - val_loss: 0.0267\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0375 - val_loss: 0.0281\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0377 - val_loss: 0.0256\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0377 - val_loss: 0.0296\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0271\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0375 - val_loss: 0.0290\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0365 - val_loss: 0.0256\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0384 - val_loss: 0.0309\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0374 - val_loss: 0.0265\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.033 - 0s 105us/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0303\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0375 - val_loss: 0.0284\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0377 - val_loss: 0.0278\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0269\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0391 - val_loss: 0.0255\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0359 - val_loss: 0.0329\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0386 - val_loss: 0.0289\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0377 - val_loss: 0.0268\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0274\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0270\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0265\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0296\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0375 - val_loss: 0.0268\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0371 - val_loss: 0.0265\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0372 - val_loss: 0.0296\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0264\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0384 - val_loss: 0.0250\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0371 - val_loss: 0.0304\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0377 - val_loss: 0.0284\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0273\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0266\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0286\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0372 - val_loss: 0.0269\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0371 - val_loss: 0.0257\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0283\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0370 - val_loss: 0.0257\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0274\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0369 - val_loss: 0.0265\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0371 - val_loss: 0.0284\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0370 - val_loss: 0.0260\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0271\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0369 - val_loss: 0.0275\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0371 - val_loss: 0.0276\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0299\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0366 - val_loss: 0.0294\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0373 - val_loss: 0.0292\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0372 - val_loss: 0.0260\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0374 - val_loss: 0.0269\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0370 - val_loss: 0.0276\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0376 - val_loss: 0.0286\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0369 - val_loss: 0.0261\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0377 - val_loss: 0.0271\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0369 - val_loss: 0.0255\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0275\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0295\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0260\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0379 - val_loss: 0.0311\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0268\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0369 - val_loss: 0.0257\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0368 - val_loss: 0.0279\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0292\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0373 - val_loss: 0.0278\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0370 - val_loss: 0.0273\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0369 - val_loss: 0.0263\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0368 - val_loss: 0.0278\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0369 - val_loss: 0.0291\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0266\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0370 - val_loss: 0.0277\n",
      "0.054668061435222626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.2734856 ,  0.37082425, -0.62255883,  0.1072548 , -0.44116533],\n",
       "        [-0.09796852,  0.05982301, -0.72311443, -0.08237629,  0.4259012 ],\n",
       "        [-0.2411061 , -0.36536554, -0.03889912, -0.38626286, -0.23531012],\n",
       "        [-0.79316694, -0.10201132, -0.5673435 ,  0.4023533 , -0.34997788],\n",
       "        [-0.3339863 ,  0.17116085,  0.19883928, -0.441598  , -0.1059728 ],\n",
       "        [-0.66712797,  0.02015126,  0.25129876, -0.11775672,  0.10107872],\n",
       "        [-0.1000431 , -0.05776119, -0.18173249,  0.01175715, -0.34270334],\n",
       "        [ 0.00133208, -0.23219587, -0.6132708 , -0.2583318 , -0.09436658],\n",
       "        [-0.32274204, -0.2266752 ,  0.01882485, -0.72619116, -0.11201993],\n",
       "        [-0.46944308, -0.43333152, -0.49910417, -0.3487509 ,  0.17863068],\n",
       "        [-0.5165795 ,  0.46585014, -0.29075336,  0.02686631,  0.3483626 ],\n",
       "        [ 0.05901462, -0.12202737, -0.26754102, -0.60565716, -0.27554104],\n",
       "        [ 0.20894448, -0.2810589 , -0.5025081 , -0.26723394, -0.45516056],\n",
       "        [-0.5797649 , -0.16902101, -0.08997033, -0.01823959, -0.17162839],\n",
       "        [ 0.00256656, -0.36670873,  0.19278452, -0.45539647,  0.41434345],\n",
       "        [-0.50497025, -0.09321007, -0.4170878 , -0.41529062, -0.41364828],\n",
       "        [-0.2209329 , -0.17411211, -0.44629303, -0.7615619 ,  0.1491715 ],\n",
       "        [ 0.04961199,  0.11144605,  0.11125478, -0.21521062, -0.19724432],\n",
       "        [-0.43660071,  0.315192  ,  0.30334714, -0.31520897,  0.3237951 ],\n",
       "        [-0.5660223 , -0.3814646 ,  0.04175861, -0.06847458, -0.11397284],\n",
       "        [ 0.03582994,  0.17736807, -0.20126338, -0.66053605, -0.19906339],\n",
       "        [ 0.24423473, -0.20420417, -0.37847883, -0.35693672, -0.31252596]],\n",
       "       dtype=float32),\n",
       " array([-0.2252851 ,  0.        , -0.26196092, -0.31358936,  0.        ],\n",
       "       dtype=float32),\n",
       " array([[ 0.21433654, -0.1349615 , -0.934758  ,  0.9265137 ,  0.03504274,\n",
       "          0.2935327 , -0.8207566 , -0.87903196,  0.21583709,  0.20526809],\n",
       "        [ 0.54677075, -0.301578  ,  0.5949063 ,  0.2217229 ,  0.46100038,\n",
       "          0.51194996,  0.5155867 ,  0.10295248, -0.15797967,  0.11445487],\n",
       "        [ 0.18218413, -0.6611371 ,  0.24172796,  0.00371868,  0.1663077 ,\n",
       "         -0.35667413,  0.49549192,  0.8701623 ,  0.0491057 ,  0.81971294],\n",
       "        [-0.22857498,  0.02383151, -0.8153884 , -0.09427459, -0.5564393 ,\n",
       "          0.69451165,  0.00222393, -0.689048  ,  0.12233549, -0.68932277],\n",
       "        [-0.2602402 ,  0.09513468, -0.2624942 ,  0.49536365,  0.42102712,\n",
       "          0.5076371 ,  0.00325418, -0.54665816, -0.05369782,  0.16182554]],\n",
       "       dtype=float32),\n",
       " array([-0.2834406 , -4.078218  , -0.75678164, -0.38140944, -0.48699003,\n",
       "        -0.454978  , -0.8936189 , -0.63158846, -0.26271296, -0.2099797 ],\n",
       "       dtype=float32),\n",
       " array([[ 4.8463303e-01],\n",
       "        [ 3.9939993e-04],\n",
       "        [-1.3029416e-01],\n",
       "        [ 3.4216768e-01],\n",
       "        [-2.1720824e-01],\n",
       "        [ 2.6952931e-01],\n",
       "        [-1.0257978e-01],\n",
       "        [-1.6560750e-01],\n",
       "        [ 5.3371280e-01],\n",
       "        [-5.2347457e-01]], dtype=float32),\n",
       " array([-0.02343157], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_sigmoid(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sigmoid_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0251\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0320 - val_loss: 0.0124\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0286 - val_loss: 0.0085\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0197 - val_loss: 0.0106\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0193 - val_loss: 0.0053\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0167 - val_loss: 0.0078\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0205 - val_loss: 0.0087\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0065\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0068\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0070\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 105us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 142us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 109us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 135us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0069\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 120us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 140us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 105us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 126us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "0.006723756901919842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.5889044 ,  0.19392361, -0.4884638 , -0.09617858, -0.42845476],\n",
       "        [ 0.02853404, -0.24259953, -0.32928628, -0.6170484 , -0.05783172],\n",
       "        [-0.00337238,  0.17819785, -0.4647619 ,  0.24383534,  0.43667543],\n",
       "        [-0.32873204, -0.08096864,  0.11507086, -0.6562619 , -0.83762246],\n",
       "        [-0.6884135 , -0.02185112,  0.21333525, -0.2928    ,  0.32583094],\n",
       "        [-0.7006366 ,  0.3433212 , -0.29000813, -0.02166773,  0.11607777],\n",
       "        [ 0.03754661,  0.34486803, -0.5789056 , -0.6496163 ,  0.14209476],\n",
       "        [-0.5123943 , -0.30852157, -0.6864574 ,  0.16015293, -0.2194032 ],\n",
       "        [-0.5204131 ,  0.17659007,  0.223694  , -0.6997629 ,  0.8458895 ],\n",
       "        [-0.08449412, -0.10583706, -0.62992996, -0.13268428, -0.37106642],\n",
       "        [-0.69442636, -0.2689401 , -0.3025766 , -0.07355729,  0.06909021],\n",
       "        [-0.209375  , -0.3966543 , -0.6346901 , -0.25619835, -1.5227519 ],\n",
       "        [-0.8082905 , -0.27908117, -0.16357328, -0.3187729 , -0.22881417],\n",
       "        [-0.07374743,  1.8875779 , -0.08203124,  0.00874932, -0.5298089 ],\n",
       "        [-0.68609273, -0.06472073, -0.07876538, -0.31394973,  0.43813962],\n",
       "        [-0.4176848 , -0.18422663, -0.334792  , -0.02187644, -0.29448757],\n",
       "        [-0.534286  , -0.525514  ,  0.15338866, -0.3910449 , -1.0440519 ],\n",
       "        [-0.8303959 ,  0.9821304 ,  0.05607864, -0.05721864,  1.4073613 ],\n",
       "        [-0.7234705 ,  0.13968983,  0.20701124, -0.83968973,  1.4941684 ],\n",
       "        [ 0.05448053,  0.514667  , -0.20274907, -0.29328167, -0.199728  ],\n",
       "        [-0.11131684, -2.0012898 , -0.5468095 ,  0.10551362, -0.1332631 ],\n",
       "        [-0.00931031,  0.3554843 , -0.69894695,  0.37579587,  0.39121094]],\n",
       "       dtype=float32),\n",
       " array([-0.40019518,  0.35506842, -0.24913287, -0.24254073, -0.04861841],\n",
       "       dtype=float32),\n",
       " array([[-0.3792194 , -0.14782594, -0.4531253 , -0.40763324,  0.02009314,\n",
       "         -0.61026675,  0.5333529 , -1.0456352 , -0.10721984,  0.5458743 ],\n",
       "        [ 0.31730217,  0.1874435 , -0.39123273, -0.39779618, -0.21839336,\n",
       "          0.3298464 , -0.17899634, -0.28868675,  0.25593978, -0.3063896 ],\n",
       "        [-0.62833   ,  0.7563639 , -0.7108949 , -0.5146562 ,  0.02429685,\n",
       "          0.3748075 , -0.26423576, -0.3819198 ,  0.34708822,  0.53820103],\n",
       "        [ 0.42040053, -0.52898806,  0.24310388, -0.08471709, -0.0587415 ,\n",
       "          0.23938785, -0.205183  , -0.07390857, -0.2682683 ,  0.31098154],\n",
       "        [ 0.7202813 , -0.22348548,  0.81781316, -0.16061594,  0.26057363,\n",
       "          0.30089673,  0.88320816,  0.6271188 , -0.38492626, -0.04328844]],\n",
       "       dtype=float32),\n",
       " array([-0.1625086 , -0.05885264,  0.29412204,  0.2762937 ,  0.07314558,\n",
       "        -0.18881463, -0.05816456,  0.10230943, -0.08935358,  0.16158864],\n",
       "       dtype=float32),\n",
       " array([[ 0.2046605 ],\n",
       "        [ 0.0458639 ],\n",
       "        [-0.32819554],\n",
       "        [-0.118495  ],\n",
       "        [-0.04793009],\n",
       "        [ 0.17013809],\n",
       "        [-0.16611521],\n",
       "        [-0.08506886],\n",
       "        [ 0.27802387],\n",
       "        [-0.21870142]], dtype=float32),\n",
       " array([0.33328682], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression_tanh(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_tanh_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 36.1617 - val_loss: 33.8020\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 33.1974 - val_loss: 29.5365\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.5326 - val_loss: 24.3018\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.9279 - val_loss: 18.1664\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 19.3101 - val_loss: 11.4911\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.9997 - val_loss: 5.4038\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8893 - val_loss: 1.9907\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3443 - val_loss: 3.4326\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3663 - val_loss: 8.1224\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3234 - val_loss: 9.5358\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 6.3301 - val_loss: 7.4774\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 5.5806 - val_loss: 4.4669\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5358 - val_loss: 2.1800\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6972 - val_loss: 1.0538\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7043 - val_loss: 0.8114\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 174us/step - loss: 0.4916 - val_loss: 1.0233\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.7335 - val_loss: 1.3704\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 1.1287 - val_loss: 1.6780\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4822 - val_loss: 1.8697\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6936 - val_loss: 1.9224\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7274 - val_loss: 1.8409\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 1.5916 - val_loss: 1.6485\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3256 - val_loss: 1.3849\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.9909 - val_loss: 1.1008\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6595 - val_loss: 0.8489\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3980 - val_loss: 0.6711\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2517 - val_loss: 0.5863\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2310 - val_loss: 0.5829\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3084 - val_loss: 0.6229\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4276 - val_loss: 0.6586\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 185us/step - loss: 0.5262 - val_loss: 0.6543\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5604 - val_loss: 0.5998\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5194 - val_loss: 0.5080\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.4224 - val_loss: 0.4033\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.3037 - val_loss: 0.3083\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1966 - val_loss: 0.2369\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1227 - val_loss: 0.1930\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0892 - val_loss: 0.1724\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0910 - val_loss: 0.1669\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1155 - val_loss: 0.1672\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1480 - val_loss: 0.1654\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1753 - val_loss: 0.1570\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.1887 - val_loss: 0.1407\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.1850 - val_loss: 0.1182\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1661 - val_loss: 0.0931\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1374 - val_loss: 0.0696\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1060 - val_loss: 0.0508\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0785 - val_loss: 0.0384\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0593 - val_loss: 0.0322\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0502 - val_loss: 0.0310\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0502 - val_loss: 0.0327\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0561 - val_loss: 0.0353\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 148us/step - loss: 0.0641 - val_loss: 0.0370\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0706 - val_loss: 0.0369\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0733 - val_loss: 0.0345\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0712 - val_loss: 0.0302\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0649 - val_loss: 0.0249\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0562 - val_loss: 0.0197\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0471 - val_loss: 0.0158\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0394 - val_loss: 0.0139\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0342 - val_loss: 0.0142\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0320 - val_loss: 0.0163\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0192\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.0221\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.0239\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0366 - val_loss: 0.0243\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0230\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0204\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0327 - val_loss: 0.0170\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0298 - val_loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0271 - val_loss: 0.0102\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0249 - val_loss: 0.0076\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0234 - val_loss: 0.0059\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0227 - val_loss: 0.0050\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0047\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0229 - val_loss: 0.0051\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0229 - val_loss: 0.0055\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0060\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0220 - val_loss: 0.0065\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0072\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0202 - val_loss: 0.0079\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0193 - val_loss: 0.0087\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0186 - val_loss: 0.0094\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0181 - val_loss: 0.0101\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0177 - val_loss: 0.0107\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0110\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0174 - val_loss: 0.0108\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0104\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0169 - val_loss: 0.0098\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0091\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0162 - val_loss: 0.0084\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0158 - val_loss: 0.0076\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0070\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0152 - val_loss: 0.0064\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0149 - val_loss: 0.0060\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.0057\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0146 - val_loss: 0.0055\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0144 - val_loss: 0.0055\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0143 - val_loss: 0.0055\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0057\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0139 - val_loss: 0.0059\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0061\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0065\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0130 - val_loss: 0.0067\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0068\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0125 - val_loss: 0.0067\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0123 - val_loss: 0.0064\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0062\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0120 - val_loss: 0.0060\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 119us/step - loss: 0.0119 - val_loss: 0.0058\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0118 - val_loss: 0.0056\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.0054\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0115 - val_loss: 0.0052\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0114 - val_loss: 0.0051\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0050\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0112 - val_loss: 0.0050\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0111 - val_loss: 0.0050\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 182us/step - loss: 0.0110 - val_loss: 0.0050\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0050\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0108 - val_loss: 0.0051\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0108 - val_loss: 0.0051\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.0052\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0106 - val_loss: 0.0052\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0049\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0047\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 0.0091 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 171us/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.0043\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0080 - val_loss: 0.0042\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0075 - val_loss: 0.0039\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0072 - val_loss: 0.0038\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0038\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 191us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0070 - val_loss: 0.0037\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0035\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0063 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 121us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 172us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 118us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 168us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 138us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 129us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 166us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 169us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 144us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 134us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 173us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.9936e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.9710e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.9486e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.9262e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.9038e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.8816e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.8591e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.8371e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.8145e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.7926e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7706e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.7486e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.7266e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.7049e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0014 - val_loss: 9.6833e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.6614e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 9.6397e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.6181e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.5965e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.5753e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.5536e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.5323e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 9.5110e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 0.0014 - val_loss: 9.4898e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.4685e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.4473e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.4262e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.4050e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 9.3840e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 9.3629e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0014 - val_loss: 9.3420e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 0.0014 - val_loss: 9.3214e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.3006e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 9.2799e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.2592e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 9.2388e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.2180e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.1977e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.1771e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.1569e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.1366e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.1161e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.0958e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 9.0756e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 9.0557e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 9.0352e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 9.0152e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.9954e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.9753e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.9556e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.9357e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 8.9160e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.8963e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.8769e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 8.8573e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 8.8378e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.8181e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.7986e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.7791e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.7600e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0013 - val_loss: 8.7404e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.7210e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.7019e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.6830e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 115us/step - loss: 0.0013 - val_loss: 8.6636e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 8.6446e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.6255e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 8.6066e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.5876e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0012 - val_loss: 8.5689e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.5502e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0012 - val_loss: 8.5313e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0012 - val_loss: 8.5126e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.4939e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.4753e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.4569e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.4384e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.4200e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.4016e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.3830e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.3648e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.3463e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.3281e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.3101e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.2918e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.2736e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.2556e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.2376e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.2199e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.2019e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.1839e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.1663e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.1483e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.1306e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.1130e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.0952e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.0780e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0012 - val_loss: 8.0604e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 8.0427e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 8.0256e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 8.0080e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 7.9908e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 7.9734e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.9562e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 7.9390e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 7.9217e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.9045e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 106us/step - loss: 0.0012 - val_loss: 7.8874e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0012 - val_loss: 7.8704e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 7.8535e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0011 - val_loss: 7.8364e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.8196e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.8027e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 7.7859e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.7692e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 7.7526e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.7357e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.7190e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.7023e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 7.6858e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6694e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6528e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6364e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6201e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.6039e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.5874e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5713e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5550e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5387e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5226e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.5066e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.4904e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.4743e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.4585e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.4425e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 175us/step - loss: 0.0011 - val_loss: 7.4265e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.4108e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.3950e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 7.3794e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.3636e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.3480e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0011 - val_loss: 7.3322e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.3166e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.3011e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0011 - val_loss: 7.2856e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.2698e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.2545e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 180us/step - loss: 0.0011 - val_loss: 7.2392e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.2237e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.2083e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 7.1934e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.1777e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.1627e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.1475e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 7.1323e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 7.1173e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 7.1022e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.0872e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.0722e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.0573e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.0423e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.0276e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.0128e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.9979e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.9832e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.9684e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0010 - val_loss: 6.9537e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.9391e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.9246e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0010 - val_loss: 6.9099e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.8954e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.8809e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 6.8663e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.8521e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.8376e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0010 - val_loss: 6.8233e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.8090e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0010 - val_loss: 6.7945e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.7804e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.7661e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 6.7520e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.7379e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 6.7237e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9952e-04 - val_loss: 6.7097e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9770e-04 - val_loss: 6.6957e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9589e-04 - val_loss: 6.6818e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9409e-04 - val_loss: 6.6678e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9228e-04 - val_loss: 6.6539e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9050e-04 - val_loss: 6.6400e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8869e-04 - val_loss: 6.6264e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8690e-04 - val_loss: 6.6124e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8512e-04 - val_loss: 6.5985e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8334e-04 - val_loss: 6.5848e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.8157e-04 - val_loss: 6.5709e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7980e-04 - val_loss: 6.5573e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7804e-04 - val_loss: 6.5437e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7629e-04 - val_loss: 6.5303e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.7453e-04 - val_loss: 6.5167e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7278e-04 - val_loss: 6.5031e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7104e-04 - val_loss: 6.4896e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6929e-04 - val_loss: 6.4761e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6756e-04 - val_loss: 6.4626e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.6583e-04 - val_loss: 6.4492e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6410e-04 - val_loss: 6.4360e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6240e-04 - val_loss: 6.4225e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.6067e-04 - val_loss: 6.4093e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5898e-04 - val_loss: 6.3959e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5727e-04 - val_loss: 6.3828e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5557e-04 - val_loss: 6.3696e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5388e-04 - val_loss: 6.3565e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5218e-04 - val_loss: 6.3434e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5050e-04 - val_loss: 6.3302e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 9.4882e-04 - val_loss: 6.3171e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4714e-04 - val_loss: 6.3041e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.4547e-04 - val_loss: 6.2912e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4380e-04 - val_loss: 6.2781e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4215e-04 - val_loss: 6.2652e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 9.4049e-04 - val_loss: 6.2523e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 9.3882e-04 - val_loss: 6.2394e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3719e-04 - val_loss: 6.2267e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3556e-04 - val_loss: 6.2138e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3391e-04 - val_loss: 6.2009e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3227e-04 - val_loss: 6.1882e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3064e-04 - val_loss: 6.1754e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2902e-04 - val_loss: 6.1627e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2739e-04 - val_loss: 6.1501e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2578e-04 - val_loss: 6.1375e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2417e-04 - val_loss: 6.1249e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 9.2256e-04 - val_loss: 6.1124e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2096e-04 - val_loss: 6.1000e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1937e-04 - val_loss: 6.0874e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1776e-04 - val_loss: 6.0751e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 96us/step - loss: 9.1618e-04 - val_loss: 6.0626e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 215us/step - loss: 9.1459e-04 - val_loss: 6.0500e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 9.1302e-04 - val_loss: 6.0378e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1142e-04 - val_loss: 6.0254e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.0986e-04 - val_loss: 6.0130e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 9.0829e-04 - val_loss: 6.0007e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0674e-04 - val_loss: 5.9886e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0517e-04 - val_loss: 5.9763e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0361e-04 - val_loss: 5.9643e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0205e-04 - val_loss: 5.9521e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0051e-04 - val_loss: 5.9400e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9898e-04 - val_loss: 5.9279e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9743e-04 - val_loss: 5.9159e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9590e-04 - val_loss: 5.9037e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.9437e-04 - val_loss: 5.8916e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.9284e-04 - val_loss: 5.8798e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9134e-04 - val_loss: 5.8679e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.8981e-04 - val_loss: 5.8560e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8829e-04 - val_loss: 5.8441e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8678e-04 - val_loss: 5.8324e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8528e-04 - val_loss: 5.8204e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8379e-04 - val_loss: 5.8085e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.8229e-04 - val_loss: 5.7965e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8078e-04 - val_loss: 5.7849e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7930e-04 - val_loss: 5.7733e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7781e-04 - val_loss: 5.7615e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7633e-04 - val_loss: 5.7500e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7486e-04 - val_loss: 5.7384e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7338e-04 - val_loss: 5.7267e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.7192e-04 - val_loss: 5.7152e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.7045e-04 - val_loss: 5.7037e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 139us/step - loss: 8.6898e-04 - val_loss: 5.6922e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6753e-04 - val_loss: 5.6809e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6608e-04 - val_loss: 5.6695e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6463e-04 - val_loss: 5.6579e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6318e-04 - val_loss: 5.6464e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6174e-04 - val_loss: 5.6350e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6029e-04 - val_loss: 5.6237e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5887e-04 - val_loss: 5.6123e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5743e-04 - val_loss: 5.6010e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5601e-04 - val_loss: 5.5898e-04\n",
      "0.0003024076868314296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-9.9752331e-01, -3.1555995e-01, -1.7062919e-02, -2.3388597e-01,\n",
       "         -1.3761693e+00],\n",
       "        [ 1.6474925e-01, -1.3092421e-01, -1.3312898e+00,  5.4147249e-01,\n",
       "          6.3627553e-01],\n",
       "        [ 5.8757341e-01, -1.2547808e+00, -5.5288953e-01, -1.3321853e-03,\n",
       "         -8.8571090e-01]], dtype=float32),\n",
       " array([-0.76307625, -0.56359273,  0.5722596 ,  0.3922834 ,  0.48349434],\n",
       "       dtype=float32),\n",
       " array([[ 0.10037835, -0.46787122,  0.27321827, -0.58838147,  0.6322562 ,\n",
       "         -0.44376007,  0.27172592, -0.20047015,  0.5082623 , -0.2694613 ],\n",
       "        [ 0.23398127, -0.5644493 , -0.7148327 ,  0.05694677, -0.03055131,\n",
       "          0.17785366,  0.5383008 , -0.3176066 ,  0.49742344, -0.49041072],\n",
       "        [-0.32708308,  0.3461977 ,  0.17793873, -0.30153468,  0.01889477,\n",
       "         -0.0641147 , -0.33417505,  0.74454826, -0.05500665,  0.34119892],\n",
       "        [ 0.05982511,  0.06425886,  0.35145316,  0.01230157, -0.24142796,\n",
       "         -0.04392471, -0.2555049 , -0.01844395,  0.1603309 ,  0.4632769 ],\n",
       "        [ 0.42757347,  0.6065782 , -0.10258795,  0.5679315 , -0.21761203,\n",
       "          0.52161586,  0.08096104,  0.06125747, -0.23500395,  0.03324705]],\n",
       "       dtype=float32),\n",
       " array([ 0.6877222 ,  0.80654716,  0.6622078 ,  0.55840266, -0.7668189 ,\n",
       "         0.7687715 , -0.7836362 , -0.7515023 , -0.79877377, -0.5637688 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.17467506],\n",
       "        [ 0.94331396],\n",
       "        [ 0.34102422],\n",
       "        [ 0.14598742],\n",
       "        [-0.5569948 ],\n",
       "        [ 0.49586102],\n",
       "        [-0.7766627 ],\n",
       "        [-0.3467795 ],\n",
       "        [-0.8744564 ],\n",
       "        [-0.11622746]], dtype=float32),\n",
       " array([0.84160584], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_linear(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_linear_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 39.8771 - val_loss: 37.3373\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5162 - val_loss: 32.5867\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 30.4851 - val_loss: 27.5412\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2183 - val_loss: 22.6294\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 19.7299 - val_loss: 17.2252\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 14.0061 - val_loss: 11.5298\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3467 - val_loss: 6.4540\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7909 - val_loss: 3.5467\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3320 - val_loss: 4.0429\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0422 - val_loss: 5.8305\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9105 - val_loss: 5.8450\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5730 - val_loss: 4.3047\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2901 - val_loss: 2.5918\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9156 - val_loss: 1.6385\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5023 - val_loss: 1.6005\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0989 - val_loss: 2.1477\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3712 - val_loss: 2.8241\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8908 - val_loss: 3.2886\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3329 - val_loss: 3.3955\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5324 - val_loss: 3.1321\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4602 - val_loss: 2.5793\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1556 - val_loss: 1.8652\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6941 - val_loss: 1.1602\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1988 - val_loss: 0.6367\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.7950 - val_loss: 0.4232\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.5770 - val_loss: 0.5123\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.5609 - val_loss: 0.7429\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.6670 - val_loss: 0.9022\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7747 - val_loss: 0.8652\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8006 - val_loss: 0.6666\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.7393 - val_loss: 0.4192\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.6252 - val_loss: 0.2093\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.5038 - val_loss: 0.0880\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4070 - val_loss: 0.0722\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3531 - val_loss: 0.1387\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3353 - val_loss: 0.2340\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3405 - val_loss: 0.3172\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3547 - val_loss: 0.3803\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3694 - val_loss: 0.4102\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3745 - val_loss: 0.4024\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.3644 - val_loss: 0.3609\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3388 - val_loss: 0.2963\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3015 - val_loss: 0.2238\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2596 - val_loss: 0.1610\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2211 - val_loss: 0.1163\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1915 - val_loss: 0.0971\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1749 - val_loss: 0.1033\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1714 - val_loss: 0.1298\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1778 - val_loss: 0.1658\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1887 - val_loss: 0.1997\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1978 - val_loss: 0.2212\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2006 - val_loss: 0.2256\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1958 - val_loss: 0.2141\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1848 - val_loss: 0.1922\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1710 - val_loss: 0.1662\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1581 - val_loss: 0.1414\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1484 - val_loss: 0.1212\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1431 - val_loss: 0.1067\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1418 - val_loss: 0.0974\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1428 - val_loss: 0.0915\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1445 - val_loss: 0.0871\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1453 - val_loss: 0.0829\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1443 - val_loss: 0.0781\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1413 - val_loss: 0.0726\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1369 - val_loss: 0.0670\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1318 - val_loss: 0.0619\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1269 - val_loss: 0.0577\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1230 - val_loss: 0.0547\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1203 - val_loss: 0.0529\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1188 - val_loss: 0.0518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1181 - val_loss: 0.0509\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1178 - val_loss: 0.0499\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1173 - val_loss: 0.0485\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1165 - val_loss: 0.0466\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1151 - val_loss: 0.0445\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1134 - val_loss: 0.0424\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1115 - val_loss: 0.0406\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1096 - val_loss: 0.0393\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1081 - val_loss: 0.0385\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1068 - val_loss: 0.0381\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1059 - val_loss: 0.0380\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1052 - val_loss: 0.0379\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1044 - val_loss: 0.0378\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1036 - val_loss: 0.0376\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1027 - val_loss: 0.0372\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1015 - val_loss: 0.0368\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1003 - val_loss: 0.0364\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0990 - val_loss: 0.0361\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0977 - val_loss: 0.0360\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0966 - val_loss: 0.0362\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0957 - val_loss: 0.0364\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0948 - val_loss: 0.0368\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0940 - val_loss: 0.0370\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0931 - val_loss: 0.0372\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0923 - val_loss: 0.0371\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0914 - val_loss: 0.0368\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0904 - val_loss: 0.0364\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0894 - val_loss: 0.0358\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0884 - val_loss: 0.0351\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0873 - val_loss: 0.0343\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0863 - val_loss: 0.0336\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0854 - val_loss: 0.0329\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0844 - val_loss: 0.0322\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0836 - val_loss: 0.0316\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0828 - val_loss: 0.0311\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0821 - val_loss: 0.0306\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0815 - val_loss: 0.0303\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0809 - val_loss: 0.0299\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0802 - val_loss: 0.0296\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0796 - val_loss: 0.0294\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0788 - val_loss: 0.0292\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0780 - val_loss: 0.0290\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0772 - val_loss: 0.0288\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0764 - val_loss: 0.0286\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0755 - val_loss: 0.0284\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0746 - val_loss: 0.0282\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0737 - val_loss: 0.0279\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0728 - val_loss: 0.0276\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0718 - val_loss: 0.0272\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0709 - val_loss: 0.0268\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0699 - val_loss: 0.0263\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0690 - val_loss: 0.0258\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0681 - val_loss: 0.0253\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0672 - val_loss: 0.0248\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0663 - val_loss: 0.0243\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0654 - val_loss: 0.0238\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0646 - val_loss: 0.0233\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0637 - val_loss: 0.0228\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0629 - val_loss: 0.0224\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0621 - val_loss: 0.0220\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0613 - val_loss: 0.0216\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0604 - val_loss: 0.0212\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0594 - val_loss: 0.0209\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0585 - val_loss: 0.0205\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0575 - val_loss: 0.0202\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0563 - val_loss: 0.0199\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0552 - val_loss: 0.0196\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0540 - val_loss: 0.0193\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0529 - val_loss: 0.0190\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0517 - val_loss: 0.0186\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0506 - val_loss: 0.0183\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0495 - val_loss: 0.0180\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0484 - val_loss: 0.0177\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0473 - val_loss: 0.0173\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0462 - val_loss: 0.0170\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0452 - val_loss: 0.0167\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0443 - val_loss: 0.0165\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0434 - val_loss: 0.0162\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0426 - val_loss: 0.0161\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0417 - val_loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0409 - val_loss: 0.0158\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0401 - val_loss: 0.0157\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0394 - val_loss: 0.0156\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0386 - val_loss: 0.0156\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0155\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0377 - val_loss: 0.0155\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0374 - val_loss: 0.0156\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0371 - val_loss: 0.0156\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0156\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0157\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0361 - val_loss: 0.0158\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0158\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0355 - val_loss: 0.0159\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0353 - val_loss: 0.0160\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0350 - val_loss: 0.0160\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0347 - val_loss: 0.0161\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0162\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0341 - val_loss: 0.0162\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0339 - val_loss: 0.0163\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0336 - val_loss: 0.0163\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0163\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0331 - val_loss: 0.0163\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0328 - val_loss: 0.0163\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0325 - val_loss: 0.0163\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0323 - val_loss: 0.0162\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.0162\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0318 - val_loss: 0.0161\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0315 - val_loss: 0.0160\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 0.0313 - val_loss: 0.0159\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0311 - val_loss: 0.0158\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0157\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0155\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0303 - val_loss: 0.0154\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0301 - val_loss: 0.0153\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0299 - val_loss: 0.0151\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0150\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0294 - val_loss: 0.0149\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0292 - val_loss: 0.0148\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0290 - val_loss: 0.0146\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0288 - val_loss: 0.0145\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0283 - val_loss: 0.0143\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0281 - val_loss: 0.0142\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0279 - val_loss: 0.0140\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0273 - val_loss: 0.0137\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0271 - val_loss: 0.0136\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0135\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0267 - val_loss: 0.0134\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0265 - val_loss: 0.0133\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0257 - val_loss: 0.0129\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0256 - val_loss: 0.0128\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0252 - val_loss: 0.0126\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0250 - val_loss: 0.0125\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0248 - val_loss: 0.0124\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.0123\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0243 - val_loss: 0.0122\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0121\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0239 - val_loss: 0.0120\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0238 - val_loss: 0.0119\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0118\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0118\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0233 - val_loss: 0.0117\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0231 - val_loss: 0.0116\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0229 - val_loss: 0.0115\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0228 - val_loss: 0.0114\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0113\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0113\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0112\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.0111\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0220 - val_loss: 0.0110\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0218 - val_loss: 0.0109\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0217 - val_loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0215 - val_loss: 0.0108\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0214 - val_loss: 0.0107\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0212 - val_loss: 0.0106\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0211 - val_loss: 0.0106\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0209 - val_loss: 0.0105\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0208 - val_loss: 0.0104\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 217us/step - loss: 0.0205 - val_loss: 0.0103\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0204 - val_loss: 0.0102\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 405us/step - loss: 0.0202 - val_loss: 0.0102\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 249us/step - loss: 0.0201 - val_loss: 0.0101\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0199 - val_loss: 0.0101\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.0100\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0197 - val_loss: 0.0099\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0195 - val_loss: 0.0099\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0194 - val_loss: 0.0098\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0193 - val_loss: 0.0097\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0191 - val_loss: 0.0097\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0190 - val_loss: 0.0096\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0189 - val_loss: 0.0095\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0187 - val_loss: 0.0094\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0186 - val_loss: 0.0094\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0185 - val_loss: 0.0093\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0184 - val_loss: 0.0092\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0182 - val_loss: 0.0092\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0181 - val_loss: 0.0091\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0180 - val_loss: 0.0090\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0179 - val_loss: 0.0090\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0178 - val_loss: 0.0089\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0176 - val_loss: 0.0088\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.0087\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0174 - val_loss: 0.0087\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0173 - val_loss: 0.0086\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.0085\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0171 - val_loss: 0.0085\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0170 - val_loss: 0.0084\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0168 - val_loss: 0.0083\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0167 - val_loss: 0.0082\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0082\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0081\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0164 - val_loss: 0.0080\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0080\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0079\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0161 - val_loss: 0.0078\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0160 - val_loss: 0.0078\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.0077\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0158 - val_loss: 0.0076\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0076\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0156 - val_loss: 0.0075\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0155 - val_loss: 0.0074\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.0074\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0153 - val_loss: 0.0073\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.0073\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.0072\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0071\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.0071\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 161us/step - loss: 0.0148 - val_loss: 0.0070\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0147 - val_loss: 0.0070\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0146 - val_loss: 0.0069\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0145 - val_loss: 0.0068\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.0068\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0067\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0067\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0142 - val_loss: 0.0066\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0141 - val_loss: 0.0066\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0065\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0139 - val_loss: 0.0064\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0064\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0063\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0063\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0136 - val_loss: 0.0062\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0135 - val_loss: 0.0062\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0061\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.0060\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0060\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0131 - val_loss: 0.0059\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.0059\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0129 - val_loss: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.0058\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0057\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.0057\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0126 - val_loss: 0.0056\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.0056\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0055\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0055\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 130us/step - loss: 0.0123 - val_loss: 0.0054\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.0054\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0054\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0121 - val_loss: 0.0053\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0120 - val_loss: 0.0053\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0052\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.0052\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0118 - val_loss: 0.0051\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0117 - val_loss: 0.0051\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0051\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.0050\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.0050\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0114 - val_loss: 0.0049\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.0049\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0112 - val_loss: 0.0048\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.0048\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0111 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0109 - val_loss: 0.0046\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.0046\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0108 - val_loss: 0.0046\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0044\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.0044\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0103 - val_loss: 0.0043\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.0042\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0042\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0100 - val_loss: 0.0042\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0099 - val_loss: 0.0042\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0041\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 189us/step - loss: 0.0097 - val_loss: 0.0041\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0096 - val_loss: 0.0041\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.0041\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0093 - val_loss: 0.0041\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.0041\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0088 - val_loss: 0.0041\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.0040\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0087 - val_loss: 0.0040\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0040\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0082 - val_loss: 0.0040\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0040\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0039\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0079 - val_loss: 0.0039\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0078 - val_loss: 0.0039\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0039\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.0038\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.0035\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0059 - val_loss: 0.0032\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.9543e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 9.8311e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.7082e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.5857e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 9.4638e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 9.3431e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.2234e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 9.1047e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.9873e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 0.0015 - val_loss: 8.8717e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.7742e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 8.6764e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.5787e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 8.4809e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 8.3832e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 8.2855e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 8.1883e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 8.0912e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 7.9943e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 7.9110e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 7.8173e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 7.7354e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 7.6526e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.5689e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 7.4845e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 7.3995e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0013 - val_loss: 7.3145e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.2376e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 7.1587e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.0865e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 7.0134e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 6.9393e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 6.8648e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.7896e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 6.7141e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.6385e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5675e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.5003e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.4366e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3717e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 6.3059e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 6.2396e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 6.1725e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 6.1053e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 6.0375e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9709e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.9144e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 5.8574e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 5.7996e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.7408e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.6813e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 5.6214e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 5.5609e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.5001e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 5.4395e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.3791e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 5.3287e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.2777e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.2257e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 5.1729e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 5.1195e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.9436e-04 - val_loss: 5.0655e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8646e-04 - val_loss: 5.0111e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7862e-04 - val_loss: 4.9563e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7084e-04 - val_loss: 4.9013e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6312e-04 - val_loss: 4.8515e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5551e-04 - val_loss: 4.8013e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4788e-04 - val_loss: 4.7554e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4035e-04 - val_loss: 4.7084e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3288e-04 - val_loss: 4.6608e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2546e-04 - val_loss: 4.6126e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1810e-04 - val_loss: 4.5638e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1079e-04 - val_loss: 4.5148e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0353e-04 - val_loss: 4.4653e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9633e-04 - val_loss: 4.4193e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8922e-04 - val_loss: 4.3754e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8212e-04 - val_loss: 4.3339e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7510e-04 - val_loss: 4.2915e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6813e-04 - val_loss: 4.2483e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6121e-04 - val_loss: 4.2044e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5435e-04 - val_loss: 4.1601e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4754e-04 - val_loss: 4.1154e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4077e-04 - val_loss: 4.0703e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 8.3406e-04 - val_loss: 4.0253e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2740e-04 - val_loss: 3.9880e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2080e-04 - val_loss: 3.9502e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.1447e-04 - val_loss: 3.9117e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0791e-04 - val_loss: 3.8726e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.0153e-04 - val_loss: 3.8324e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.9529e-04 - val_loss: 3.7912e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8907e-04 - val_loss: 3.7484e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 7.8285e-04 - val_loss: 3.7047e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.7665e-04 - val_loss: 3.6602e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7046e-04 - val_loss: 3.6222e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.6438e-04 - val_loss: 3.5785e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5821e-04 - val_loss: 3.5414e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.5219e-04 - val_loss: 3.5038e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4622e-04 - val_loss: 3.4663e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4029e-04 - val_loss: 3.4290e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3441e-04 - val_loss: 3.3919e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2872e-04 - val_loss: 3.3547e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2276e-04 - val_loss: 3.3231e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1707e-04 - val_loss: 3.2882e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1134e-04 - val_loss: 3.2578e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.0570e-04 - val_loss: 3.2264e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0011e-04 - val_loss: 3.1942e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.9455e-04 - val_loss: 3.1609e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8903e-04 - val_loss: 3.1267e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8352e-04 - val_loss: 3.0919e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.7806e-04 - val_loss: 3.0589e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7272e-04 - val_loss: 3.0278e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6737e-04 - val_loss: 2.9978e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6208e-04 - val_loss: 2.9669e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5681e-04 - val_loss: 2.9352e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.5157e-04 - val_loss: 2.9032e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4638e-04 - val_loss: 2.8708e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4122e-04 - val_loss: 2.8383e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.3615e-04 - val_loss: 2.8060e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3105e-04 - val_loss: 2.7770e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.2607e-04 - val_loss: 2.7473e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2107e-04 - val_loss: 2.7205e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1614e-04 - val_loss: 2.6930e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1124e-04 - val_loss: 2.6649e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0636e-04 - val_loss: 2.6363e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.0152e-04 - val_loss: 2.6075e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9670e-04 - val_loss: 2.5783e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9192e-04 - val_loss: 2.5525e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8720e-04 - val_loss: 2.5254e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8249e-04 - val_loss: 2.5012e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7785e-04 - val_loss: 2.4765e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.7325e-04 - val_loss: 2.4511e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6869e-04 - val_loss: 2.4251e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6415e-04 - val_loss: 2.3987e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5963e-04 - val_loss: 2.3718e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5515e-04 - val_loss: 2.3448e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5069e-04 - val_loss: 2.3210e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4630e-04 - val_loss: 2.2954e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4194e-04 - val_loss: 2.2730e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3758e-04 - val_loss: 2.2498e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.3329e-04 - val_loss: 2.2263e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2904e-04 - val_loss: 2.2024e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.2481e-04 - val_loss: 2.1780e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2060e-04 - val_loss: 2.1534e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1642e-04 - val_loss: 2.1296e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.1227e-04 - val_loss: 2.1085e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0815e-04 - val_loss: 2.0879e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0407e-04 - val_loss: 2.0669e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0019e-04 - val_loss: 2.0455e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9603e-04 - val_loss: 2.0239e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9206e-04 - val_loss: 2.0018e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8812e-04 - val_loss: 1.9794e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8421e-04 - val_loss: 1.9568e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8032e-04 - val_loss: 1.9352e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7647e-04 - val_loss: 1.9153e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7263e-04 - val_loss: 1.8962e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6881e-04 - val_loss: 1.8766e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.6513e-04 - val_loss: 1.8567e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.6132e-04 - val_loss: 1.8365e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5763e-04 - val_loss: 1.8160e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 4.5396e-04 - val_loss: 1.7952e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5031e-04 - val_loss: 1.7745e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.4669e-04 - val_loss: 1.7573e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4309e-04 - val_loss: 1.7398e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3952e-04 - val_loss: 1.7217e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3597e-04 - val_loss: 1.7036e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.3246e-04 - val_loss: 1.6852e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2899e-04 - val_loss: 1.6665e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2555e-04 - val_loss: 1.6477e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.2213e-04 - val_loss: 1.6285e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1874e-04 - val_loss: 1.6099e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1537e-04 - val_loss: 1.5936e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.1201e-04 - val_loss: 1.5775e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0868e-04 - val_loss: 1.5610e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0538e-04 - val_loss: 1.5442e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.0209e-04 - val_loss: 1.5272e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9886e-04 - val_loss: 1.5100e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9564e-04 - val_loss: 1.4928e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9245e-04 - val_loss: 1.4754e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8929e-04 - val_loss: 1.4607e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8619e-04 - val_loss: 1.4436e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8304e-04 - val_loss: 1.4289e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7994e-04 - val_loss: 1.4138e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7687e-04 - val_loss: 1.3985e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7381e-04 - val_loss: 1.3829e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.7078e-04 - val_loss: 1.3672e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6787e-04 - val_loss: 1.3514e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6481e-04 - val_loss: 1.3371e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6189e-04 - val_loss: 1.3228e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5896e-04 - val_loss: 1.3095e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5606e-04 - val_loss: 1.2958e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5318e-04 - val_loss: 1.2819e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 203us/step - loss: 3.5032e-04 - val_loss: 1.2676e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4748e-04 - val_loss: 1.2530e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4465e-04 - val_loss: 1.2385e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4190e-04 - val_loss: 1.2238e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3910e-04 - val_loss: 1.2097e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3637e-04 - val_loss: 1.1971e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3365e-04 - val_loss: 1.1848e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3096e-04 - val_loss: 1.1721e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2828e-04 - val_loss: 1.1592e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2561e-04 - val_loss: 1.1460e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2297e-04 - val_loss: 1.1327e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2034e-04 - val_loss: 1.1193e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1773e-04 - val_loss: 1.1059e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1524e-04 - val_loss: 1.0939e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1261e-04 - val_loss: 1.0817e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 3.1008e-04 - val_loss: 1.0706e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0758e-04 - val_loss: 1.0592e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0509e-04 - val_loss: 1.0475e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0261e-04 - val_loss: 1.0356e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0016e-04 - val_loss: 1.0235e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9771e-04 - val_loss: 1.0112e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9528e-04 - val_loss: 9.9905e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9290e-04 - val_loss: 9.8903e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.9052e-04 - val_loss: 9.7880e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8817e-04 - val_loss: 9.6834e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8584e-04 - val_loss: 9.5763e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8352e-04 - val_loss: 9.4667e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8122e-04 - val_loss: 9.3547e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7894e-04 - val_loss: 9.2427e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7666e-04 - val_loss: 9.1296e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 211us/step - loss: 2.7441e-04 - val_loss: 9.0159e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7217e-04 - val_loss: 8.9132e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7001e-04 - val_loss: 8.8125e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6777e-04 - val_loss: 8.7196e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6560e-04 - val_loss: 8.6250e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6345e-04 - val_loss: 8.5281e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6131e-04 - val_loss: 8.4295e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 2.5919e-04 - val_loss: 8.3292e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5708e-04 - val_loss: 8.2276e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5498e-04 - val_loss: 8.1286e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5290e-04 - val_loss: 8.0428e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.5084e-04 - val_loss: 7.9578e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4887e-04 - val_loss: 7.8712e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4678e-04 - val_loss: 7.7838e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4480e-04 - val_loss: 7.7043e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4281e-04 - val_loss: 7.6226e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4085e-04 - val_loss: 7.5377e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3890e-04 - val_loss: 7.4500e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3696e-04 - val_loss: 7.3597e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3503e-04 - val_loss: 7.2684e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3311e-04 - val_loss: 7.1759e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3120e-04 - val_loss: 7.0834e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2933e-04 - val_loss: 6.9895e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2748e-04 - val_loss: 6.9131e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2565e-04 - val_loss: 6.8266e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2381e-04 - val_loss: 6.7586e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2199e-04 - val_loss: 6.6940e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2018e-04 - val_loss: 6.6273e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1839e-04 - val_loss: 6.5578e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1661e-04 - val_loss: 6.4859e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1486e-04 - val_loss: 6.4130e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1314e-04 - val_loss: 6.3474e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1139e-04 - val_loss: 6.2790e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0970e-04 - val_loss: 6.2086e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0800e-04 - val_loss: 6.1345e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0632e-04 - val_loss: 6.0585e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0464e-04 - val_loss: 5.9799e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0296e-04 - val_loss: 5.9009e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0130e-04 - val_loss: 5.8209e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 1.9965e-04 - val_loss: 5.7412e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9805e-04 - val_loss: 5.6618e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9642e-04 - val_loss: 5.5913e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9483e-04 - val_loss: 5.5226e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9325e-04 - val_loss: 5.4671e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9168e-04 - val_loss: 5.4135e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9013e-04 - val_loss: 5.3575e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8858e-04 - val_loss: 5.3000e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8705e-04 - val_loss: 5.2407e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 136us/step - loss: 1.8555e-04 - val_loss: 5.1876e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8402e-04 - val_loss: 5.1324e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8258e-04 - val_loss: 5.0761e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8106e-04 - val_loss: 5.0173e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7960e-04 - val_loss: 4.9565e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7816e-04 - val_loss: 4.8934e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7671e-04 - val_loss: 4.8288e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7527e-04 - val_loss: 4.7625e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7384e-04 - val_loss: 4.6967e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7243e-04 - val_loss: 4.6302e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7102e-04 - val_loss: 4.5647e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6970e-04 - val_loss: 4.4992e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6825e-04 - val_loss: 4.4352e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6689e-04 - val_loss: 4.3852e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6555e-04 - val_loss: 4.3283e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6421e-04 - val_loss: 4.2784e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6287e-04 - val_loss: 4.2349e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6155e-04 - val_loss: 4.1903e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 1.6024e-04 - val_loss: 4.1498e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5894e-04 - val_loss: 4.1079e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5766e-04 - val_loss: 4.0642e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5641e-04 - val_loss: 4.0188e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5513e-04 - val_loss: 3.9714e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5388e-04 - val_loss: 3.9222e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5264e-04 - val_loss: 3.8716e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5141e-04 - val_loss: 3.8195e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5018e-04 - val_loss: 3.7665e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4895e-04 - val_loss: 3.7132e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4774e-04 - val_loss: 3.6607e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4654e-04 - val_loss: 3.6079e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4542e-04 - val_loss: 3.5557e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4418e-04 - val_loss: 3.5040e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4302e-04 - val_loss: 3.4532e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4186e-04 - val_loss: 3.4031e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4072e-04 - val_loss: 3.3595e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3958e-04 - val_loss: 3.3149e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3847e-04 - val_loss: 3.2845e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3734e-04 - val_loss: 3.2543e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3623e-04 - val_loss: 3.2223e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 162us/step - loss: 1.3513e-04 - val_loss: 3.1885e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3404e-04 - val_loss: 3.1535e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3297e-04 - val_loss: 3.1169e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3191e-04 - val_loss: 3.0789e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3085e-04 - val_loss: 3.0396e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2980e-04 - val_loss: 2.9990e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2875e-04 - val_loss: 2.9583e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2770e-04 - val_loss: 2.9171e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2667e-04 - val_loss: 2.8759e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2565e-04 - val_loss: 2.8351e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2466e-04 - val_loss: 2.7948e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2363e-04 - val_loss: 2.7544e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2264e-04 - val_loss: 2.7146e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2166e-04 - val_loss: 2.6750e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2068e-04 - val_loss: 2.6358e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1971e-04 - val_loss: 2.5972e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1877e-04 - val_loss: 2.5623e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1779e-04 - val_loss: 2.5274e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1685e-04 - val_loss: 2.4921e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1591e-04 - val_loss: 2.4570e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1497e-04 - val_loss: 2.4217e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1406e-04 - val_loss: 2.3867e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1314e-04 - val_loss: 2.3564e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1224e-04 - val_loss: 2.3233e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1134e-04 - val_loss: 2.2937e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1045e-04 - val_loss: 2.2638e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0957e-04 - val_loss: 2.2337e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0869e-04 - val_loss: 2.2037e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0782e-04 - val_loss: 2.1736e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0695e-04 - val_loss: 2.1437e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0614e-04 - val_loss: 2.1140e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0525e-04 - val_loss: 2.0842e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0441e-04 - val_loss: 2.0548e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0358e-04 - val_loss: 2.0256e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0276e-04 - val_loss: 1.9963e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0195e-04 - val_loss: 1.9702e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0113e-04 - val_loss: 1.9437e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0033e-04 - val_loss: 1.9169e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9528e-05 - val_loss: 1.8897e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8731e-05 - val_loss: 1.8625e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7940e-05 - val_loss: 1.8379e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7202e-05 - val_loss: 1.8131e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6393e-05 - val_loss: 1.7903e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5632e-05 - val_loss: 1.7671e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 9.4874e-05 - val_loss: 1.7438e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4122e-05 - val_loss: 1.7201e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3375e-05 - val_loss: 1.6964e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2634e-05 - val_loss: 1.6729e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1898e-05 - val_loss: 1.6492e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1181e-05 - val_loss: 1.6257e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0451e-05 - val_loss: 1.6025e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9741e-05 - val_loss: 1.5790e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9034e-05 - val_loss: 1.5559e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8334e-05 - val_loss: 1.5351e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7638e-05 - val_loss: 1.5143e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6950e-05 - val_loss: 1.4929e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6264e-05 - val_loss: 1.4715e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5581e-05 - val_loss: 1.4503e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4903e-05 - val_loss: 1.4290e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4232e-05 - val_loss: 1.4085e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3571e-05 - val_loss: 1.3906e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2914e-05 - val_loss: 1.3731e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2266e-05 - val_loss: 1.3554e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1621e-05 - val_loss: 1.3376e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0983e-05 - val_loss: 1.3196e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0348e-05 - val_loss: 1.3015e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9717e-05 - val_loss: 1.2833e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9090e-05 - val_loss: 1.2655e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8468e-05 - val_loss: 1.2475e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7852e-05 - val_loss: 1.2296e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7267e-05 - val_loss: 1.2120e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6644e-05 - val_loss: 1.1965e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.6047e-05 - val_loss: 1.1809e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5463e-05 - val_loss: 1.1650e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4878e-05 - val_loss: 1.1486e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4297e-05 - val_loss: 1.1320e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.3717e-05 - val_loss: 1.1150e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3140e-05 - val_loss: 1.0984e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2571e-05 - val_loss: 1.0818e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.2003e-05 - val_loss: 1.0655e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1465e-05 - val_loss: 1.0496e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0891e-05 - val_loss: 1.0338e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0343e-05 - val_loss: 1.0184e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9801e-05 - val_loss: 1.0029e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9260e-05 - val_loss: 9.8829e-06\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8725e-05 - val_loss: 9.7332e-06\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8195e-05 - val_loss: 9.5880e-06\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7666e-05 - val_loss: 9.4450e-06\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.7141e-05 - val_loss: 9.3030e-06\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6622e-05 - val_loss: 9.1656e-06\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6135e-05 - val_loss: 9.0445e-06\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5604e-05 - val_loss: 8.9240e-06\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5106e-05 - val_loss: 8.7995e-06\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4610e-05 - val_loss: 8.6741e-06\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4117e-05 - val_loss: 8.5463e-06\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3627e-05 - val_loss: 8.4174e-06\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3137e-05 - val_loss: 8.2896e-06\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2652e-05 - val_loss: 8.1617e-06\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2169e-05 - val_loss: 8.0400e-06\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1693e-05 - val_loss: 7.9204e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1240e-05 - val_loss: 7.8016e-06\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0758e-05 - val_loss: 7.6854e-06\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0296e-05 - val_loss: 7.5705e-06\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9838e-05 - val_loss: 7.4597e-06\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.9382e-05 - val_loss: 7.3495e-06\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8931e-05 - val_loss: 7.2424e-06\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8485e-05 - val_loss: 7.1335e-06\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8039e-05 - val_loss: 7.0300e-06\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7599e-05 - val_loss: 6.9263e-06\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7159e-05 - val_loss: 6.8236e-06\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6738e-05 - val_loss: 6.7329e-06\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6313e-05 - val_loss: 6.6433e-06\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5876e-05 - val_loss: 6.5543e-06\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5459e-05 - val_loss: 6.4626e-06\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5047e-05 - val_loss: 6.3706e-06\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4633e-05 - val_loss: 6.2781e-06\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4222e-05 - val_loss: 6.1843e-06\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3814e-05 - val_loss: 6.0918e-06\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3407e-05 - val_loss: 6.0000e-06\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3005e-05 - val_loss: 5.9130e-06\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2615e-05 - val_loss: 5.8258e-06\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2217e-05 - val_loss: 5.7396e-06\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1830e-05 - val_loss: 5.6563e-06\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1445e-05 - val_loss: 5.5748e-06\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1062e-05 - val_loss: 5.4951e-06\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0681e-05 - val_loss: 5.4151e-06\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0305e-05 - val_loss: 5.3377e-06\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.9929e-05 - val_loss: 5.2610e-06\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9556e-05 - val_loss: 5.1871e-06\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9194e-05 - val_loss: 5.1193e-06\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8826e-05 - val_loss: 5.0543e-06\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8460e-05 - val_loss: 4.9866e-06\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8112e-05 - val_loss: 4.9221e-06\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7751e-05 - val_loss: 4.8574e-06\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7404e-05 - val_loss: 4.7903e-06\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7055e-05 - val_loss: 4.7237e-06\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6711e-05 - val_loss: 4.6554e-06\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6366e-05 - val_loss: 4.5870e-06\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6026e-05 - val_loss: 4.5210e-06\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5686e-05 - val_loss: 4.4572e-06\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5350e-05 - val_loss: 4.3944e-06\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5031e-05 - val_loss: 4.3311e-06\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4692e-05 - val_loss: 4.2701e-06\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.4367e-05 - val_loss: 4.2116e-06\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4043e-05 - val_loss: 4.1539e-06\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3725e-05 - val_loss: 4.0973e-06\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3407e-05 - val_loss: 4.0414e-06\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3092e-05 - val_loss: 3.9857e-06\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2779e-05 - val_loss: 3.9313e-06\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2473e-05 - val_loss: 3.8817e-06\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2162e-05 - val_loss: 3.8331e-06\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1856e-05 - val_loss: 3.7851e-06\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1555e-05 - val_loss: 3.7359e-06\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1263e-05 - val_loss: 3.6880e-06\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0960e-05 - val_loss: 3.6403e-06\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0668e-05 - val_loss: 3.5917e-06\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0378e-05 - val_loss: 3.5433e-06\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0089e-05 - val_loss: 3.4954e-06\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9801e-05 - val_loss: 3.4469e-06\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9516e-05 - val_loss: 3.4002e-06\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9233e-05 - val_loss: 3.3541e-06\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8953e-05 - val_loss: 3.3104e-06\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8682e-05 - val_loss: 3.2659e-06\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8399e-05 - val_loss: 3.2243e-06\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8129e-05 - val_loss: 3.1817e-06\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7859e-05 - val_loss: 3.1412e-06\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7593e-05 - val_loss: 3.1013e-06\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7327e-05 - val_loss: 3.0619e-06\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7065e-05 - val_loss: 3.0225e-06\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6800e-05 - val_loss: 2.9840e-06\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6551e-05 - val_loss: 2.9482e-06\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6284e-05 - val_loss: 2.9130e-06\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6029e-05 - val_loss: 2.8771e-06\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5777e-05 - val_loss: 2.8420e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5528e-05 - val_loss: 2.8085e-06\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5280e-05 - val_loss: 2.7744e-06\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5035e-05 - val_loss: 2.7402e-06\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4793e-05 - val_loss: 2.7057e-06\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4550e-05 - val_loss: 2.6715e-06\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4310e-05 - val_loss: 2.6369e-06\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4071e-05 - val_loss: 2.6035e-06\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3835e-05 - val_loss: 2.5714e-06\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3600e-05 - val_loss: 2.5403e-06\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3367e-05 - val_loss: 2.5093e-06\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3147e-05 - val_loss: 2.4801e-06\n",
      "1.5378417401734623e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.9219294 ,  0.44215757,  0.10391867, -0.37924078, -0.3759693 ],\n",
       "        [ 0.47896558,  0.07363355,  0.33559403,  0.0241494 , -0.19954336],\n",
       "        [-0.6338427 ,  0.0635384 , -0.40376842,  0.68505996,  0.52652735]],\n",
       "       dtype=float32),\n",
       " array([ 0.3794753 ,  0.65615785, -0.9606186 , -0.42730734, -0.3283308 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.8603611 , -0.5180804 , -0.5690867 , -0.8689221 , -0.71206355,\n",
       "          0.3129275 , -0.31382498, -0.29927102,  0.08487971, -0.28820184],\n",
       "        [ 0.21627145,  0.25794956, -0.04992134, -0.43567356, -0.35210237,\n",
       "          0.26018995, -0.32079503, -0.1833877 , -0.43695438, -0.91326874],\n",
       "        [ 0.48736584, -0.49094352, -0.64752156, -1.0644721 , -0.47382152,\n",
       "          0.1684925 , -0.55093396, -0.44319934, -0.60839975, -0.08144208],\n",
       "        [-0.09109637, -1.6526837 ,  0.18868119,  0.11106791, -0.15836439,\n",
       "         -0.37076148, -0.568552  , -0.51943564,  1.0294694 , -0.4451972 ],\n",
       "        [ 0.3621109 , -1.0105616 ,  0.47697183,  0.20700808, -0.09018752,\n",
       "         -0.52677923, -0.06241781, -0.42466372,  0.45436582, -0.2641594 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.0425901 ,  1.0298643 ,  1.229417  , -0.25367582, -0.64700633,\n",
       "         0.947396  , -0.31753737, -0.5347744 ,  1.069873  , -0.6046204 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.9313082 ],\n",
       "        [ 0.7602902 ],\n",
       "        [ 1.1798218 ],\n",
       "        [ 0.25687256],\n",
       "        [-0.16014068],\n",
       "        [ 0.6173682 ],\n",
       "        [-0.42691413],\n",
       "        [ 0.43512997],\n",
       "        [ 1.0690981 ],\n",
       "        [ 0.40665206]], dtype=float32),\n",
       " array([1.0215381], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_relu(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_relu_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 33.3646 - val_loss: 30.6454\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 30.2522 - val_loss: 26.7937\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 26.3332 - val_loss: 22.7027\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 22.1582 - val_loss: 18.6807\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 18.0647 - val_loss: 14.9077\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 14.2645 - val_loss: 11.4616\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 10.8659 - val_loss: 8.3897\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9313 - val_loss: 5.6988\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4852 - val_loss: 3.4484\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5297 - val_loss: 1.7487\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0535 - val_loss: 0.6640\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0787 - val_loss: 0.1985\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5903 - val_loss: 0.2767\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5261 - val_loss: 0.7377\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.7726 - val_loss: 1.3795\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1886 - val_loss: 2.0204\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6407 - val_loss: 2.5341\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0225 - val_loss: 2.8575\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2726 - val_loss: 2.9791\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3723 - val_loss: 2.9205\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3321 - val_loss: 2.7197\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1798 - val_loss: 2.4203\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9510 - val_loss: 2.0642\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6807 - val_loss: 1.6889\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4008 - val_loss: 1.3241\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1263 - val_loss: 0.9918\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8745 - val_loss: 0.7066\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6551 - val_loss: 0.4765\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4757 - val_loss: 0.3037\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.3393 - val_loss: 0.1859\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2448 - val_loss: 0.1157\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1879 - val_loss: 0.0850\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1626 - val_loss: 0.0846\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1615 - val_loss: 0.1052\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1772 - val_loss: 0.1381\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2025 - val_loss: 0.1757\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2310 - val_loss: 0.2119\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2576 - val_loss: 0.2422\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.2786 - val_loss: 0.2634\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2916 - val_loss: 0.2741\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2954 - val_loss: 0.2741\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2898 - val_loss: 0.2640\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.2757 - val_loss: 0.2455\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2543 - val_loss: 0.2207\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2277 - val_loss: 0.1919\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1980 - val_loss: 0.1613\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1673 - val_loss: 0.1311\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1374 - val_loss: 0.1031\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1100 - val_loss: 0.0783\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0860 - val_loss: 0.0576\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0660 - val_loss: 0.0414\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0502 - val_loss: 0.0293\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0383 - val_loss: 0.0211\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0299 - val_loss: 0.0160\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0133\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0203 - val_loss: 0.0124\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0178 - val_loss: 0.0125\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0150 - val_loss: 0.0141\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0133 - val_loss: 0.0160\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0116 - val_loss: 0.0148\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0108 - val_loss: 0.0137\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7142e-04 - val_loss: 0.0027\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3531e-04 - val_loss: 0.0027\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0187e-04 - val_loss: 0.0026\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7137e-04 - val_loss: 0.0026\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4387e-04 - val_loss: 0.0025\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1928e-04 - val_loss: 0.0024\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9736e-04 - val_loss: 0.0024\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7781e-04 - val_loss: 0.0023\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6023e-04 - val_loss: 0.0023\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4428e-04 - val_loss: 0.0023\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2956e-04 - val_loss: 0.0022\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1574e-04 - val_loss: 0.0022\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0255e-04 - val_loss: 0.0021\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8979e-04 - val_loss: 0.0021\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7731e-04 - val_loss: 0.0021\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 6.6502e-04 - val_loss: 0.0021\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5289e-04 - val_loss: 0.0020\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4095e-04 - val_loss: 0.0020\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2924e-04 - val_loss: 0.0020\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1782e-04 - val_loss: 0.0020\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0674e-04 - val_loss: 0.0019\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9608e-04 - val_loss: 0.0019\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8590e-04 - val_loss: 0.0019\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7623e-04 - val_loss: 0.0019\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6707e-04 - val_loss: 0.0019\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5844e-04 - val_loss: 0.0019\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5032e-04 - val_loss: 0.0018\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.4266e-04 - val_loss: 0.0018\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3543e-04 - val_loss: 0.0018\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2858e-04 - val_loss: 0.0018\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2205e-04 - val_loss: 0.0018\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1581e-04 - val_loss: 0.0018\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0979e-04 - val_loss: 0.0018\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0397e-04 - val_loss: 0.0017\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9830e-04 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9276e-04 - val_loss: 0.0017\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8733e-04 - val_loss: 0.0017\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8200e-04 - val_loss: 0.0017\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7677e-04 - val_loss: 0.0017\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7164e-04 - val_loss: 0.0016\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6659e-04 - val_loss: 0.0016\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6165e-04 - val_loss: 0.0016\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5680e-04 - val_loss: 0.0016\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5207e-04 - val_loss: 0.0016\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4743e-04 - val_loss: 0.0015\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.4292e-04 - val_loss: 0.0015\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3849e-04 - val_loss: 0.0015\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3417e-04 - val_loss: 0.0015\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2995e-04 - val_loss: 0.0015\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2582e-04 - val_loss: 0.0015\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2177e-04 - val_loss: 0.0014\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1779e-04 - val_loss: 0.0014\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1389e-04 - val_loss: 0.0014\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1005e-04 - val_loss: 0.0014\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0626e-04 - val_loss: 0.0014\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0253e-04 - val_loss: 0.0014\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9885e-04 - val_loss: 0.0014\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.9521e-04 - val_loss: 0.0013\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.9162e-04 - val_loss: 0.0013\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8806e-04 - val_loss: 0.0013\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8455e-04 - val_loss: 0.0013\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.8109e-04 - val_loss: 0.0013\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7765e-04 - val_loss: 0.0013\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7426e-04 - val_loss: 0.0013\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7091e-04 - val_loss: 0.0013\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6760e-04 - val_loss: 0.0012\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6433e-04 - val_loss: 0.0012\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.6109e-04 - val_loss: 0.0012\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5790e-04 - val_loss: 0.0012\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5474e-04 - val_loss: 0.0012\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5161e-04 - val_loss: 0.0012\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4853e-04 - val_loss: 0.0012\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4548e-04 - val_loss: 0.0012\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4245e-04 - val_loss: 0.0012\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3947e-04 - val_loss: 0.0011\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3651e-04 - val_loss: 0.0011\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3358e-04 - val_loss: 0.0011\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3069e-04 - val_loss: 0.0011\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2782e-04 - val_loss: 0.0011\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2498e-04 - val_loss: 0.0011\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2217e-04 - val_loss: 0.0011\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1939e-04 - val_loss: 0.0011\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1663e-04 - val_loss: 0.0011\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.1390e-04 - val_loss: 0.0011\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.1120e-04 - val_loss: 0.0010\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0853e-04 - val_loss: 0.0010\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0588e-04 - val_loss: 0.0010\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0325e-04 - val_loss: 0.0010\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0066e-04 - val_loss: 0.0010\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9809e-04 - val_loss: 9.9442e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9554e-04 - val_loss: 9.8482e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9302e-04 - val_loss: 9.7532e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.9052e-04 - val_loss: 9.6594e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8805e-04 - val_loss: 9.5666e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8560e-04 - val_loss: 9.4752e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8318e-04 - val_loss: 9.3845e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8078e-04 - val_loss: 9.2949e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7840e-04 - val_loss: 9.2066e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7605e-04 - val_loss: 9.1190e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7371e-04 - val_loss: 9.0327e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7140e-04 - val_loss: 8.9475e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6911e-04 - val_loss: 8.8632e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 2.6684e-04 - val_loss: 8.7797e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6460e-04 - val_loss: 8.6973e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6238e-04 - val_loss: 8.6156e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.6018e-04 - val_loss: 8.5349e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5800e-04 - val_loss: 8.4548e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5583e-04 - val_loss: 8.3758e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5370e-04 - val_loss: 8.2975e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5158e-04 - val_loss: 8.2197e-04\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 156us/step - loss: 2.4948e-04 - val_loss: 8.1426e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4739e-04 - val_loss: 8.0663e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4534e-04 - val_loss: 7.9908e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4330e-04 - val_loss: 7.9159e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4128e-04 - val_loss: 7.8416e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3928e-04 - val_loss: 7.7678e-04\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 176us/step - loss: 2.3729e-04 - val_loss: 7.6948e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3534e-04 - val_loss: 7.6224e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3339e-04 - val_loss: 7.5507e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3147e-04 - val_loss: 7.4795e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2956e-04 - val_loss: 7.4089e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2767e-04 - val_loss: 7.3389e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2580e-04 - val_loss: 7.2696e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2395e-04 - val_loss: 7.2009e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2211e-04 - val_loss: 7.1329e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2030e-04 - val_loss: 7.0654e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1850e-04 - val_loss: 6.9985e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1671e-04 - val_loss: 6.9322e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1495e-04 - val_loss: 6.8666e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.1320e-04 - val_loss: 6.8016e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1146e-04 - val_loss: 6.7373e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0975e-04 - val_loss: 6.6735e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0805e-04 - val_loss: 6.6104e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0637e-04 - val_loss: 6.5478e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0470e-04 - val_loss: 6.4860e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0305e-04 - val_loss: 6.4246e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0141e-04 - val_loss: 6.3640e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9979e-04 - val_loss: 6.3041e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9819e-04 - val_loss: 6.2446e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9660e-04 - val_loss: 6.1859e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9503e-04 - val_loss: 6.1275e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9347e-04 - val_loss: 6.0698e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.9193e-04 - val_loss: 6.0129e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9040e-04 - val_loss: 5.9564e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8889e-04 - val_loss: 5.9004e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8739e-04 - val_loss: 5.8451e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8590e-04 - val_loss: 5.7905e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8444e-04 - val_loss: 5.7362e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8298e-04 - val_loss: 5.6824e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8154e-04 - val_loss: 5.6293e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.8011e-04 - val_loss: 5.5766e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7870e-04 - val_loss: 5.5245e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7730e-04 - val_loss: 5.4729e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7591e-04 - val_loss: 5.4219e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7454e-04 - val_loss: 5.3714e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.7318e-04 - val_loss: 5.3211e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7183e-04 - val_loss: 5.2716e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7050e-04 - val_loss: 5.2226e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6918e-04 - val_loss: 5.1740e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6787e-04 - val_loss: 5.1258e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6658e-04 - val_loss: 5.0782e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6530e-04 - val_loss: 5.0310e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6402e-04 - val_loss: 4.9843e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6277e-04 - val_loss: 4.9382e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6153e-04 - val_loss: 4.8924e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6030e-04 - val_loss: 4.8470e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5907e-04 - val_loss: 4.8021e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5786e-04 - val_loss: 4.7578e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5667e-04 - val_loss: 4.7139e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.5548e-04 - val_loss: 4.6704e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5431e-04 - val_loss: 4.6274e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5315e-04 - val_loss: 4.5848e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5200e-04 - val_loss: 4.5424e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5086e-04 - val_loss: 4.5008e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4973e-04 - val_loss: 4.4595e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4862e-04 - val_loss: 4.4186e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4751e-04 - val_loss: 4.3782e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4642e-04 - val_loss: 4.3381e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4534e-04 - val_loss: 4.2985e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4426e-04 - val_loss: 4.2595e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4320e-04 - val_loss: 4.2205e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4215e-04 - val_loss: 4.1822e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4111e-04 - val_loss: 4.1443e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4008e-04 - val_loss: 4.1066e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.3906e-04 - val_loss: 4.0696e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3805e-04 - val_loss: 4.0327e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.3705e-04 - val_loss: 3.9965e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3606e-04 - val_loss: 3.9604e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3508e-04 - val_loss: 3.9248e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3411e-04 - val_loss: 3.8895e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3315e-04 - val_loss: 3.8546e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3220e-04 - val_loss: 3.8201e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3126e-04 - val_loss: 3.7859e-04\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3033e-04 - val_loss: 3.7523e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2941e-04 - val_loss: 3.7188e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2849e-04 - val_loss: 3.6857e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2758e-04 - val_loss: 3.6530e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2669e-04 - val_loss: 3.6206e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2580e-04 - val_loss: 3.5886e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.2493e-04 - val_loss: 3.5569e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2406e-04 - val_loss: 3.5256e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2320e-04 - val_loss: 3.4946e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2235e-04 - val_loss: 3.4639e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2151e-04 - val_loss: 3.4337e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2067e-04 - val_loss: 3.4035e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1984e-04 - val_loss: 3.3739e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1903e-04 - val_loss: 3.3446e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1822e-04 - val_loss: 3.3157e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1742e-04 - val_loss: 3.2869e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1663e-04 - val_loss: 3.2584e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1584e-04 - val_loss: 3.2305e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1507e-04 - val_loss: 3.2026e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1430e-04 - val_loss: 3.1751e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1354e-04 - val_loss: 3.1479e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1279e-04 - val_loss: 3.1210e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1204e-04 - val_loss: 3.0944e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1130e-04 - val_loss: 3.0682e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 1.1057e-04 - val_loss: 3.0421e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0985e-04 - val_loss: 3.0165e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.0913e-04 - val_loss: 2.9909e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0842e-04 - val_loss: 2.9658e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0772e-04 - val_loss: 2.9409e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0703e-04 - val_loss: 2.9163e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0634e-04 - val_loss: 2.8919e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0566e-04 - val_loss: 2.8677e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0498e-04 - val_loss: 2.8440e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0432e-04 - val_loss: 2.8205e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0366e-04 - val_loss: 2.7972e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0301e-04 - val_loss: 2.7742e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0236e-04 - val_loss: 2.7513e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0172e-04 - val_loss: 2.7289e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0109e-04 - val_loss: 2.7066e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0046e-04 - val_loss: 2.6845e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9840e-05 - val_loss: 2.6626e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.9223e-05 - val_loss: 2.6411e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8619e-05 - val_loss: 2.6197e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8011e-05 - val_loss: 2.5986e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.7415e-05 - val_loss: 2.5779e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6828e-05 - val_loss: 2.5573e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6243e-05 - val_loss: 2.5369e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5664e-05 - val_loss: 2.5166e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5092e-05 - val_loss: 2.4969e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4528e-05 - val_loss: 2.4771e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3965e-05 - val_loss: 2.4576e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3409e-05 - val_loss: 2.4384e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2858e-05 - val_loss: 2.4193e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2317e-05 - val_loss: 2.4006e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1778e-05 - val_loss: 2.3818e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1245e-05 - val_loss: 2.3635e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0717e-05 - val_loss: 2.3451e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0193e-05 - val_loss: 2.3272e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9677e-05 - val_loss: 2.3094e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9166e-05 - val_loss: 2.2918e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8657e-05 - val_loss: 2.2744e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8154e-05 - val_loss: 2.2571e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7657e-05 - val_loss: 2.2401e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7164e-05 - val_loss: 2.2233e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6679e-05 - val_loss: 2.2067e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6197e-05 - val_loss: 2.1902e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5718e-05 - val_loss: 2.1739e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5243e-05 - val_loss: 2.1578e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4778e-05 - val_loss: 2.1419e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4314e-05 - val_loss: 2.1262e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3856e-05 - val_loss: 2.1106e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3402e-05 - val_loss: 2.0952e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2951e-05 - val_loss: 2.0800e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.2506e-05 - val_loss: 2.0648e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2061e-05 - val_loss: 2.0500e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1629e-05 - val_loss: 2.0351e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1195e-05 - val_loss: 2.0206e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.0766e-05 - val_loss: 2.0062e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0342e-05 - val_loss: 1.9920e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9923e-05 - val_loss: 1.9779e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.9507e-05 - val_loss: 1.9639e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.9094e-05 - val_loss: 1.9501e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8686e-05 - val_loss: 1.9365e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8283e-05 - val_loss: 1.9230e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7883e-05 - val_loss: 1.9096e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7486e-05 - val_loss: 1.8966e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.7095e-05 - val_loss: 1.8834e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6704e-05 - val_loss: 1.8705e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6322e-05 - val_loss: 1.8577e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5936e-05 - val_loss: 1.8452e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5561e-05 - val_loss: 1.8328e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5190e-05 - val_loss: 1.8203e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4817e-05 - val_loss: 1.8081e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4449e-05 - val_loss: 1.7961e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4086e-05 - val_loss: 1.7842e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.3727e-05 - val_loss: 1.7723e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3371e-05 - val_loss: 1.7607e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3018e-05 - val_loss: 1.7492e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2667e-05 - val_loss: 1.7377e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2318e-05 - val_loss: 1.7263e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.1976e-05 - val_loss: 1.7152e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.1634e-05 - val_loss: 1.7042e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1300e-05 - val_loss: 1.6932e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0966e-05 - val_loss: 1.6823e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0633e-05 - val_loss: 1.6717e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0308e-05 - val_loss: 1.6610e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9982e-05 - val_loss: 1.6505e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9659e-05 - val_loss: 1.6402e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9342e-05 - val_loss: 1.6299e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9024e-05 - val_loss: 1.6198e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8712e-05 - val_loss: 1.6097e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8399e-05 - val_loss: 1.5997e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8093e-05 - val_loss: 1.5899e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7788e-05 - val_loss: 1.5801e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7486e-05 - val_loss: 1.5705e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 159us/step - loss: 6.7186e-05 - val_loss: 1.5610e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6890e-05 - val_loss: 1.5515e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6594e-05 - val_loss: 1.5422e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6302e-05 - val_loss: 1.5329e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.6016e-05 - val_loss: 1.5238e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5730e-05 - val_loss: 1.5148e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5445e-05 - val_loss: 1.5057e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.5162e-05 - val_loss: 1.4969e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4884e-05 - val_loss: 1.4882e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4608e-05 - val_loss: 1.4795e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4333e-05 - val_loss: 1.4709e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4061e-05 - val_loss: 1.4623e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3791e-05 - val_loss: 1.4540e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3527e-05 - val_loss: 1.4456e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3260e-05 - val_loss: 1.4374e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2998e-05 - val_loss: 1.4292e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2737e-05 - val_loss: 1.4211e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 6.2480e-05 - val_loss: 1.4131e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2225e-05 - val_loss: 1.4053e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1971e-05 - val_loss: 1.3973e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1718e-05 - val_loss: 1.3896e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1469e-05 - val_loss: 1.3818e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1221e-05 - val_loss: 1.3742e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0975e-05 - val_loss: 1.3668e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0732e-05 - val_loss: 1.3593e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0490e-05 - val_loss: 1.3519e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0250e-05 - val_loss: 1.3446e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0011e-05 - val_loss: 1.3373e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9775e-05 - val_loss: 1.3302e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9542e-05 - val_loss: 1.3230e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9311e-05 - val_loss: 1.3159e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9080e-05 - val_loss: 1.3090e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8852e-05 - val_loss: 1.3021e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8625e-05 - val_loss: 1.2953e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8402e-05 - val_loss: 1.2885e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8180e-05 - val_loss: 1.2818e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7960e-05 - val_loss: 1.2751e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7740e-05 - val_loss: 1.2684e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7520e-05 - val_loss: 1.2619e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7306e-05 - val_loss: 1.2554e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7088e-05 - val_loss: 1.2490e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.6880e-05 - val_loss: 1.2427e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6669e-05 - val_loss: 1.2364e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6459e-05 - val_loss: 1.2302e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.6248e-05 - val_loss: 1.2240e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6041e-05 - val_loss: 1.2179e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5838e-05 - val_loss: 1.2118e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5635e-05 - val_loss: 1.2058e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5431e-05 - val_loss: 1.1998e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.5229e-05 - val_loss: 1.1939e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5033e-05 - val_loss: 1.1881e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4834e-05 - val_loss: 1.1824e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4639e-05 - val_loss: 1.1766e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4445e-05 - val_loss: 1.1709e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.4252e-05 - val_loss: 1.1653e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4059e-05 - val_loss: 1.1597e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3869e-05 - val_loss: 1.1541e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3680e-05 - val_loss: 1.1486e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3491e-05 - val_loss: 1.1431e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3304e-05 - val_loss: 1.1378e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3123e-05 - val_loss: 1.1324e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2936e-05 - val_loss: 1.1271e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2754e-05 - val_loss: 1.1219e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2572e-05 - val_loss: 1.1166e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2394e-05 - val_loss: 1.1114e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2214e-05 - val_loss: 1.1063e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2036e-05 - val_loss: 1.1012e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1860e-05 - val_loss: 1.0961e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1684e-05 - val_loss: 1.0911e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1510e-05 - val_loss: 1.0861e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1336e-05 - val_loss: 1.0811e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.1165e-05 - val_loss: 1.0762e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0994e-05 - val_loss: 1.0714e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0824e-05 - val_loss: 1.0666e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0656e-05 - val_loss: 1.0618e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 5.0489e-05 - val_loss: 1.0571e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0323e-05 - val_loss: 1.0524e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0158e-05 - val_loss: 1.0477e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9993e-05 - val_loss: 1.0431e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9831e-05 - val_loss: 1.0384e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9668e-05 - val_loss: 1.0339e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9508e-05 - val_loss: 1.0294e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9348e-05 - val_loss: 1.0249e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9189e-05 - val_loss: 1.0204e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9030e-05 - val_loss: 1.0160e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8873e-05 - val_loss: 1.0116e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8717e-05 - val_loss: 1.0074e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8562e-05 - val_loss: 1.0030e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8408e-05 - val_loss: 9.9869e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8254e-05 - val_loss: 9.9454e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.8104e-05 - val_loss: 9.9028e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7951e-05 - val_loss: 9.8609e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7802e-05 - val_loss: 9.8194e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7651e-05 - val_loss: 9.7778e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7504e-05 - val_loss: 9.7364e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7354e-05 - val_loss: 9.6962e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7207e-05 - val_loss: 9.6556e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7061e-05 - val_loss: 9.6155e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6917e-05 - val_loss: 9.5752e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 160us/step - loss: 4.6770e-05 - val_loss: 9.5360e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6626e-05 - val_loss: 9.4965e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6484e-05 - val_loss: 9.4576e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6343e-05 - val_loss: 9.4192e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6202e-05 - val_loss: 9.3803e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6060e-05 - val_loss: 9.3424e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5920e-05 - val_loss: 9.3044e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5780e-05 - val_loss: 9.2673e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5646e-05 - val_loss: 9.2297e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5507e-05 - val_loss: 9.1920e-05\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5370e-05 - val_loss: 9.1555e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5235e-05 - val_loss: 9.1184e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5097e-05 - val_loss: 9.0820e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4964e-05 - val_loss: 9.0450e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4830e-05 - val_loss: 9.0107e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4700e-05 - val_loss: 8.9747e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4567e-05 - val_loss: 8.9383e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4433e-05 - val_loss: 8.9036e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4303e-05 - val_loss: 8.8687e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4173e-05 - val_loss: 8.8335e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4043e-05 - val_loss: 8.8000e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3915e-05 - val_loss: 8.7640e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3786e-05 - val_loss: 8.7302e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3659e-05 - val_loss: 8.6963e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3530e-05 - val_loss: 8.6624e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.3405e-05 - val_loss: 8.6289e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3280e-05 - val_loss: 8.5958e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3156e-05 - val_loss: 8.5626e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3031e-05 - val_loss: 8.5293e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2906e-05 - val_loss: 8.4973e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2784e-05 - val_loss: 8.4640e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2660e-05 - val_loss: 8.4319e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2539e-05 - val_loss: 8.3995e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2418e-05 - val_loss: 8.3678e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2299e-05 - val_loss: 8.3361e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.2178e-05 - val_loss: 8.3037e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.2057e-05 - val_loss: 8.2731e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1939e-05 - val_loss: 8.2419e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1822e-05 - val_loss: 8.2112e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1705e-05 - val_loss: 8.1798e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1585e-05 - val_loss: 8.1497e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1469e-05 - val_loss: 8.1190e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1352e-05 - val_loss: 8.0891e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1238e-05 - val_loss: 8.0584e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1123e-05 - val_loss: 8.0290e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1009e-05 - val_loss: 7.9995e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0894e-05 - val_loss: 7.9700e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0780e-05 - val_loss: 7.9404e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0669e-05 - val_loss: 7.9112e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0554e-05 - val_loss: 7.8821e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0444e-05 - val_loss: 7.8532e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0332e-05 - val_loss: 7.8236e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0219e-05 - val_loss: 7.7958e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0110e-05 - val_loss: 7.7667e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0000e-05 - val_loss: 7.7385e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9890e-05 - val_loss: 7.7105e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9781e-05 - val_loss: 7.6825e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9673e-05 - val_loss: 7.6542e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9565e-05 - val_loss: 7.6264e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9457e-05 - val_loss: 7.5989e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9350e-05 - val_loss: 7.5718e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9245e-05 - val_loss: 7.5442e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9137e-05 - val_loss: 7.5167e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9032e-05 - val_loss: 7.4904e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8928e-05 - val_loss: 7.4630e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8823e-05 - val_loss: 7.4366e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8719e-05 - val_loss: 7.4098e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8615e-05 - val_loss: 7.3832e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8510e-05 - val_loss: 7.3570e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8407e-05 - val_loss: 7.3305e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8305e-05 - val_loss: 7.3046e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8202e-05 - val_loss: 7.2791e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8102e-05 - val_loss: 7.2522e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8001e-05 - val_loss: 7.2274e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7900e-05 - val_loss: 7.2014e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7799e-05 - val_loss: 7.1765e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7700e-05 - val_loss: 7.1511e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7601e-05 - val_loss: 7.1250e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7500e-05 - val_loss: 7.1006e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7401e-05 - val_loss: 7.0757e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7304e-05 - val_loss: 7.0512e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7206e-05 - val_loss: 7.0266e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7107e-05 - val_loss: 7.0015e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7010e-05 - val_loss: 6.9772e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6913e-05 - val_loss: 6.9530e-05\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6819e-05 - val_loss: 6.9289e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6723e-05 - val_loss: 6.9042e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6623e-05 - val_loss: 6.8808e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6531e-05 - val_loss: 6.8565e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6436e-05 - val_loss: 6.8330e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6343e-05 - val_loss: 6.8095e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6248e-05 - val_loss: 6.7859e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6154e-05 - val_loss: 6.7621e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6060e-05 - val_loss: 6.7389e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5969e-05 - val_loss: 6.7160e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5876e-05 - val_loss: 6.6928e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5784e-05 - val_loss: 6.6694e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5691e-05 - val_loss: 6.6467e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5600e-05 - val_loss: 6.6236e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5509e-05 - val_loss: 6.6009e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5417e-05 - val_loss: 6.5786e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5328e-05 - val_loss: 6.5560e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5237e-05 - val_loss: 6.5339e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5148e-05 - val_loss: 6.5113e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5059e-05 - val_loss: 6.4896e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4971e-05 - val_loss: 6.4671e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4882e-05 - val_loss: 6.4454e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4794e-05 - val_loss: 6.4232e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4703e-05 - val_loss: 6.4015e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4617e-05 - val_loss: 6.3797e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4530e-05 - val_loss: 6.3578e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4443e-05 - val_loss: 6.3367e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4357e-05 - val_loss: 6.3153e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4271e-05 - val_loss: 6.2937e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4184e-05 - val_loss: 6.2725e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4097e-05 - val_loss: 6.2517e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4014e-05 - val_loss: 6.2310e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3928e-05 - val_loss: 6.2092e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3842e-05 - val_loss: 6.1885e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.3759e-05 - val_loss: 6.1678e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3673e-05 - val_loss: 6.1472e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3590e-05 - val_loss: 6.1263e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3505e-05 - val_loss: 6.1059e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3424e-05 - val_loss: 6.0858e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3341e-05 - val_loss: 6.0655e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3257e-05 - val_loss: 6.0453e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.3175e-05 - val_loss: 6.0250e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3093e-05 - val_loss: 6.0048e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.3011e-05 - val_loss: 5.9848e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2929e-05 - val_loss: 5.9649e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.2849e-05 - val_loss: 5.9450e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2767e-05 - val_loss: 5.9251e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2686e-05 - val_loss: 5.9057e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2607e-05 - val_loss: 5.8862e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.2527e-05 - val_loss: 5.8664e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2447e-05 - val_loss: 5.8470e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2367e-05 - val_loss: 5.8278e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.2290e-05 - val_loss: 5.8088e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.2212e-05 - val_loss: 5.7896e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2131e-05 - val_loss: 5.7697e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2053e-05 - val_loss: 5.7511e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1973e-05 - val_loss: 5.7319e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1896e-05 - val_loss: 5.7132e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1819e-05 - val_loss: 5.6947e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1743e-05 - val_loss: 5.6756e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1666e-05 - val_loss: 5.6572e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1587e-05 - val_loss: 5.6392e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1513e-05 - val_loss: 5.6206e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1435e-05 - val_loss: 5.6020e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1360e-05 - val_loss: 5.5839e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1285e-05 - val_loss: 5.5656e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1209e-05 - val_loss: 5.5473e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.1132e-05 - val_loss: 5.5290e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.1059e-05 - val_loss: 5.5103e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0983e-05 - val_loss: 5.4930e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0911e-05 - val_loss: 5.4746e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0836e-05 - val_loss: 5.4569e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0762e-05 - val_loss: 5.4394e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.0690e-05 - val_loss: 5.4213e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0615e-05 - val_loss: 5.4033e-05\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0543e-05 - val_loss: 5.3855e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0467e-05 - val_loss: 5.3678e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0394e-05 - val_loss: 5.3507e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.0323e-05 - val_loss: 5.3333e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0251e-05 - val_loss: 5.3161e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0180e-05 - val_loss: 5.2988e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0107e-05 - val_loss: 5.2818e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.0036e-05 - val_loss: 5.2645e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9965e-05 - val_loss: 5.2474e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9893e-05 - val_loss: 5.2304e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9823e-05 - val_loss: 5.2133e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9753e-05 - val_loss: 5.1966e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.9683e-05 - val_loss: 5.1801e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9613e-05 - val_loss: 5.1639e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9544e-05 - val_loss: 5.1466e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9474e-05 - val_loss: 5.1296e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9404e-05 - val_loss: 5.1132e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9335e-05 - val_loss: 5.0967e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9266e-05 - val_loss: 5.0802e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 150us/step - loss: 2.9199e-05 - val_loss: 5.0643e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9131e-05 - val_loss: 5.0468e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.9061e-05 - val_loss: 5.0308e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.8992e-05 - val_loss: 5.0147e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8925e-05 - val_loss: 4.9985e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8857e-05 - val_loss: 4.9821e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.8790e-05 - val_loss: 4.9662e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8723e-05 - val_loss: 4.9505e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8656e-05 - val_loss: 4.9345e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8588e-05 - val_loss: 4.9185e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8523e-05 - val_loss: 4.9027e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.8457e-05 - val_loss: 4.8868e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8390e-05 - val_loss: 4.8715e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8325e-05 - val_loss: 4.8561e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8259e-05 - val_loss: 4.8405e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8193e-05 - val_loss: 4.8249e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8127e-05 - val_loss: 4.8099e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8064e-05 - val_loss: 4.7943e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7997e-05 - val_loss: 4.7786e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7933e-05 - val_loss: 4.7642e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7869e-05 - val_loss: 4.7485e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7805e-05 - val_loss: 4.7335e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7742e-05 - val_loss: 4.7185e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7675e-05 - val_loss: 4.7037e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7614e-05 - val_loss: 4.6885e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7549e-05 - val_loss: 4.6738e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 147us/step - loss: 2.7487e-05 - val_loss: 4.6584e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7422e-05 - val_loss: 4.6435e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7359e-05 - val_loss: 4.6290e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7297e-05 - val_loss: 4.6141e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7235e-05 - val_loss: 4.5997e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7174e-05 - val_loss: 4.5850e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7110e-05 - val_loss: 4.5702e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7048e-05 - val_loss: 4.5555e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6987e-05 - val_loss: 4.5415e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6927e-05 - val_loss: 4.5263e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6863e-05 - val_loss: 4.5122e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6803e-05 - val_loss: 4.4977e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6741e-05 - val_loss: 4.4836e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6682e-05 - val_loss: 4.4698e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6622e-05 - val_loss: 4.4553e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6562e-05 - val_loss: 4.4415e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6502e-05 - val_loss: 4.4272e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6440e-05 - val_loss: 4.4132e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6381e-05 - val_loss: 4.3989e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6320e-05 - val_loss: 4.3855e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6263e-05 - val_loss: 4.3716e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6202e-05 - val_loss: 4.3585e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6144e-05 - val_loss: 4.3443e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6085e-05 - val_loss: 4.3307e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.6027e-05 - val_loss: 4.3169e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5968e-05 - val_loss: 4.3035e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5909e-05 - val_loss: 4.2895e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5850e-05 - val_loss: 4.2763e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5793e-05 - val_loss: 4.2627e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5736e-05 - val_loss: 4.2494e-05\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5678e-05 - val_loss: 4.2362e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5620e-05 - val_loss: 4.2227e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5563e-05 - val_loss: 4.2095e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5506e-05 - val_loss: 4.1960e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.5448e-05 - val_loss: 4.1834e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5393e-05 - val_loss: 4.1701e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5337e-05 - val_loss: 4.1567e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5279e-05 - val_loss: 4.1436e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5224e-05 - val_loss: 4.1307e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5167e-05 - val_loss: 4.1174e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5111e-05 - val_loss: 4.1047e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5056e-05 - val_loss: 4.0921e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4999e-05 - val_loss: 4.0791e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4945e-05 - val_loss: 4.0665e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4891e-05 - val_loss: 4.0536e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.4835e-05 - val_loss: 4.0409e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4779e-05 - val_loss: 4.0280e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4725e-05 - val_loss: 4.0152e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4669e-05 - val_loss: 4.0028e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4616e-05 - val_loss: 3.9902e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4562e-05 - val_loss: 3.9781e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4509e-05 - val_loss: 3.9651e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4452e-05 - val_loss: 3.9529e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4400e-05 - val_loss: 3.9406e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4347e-05 - val_loss: 3.9285e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4294e-05 - val_loss: 3.9164e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4240e-05 - val_loss: 3.9038e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4189e-05 - val_loss: 3.8914e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4134e-05 - val_loss: 3.8792e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4082e-05 - val_loss: 3.8672e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4029e-05 - val_loss: 3.8552e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3977e-05 - val_loss: 3.8433e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3924e-05 - val_loss: 3.8315e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3871e-05 - val_loss: 3.8196e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.3820e-05 - val_loss: 3.8077e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3769e-05 - val_loss: 3.7956e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3716e-05 - val_loss: 3.7840e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3665e-05 - val_loss: 3.7719e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3613e-05 - val_loss: 3.7602e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3562e-05 - val_loss: 3.7485e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3512e-05 - val_loss: 3.7372e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3461e-05 - val_loss: 3.7253e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3409e-05 - val_loss: 3.7141e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3359e-05 - val_loss: 3.7023e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3308e-05 - val_loss: 3.6909e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3259e-05 - val_loss: 3.6793e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3208e-05 - val_loss: 3.6679e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3159e-05 - val_loss: 3.6562e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3108e-05 - val_loss: 3.6450e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3058e-05 - val_loss: 3.6335e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3008e-05 - val_loss: 3.6225e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2959e-05 - val_loss: 3.6112e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2910e-05 - val_loss: 3.6002e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2861e-05 - val_loss: 3.5891e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2812e-05 - val_loss: 3.5776e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2763e-05 - val_loss: 3.5667e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2713e-05 - val_loss: 3.5557e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2666e-05 - val_loss: 3.5450e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2618e-05 - val_loss: 3.5333e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2567e-05 - val_loss: 3.5225e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2520e-05 - val_loss: 3.5119e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2474e-05 - val_loss: 3.5011e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2424e-05 - val_loss: 3.4901e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2377e-05 - val_loss: 3.4794e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2330e-05 - val_loss: 3.4685e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2281e-05 - val_loss: 3.4579e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2234e-05 - val_loss: 3.4473e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2187e-05 - val_loss: 3.4364e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2140e-05 - val_loss: 3.4260e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.2093e-05 - val_loss: 3.4154e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.2047e-05 - val_loss: 3.4052e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2001e-05 - val_loss: 3.3945e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1954e-05 - val_loss: 3.3841e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1907e-05 - val_loss: 3.3739e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1862e-05 - val_loss: 3.3631e-05\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1814e-05 - val_loss: 3.3527e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1769e-05 - val_loss: 3.3422e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1722e-05 - val_loss: 3.3319e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1677e-05 - val_loss: 3.3217e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1632e-05 - val_loss: 3.3117e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1586e-05 - val_loss: 3.3016e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1542e-05 - val_loss: 3.2911e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1496e-05 - val_loss: 3.2809e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1451e-05 - val_loss: 3.2709e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1407e-05 - val_loss: 3.2609e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1362e-05 - val_loss: 3.2509e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1318e-05 - val_loss: 3.2410e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1273e-05 - val_loss: 3.2310e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1228e-05 - val_loss: 3.2208e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1184e-05 - val_loss: 3.2113e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1141e-05 - val_loss: 3.2012e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1096e-05 - val_loss: 3.1917e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1052e-05 - val_loss: 3.1816e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1009e-05 - val_loss: 3.1722e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0966e-05 - val_loss: 3.1622e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0921e-05 - val_loss: 3.1525e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0878e-05 - val_loss: 3.1431e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0835e-05 - val_loss: 3.1334e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0792e-05 - val_loss: 3.1237e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0749e-05 - val_loss: 3.1143e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0707e-05 - val_loss: 3.1044e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0662e-05 - val_loss: 3.0953e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0621e-05 - val_loss: 3.0857e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0578e-05 - val_loss: 3.0761e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0536e-05 - val_loss: 3.0666e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0494e-05 - val_loss: 3.0572e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0452e-05 - val_loss: 3.0479e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0410e-05 - val_loss: 3.0381e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0368e-05 - val_loss: 3.0293e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0328e-05 - val_loss: 3.0198e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0284e-05 - val_loss: 3.0104e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0243e-05 - val_loss: 3.0013e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0202e-05 - val_loss: 2.9921e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0161e-05 - val_loss: 2.9828e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0120e-05 - val_loss: 2.9740e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.0078e-05 - val_loss: 2.9648e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0037e-05 - val_loss: 2.9562e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.9997e-05 - val_loss: 2.9469e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9956e-05 - val_loss: 2.9378e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9915e-05 - val_loss: 2.9287e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9874e-05 - val_loss: 2.9200e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9835e-05 - val_loss: 2.9112e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9794e-05 - val_loss: 2.9020e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9754e-05 - val_loss: 2.8936e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9714e-05 - val_loss: 2.8844e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9674e-05 - val_loss: 2.8758e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9634e-05 - val_loss: 2.8669e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9595e-05 - val_loss: 2.8585e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9556e-05 - val_loss: 2.8496e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9516e-05 - val_loss: 2.8409e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9475e-05 - val_loss: 2.8324e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9437e-05 - val_loss: 2.8240e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9399e-05 - val_loss: 2.8152e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9359e-05 - val_loss: 2.8068e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9321e-05 - val_loss: 2.7980e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9282e-05 - val_loss: 2.7898e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9242e-05 - val_loss: 2.7813e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9204e-05 - val_loss: 2.7729e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9166e-05 - val_loss: 2.7645e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9128e-05 - val_loss: 2.7559e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9089e-05 - val_loss: 2.7478e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9051e-05 - val_loss: 2.7392e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9013e-05 - val_loss: 2.7307e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8976e-05 - val_loss: 2.7224e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8937e-05 - val_loss: 2.7142e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8901e-05 - val_loss: 2.7059e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.8863e-05 - val_loss: 2.6974e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8825e-05 - val_loss: 2.6895e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8787e-05 - val_loss: 2.6811e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8751e-05 - val_loss: 2.6734e-05\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8715e-05 - val_loss: 2.6653e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8677e-05 - val_loss: 2.6573e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8639e-05 - val_loss: 2.6491e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8602e-05 - val_loss: 2.6412e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8566e-05 - val_loss: 2.6333e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8529e-05 - val_loss: 2.6251e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8492e-05 - val_loss: 2.6174e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8457e-05 - val_loss: 2.6091e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8420e-05 - val_loss: 2.6013e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8384e-05 - val_loss: 2.5938e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8348e-05 - val_loss: 2.5859e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8312e-05 - val_loss: 2.5779e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8276e-05 - val_loss: 2.5700e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8242e-05 - val_loss: 2.5623e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8205e-05 - val_loss: 2.5545e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8169e-05 - val_loss: 2.5470e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8134e-05 - val_loss: 2.5391e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8099e-05 - val_loss: 2.5315e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8064e-05 - val_loss: 2.5237e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8028e-05 - val_loss: 2.5164e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7994e-05 - val_loss: 2.5087e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7958e-05 - val_loss: 2.5012e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7923e-05 - val_loss: 2.4938e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7889e-05 - val_loss: 2.4864e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7855e-05 - val_loss: 2.4787e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7819e-05 - val_loss: 2.4714e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7786e-05 - val_loss: 2.4640e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7751e-05 - val_loss: 2.4564e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7716e-05 - val_loss: 2.4490e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7682e-05 - val_loss: 2.4419e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7648e-05 - val_loss: 2.4343e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7615e-05 - val_loss: 2.4269e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7580e-05 - val_loss: 2.4196e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7546e-05 - val_loss: 2.4123e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7512e-05 - val_loss: 2.4052e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7480e-05 - val_loss: 2.3978e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7444e-05 - val_loss: 2.3907e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7412e-05 - val_loss: 2.3836e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7379e-05 - val_loss: 2.3764e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7345e-05 - val_loss: 2.3692e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7312e-05 - val_loss: 2.3621e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7279e-05 - val_loss: 2.3552e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7246e-05 - val_loss: 2.3481e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7213e-05 - val_loss: 2.3408e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7180e-05 - val_loss: 2.3339e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7147e-05 - val_loss: 2.3271e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7116e-05 - val_loss: 2.3202e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7083e-05 - val_loss: 2.3131e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7051e-05 - val_loss: 2.3059e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7018e-05 - val_loss: 2.2991e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6986e-05 - val_loss: 2.2924e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6954e-05 - val_loss: 2.2856e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6921e-05 - val_loss: 2.2788e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6891e-05 - val_loss: 2.2717e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6858e-05 - val_loss: 2.2651e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6826e-05 - val_loss: 2.2582e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6794e-05 - val_loss: 2.2514e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6763e-05 - val_loss: 2.2448e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6731e-05 - val_loss: 2.2382e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6701e-05 - val_loss: 2.2315e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6669e-05 - val_loss: 2.2248e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6637e-05 - val_loss: 2.2181e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6606e-05 - val_loss: 2.2113e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6574e-05 - val_loss: 2.2046e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6543e-05 - val_loss: 2.1983e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6513e-05 - val_loss: 2.1914e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6482e-05 - val_loss: 2.1850e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6451e-05 - val_loss: 2.1786e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6421e-05 - val_loss: 2.1722e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6390e-05 - val_loss: 2.1658e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6360e-05 - val_loss: 2.1591e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6329e-05 - val_loss: 2.1527e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6299e-05 - val_loss: 2.1462e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6268e-05 - val_loss: 2.1400e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.6238e-05 - val_loss: 2.1337e-05\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6208e-05 - val_loss: 2.1273e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6178e-05 - val_loss: 2.1208e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6149e-05 - val_loss: 2.1145e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6118e-05 - val_loss: 2.1084e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6089e-05 - val_loss: 2.1023e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6060e-05 - val_loss: 2.0958e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6030e-05 - val_loss: 2.0896e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6000e-05 - val_loss: 2.0832e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5970e-05 - val_loss: 2.0773e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5942e-05 - val_loss: 2.0711e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5912e-05 - val_loss: 2.0649e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5883e-05 - val_loss: 2.0589e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5855e-05 - val_loss: 2.0527e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5825e-05 - val_loss: 2.0467e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.5796e-05 - val_loss: 2.0406e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5768e-05 - val_loss: 2.0344e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5739e-05 - val_loss: 2.0282e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5709e-05 - val_loss: 2.0222e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5681e-05 - val_loss: 2.0166e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5654e-05 - val_loss: 2.0106e-05\n",
      "4.836893822357524e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.6241488 ,  0.3950121 ,  1.0222819 , -0.38111869,  0.03728871],\n",
       "        [-0.9257945 ,  0.3280026 , -0.89387   ,  0.3939142 ,  0.05936173],\n",
       "        [ 1.3252648 ,  0.10865033,  1.2346674 , -0.14851665, -0.38040066]],\n",
       "       dtype=float32),\n",
       " array([ 0.72371936, -0.6790009 ,  0.9120876 , -0.77194107, -0.6514658 ],\n",
       "       dtype=float32),\n",
       " array([[-0.24172854, -1.073463  ,  0.9140583 ,  0.96402   ,  1.2402463 ,\n",
       "         -1.3685745 ,  0.66942185, -0.89072174, -1.2900589 ,  1.2639164 ],\n",
       "        [ 0.27368662, -0.45651546,  0.32009128,  0.26671144,  0.5060737 ,\n",
       "         -0.48823732,  0.18656494, -0.83235097, -0.7063517 ,  1.0356672 ],\n",
       "        [-1.076289  , -0.78816813,  1.5337472 ,  0.68875283,  0.3815732 ,\n",
       "         -1.317498  ,  1.3186015 , -1.248862  , -1.1567262 ,  0.4609596 ],\n",
       "        [ 0.48327595, -0.7269102 ,  0.4793119 ,  0.39941725,  0.6119275 ,\n",
       "         -0.5928275 ,  0.2756223 , -0.6380049 , -0.18318164,  0.14729273],\n",
       "        [ 0.6362725 , -0.42463973,  0.72592646,  0.6511137 ,  0.34374812,\n",
       "         -0.8141107 ,  0.45534858, -0.34465182, -0.781465  ,  0.26625854]],\n",
       "       dtype=float32),\n",
       " array([ 0.56426096, -0.8170881 ,  1.2008832 ,  1.1143397 ,  1.0955795 ,\n",
       "         0.12734488,  1.1035824 , -0.68433875, -0.8887304 ,  1.1517116 ],\n",
       "       dtype=float32),\n",
       " array([[0.5114299 ],\n",
       "        [0.5625607 ],\n",
       "        [0.7886536 ],\n",
       "        [1.0386485 ],\n",
       "        [1.1839415 ],\n",
       "        [0.8685775 ],\n",
       "        [1.3206096 ],\n",
       "        [0.7024868 ],\n",
       "        [0.2989198 ],\n",
       "        [0.88012135]], dtype=float32),\n",
       " array([0.78144056], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_sigmoid(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sigmoid_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 42.5138 - val_loss: 39.1352\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 37.1406 - val_loss: 32.7931\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 31.1584 - val_loss: 26.8454\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.2430 - val_loss: 21.1332\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 19.3600 - val_loss: 15.7386\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 13.6951 - val_loss: 10.7645\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6089 - val_loss: 6.5541\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 4.5417 - val_loss: 3.4056\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7832 - val_loss: 1.4024\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4138 - val_loss: 0.5563\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.2507 - val_loss: 0.6623\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.8808 - val_loss: 1.2668\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7742 - val_loss: 1.8763\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4801 - val_loss: 2.1978\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7757 - val_loss: 2.1606\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6527 - val_loss: 1.8356\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2220 - val_loss: 1.3505\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6326 - val_loss: 0.8379\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0263 - val_loss: 0.4051\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5150 - val_loss: 0.1214\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1690 - val_loss: 0.0125\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.0629\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0319 - val_loss: 0.2248\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1734 - val_loss: 0.4332\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.3708 - val_loss: 0.6244\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5575 - val_loss: 0.7506\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.6837 - val_loss: 0.7885\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.7247 - val_loss: 0.7392\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.6804 - val_loss: 0.6224\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5701 - val_loss: 0.4680\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.4234 - val_loss: 0.3077\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.2717 - val_loss: 0.1685\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1417 - val_loss: 0.0682\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0510 - val_loss: 0.0142\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0063 - val_loss: 0.0033\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0249\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.0642\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0794 - val_loss: 0.1059\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1258 - val_loss: 0.1380\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1607 - val_loss: 0.1529\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1766 - val_loss: 0.1489\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1719 - val_loss: 0.1288\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1496 - val_loss: 0.0984\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1161 - val_loss: 0.0649\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0787 - val_loss: 0.0351\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0447 - val_loss: 0.0136\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0190 - val_loss: 0.0029\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9312e-04 - val_loss: 0.0107\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0233\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.0367\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0272 - val_loss: 0.0477\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0369 - val_loss: 0.0539\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0426 - val_loss: 0.0546\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0433 - val_loss: 0.0501\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0393 - val_loss: 0.0417\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0211\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.5745e-04 - val_loss: 0.0014\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9388e-04 - val_loss: 0.0022\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6814e-04 - val_loss: 0.0022\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.2882e-04 - val_loss: 0.0033\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6011e-04 - val_loss: 0.0046\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0066\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1751e-04 - val_loss: 0.0028\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3504e-04 - val_loss: 0.0022\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.1928e-04 - val_loss: 0.0017\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.6855e-04 - val_loss: 0.0014\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4863e-04 - val_loss: 0.0013\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0579e-04 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8162e-04 - val_loss: 0.0012\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 8.2586e-04 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0537e-04 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0764e-04 - val_loss: 0.0012\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3950e-04 - val_loss: 0.0012\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.2185e-04 - val_loss: 0.0012\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8274e-04 - val_loss: 0.0013\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4997e-04 - val_loss: 0.0014\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 3.4530e-04 - val_loss: 0.0015\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8095e-04 - val_loss: 0.0017\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5885e-04 - val_loss: 0.0019\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7207e-04 - val_loss: 0.0021\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.0791e-04 - val_loss: 0.0022\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5166e-04 - val_loss: 0.0023\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8997e-04 - val_loss: 0.0024\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1342e-04 - val_loss: 0.0024\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 4.1772e-04 - val_loss: 0.0024\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 4.0364e-04 - val_loss: 0.0023\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7581e-04 - val_loss: 0.0022\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 3.4109e-04 - val_loss: 0.0021\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.0665e-04 - val_loss: 0.0019\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7835e-04 - val_loss: 0.0018\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5979e-04 - val_loss: 0.0017\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5197e-04 - val_loss: 0.0016\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5348e-04 - val_loss: 0.0015\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 2.6136e-04 - val_loss: 0.0015\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7188e-04 - val_loss: 0.0014\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.8157e-04 - val_loss: 0.0014\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.8785e-04 - val_loss: 0.0014\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8938e-04 - val_loss: 0.0014\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.8616e-04 - val_loss: 0.0014\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.7924e-04 - val_loss: 0.0014\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.7029e-04 - val_loss: 0.0015\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.6113e-04 - val_loss: 0.0015\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5333e-04 - val_loss: 0.0015\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4790e-04 - val_loss: 0.0016\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4519e-04 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.4492e-04 - val_loss: 0.0017\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.4638e-04 - val_loss: 0.0017\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4865e-04 - val_loss: 0.0017\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5080e-04 - val_loss: 0.0017\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.5216e-04 - val_loss: 0.0017\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.5235e-04 - val_loss: 0.0017\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.5131e-04 - val_loss: 0.0017\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.4930e-04 - val_loss: 0.0017\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4671e-04 - val_loss: 0.0017\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.4403e-04 - val_loss: 0.0016\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.4166e-04 - val_loss: 0.0016\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.3987e-04 - val_loss: 0.0016\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3876e-04 - val_loss: 0.0015\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3830e-04 - val_loss: 0.0015\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3829e-04 - val_loss: 0.0015\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3851e-04 - val_loss: 0.0015\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3873e-04 - val_loss: 0.0015\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3875e-04 - val_loss: 0.0015\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3848e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3791e-04 - val_loss: 0.0015\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3707e-04 - val_loss: 0.0015\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3608e-04 - val_loss: 0.0015\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3506e-04 - val_loss: 0.0015\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3412e-04 - val_loss: 0.0015\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.3332e-04 - val_loss: 0.0015\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3270e-04 - val_loss: 0.0015\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3224e-04 - val_loss: 0.0015\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3191e-04 - val_loss: 0.0015\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3164e-04 - val_loss: 0.0015\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3137e-04 - val_loss: 0.0015\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3105e-04 - val_loss: 0.0015\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.3066e-04 - val_loss: 0.0015\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.3019e-04 - val_loss: 0.0015\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2966e-04 - val_loss: 0.0015\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2909e-04 - val_loss: 0.0015\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2851e-04 - val_loss: 0.0015\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 2.2795e-04 - val_loss: 0.0015\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2743e-04 - val_loss: 0.0015\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2695e-04 - val_loss: 0.0015\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2652e-04 - val_loss: 0.0015\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2612e-04 - val_loss: 0.0015\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2574e-04 - val_loss: 0.0014\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2535e-04 - val_loss: 0.0014\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.2496e-04 - val_loss: 0.0014\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2456e-04 - val_loss: 0.0014\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2413e-04 - val_loss: 0.0014\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2368e-04 - val_loss: 0.0014\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2323e-04 - val_loss: 0.0014\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2278e-04 - val_loss: 0.0014\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2233e-04 - val_loss: 0.0014\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2190e-04 - val_loss: 0.0014\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2147e-04 - val_loss: 0.0014\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2106e-04 - val_loss: 0.0014\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.2066e-04 - val_loss: 0.0014\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.2026e-04 - val_loss: 0.0014\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1987e-04 - val_loss: 0.0014\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1947e-04 - val_loss: 0.0014\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1907e-04 - val_loss: 0.0014\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1866e-04 - val_loss: 0.0014\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1826e-04 - val_loss: 0.0014\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1785e-04 - val_loss: 0.0014\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1744e-04 - val_loss: 0.0014\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1704e-04 - val_loss: 0.0014\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1664e-04 - val_loss: 0.0014\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1624e-04 - val_loss: 0.0014\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1585e-04 - val_loss: 0.0014\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1546e-04 - val_loss: 0.0014\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1507e-04 - val_loss: 0.0014\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1469e-04 - val_loss: 0.0014\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1430e-04 - val_loss: 0.0014\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1392e-04 - val_loss: 0.0014\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1353e-04 - val_loss: 0.0014\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1314e-04 - val_loss: 0.0014\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.1276e-04 - val_loss: 0.0014\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.1238e-04 - val_loss: 0.0014\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1200e-04 - val_loss: 0.0014\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1162e-04 - val_loss: 0.0014\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1124e-04 - val_loss: 0.0014\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.1086e-04 - val_loss: 0.0014\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.1049e-04 - val_loss: 0.0014\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.1012e-04 - val_loss: 0.0013\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0974e-04 - val_loss: 0.0013\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0937e-04 - val_loss: 0.0013\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0900e-04 - val_loss: 0.0013\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0863e-04 - val_loss: 0.0013\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 2.0827e-04 - val_loss: 0.0013\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0790e-04 - val_loss: 0.0013\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0753e-04 - val_loss: 0.0013\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0717e-04 - val_loss: 0.0013\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0681e-04 - val_loss: 0.0013\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0645e-04 - val_loss: 0.0013\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0609e-04 - val_loss: 0.0013\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0573e-04 - val_loss: 0.0013\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0537e-04 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0501e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0466e-04 - val_loss: 0.0013\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0430e-04 - val_loss: 0.0013\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0395e-04 - val_loss: 0.0013\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 2.0360e-04 - val_loss: 0.0013\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0325e-04 - val_loss: 0.0013\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0290e-04 - val_loss: 0.0013\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0255e-04 - val_loss: 0.0013\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0220e-04 - val_loss: 0.0013\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0186e-04 - val_loss: 0.0013\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0151e-04 - val_loss: 0.0013\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.0117e-04 - val_loss: 0.0013\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 2.0082e-04 - val_loss: 0.0013\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.0048e-04 - val_loss: 0.0013\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 2.0014e-04 - val_loss: 0.0013\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9980e-04 - val_loss: 0.0013\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9946e-04 - val_loss: 0.0013\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9912e-04 - val_loss: 0.0013\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9879e-04 - val_loss: 0.0013\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9846e-04 - val_loss: 0.0013\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9812e-04 - val_loss: 0.0013\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9779e-04 - val_loss: 0.0013\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9745e-04 - val_loss: 0.0013\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9712e-04 - val_loss: 0.0013\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 145us/step - loss: 1.9679e-04 - val_loss: 0.0012\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9646e-04 - val_loss: 0.0012\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9613e-04 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9581e-04 - val_loss: 0.0012\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9548e-04 - val_loss: 0.0012\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9516e-04 - val_loss: 0.0012\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9483e-04 - val_loss: 0.0012\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9451e-04 - val_loss: 0.0012\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.9419e-04 - val_loss: 0.0012\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9386e-04 - val_loss: 0.0012\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9354e-04 - val_loss: 0.0012\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 1.9323e-04 - val_loss: 0.0012\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9291e-04 - val_loss: 0.0012\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9259e-04 - val_loss: 0.0012\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9228e-04 - val_loss: 0.0012\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9196e-04 - val_loss: 0.0012\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9164e-04 - val_loss: 0.0012\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.9133e-04 - val_loss: 0.0012\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.9102e-04 - val_loss: 0.0012\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.9071e-04 - val_loss: 0.0012\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9040e-04 - val_loss: 0.0012\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.9008e-04 - val_loss: 0.0012\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8978e-04 - val_loss: 0.0012\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.8947e-04 - val_loss: 0.0012\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8917e-04 - val_loss: 0.0012\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8886e-04 - val_loss: 0.0012\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8855e-04 - val_loss: 0.0012\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8825e-04 - val_loss: 0.0012\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8794e-04 - val_loss: 0.0012\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8764e-04 - val_loss: 0.0012\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8734e-04 - val_loss: 0.0012\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8704e-04 - val_loss: 0.0012\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8674e-04 - val_loss: 0.0012\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8644e-04 - val_loss: 0.0012\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8614e-04 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.8585e-04 - val_loss: 0.0012\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8555e-04 - val_loss: 0.0012\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8526e-04 - val_loss: 0.0012\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8496e-04 - val_loss: 0.0012\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8467e-04 - val_loss: 0.0012\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8438e-04 - val_loss: 0.0012\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8408e-04 - val_loss: 0.0012\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8379e-04 - val_loss: 0.0012\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8350e-04 - val_loss: 0.0012\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8321e-04 - val_loss: 0.0012\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8292e-04 - val_loss: 0.0011\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8264e-04 - val_loss: 0.0011\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.8235e-04 - val_loss: 0.0011\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8207e-04 - val_loss: 0.0011\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8178e-04 - val_loss: 0.0011\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8149e-04 - val_loss: 0.0011\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8122e-04 - val_loss: 0.0011\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.8093e-04 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.8065e-04 - val_loss: 0.0011\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.8037e-04 - val_loss: 0.0011\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.8009e-04 - val_loss: 0.0011\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7981e-04 - val_loss: 0.0011\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7953e-04 - val_loss: 0.0011\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7925e-04 - val_loss: 0.0011\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7897e-04 - val_loss: 0.0011\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7870e-04 - val_loss: 0.0011\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7842e-04 - val_loss: 0.0011\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7815e-04 - val_loss: 0.0011\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7788e-04 - val_loss: 0.0011\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7760e-04 - val_loss: 0.0011\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7733e-04 - val_loss: 0.0011\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7706e-04 - val_loss: 0.0011\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7679e-04 - val_loss: 0.0011\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7652e-04 - val_loss: 0.0011\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7625e-04 - val_loss: 0.0011\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7598e-04 - val_loss: 0.0011\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7571e-04 - val_loss: 0.0011\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7545e-04 - val_loss: 0.0011\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7518e-04 - val_loss: 0.0011\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7491e-04 - val_loss: 0.0011\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7465e-04 - val_loss: 0.0011\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7439e-04 - val_loss: 0.0011\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 154us/step - loss: 1.7412e-04 - val_loss: 0.0011\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7386e-04 - val_loss: 0.0011\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7360e-04 - val_loss: 0.0011\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7334e-04 - val_loss: 0.0011\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.7307e-04 - val_loss: 0.0011\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7281e-04 - val_loss: 0.0011\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7256e-04 - val_loss: 0.0011\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7230e-04 - val_loss: 0.0011\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.7204e-04 - val_loss: 0.0011\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.7178e-04 - val_loss: 0.0011\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7153e-04 - val_loss: 0.0011\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.7127e-04 - val_loss: 0.0011\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7102e-04 - val_loss: 0.0011\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7076e-04 - val_loss: 0.0011\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7051e-04 - val_loss: 0.0011\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7026e-04 - val_loss: 0.0011\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.7001e-04 - val_loss: 0.0011\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6976e-04 - val_loss: 0.0011\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6950e-04 - val_loss: 0.0011\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6925e-04 - val_loss: 0.0011\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6901e-04 - val_loss: 0.0010\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6876e-04 - val_loss: 0.0010\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6851e-04 - val_loss: 0.0010\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6826e-04 - val_loss: 0.0010\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6801e-04 - val_loss: 0.0010\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6777e-04 - val_loss: 0.0010\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6752e-04 - val_loss: 0.0010\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6728e-04 - val_loss: 0.0010\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.6704e-04 - val_loss: 0.0010\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6679e-04 - val_loss: 0.0010\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.6655e-04 - val_loss: 0.0010\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6631e-04 - val_loss: 0.0010\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6606e-04 - val_loss: 0.0010\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6582e-04 - val_loss: 0.0010\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6558e-04 - val_loss: 0.0010\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6534e-04 - val_loss: 0.0010\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6510e-04 - val_loss: 0.0010\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6487e-04 - val_loss: 0.0010\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6463e-04 - val_loss: 0.0010\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6440e-04 - val_loss: 0.0010\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.6416e-04 - val_loss: 0.0010\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6392e-04 - val_loss: 0.0010\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6369e-04 - val_loss: 0.0010\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6345e-04 - val_loss: 0.0010\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6322e-04 - val_loss: 0.0010\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6298e-04 - val_loss: 0.0010\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6275e-04 - val_loss: 0.0010\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6252e-04 - val_loss: 0.0010\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6229e-04 - val_loss: 0.0010\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6206e-04 - val_loss: 9.9975e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6183e-04 - val_loss: 9.9813e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6160e-04 - val_loss: 9.9648e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6136e-04 - val_loss: 9.9489e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6114e-04 - val_loss: 9.9326e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6091e-04 - val_loss: 9.9166e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6068e-04 - val_loss: 9.9005e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6046e-04 - val_loss: 9.8844e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6023e-04 - val_loss: 9.8686e-04\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.6001e-04 - val_loss: 9.8527e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5978e-04 - val_loss: 9.8368e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5956e-04 - val_loss: 9.8209e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5933e-04 - val_loss: 9.8051e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5911e-04 - val_loss: 9.7895e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5889e-04 - val_loss: 9.7736e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5866e-04 - val_loss: 9.7579e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5844e-04 - val_loss: 9.7424e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5822e-04 - val_loss: 9.7266e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5800e-04 - val_loss: 9.7112e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5778e-04 - val_loss: 9.6956e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5756e-04 - val_loss: 9.6801e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5734e-04 - val_loss: 9.6648e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5713e-04 - val_loss: 9.6493e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5691e-04 - val_loss: 9.6341e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5669e-04 - val_loss: 9.6185e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5647e-04 - val_loss: 9.6035e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5626e-04 - val_loss: 9.5882e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5604e-04 - val_loss: 9.5729e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5583e-04 - val_loss: 9.5580e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5561e-04 - val_loss: 9.5430e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5540e-04 - val_loss: 9.5280e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5519e-04 - val_loss: 9.5128e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5497e-04 - val_loss: 9.4980e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5476e-04 - val_loss: 9.4830e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5455e-04 - val_loss: 9.4680e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5434e-04 - val_loss: 9.4533e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5413e-04 - val_loss: 9.4384e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5392e-04 - val_loss: 9.4238e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5371e-04 - val_loss: 9.4090e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5350e-04 - val_loss: 9.3943e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5329e-04 - val_loss: 9.3797e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5308e-04 - val_loss: 9.3652e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5287e-04 - val_loss: 9.3504e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5267e-04 - val_loss: 9.3360e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5246e-04 - val_loss: 9.3216e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5226e-04 - val_loss: 9.3073e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5205e-04 - val_loss: 9.2927e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5185e-04 - val_loss: 9.2783e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5164e-04 - val_loss: 9.2641e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5144e-04 - val_loss: 9.2497e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5123e-04 - val_loss: 9.2355e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5103e-04 - val_loss: 9.2213e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5083e-04 - val_loss: 9.2070e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.5062e-04 - val_loss: 9.1930e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.5042e-04 - val_loss: 9.1789e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5022e-04 - val_loss: 9.1648e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.5002e-04 - val_loss: 9.1507e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4982e-04 - val_loss: 9.1365e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4962e-04 - val_loss: 9.1225e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4942e-04 - val_loss: 9.1089e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4922e-04 - val_loss: 9.0948e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4902e-04 - val_loss: 9.0811e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4883e-04 - val_loss: 9.0672e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4863e-04 - val_loss: 9.0534e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4843e-04 - val_loss: 9.0397e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 1.4824e-04 - val_loss: 9.0259e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4804e-04 - val_loss: 9.0123e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4784e-04 - val_loss: 8.9988e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4765e-04 - val_loss: 8.9851e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4746e-04 - val_loss: 8.9718e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4726e-04 - val_loss: 8.9581e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4707e-04 - val_loss: 8.9446e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4688e-04 - val_loss: 8.9313e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4668e-04 - val_loss: 8.9178e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4649e-04 - val_loss: 8.9044e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4630e-04 - val_loss: 8.8909e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4611e-04 - val_loss: 8.8778e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4592e-04 - val_loss: 8.8645e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4573e-04 - val_loss: 8.8510e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4554e-04 - val_loss: 8.8378e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 133us/step - loss: 1.4535e-04 - val_loss: 8.8246e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4515e-04 - val_loss: 8.8117e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4497e-04 - val_loss: 8.7986e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4478e-04 - val_loss: 8.7855e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4459e-04 - val_loss: 8.7722e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4440e-04 - val_loss: 8.7595e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4422e-04 - val_loss: 8.7464e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4403e-04 - val_loss: 8.7334e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4385e-04 - val_loss: 8.7205e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4366e-04 - val_loss: 8.7075e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4347e-04 - val_loss: 8.6947e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4329e-04 - val_loss: 8.6818e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4310e-04 - val_loss: 8.6690e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4292e-04 - val_loss: 8.6563e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4274e-04 - val_loss: 8.6435e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4255e-04 - val_loss: 8.6307e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4237e-04 - val_loss: 8.6183e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.4219e-04 - val_loss: 8.6055e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4201e-04 - val_loss: 8.5928e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4182e-04 - val_loss: 8.5807e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4165e-04 - val_loss: 8.5681e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.4147e-04 - val_loss: 8.5555e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4128e-04 - val_loss: 8.5431e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4111e-04 - val_loss: 8.5306e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 374us/step - loss: 1.4093e-04 - val_loss: 8.5184e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4075e-04 - val_loss: 8.5060e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4057e-04 - val_loss: 8.4935e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4039e-04 - val_loss: 8.4812e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.4021e-04 - val_loss: 8.4690e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.4004e-04 - val_loss: 8.4568e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.3986e-04 - val_loss: 8.4447e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3968e-04 - val_loss: 8.4322e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3951e-04 - val_loss: 8.4202e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3933e-04 - val_loss: 8.4078e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3915e-04 - val_loss: 8.3958e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3898e-04 - val_loss: 8.3839e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3881e-04 - val_loss: 8.3716e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3863e-04 - val_loss: 8.3596e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3846e-04 - val_loss: 8.3476e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3828e-04 - val_loss: 8.3357e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3811e-04 - val_loss: 8.3238e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3794e-04 - val_loss: 8.3118e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3777e-04 - val_loss: 8.3001e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3760e-04 - val_loss: 8.2880e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3742e-04 - val_loss: 8.2762e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3725e-04 - val_loss: 8.2647e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3708e-04 - val_loss: 8.2530e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3692e-04 - val_loss: 8.2412e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3675e-04 - val_loss: 8.2298e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3658e-04 - val_loss: 8.2179e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3640e-04 - val_loss: 8.2063e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3623e-04 - val_loss: 8.1945e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3606e-04 - val_loss: 8.1830e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3590e-04 - val_loss: 8.1715e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 153us/step - loss: 1.3573e-04 - val_loss: 8.1600e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3556e-04 - val_loss: 8.1482e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3540e-04 - val_loss: 8.1370e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3523e-04 - val_loss: 8.1253e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3506e-04 - val_loss: 8.1138e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.3490e-04 - val_loss: 8.1027e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3473e-04 - val_loss: 8.0913e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3457e-04 - val_loss: 8.0801e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3440e-04 - val_loss: 8.0686e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3424e-04 - val_loss: 8.0574e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3408e-04 - val_loss: 8.0462e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3391e-04 - val_loss: 8.0349e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3375e-04 - val_loss: 8.0239e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3358e-04 - val_loss: 8.0128e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3342e-04 - val_loss: 8.0016e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3326e-04 - val_loss: 7.9905e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3310e-04 - val_loss: 7.9792e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3293e-04 - val_loss: 7.9682e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 1.3278e-04 - val_loss: 7.9574e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3261e-04 - val_loss: 7.9461e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3245e-04 - val_loss: 7.9353e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3230e-04 - val_loss: 7.9242e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3213e-04 - val_loss: 7.9133e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.3197e-04 - val_loss: 7.9025e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3182e-04 - val_loss: 7.8917e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3166e-04 - val_loss: 7.8805e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3150e-04 - val_loss: 7.8699e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3134e-04 - val_loss: 7.8589e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3118e-04 - val_loss: 7.8481e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3102e-04 - val_loss: 7.8373e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3087e-04 - val_loss: 7.8266e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3071e-04 - val_loss: 7.8160e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3055e-04 - val_loss: 7.8054e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3040e-04 - val_loss: 7.7945e-04\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.3024e-04 - val_loss: 7.7841e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.3009e-04 - val_loss: 7.7734e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 1.2993e-04 - val_loss: 7.7628e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2978e-04 - val_loss: 7.7523e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2962e-04 - val_loss: 7.7419e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2947e-04 - val_loss: 7.7311e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2931e-04 - val_loss: 7.7209e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2916e-04 - val_loss: 7.7105e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2901e-04 - val_loss: 7.7000e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2886e-04 - val_loss: 7.6895e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2870e-04 - val_loss: 7.6792e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2855e-04 - val_loss: 7.6688e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2840e-04 - val_loss: 7.6583e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2824e-04 - val_loss: 7.6481e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2810e-04 - val_loss: 7.6379e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2794e-04 - val_loss: 7.6274e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2779e-04 - val_loss: 7.6174e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2765e-04 - val_loss: 7.6072e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2749e-04 - val_loss: 7.5970e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2735e-04 - val_loss: 7.5865e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2719e-04 - val_loss: 7.5765e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2704e-04 - val_loss: 7.5664e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2690e-04 - val_loss: 7.5564e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2675e-04 - val_loss: 7.5461e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2660e-04 - val_loss: 7.5363e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2645e-04 - val_loss: 7.5261e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2630e-04 - val_loss: 7.5162e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2616e-04 - val_loss: 7.5062e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2601e-04 - val_loss: 7.4963e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2587e-04 - val_loss: 7.4863e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2572e-04 - val_loss: 7.4766e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2557e-04 - val_loss: 7.4663e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 1.2543e-04 - val_loss: 7.4565e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2528e-04 - val_loss: 7.4467e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2514e-04 - val_loss: 7.4369e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2499e-04 - val_loss: 7.4270e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2485e-04 - val_loss: 7.4173e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2470e-04 - val_loss: 7.4074e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2456e-04 - val_loss: 7.3975e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2441e-04 - val_loss: 7.3878e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2427e-04 - val_loss: 7.3782e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2413e-04 - val_loss: 7.3686e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2399e-04 - val_loss: 7.3590e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2384e-04 - val_loss: 7.3495e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.2370e-04 - val_loss: 7.3399e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2356e-04 - val_loss: 7.3301e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 1.2342e-04 - val_loss: 7.3206e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2328e-04 - val_loss: 7.3111e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2314e-04 - val_loss: 7.3016e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.2299e-04 - val_loss: 7.2919e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2285e-04 - val_loss: 7.2826e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2271e-04 - val_loss: 7.2731e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2257e-04 - val_loss: 7.2637e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2243e-04 - val_loss: 7.2542e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2229e-04 - val_loss: 7.2447e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2216e-04 - val_loss: 7.2354e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2202e-04 - val_loss: 7.2261e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2188e-04 - val_loss: 7.2166e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2174e-04 - val_loss: 7.2074e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2160e-04 - val_loss: 7.1980e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2146e-04 - val_loss: 7.1887e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2133e-04 - val_loss: 7.1793e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.2119e-04 - val_loss: 7.1702e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2105e-04 - val_loss: 7.1609e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2091e-04 - val_loss: 7.1518e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2078e-04 - val_loss: 7.1424e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2064e-04 - val_loss: 7.1337e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2051e-04 - val_loss: 7.1244e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.2037e-04 - val_loss: 7.1152e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2024e-04 - val_loss: 7.1061e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2010e-04 - val_loss: 7.0972e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1997e-04 - val_loss: 7.0878e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1983e-04 - val_loss: 7.0791e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1970e-04 - val_loss: 7.0699e-04\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1956e-04 - val_loss: 7.0610e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1943e-04 - val_loss: 7.0520e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1930e-04 - val_loss: 7.0430e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1916e-04 - val_loss: 7.0340e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1903e-04 - val_loss: 7.0251e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1890e-04 - val_loss: 7.0164e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1877e-04 - val_loss: 7.0076e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1864e-04 - val_loss: 6.9985e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1850e-04 - val_loss: 6.9897e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1837e-04 - val_loss: 6.9807e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1824e-04 - val_loss: 6.9721e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1811e-04 - val_loss: 6.9631e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1798e-04 - val_loss: 6.9545e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1785e-04 - val_loss: 6.9457e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1772e-04 - val_loss: 6.9370e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1759e-04 - val_loss: 6.9282e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1746e-04 - val_loss: 6.9196e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1733e-04 - val_loss: 6.9109e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1720e-04 - val_loss: 6.9024e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1707e-04 - val_loss: 6.8934e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1694e-04 - val_loss: 6.8850e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1681e-04 - val_loss: 6.8764e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1668e-04 - val_loss: 6.8677e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1655e-04 - val_loss: 6.8592e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1643e-04 - val_loss: 6.8508e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1630e-04 - val_loss: 6.8421e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1617e-04 - val_loss: 6.8336e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1604e-04 - val_loss: 6.8251e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1592e-04 - val_loss: 6.8167e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1579e-04 - val_loss: 6.8082e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.1566e-04 - val_loss: 6.7997e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1554e-04 - val_loss: 6.7913e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1541e-04 - val_loss: 6.7830e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1529e-04 - val_loss: 6.7747e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1516e-04 - val_loss: 6.7664e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1504e-04 - val_loss: 6.7578e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1491e-04 - val_loss: 6.7497e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1479e-04 - val_loss: 6.7410e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1466e-04 - val_loss: 6.7328e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1454e-04 - val_loss: 6.7244e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1441e-04 - val_loss: 6.7162e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1429e-04 - val_loss: 6.7080e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1416e-04 - val_loss: 6.6999e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1404e-04 - val_loss: 6.6917e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1392e-04 - val_loss: 6.6835e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1380e-04 - val_loss: 6.6753e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1368e-04 - val_loss: 6.6672e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1355e-04 - val_loss: 6.6589e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1343e-04 - val_loss: 6.6509e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1331e-04 - val_loss: 6.6427e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1319e-04 - val_loss: 6.6347e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1306e-04 - val_loss: 6.6264e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1294e-04 - val_loss: 6.6185e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1282e-04 - val_loss: 6.6103e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1270e-04 - val_loss: 6.6024e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1258e-04 - val_loss: 6.5942e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1246e-04 - val_loss: 6.5863e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1234e-04 - val_loss: 6.5783e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1222e-04 - val_loss: 6.5704e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1210e-04 - val_loss: 6.5624e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1198e-04 - val_loss: 6.5544e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1186e-04 - val_loss: 6.5465e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1175e-04 - val_loss: 6.5387e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1162e-04 - val_loss: 6.5308e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1150e-04 - val_loss: 6.5231e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.1139e-04 - val_loss: 6.5150e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1127e-04 - val_loss: 6.5074e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1115e-04 - val_loss: 6.4994e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1103e-04 - val_loss: 6.4917e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1091e-04 - val_loss: 6.4840e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1080e-04 - val_loss: 6.4762e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1068e-04 - val_loss: 6.4683e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1056e-04 - val_loss: 6.4607e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1045e-04 - val_loss: 6.4528e-04\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1033e-04 - val_loss: 6.4453e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1021e-04 - val_loss: 6.4374e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.1010e-04 - val_loss: 6.4297e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0998e-04 - val_loss: 6.4220e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0987e-04 - val_loss: 6.4146e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0975e-04 - val_loss: 6.4068e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0964e-04 - val_loss: 6.3993e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0952e-04 - val_loss: 6.3916e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0941e-04 - val_loss: 6.3842e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0929e-04 - val_loss: 6.3764e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0918e-04 - val_loss: 6.3689e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0906e-04 - val_loss: 6.3614e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0895e-04 - val_loss: 6.3540e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0884e-04 - val_loss: 6.3465e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0872e-04 - val_loss: 6.3391e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0861e-04 - val_loss: 6.3313e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0849e-04 - val_loss: 6.3241e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0838e-04 - val_loss: 6.3164e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0827e-04 - val_loss: 6.3092e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0816e-04 - val_loss: 6.3016e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0804e-04 - val_loss: 6.2941e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0793e-04 - val_loss: 6.2869e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0782e-04 - val_loss: 6.2796e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0771e-04 - val_loss: 6.2720e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0760e-04 - val_loss: 6.2647e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0748e-04 - val_loss: 6.2575e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0738e-04 - val_loss: 6.2502e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0726e-04 - val_loss: 6.2428e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0715e-04 - val_loss: 6.2355e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0704e-04 - val_loss: 6.2282e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0693e-04 - val_loss: 6.2209e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0682e-04 - val_loss: 6.2135e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0671e-04 - val_loss: 6.2065e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0660e-04 - val_loss: 6.1991e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0649e-04 - val_loss: 6.1920e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0638e-04 - val_loss: 6.1847e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0627e-04 - val_loss: 6.1776e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0616e-04 - val_loss: 6.1704e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0605e-04 - val_loss: 6.1633e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0594e-04 - val_loss: 6.1562e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0584e-04 - val_loss: 6.1492e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0573e-04 - val_loss: 6.1419e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0562e-04 - val_loss: 6.1348e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0551e-04 - val_loss: 6.1278e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0541e-04 - val_loss: 6.1209e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0530e-04 - val_loss: 6.1136e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0519e-04 - val_loss: 6.1067e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 1.0508e-04 - val_loss: 6.0995e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0497e-04 - val_loss: 6.0926e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0487e-04 - val_loss: 6.0856e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0476e-04 - val_loss: 6.0787e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0466e-04 - val_loss: 6.0716e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0455e-04 - val_loss: 6.0647e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0444e-04 - val_loss: 6.0576e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0434e-04 - val_loss: 6.0508e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0423e-04 - val_loss: 6.0438e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0412e-04 - val_loss: 6.0369e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0402e-04 - val_loss: 6.0300e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0391e-04 - val_loss: 6.0231e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0381e-04 - val_loss: 6.0162e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0370e-04 - val_loss: 6.0096e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0360e-04 - val_loss: 6.0027e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0350e-04 - val_loss: 5.9959e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0339e-04 - val_loss: 5.9891e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0329e-04 - val_loss: 5.9821e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0318e-04 - val_loss: 5.9756e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0308e-04 - val_loss: 5.9688e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0298e-04 - val_loss: 5.9619e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0287e-04 - val_loss: 5.9552e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0277e-04 - val_loss: 5.9483e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 1.0266e-04 - val_loss: 5.9419e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0256e-04 - val_loss: 5.9351e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0246e-04 - val_loss: 5.9283e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0236e-04 - val_loss: 5.9217e-04\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0226e-04 - val_loss: 5.9150e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0215e-04 - val_loss: 5.9083e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0205e-04 - val_loss: 5.9018e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0195e-04 - val_loss: 5.8952e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0185e-04 - val_loss: 5.8886e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0175e-04 - val_loss: 5.8820e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0165e-04 - val_loss: 5.8753e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0154e-04 - val_loss: 5.8687e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0145e-04 - val_loss: 5.8621e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0134e-04 - val_loss: 5.8555e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0124e-04 - val_loss: 5.8492e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0114e-04 - val_loss: 5.8424e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0104e-04 - val_loss: 5.8359e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0094e-04 - val_loss: 5.8292e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0084e-04 - val_loss: 5.8228e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0074e-04 - val_loss: 5.8164e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0064e-04 - val_loss: 5.8099e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0054e-04 - val_loss: 5.8033e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 1.0044e-04 - val_loss: 5.7969e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.0034e-04 - val_loss: 5.7905e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.0025e-04 - val_loss: 5.7842e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0015e-04 - val_loss: 5.7776e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.0005e-04 - val_loss: 5.7713e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9950e-05 - val_loss: 5.7649e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9851e-05 - val_loss: 5.7587e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9754e-05 - val_loss: 5.7522e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9656e-05 - val_loss: 5.7461e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9559e-05 - val_loss: 5.7397e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9461e-05 - val_loss: 5.7333e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9364e-05 - val_loss: 5.7269e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9263e-05 - val_loss: 5.7207e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9169e-05 - val_loss: 5.7144e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.9072e-05 - val_loss: 5.7081e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8975e-05 - val_loss: 5.7018e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.8878e-05 - val_loss: 5.6955e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8781e-05 - val_loss: 5.6893e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8687e-05 - val_loss: 5.6832e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8591e-05 - val_loss: 5.6767e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8492e-05 - val_loss: 5.6706e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8398e-05 - val_loss: 5.6643e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8302e-05 - val_loss: 5.6582e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8205e-05 - val_loss: 5.6520e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8111e-05 - val_loss: 5.6458e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.8015e-05 - val_loss: 5.6397e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7921e-05 - val_loss: 5.6335e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7824e-05 - val_loss: 5.6274e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7731e-05 - val_loss: 5.6214e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7636e-05 - val_loss: 5.6150e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7539e-05 - val_loss: 5.6089e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7445e-05 - val_loss: 5.6029e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7352e-05 - val_loss: 5.5970e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7259e-05 - val_loss: 5.5909e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7164e-05 - val_loss: 5.5848e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7070e-05 - val_loss: 5.5788e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6979e-05 - val_loss: 5.5727e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6884e-05 - val_loss: 5.5667e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6791e-05 - val_loss: 5.5607e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6697e-05 - val_loss: 5.5547e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6604e-05 - val_loss: 5.5487e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6513e-05 - val_loss: 5.5428e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6420e-05 - val_loss: 5.5367e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6327e-05 - val_loss: 5.5309e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6237e-05 - val_loss: 5.5249e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6143e-05 - val_loss: 5.5191e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6053e-05 - val_loss: 5.5131e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5961e-05 - val_loss: 5.5072e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5867e-05 - val_loss: 5.5011e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5776e-05 - val_loss: 5.4952e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5684e-05 - val_loss: 5.4893e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.5592e-05 - val_loss: 5.4836e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5502e-05 - val_loss: 5.4777e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5411e-05 - val_loss: 5.4719e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5322e-05 - val_loss: 5.4661e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5228e-05 - val_loss: 5.4602e-04\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.5139e-05 - val_loss: 5.4544e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5049e-05 - val_loss: 5.4484e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4958e-05 - val_loss: 5.4429e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4870e-05 - val_loss: 5.4369e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4779e-05 - val_loss: 5.4313e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4688e-05 - val_loss: 5.4255e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4600e-05 - val_loss: 5.4198e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4511e-05 - val_loss: 5.4140e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4421e-05 - val_loss: 5.4083e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4333e-05 - val_loss: 5.4025e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4243e-05 - val_loss: 5.3968e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4151e-05 - val_loss: 5.3910e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4065e-05 - val_loss: 5.3854e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 142us/step - loss: 9.3975e-05 - val_loss: 5.3796e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3885e-05 - val_loss: 5.3740e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3798e-05 - val_loss: 5.3683e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3709e-05 - val_loss: 5.3627e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 9.3622e-05 - val_loss: 5.3570e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3533e-05 - val_loss: 5.3514e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3447e-05 - val_loss: 5.3458e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3361e-05 - val_loss: 5.3400e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3269e-05 - val_loss: 5.3344e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3181e-05 - val_loss: 5.3290e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3097e-05 - val_loss: 5.3234e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.3008e-05 - val_loss: 5.3179e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2923e-05 - val_loss: 5.3124e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2835e-05 - val_loss: 5.3069e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2749e-05 - val_loss: 5.3012e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2661e-05 - val_loss: 5.2957e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2576e-05 - val_loss: 5.2902e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2489e-05 - val_loss: 5.2847e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2403e-05 - val_loss: 5.2791e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2317e-05 - val_loss: 5.2735e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.2228e-05 - val_loss: 5.2681e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.2145e-05 - val_loss: 5.2627e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2059e-05 - val_loss: 5.2570e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1973e-05 - val_loss: 5.2515e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1888e-05 - val_loss: 5.2462e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1805e-05 - val_loss: 5.2409e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1722e-05 - val_loss: 5.2354e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1635e-05 - val_loss: 5.2300e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1549e-05 - val_loss: 5.2246e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1464e-05 - val_loss: 5.2191e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1380e-05 - val_loss: 5.2138e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1296e-05 - val_loss: 5.2084e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.1212e-05 - val_loss: 5.2030e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1125e-05 - val_loss: 5.1976e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.1041e-05 - val_loss: 5.1922e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0957e-05 - val_loss: 5.1870e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0873e-05 - val_loss: 5.1817e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0792e-05 - val_loss: 5.1763e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0707e-05 - val_loss: 5.1710e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0624e-05 - val_loss: 5.1657e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0541e-05 - val_loss: 5.1605e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0458e-05 - val_loss: 5.1549e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0372e-05 - val_loss: 5.1497e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0290e-05 - val_loss: 5.1444e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.0208e-05 - val_loss: 5.1393e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0127e-05 - val_loss: 5.1340e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.0044e-05 - val_loss: 5.1287e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9963e-05 - val_loss: 5.1236e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.9878e-05 - val_loss: 5.1183e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9796e-05 - val_loss: 5.1130e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9713e-05 - val_loss: 5.1077e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9631e-05 - val_loss: 5.1025e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9549e-05 - val_loss: 5.0974e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9469e-05 - val_loss: 5.0925e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9390e-05 - val_loss: 5.0870e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9306e-05 - val_loss: 5.0819e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9223e-05 - val_loss: 5.0768e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9143e-05 - val_loss: 5.0717e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9066e-05 - val_loss: 5.0666e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8982e-05 - val_loss: 5.0613e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8899e-05 - val_loss: 5.0562e-04\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8820e-05 - val_loss: 5.0509e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8737e-05 - val_loss: 5.0459e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8658e-05 - val_loss: 5.0409e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8580e-05 - val_loss: 5.0360e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.8500e-05 - val_loss: 5.0308e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8418e-05 - val_loss: 5.0255e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8337e-05 - val_loss: 5.0206e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8260e-05 - val_loss: 5.0156e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8180e-05 - val_loss: 5.0105e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8099e-05 - val_loss: 5.0055e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.8022e-05 - val_loss: 5.0006e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7942e-05 - val_loss: 4.9955e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7861e-05 - val_loss: 4.9904e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7783e-05 - val_loss: 4.9854e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7702e-05 - val_loss: 4.9804e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7624e-05 - val_loss: 4.9753e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7545e-05 - val_loss: 4.9704e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.7466e-05 - val_loss: 4.9653e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7388e-05 - val_loss: 4.9606e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7310e-05 - val_loss: 4.9556e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7231e-05 - val_loss: 4.9506e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7153e-05 - val_loss: 4.9458e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.7075e-05 - val_loss: 4.9407e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6997e-05 - val_loss: 4.9358e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6919e-05 - val_loss: 4.9309e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.6841e-05 - val_loss: 4.9260e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6765e-05 - val_loss: 4.9212e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6686e-05 - val_loss: 4.9163e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6609e-05 - val_loss: 4.9113e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6531e-05 - val_loss: 4.9066e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6454e-05 - val_loss: 4.9017e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6378e-05 - val_loss: 4.8968e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 8.6302e-05 - val_loss: 4.8919e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6223e-05 - val_loss: 4.8871e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.6147e-05 - val_loss: 4.8822e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6070e-05 - val_loss: 4.8776e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5993e-05 - val_loss: 4.8726e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5918e-05 - val_loss: 4.8679e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5843e-05 - val_loss: 4.8629e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5765e-05 - val_loss: 4.8583e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5691e-05 - val_loss: 4.8534e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5613e-05 - val_loss: 4.8486e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5538e-05 - val_loss: 4.8438e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5461e-05 - val_loss: 4.8390e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5386e-05 - val_loss: 4.8344e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5311e-05 - val_loss: 4.8295e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5236e-05 - val_loss: 4.8249e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5161e-05 - val_loss: 4.8203e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.5087e-05 - val_loss: 4.8154e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.5010e-05 - val_loss: 4.8108e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4936e-05 - val_loss: 4.8059e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4859e-05 - val_loss: 4.8013e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4785e-05 - val_loss: 4.7967e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4712e-05 - val_loss: 4.7919e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4635e-05 - val_loss: 4.7873e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4563e-05 - val_loss: 4.7826e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4487e-05 - val_loss: 4.7780e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4414e-05 - val_loss: 4.7733e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4339e-05 - val_loss: 4.7686e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4266e-05 - val_loss: 4.7642e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.4193e-05 - val_loss: 4.7595e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4117e-05 - val_loss: 4.7548e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4045e-05 - val_loss: 4.7501e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3972e-05 - val_loss: 4.7456e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3896e-05 - val_loss: 4.7410e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3825e-05 - val_loss: 4.7364e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3751e-05 - val_loss: 4.7317e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3677e-05 - val_loss: 4.7271e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.3605e-05 - val_loss: 4.7227e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 8.3532e-05 - val_loss: 4.7181e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3461e-05 - val_loss: 4.7135e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3386e-05 - val_loss: 4.7090e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3315e-05 - val_loss: 4.7044e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3243e-05 - val_loss: 4.6999e-04\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3169e-05 - val_loss: 4.6953e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3097e-05 - val_loss: 4.6908e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.3025e-05 - val_loss: 4.6863e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2952e-05 - val_loss: 4.6818e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2880e-05 - val_loss: 4.6774e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2809e-05 - val_loss: 4.6729e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2736e-05 - val_loss: 4.6684e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2667e-05 - val_loss: 4.6638e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2592e-05 - val_loss: 4.6594e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2522e-05 - val_loss: 4.6550e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2451e-05 - val_loss: 4.6505e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2380e-05 - val_loss: 4.6460e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2308e-05 - val_loss: 4.6415e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2237e-05 - val_loss: 4.6372e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2168e-05 - val_loss: 4.6327e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 8.2095e-05 - val_loss: 4.6283e-04\n",
      "0.00023442189558409154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.15381368, -1.0809047 , -0.1159108 , -1.2999389 ,  0.9747637 ],\n",
       "        [ 0.87885827, -0.10849021,  0.11061154,  1.6438621 , -0.6303825 ],\n",
       "        [ 0.8151316 , -0.09922495,  0.05797448, -1.2769158 ,  1.0791589 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.36133102, -0.6233743 , -0.47601688,  0.9447642 ,  0.63551754],\n",
       "       dtype=float32),\n",
       " array([[ 0.743674  , -0.8812604 , -0.43037215,  0.42600518, -0.8458779 ,\n",
       "          1.2208589 ,  0.30528337,  0.819732  , -0.63974625,  0.6732348 ],\n",
       "        [ 1.246652  , -0.22151151, -0.36865497,  0.32996434, -0.67205495,\n",
       "          0.44576684,  0.52914613,  0.8077338 , -0.51843184,  0.48301336],\n",
       "        [ 1.1811669 , -0.45939735, -0.49304518,  1.3686377 , -0.6425174 ,\n",
       "          0.1828737 ,  0.48255694,  0.24234563, -0.73485154,  0.10549297],\n",
       "        [ 0.6428004 , -1.0800214 , -0.7143149 ,  0.87714434, -1.4137437 ,\n",
       "          0.75901186,  0.9777218 ,  0.35423937, -0.9200361 ,  1.2088847 ],\n",
       "        [ 1.6090413 , -0.7208156 , -0.26685953,  1.3686955 , -1.5426638 ,\n",
       "          1.0029707 ,  1.4294924 ,  0.77688056, -0.65064776,  0.4405787 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.96345085, -0.8827987 , -0.86399585,  0.9554802 , -0.8905705 ,\n",
       "         0.8648112 ,  0.8737396 ,  0.80301464, -0.8801003 ,  0.86765635],\n",
       "       dtype=float32),\n",
       " array([[ 0.6831122 ],\n",
       "        [-0.7892879 ],\n",
       "        [ 0.10028164],\n",
       "        [ 0.68909615],\n",
       "        [-1.0104265 ],\n",
       "        [ 0.47206438],\n",
       "        [ 0.68262273],\n",
       "        [-0.3123782 ],\n",
       "        [-0.76667225],\n",
       "        [ 0.5604665 ]], dtype=float32),\n",
       " array([0.7617484], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression_tanh(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_tanh_5th.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
