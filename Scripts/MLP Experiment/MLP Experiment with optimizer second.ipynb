{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 1s 485us/step - loss: 15263.3903 - val_loss: 14583.1551\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12280.7326 - val_loss: 8489.5911\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 4218.6608 - val_loss: 695.0834\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 142.7210 - val_loss: 45.9292\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 31.3965 - val_loss: 27.9719\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 24.8544 - val_loss: 27.2285\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.3171 - val_loss: 27.2848\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.9289 - val_loss: 27.5618\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6963 - val_loss: 27.4228\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5417 - val_loss: 27.5754\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5314 - val_loss: 27.1748\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.4228 - val_loss: 27.5818\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1645 - val_loss: 27.3248\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1707 - val_loss: 27.1480\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1584 - val_loss: 27.2127\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0687 - val_loss: 27.2046\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1439 - val_loss: 27.0961\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1008 - val_loss: 26.6925\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9199 - val_loss: 27.8685\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.3683 - val_loss: 26.6667\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9594 - val_loss: 26.5160\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7256 - val_loss: 26.9043\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.7550 - val_loss: 26.9905\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.8914 - val_loss: 26.2741\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8102 - val_loss: 26.2177\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9344 - val_loss: 26.5478\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8522 - val_loss: 27.0251\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7428 - val_loss: 26.6657\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6898 - val_loss: 26.4799\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8044 - val_loss: 26.9902\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2071 - val_loss: 25.9669\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6164 - val_loss: 26.8126\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1755 - val_loss: 26.4614\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.2679 - val_loss: 26.4131\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9656 - val_loss: 26.7452\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5824 - val_loss: 26.5885\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7617 - val_loss: 27.5216\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8604 - val_loss: 26.5155\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8684 - val_loss: 25.9777\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7415 - val_loss: 26.0813\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.5999 - val_loss: 25.8841\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9154 - val_loss: 26.1822\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7773 - val_loss: 26.2827\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6350 - val_loss: 25.9897\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5974 - val_loss: 25.9495\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6352 - val_loss: 26.1122\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6836 - val_loss: 25.7944\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.6742 - val_loss: 26.0920\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5089 - val_loss: 25.9426\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7092 - val_loss: 26.4572\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8676 - val_loss: 26.6930\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8613 - val_loss: 26.0296\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5351 - val_loss: 26.0052\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6717 - val_loss: 25.7535\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8892 - val_loss: 25.9336\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1944 - val_loss: 26.5254\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0933 - val_loss: 26.4021\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9682 - val_loss: 26.3824\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8168 - val_loss: 26.0745\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6143 - val_loss: 26.2709\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7417 - val_loss: 26.2014\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.4344 - val_loss: 25.5413\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3653 - val_loss: 25.7342\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.8418 - val_loss: 27.0396\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7126 - val_loss: 26.4958\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9320 - val_loss: 26.1411\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.5440 - val_loss: 25.6644\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6607 - val_loss: 25.8389\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5857 - val_loss: 25.5477\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.7111 - val_loss: 26.9015\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9441 - val_loss: 27.4790\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 22.72 - 0s 86us/step - loss: 21.8520 - val_loss: 27.2168\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.6825 - val_loss: 25.8909\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6934 - val_loss: 25.4328\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3815 - val_loss: 26.1161\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.1670 - val_loss: 25.6179\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.5404 - val_loss: 26.8523\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7121 - val_loss: 25.2697\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6535 - val_loss: 30.0038\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9082 - val_loss: 25.9209\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9044 - val_loss: 26.0587\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8184 - val_loss: 25.5898\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5273 - val_loss: 26.0604\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0462 - val_loss: 26.2174\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 21.6973 - val_loss: 25.6726\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3417 - val_loss: 25.9920\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.5269 - val_loss: 25.6112\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8343 - val_loss: 27.4473\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0088 - val_loss: 25.6819\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.0356 - val_loss: 26.7164\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8446 - val_loss: 25.6895\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1415 - val_loss: 28.1033\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4532 - val_loss: 25.7094\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1733 - val_loss: 25.8974\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 21.9857 - val_loss: 26.0924\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0082 - val_loss: 25.6151\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2355 - val_loss: 25.5485\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1177 - val_loss: 28.3369\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.2462 - val_loss: 27.2051\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.6794 - val_loss: 25.9055\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9515 - val_loss: 26.0741\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6017 - val_loss: 25.8478\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9454 - val_loss: 25.6976\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9033 - val_loss: 26.2946\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7561 - val_loss: 25.5552\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.6743 - val_loss: 25.5469\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7263 - val_loss: 26.3215\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5431 - val_loss: 25.7264\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0147 - val_loss: 26.4021\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1006 - val_loss: 27.6245\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0253 - val_loss: 26.3632\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.8276 - val_loss: 26.3497\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.3297 - val_loss: 26.6462\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7990 - val_loss: 26.3784\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3849 - val_loss: 27.4379\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.7259 - val_loss: 27.2835\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7558 - val_loss: 27.2717\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.8188 - val_loss: 26.7603\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9112 - val_loss: 27.9912\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3475 - val_loss: 26.2808\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9092 - val_loss: 26.3445\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1114 - val_loss: 25.5678\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0822 - val_loss: 25.5845\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6093 - val_loss: 27.0330\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8558 - val_loss: 27.4333\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.4348 - val_loss: 25.4925\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7610 - val_loss: 25.2849\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7328 - val_loss: 26.2131\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8357 - val_loss: 25.1963\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6414 - val_loss: 26.0098\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.4565 - val_loss: 25.2322\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.9866 - val_loss: 26.7294\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.7965 - val_loss: 25.1452\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4981 - val_loss: 25.8624\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.0668 - val_loss: 27.5600\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 22.1070 - val_loss: 25.9732\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.3797 - val_loss: 25.7616\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6330 - val_loss: 25.8795\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.2925 - val_loss: 27.4949\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.4253 - val_loss: 26.3811\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6183 - val_loss: 25.9107\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.3077 - val_loss: 24.9708\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.1383 - val_loss: 25.5722\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1433 - val_loss: 28.0719\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6057 - val_loss: 25.4628\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 20.5926 - val_loss: 25.2125\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 20.7283 - val_loss: 24.3924\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.8032 - val_loss: 24.3128\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 20.34 - 0s 85us/step - loss: 20.0952 - val_loss: 24.3322\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.4259 - val_loss: 25.0567\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.9876 - val_loss: 23.8419\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.7707 - val_loss: 23.4689\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3964 - val_loss: 24.5379\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 18.6903 - val_loss: 23.5225\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 19.3215 - val_loss: 24.2603\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.6263 - val_loss: 23.1883\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 18.6765 - val_loss: 23.0024\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.3361 - val_loss: 23.7327\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.8605 - val_loss: 22.4678\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.0494 - val_loss: 22.3918\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 18.5592 - val_loss: 21.6267\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.2102 - val_loss: 23.3625\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.4779 - val_loss: 21.4395\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 18.3495 - val_loss: 21.7162\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 18.8724 - val_loss: 21.6662\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 17.8762 - val_loss: 20.9971\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 17.5666 - val_loss: 21.2845\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 17.3720 - val_loss: 20.6975\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 18.0631 - val_loss: 21.3647\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.6529 - val_loss: 21.6009\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.4618 - val_loss: 19.6398\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.6860 - val_loss: 21.1966\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 17.7960 - val_loss: 21.4524\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.4217 - val_loss: 20.4461\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.1185 - val_loss: 21.9851\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 19.0826 - val_loss: 19.8871\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 17.7592 - val_loss: 20.6492\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.8025 - val_loss: 20.2297\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 18.4536 - val_loss: 19.0713\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.5829 - val_loss: 18.7425\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.8437 - val_loss: 18.8544\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.2498 - val_loss: 19.2898\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.0088 - val_loss: 21.2594\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.4401 - val_loss: 19.2364\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0588 - val_loss: 19.4660\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.5859 - val_loss: 18.9369\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0086 - val_loss: 21.0982\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.5260 - val_loss: 19.4586\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 16.3670 - val_loss: 20.0489\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.2972 - val_loss: 19.4175\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.3498 - val_loss: 19.8805\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.2517 - val_loss: 19.3560\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.2044 - val_loss: 20.3702\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0856 - val_loss: 18.3847\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.2827 - val_loss: 18.2984\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.2276 - val_loss: 22.1987\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.3061 - val_loss: 22.0489\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.2722 - val_loss: 18.2217\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 15.2872 - val_loss: 18.7872\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 15.9994 - val_loss: 18.7363\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.0115 - val_loss: 20.4055\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.9663 - val_loss: 18.9204\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2805 - val_loss: 18.3679\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4700 - val_loss: 17.8784\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.4415 - val_loss: 17.6758\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.4558 - val_loss: 19.5214\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 15.3764 - val_loss: 17.7086\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.0919 - val_loss: 18.3327\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 15.7242 - val_loss: 21.3891\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4374 - val_loss: 19.7428\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4209 - val_loss: 17.8866\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 15.1054 - val_loss: 18.4438\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 14.9286 - val_loss: 18.8087\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1689 - val_loss: 18.6253\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7134 - val_loss: 17.5741\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.5678 - val_loss: 18.2298\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7401 - val_loss: 19.4454\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.1028 - val_loss: 16.4808\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7663 - val_loss: 20.7298\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.9431 - val_loss: 16.9210\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.0195 - val_loss: 16.9503\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.1613 - val_loss: 17.4071\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3983 - val_loss: 17.6971\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.9880 - val_loss: 18.1508\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.8823 - val_loss: 16.8276\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8016 - val_loss: 16.1833\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 14.1291 - val_loss: 17.9095\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.0139 - val_loss: 16.3455\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.2341 - val_loss: 16.4972\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 13.5796 - val_loss: 15.9512\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.6972 - val_loss: 16.3083\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.5963 - val_loss: 17.1323\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.1945 - val_loss: 16.5235\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.9499 - val_loss: 15.9036\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.6439 - val_loss: 16.3805\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 13.3467 - val_loss: 16.1228\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 12.9906 - val_loss: 15.6629\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.7732 - val_loss: 15.0374\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.9868 - val_loss: 15.4527\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9133 - val_loss: 15.9262\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.2179 - val_loss: 20.0387\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.1859 - val_loss: 14.8574\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.6705 - val_loss: 16.0648\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3026 - val_loss: 15.7679\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.2862 - val_loss: 16.5152\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.2733 - val_loss: 16.2544\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.1346 - val_loss: 14.8420\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3253 - val_loss: 14.9944\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.9281 - val_loss: 15.8967\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3345 - val_loss: 16.4710\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.0676 - val_loss: 14.2871\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.1203 - val_loss: 15.1233\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7290 - val_loss: 15.9589\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.6718 - val_loss: 18.1288\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.0082 - val_loss: 17.8619\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7105 - val_loss: 15.9881\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.7085 - val_loss: 15.1442\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.7734 - val_loss: 15.3046\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.7183 - val_loss: 18.5096\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.3404 - val_loss: 14.6093\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.8164 - val_loss: 15.3088\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.2385 - val_loss: 13.9729\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.6276 - val_loss: 13.7051\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1287 - val_loss: 13.7654\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.1606 - val_loss: 14.6727\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.3024 - val_loss: 15.3531\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.3767 - val_loss: 13.5733\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4776 - val_loss: 13.4129\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1621 - val_loss: 14.5397\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2892 - val_loss: 15.7045\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.3209 - val_loss: 14.1571\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.7928 - val_loss: 13.2180\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.7558 - val_loss: 14.0745\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1523 - val_loss: 13.8769\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.2578 - val_loss: 14.1518\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1445 - val_loss: 16.8125\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.5419 - val_loss: 13.6579\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1351 - val_loss: 13.4061\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.5318 - val_loss: 14.0641\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.9954 - val_loss: 13.3731\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.0407 - val_loss: 13.8780\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.7035 - val_loss: 14.0552\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4383 - val_loss: 13.5831\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1468 - val_loss: 13.2987\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1116 - val_loss: 12.9445\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.4859 - val_loss: 14.7944\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.8297 - val_loss: 12.1215\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0596 - val_loss: 11.8647\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.4523 - val_loss: 12.1901\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.6072 - val_loss: 13.3669\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1618 - val_loss: 12.1901\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1894 - val_loss: 12.8353\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0313 - val_loss: 11.9468\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0668 - val_loss: 13.1120\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.5541 - val_loss: 12.6360\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0971 - val_loss: 12.2707\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9403 - val_loss: 12.7971\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.7066 - val_loss: 13.2847\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9655 - val_loss: 12.1658\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0836 - val_loss: 12.3295\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.2580 - val_loss: 14.5900\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7960 - val_loss: 12.8982\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5695 - val_loss: 12.0578\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.3909 - val_loss: 12.6111\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8044 - val_loss: 11.8786\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6583 - val_loss: 11.4131\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8378 - val_loss: 12.6417\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5300 - val_loss: 12.3936\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5945 - val_loss: 11.9416\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9632 - val_loss: 13.1070\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6999 - val_loss: 11.6475\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4664 - val_loss: 11.5036\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1370 - val_loss: 11.5744\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0339 - val_loss: 11.4100\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5859 - val_loss: 12.2944\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8075 - val_loss: 11.3947\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9336 - val_loss: 12.3986\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0650 - val_loss: 14.3174\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0803 - val_loss: 12.9509\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7645 - val_loss: 12.1083\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0827 - val_loss: 11.6509\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.1760 - val_loss: 12.3955\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7164 - val_loss: 11.5402\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2842 - val_loss: 11.8715\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6418 - val_loss: 11.6483\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5977 - val_loss: 12.9236\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1981 - val_loss: 13.2127\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.8882 - val_loss: 11.7603\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5211 - val_loss: 12.6215\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4013 - val_loss: 11.7821\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.6417 - val_loss: 11.1247\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2872 - val_loss: 12.5545\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5997 - val_loss: 13.2316\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1887 - val_loss: 11.1502\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4533 - val_loss: 11.5093\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3829 - val_loss: 11.3361\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5570 - val_loss: 11.4448\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4915 - val_loss: 11.5261\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4171 - val_loss: 12.3363\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5432 - val_loss: 13.1396\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4868 - val_loss: 11.7953\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1476 - val_loss: 11.1646\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5413 - val_loss: 13.3015\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0073 - val_loss: 11.2686\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3615 - val_loss: 11.2934\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0893 - val_loss: 11.7528\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6716 - val_loss: 11.2445\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7574 - val_loss: 11.8015\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3456 - val_loss: 11.5688\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3366 - val_loss: 13.0829\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5568 - val_loss: 11.8314\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.2026 - val_loss: 11.0579\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4740 - val_loss: 13.0712\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9620 - val_loss: 13.4576\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0301 - val_loss: 11.7685\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3259 - val_loss: 11.4027\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5403 - val_loss: 11.5071\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3106 - val_loss: 12.4369\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6130 - val_loss: 12.2006\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1315 - val_loss: 11.6374\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8747 - val_loss: 13.6679\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9421 - val_loss: 10.9028\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4685 - val_loss: 11.6688\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6856 - val_loss: 13.0355\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4303 - val_loss: 11.2817\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2200 - val_loss: 11.6066\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0937 - val_loss: 12.1524\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2408 - val_loss: 12.7673\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7743 - val_loss: 11.1173\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7947 - val_loss: 12.6112\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7790 - val_loss: 13.2766\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6968 - val_loss: 11.2647\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4414 - val_loss: 12.0807\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1464 - val_loss: 12.3588\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1268 - val_loss: 11.0602\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3642 - val_loss: 12.3555\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4422 - val_loss: 11.1545\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9730 - val_loss: 10.9356\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3219 - val_loss: 10.9259\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1527 - val_loss: 11.3670\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.9924 - val_loss: 10.9597\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8690 - val_loss: 11.2949\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1301 - val_loss: 11.3871\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8056 - val_loss: 11.3411\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1778 - val_loss: 11.0771\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4000 - val_loss: 13.0677\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2943 - val_loss: 11.3643\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0432 - val_loss: 11.4380\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3620 - val_loss: 10.9287\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7442 - val_loss: 10.9648\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4949 - val_loss: 11.4490\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.7249 - val_loss: 11.4548\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0792 - val_loss: 11.4747\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.3598 - val_loss: 12.6444\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.6155 - val_loss: 11.3849\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0677 - val_loss: 13.9262\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5085 - val_loss: 11.5631\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4125 - val_loss: 11.2411\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3346 - val_loss: 11.0810\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9410 - val_loss: 11.5353\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3865 - val_loss: 11.4346\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0198 - val_loss: 13.1078\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4077 - val_loss: 11.8674\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.0658 - 0s 88us/step - loss: 9.6500 - val_loss: 12.3199\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.5091 - val_loss: 12.8061\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8796 - val_loss: 12.1314\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4304 - val_loss: 11.3800\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2303 - val_loss: 11.0174\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5453 - val_loss: 12.6116\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3140 - val_loss: 11.6359\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2298 - val_loss: 10.9075\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8818 - val_loss: 11.5119\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4360 - val_loss: 14.4383\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2514 - val_loss: 11.0429\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3099 - val_loss: 11.0537\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3142 - val_loss: 11.8535\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4461 - val_loss: 12.7393\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4766 - val_loss: 11.4800\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5787 - val_loss: 12.9312\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7001 - val_loss: 11.4876\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.0103 - val_loss: 12.0378\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1543 - val_loss: 11.1816\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1378 - val_loss: 12.5198\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6078 - val_loss: 13.3626\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8141 - val_loss: 10.9908\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1520 - val_loss: 13.8993\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6086 - val_loss: 11.0457\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0547 - val_loss: 12.3123\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5523 - val_loss: 11.2703\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1720 - val_loss: 12.0583\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0169 - val_loss: 12.0703\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6448 - val_loss: 13.1202\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9068 - val_loss: 12.3141\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3228 - val_loss: 11.7362\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.4946 - val_loss: 11.0971\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3921 - val_loss: 12.4795\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7157 - val_loss: 11.0632\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4797 - val_loss: 11.5755\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2834 - val_loss: 10.7107\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0977 - val_loss: 10.9475\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4244 - val_loss: 11.6847\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9581 - val_loss: 11.0811\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1309 - val_loss: 11.1775\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7169 - val_loss: 14.5267\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3777 - val_loss: 10.7335\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5535 - val_loss: 11.6432\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9839 - val_loss: 11.6812\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2209 - val_loss: 12.1662\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0236 - val_loss: 11.1218\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0935 - val_loss: 11.0985\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2771 - val_loss: 13.6380\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6446 - val_loss: 11.0677\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2599 - val_loss: 10.8769\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9773 - val_loss: 11.0620\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.0904 - val_loss: 11.2078\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9010 - val_loss: 11.4925\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0070 - val_loss: 10.9674\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9527 - val_loss: 11.2725\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9641 - val_loss: 11.6204\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2092 - val_loss: 10.8693\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6731 - val_loss: 11.6128\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1741 - val_loss: 11.3631\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1211 - val_loss: 10.9343\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.4862 - val_loss: 11.0731\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2718 - val_loss: 12.7352\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4193 - val_loss: 11.3292\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0706 - val_loss: 10.6437\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 9.5494 - val_loss: 11.4727\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2322 - val_loss: 11.2014\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1446 - val_loss: 11.5537\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2930 - val_loss: 10.9755\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7586 - val_loss: 11.8437\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4217 - val_loss: 11.3111\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5268 - val_loss: 11.8807\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1681 - val_loss: 12.5733\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5293 - val_loss: 10.9588\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3312 - val_loss: 11.1401\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0192 - val_loss: 11.1060\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7476 - val_loss: 12.2706\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3530 - val_loss: 11.4329\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2907 - val_loss: 12.5079\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4431 - val_loss: 10.7135\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9963 - val_loss: 11.3381\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7777 - val_loss: 11.7945\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4538 - val_loss: 11.0117\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1915 - val_loss: 11.0442\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9273 - val_loss: 10.9727\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2652 - val_loss: 11.2810\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1074 - val_loss: 10.9102\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9855 - val_loss: 11.0586\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8668 - val_loss: 10.7701\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9579 - val_loss: 11.8056\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9556 - val_loss: 12.0418\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9274 - val_loss: 12.2996\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9550 - val_loss: 11.7269\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4599 - val_loss: 11.2849\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 9.0719 - val_loss: 11.3234\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9936 - val_loss: 12.3082\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3665 - val_loss: 10.7956\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8992 - val_loss: 10.8617\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1334 - val_loss: 11.4329\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2931 - val_loss: 11.4326\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4792 - val_loss: 11.9349\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.6184 - val_loss: 11.4071\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9943 - val_loss: 11.8444\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3482 - val_loss: 11.8331\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4147 - val_loss: 11.4571\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1725 - val_loss: 11.7053\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4751 - val_loss: 13.9053\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2417 - val_loss: 10.8682\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3645 - val_loss: 12.1048\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1300 - val_loss: 10.8657\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4644 - val_loss: 13.9243\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7514 - val_loss: 11.2638\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0211 - val_loss: 13.8839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7927 - val_loss: 11.0520\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3270 - val_loss: 13.0387\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5547 - val_loss: 12.3746\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4677 - val_loss: 12.4263\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1583 - val_loss: 11.1995\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2582 - val_loss: 11.0119\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8225 - val_loss: 12.0320\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2575 - val_loss: 10.7490\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9381 - val_loss: 10.8005\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8547 - val_loss: 10.9332\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2011 - val_loss: 10.5687\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2023 - val_loss: 10.7231\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1249 - val_loss: 11.4188\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4014 - val_loss: 14.0893\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2867 - val_loss: 11.6341\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3604 - val_loss: 11.3580\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.9870 - val_loss: 10.8007\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7222 - val_loss: 10.7748\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2611 - val_loss: 12.9605\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5632 - val_loss: 10.9447\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1097 - val_loss: 11.1105\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7023 - val_loss: 11.3404\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8056 - val_loss: 10.4629\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1936 - val_loss: 11.2463\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2822 - val_loss: 11.9514\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3411 - val_loss: 12.4296\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7717 - val_loss: 11.0750\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1598 - val_loss: 11.3107\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3005 - val_loss: 11.0574\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9124 - val_loss: 10.7985\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8417 - val_loss: 15.3043\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0885 - val_loss: 11.0731\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2051 - val_loss: 10.9390\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1813 - val_loss: 12.4649\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1021 - val_loss: 11.1806\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2290 - val_loss: 11.5181\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1629 - val_loss: 10.6706\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2098 - val_loss: 11.0796\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2797 - val_loss: 11.3959\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3617 - val_loss: 10.9239\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8197 - val_loss: 11.3084\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1865 - val_loss: 11.1416\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3317 - val_loss: 12.3776\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3149 - val_loss: 11.0374\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8166 - val_loss: 11.3418\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5946 - val_loss: 11.0549\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8760 - val_loss: 11.0046\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 10.0202 - val_loss: 13.4054\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3652 - val_loss: 11.3314\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2264 - val_loss: 10.6123\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0157 - val_loss: 11.1993\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9395 - val_loss: 10.7549\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1095 - val_loss: 10.5545\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2477 - val_loss: 11.8246\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3079 - val_loss: 11.2329\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1517 - val_loss: 12.4046\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1926 - val_loss: 10.9652\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1849 - val_loss: 10.6023\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.6906 - val_loss: 10.9431\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9807 - val_loss: 10.9297\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0510 - val_loss: 10.7929\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3277 - val_loss: 10.8725\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9499 - val_loss: 11.0845\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0259 - val_loss: 11.3462\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6106 - val_loss: 14.5363\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5432 - val_loss: 10.8608\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.0641 - val_loss: 10.5782\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8227 - val_loss: 10.8577\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0348 - val_loss: 10.9605\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9670 - val_loss: 11.0321\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1365 - val_loss: 10.6095\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1524 - val_loss: 10.4930\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8649 - val_loss: 11.3885\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0450 - val_loss: 11.0125\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0476 - val_loss: 12.8266\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2429 - val_loss: 11.3842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9974 - val_loss: 12.0121\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2172 - val_loss: 11.4984\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9826 - val_loss: 10.8043\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4204 - val_loss: 11.1951\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8050 - val_loss: 11.4566\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0145 - val_loss: 10.4006\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2591 - val_loss: 12.1347\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4767 - val_loss: 11.5091\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0580 - val_loss: 10.6967\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2213 - val_loss: 10.5238\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0739 - val_loss: 11.2725\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1199 - val_loss: 12.9327\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7287 - val_loss: 10.9729\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5928 - val_loss: 12.0763\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9031 - val_loss: 11.2731\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4118 - val_loss: 11.0759\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0334 - val_loss: 11.7042\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1865 - val_loss: 11.7130\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4736 - val_loss: 12.1868\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6970 - val_loss: 11.1931\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4501 - val_loss: 11.6154\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8588 - val_loss: 10.7738\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1407 - val_loss: 11.5837\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9340 - val_loss: 11.4023\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7860 - val_loss: 10.8366\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0318 - val_loss: 11.7188\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.7892 - val_loss: 11.0903\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6319 - val_loss: 11.9480\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2184 - val_loss: 10.9682\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8531 - val_loss: 10.9719\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0465 - val_loss: 10.8035\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2805 - val_loss: 12.5804\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2874 - val_loss: 10.6004\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8919 - val_loss: 10.9702\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7072 - val_loss: 10.9560\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0514 - val_loss: 11.2077\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6506 - val_loss: 11.2431\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0733 - val_loss: 10.7595\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7896 - val_loss: 10.9125\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9851 - val_loss: 10.4186\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4232 - val_loss: 11.4186\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1885 - val_loss: 11.4062\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2529 - val_loss: 11.9218\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0063 - val_loss: 11.3210\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9097 - val_loss: 11.4917\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2396 - val_loss: 11.0343\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8541 - val_loss: 10.6876\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0983 - val_loss: 11.8104\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1583 - val_loss: 11.6523\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1078 - val_loss: 12.5559\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3126 - val_loss: 10.5582\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7927 - val_loss: 10.5806\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9072 - val_loss: 10.7115\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4122 - val_loss: 10.9844\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2078 - val_loss: 11.7241\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7826 - val_loss: 10.4875\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1721 - val_loss: 10.5483\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9532 - val_loss: 11.3641\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9261 - val_loss: 10.5641\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2853 - val_loss: 13.2267\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0782 - val_loss: 11.8417\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9383 - val_loss: 10.5453\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2254 - val_loss: 10.9368\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8303 - val_loss: 10.8244\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8090 - val_loss: 11.5869\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3212 - val_loss: 10.8292\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8774 - val_loss: 11.5253\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0802 - val_loss: 10.8853\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1137 - val_loss: 12.5589\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9764 - val_loss: 10.6940\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9827 - val_loss: 11.0763\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.6956 - val_loss: 10.7238\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.8829 - val_loss: 10.4207\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4160 - val_loss: 12.9385\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4461 - val_loss: 10.7558\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1530 - val_loss: 10.8807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2162 - val_loss: 10.5600\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9967 - val_loss: 11.6695\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0231 - val_loss: 10.8011\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1626 - val_loss: 13.1078\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7006 - val_loss: 13.0653\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2366 - val_loss: 10.6873\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3999 - val_loss: 11.3845\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7939 - val_loss: 10.8954\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9048 - val_loss: 10.5226\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0126 - val_loss: 11.2703\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7762 - val_loss: 10.5071\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.9041 - val_loss: 12.2951\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3421 - val_loss: 12.2734\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7599 - val_loss: 10.9550\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0984 - val_loss: 10.8318\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8785 - val_loss: 11.5185\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.9812 - val_loss: 10.5314\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9010 - val_loss: 11.0228\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8917 - val_loss: 10.5384\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6940 - val_loss: 10.5047\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8534 - val_loss: 12.0578\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9602 - val_loss: 11.1268\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7579 - val_loss: 10.5628\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0227 - val_loss: 10.3982\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0246 - val_loss: 11.2107\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0010 - val_loss: 10.7926\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5830 - val_loss: 13.4068\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4925 - val_loss: 11.0164\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.8213 - 0s 91us/step - loss: 8.8017 - val_loss: 10.7347\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2808 - val_loss: 10.9691\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0695 - val_loss: 10.8982\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5828 - val_loss: 10.6382\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4858 - val_loss: 12.7771\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0286 - val_loss: 10.9368\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8079 - val_loss: 11.9253\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6935 - val_loss: 10.9575\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7597 - val_loss: 11.7242\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1427 - val_loss: 10.5555\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3549 - val_loss: 12.7237\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9565 - val_loss: 10.7913\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0163 - val_loss: 10.9219\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2182 - val_loss: 10.6101\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9499 - val_loss: 10.4885\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9355 - val_loss: 10.6424\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8463 - val_loss: 10.7022\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0731 - val_loss: 10.9999\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3715 - val_loss: 10.4408\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8743 - val_loss: 10.9745\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9153 - val_loss: 10.8849\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9262 - val_loss: 10.8891\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0837 - val_loss: 10.9527\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8493 - val_loss: 11.2283\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1942 - val_loss: 10.7964\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2619 - val_loss: 10.6986\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9504 - val_loss: 10.3536\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3868 - val_loss: 12.2303\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3263 - val_loss: 11.0163\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2211 - val_loss: 12.3835\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1568 - val_loss: 10.8504\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9367 - val_loss: 11.1702\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0457 - val_loss: 11.8055\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4503 - val_loss: 11.4330\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9516 - val_loss: 11.6858\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0505 - val_loss: 10.9303\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0815 - val_loss: 11.2805\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1864 - val_loss: 10.4084\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8487 - val_loss: 10.7606\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9845 - val_loss: 10.9508\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.5845 - val_loss: 10.9572\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7880 - val_loss: 11.6825\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8873 - val_loss: 11.4202\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8847 - val_loss: 11.1956\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8226 - val_loss: 11.0569\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1020 - val_loss: 10.5448\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6717 - val_loss: 10.7567\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7025 - val_loss: 10.5626\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5300 - val_loss: 10.5586\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9198 - val_loss: 10.4640\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7155 - val_loss: 10.3637\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8876 - val_loss: 11.3862\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0657 - val_loss: 10.8814\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6983 - val_loss: 10.5361\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8289 - val_loss: 10.5193\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8866 - val_loss: 11.0140\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0025 - val_loss: 11.5836\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9944 - val_loss: 13.2969\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1370 - val_loss: 11.2103\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9609 - val_loss: 11.1652\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8007 - val_loss: 11.7586\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1590 - val_loss: 10.8129\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0550 - val_loss: 10.6640\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2615 - val_loss: 11.5842\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5553 - val_loss: 11.6632\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2217 - val_loss: 10.4424\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0804 - val_loss: 13.1608\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3150 - val_loss: 11.1342\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9175 - val_loss: 10.5202\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8335 - val_loss: 10.5325\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9765 - val_loss: 11.7875\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7943 - val_loss: 11.1958\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2240 - val_loss: 11.3017\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0063 - val_loss: 10.7071\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9766 - val_loss: 10.5112\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6498 - val_loss: 12.1747\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2145 - val_loss: 11.0160\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7052 - val_loss: 11.3375\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8784 - val_loss: 10.5571\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6811 - val_loss: 10.7089\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7326 - val_loss: 11.4046\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7544 - val_loss: 11.4003\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4234 - val_loss: 11.6889\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8387 - val_loss: 11.0580\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9648 - val_loss: 10.8559\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8587 - val_loss: 10.8123\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0365 - val_loss: 12.8028\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.4456 - val_loss: 10.9217\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3709 - val_loss: 11.1482\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0058 - val_loss: 10.5046\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0227 - val_loss: 10.6847\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8612 - val_loss: 11.5221\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0595 - val_loss: 10.6694\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9858 - val_loss: 10.7680\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9002 - val_loss: 10.9958\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0972 - val_loss: 12.9998\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6924 - val_loss: 11.1449\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5156 - val_loss: 11.5744\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9782 - val_loss: 10.8371\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9995 - val_loss: 11.1231\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9445 - val_loss: 10.8100\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4197 - val_loss: 12.4467\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6609 - val_loss: 10.5346\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0016 - val_loss: 10.8504\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9551 - val_loss: 12.1131\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6563 - val_loss: 11.9528\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2689 - val_loss: 10.7169\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2826 - val_loss: 12.1817\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6990 - val_loss: 10.5209\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8605 - val_loss: 14.6705\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0336 - val_loss: 10.3896\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1486 - val_loss: 11.1460\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7955 - val_loss: 11.1861\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1394 - val_loss: 10.5303\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8236 - val_loss: 11.4278\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9620 - val_loss: 11.6775\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0035 - val_loss: 11.8711\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0564 - val_loss: 11.7717\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8153 - val_loss: 11.2543\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9792 - val_loss: 10.5718\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8764 - val_loss: 10.6342\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4930 - val_loss: 10.4324\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6839 - val_loss: 12.2827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0641 - val_loss: 10.5678\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7556 - val_loss: 10.8177\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.8810 - val_loss: 10.7610\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9185 - val_loss: 11.3101\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5719 - val_loss: 10.5796\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9067 - val_loss: 10.4681\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9615 - val_loss: 11.1061\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0102 - val_loss: 11.6883\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8409 - val_loss: 10.3841\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8815 - val_loss: 10.9466\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6067 - val_loss: 11.5089\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5379 - val_loss: 10.3553\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9095 - val_loss: 11.6188\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 9.0273 - val_loss: 10.7415\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.0336 - val_loss: 11.3757\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7136 - val_loss: 10.5285\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8517 - val_loss: 10.5191\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7978 - val_loss: 10.4510\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 9.4569 - val_loss: 11.4248\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6937 - val_loss: 12.2048\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2521 - val_loss: 10.3012\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2912 - val_loss: 11.9985\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0322 - val_loss: 11.2295\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7368 - val_loss: 10.6444\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0483 - val_loss: 10.5660\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6704 - val_loss: 11.4820\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0133 - val_loss: 12.7857\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8959 - val_loss: 11.1007\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2880 - val_loss: 10.3320\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5387 - val_loss: 10.5614\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9012 - val_loss: 10.6717\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2824 - val_loss: 11.4209\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0337 - val_loss: 10.7062\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0704 - val_loss: 10.4251\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8128 - val_loss: 10.6246\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5792 - val_loss: 11.4598\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0008 - val_loss: 11.8798\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3029 - val_loss: 11.0048\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1095 - val_loss: 10.7505\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2972 - val_loss: 10.9708\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.9764 - val_loss: 11.4434\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.4268 - val_loss: 10.9434\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0412 - val_loss: 11.2446\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1166 - val_loss: 10.7533\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8977 - val_loss: 10.6003\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7313 - val_loss: 11.4927\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9597 - val_loss: 10.7377\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8235 - val_loss: 10.5310\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0734 - val_loss: 11.6153\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6087 - val_loss: 10.9090\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6362 - val_loss: 10.4986\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9007 - val_loss: 10.6126\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9569 - val_loss: 10.7054\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8745 - val_loss: 11.1126\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8046 - val_loss: 10.3890\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9030 - val_loss: 10.4917\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7394 - val_loss: 11.4210\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9923 - val_loss: 10.8420\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1905 - val_loss: 13.1383\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8555 - val_loss: 11.5987\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5919 - val_loss: 10.5451\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0234 - val_loss: 11.0528\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9268 - val_loss: 11.1447\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6205 - val_loss: 11.1866\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.353 - 0s 87us/step - loss: 8.7099 - val_loss: 10.4476\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5890 - val_loss: 10.9871\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9092 - val_loss: 11.1674\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8577 - val_loss: 10.7465\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6951 - val_loss: 11.3898\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8778 - val_loss: 12.4202\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.5799 - val_loss: 10.9127\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9566 - val_loss: 10.6019\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0669 - val_loss: 11.5856\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4566 - val_loss: 11.1187\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0884 - val_loss: 11.1731\n",
      "Epoch 894/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1436 - val_loss: 12.1122\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1187 - val_loss: 10.7949\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7415 - val_loss: 10.9564\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8110 - val_loss: 11.6986\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9090 - val_loss: 11.3493\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7616 - val_loss: 12.3338\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9793 - val_loss: 10.7071\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6278 - val_loss: 11.3630\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9190 - val_loss: 10.5193\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8658 - val_loss: 10.3713\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0044 - val_loss: 10.2330\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1660 - val_loss: 12.0291\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7714 - val_loss: 10.4683\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5903 - val_loss: 10.3801\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9832 - val_loss: 11.3314\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4099 - val_loss: 11.9689\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8614 - val_loss: 11.0897\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.4718 - val_loss: 10.2760\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.4899 - val_loss: 11.8280\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2652 - val_loss: 10.5218\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7390 - val_loss: 10.9681\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9654 - val_loss: 11.6134\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0557 - val_loss: 11.3641\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7599 - val_loss: 10.3971\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6191 - val_loss: 10.3261\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5775 - val_loss: 14.8951\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1787 - val_loss: 10.6579\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.6320 - val_loss: 10.4633\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6860 - val_loss: 11.4355\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.0500 - val_loss: 10.7995\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7169 - val_loss: 10.8048\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8347 - val_loss: 10.9263\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1060 - val_loss: 10.6494\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6619 - val_loss: 10.6612\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7778 - val_loss: 10.9116\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3644 - val_loss: 10.8052\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9880 - val_loss: 11.3528\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.5002 - val_loss: 10.4637\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7630 - val_loss: 11.4262\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.6462 - val_loss: 11.2272\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4902 - val_loss: 11.2277\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8081 - val_loss: 10.9101\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9215 - val_loss: 10.7270\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2000 - val_loss: 10.9330\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6685 - val_loss: 10.3909\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1411 - val_loss: 10.9275\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.6139 - val_loss: 11.2289\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6199 - val_loss: 11.0541\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6211 - val_loss: 10.6015\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8377 - val_loss: 11.4685\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9590 - val_loss: 11.1506\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8764 - val_loss: 11.3813\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7356 - val_loss: 10.4277\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1404 - val_loss: 11.3711\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9919 - val_loss: 10.6262\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8509 - val_loss: 10.9140\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1295 - val_loss: 10.3016\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8050 - val_loss: 11.9055\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9553 - val_loss: 12.7207\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9789 - val_loss: 10.8072\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7875 - val_loss: 11.0103\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0754 - val_loss: 10.3052\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7665 - val_loss: 10.4755\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7397 - val_loss: 11.0878\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2305 - val_loss: 10.4057\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6120 - val_loss: 10.6306\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1685 - val_loss: 10.4608\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8206 - val_loss: 10.7779\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 8.578 - 0s 87us/step - loss: 8.7253 - val_loss: 10.5764\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7046 - val_loss: 10.1807\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0854 - val_loss: 10.9916\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0858 - val_loss: 10.4561\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9622 - val_loss: 10.9292\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4655 - val_loss: 10.5591\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9828 - val_loss: 10.7658\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0542 - val_loss: 10.6036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5243 - val_loss: 10.6193\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5627 - val_loss: 10.4173\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2062 - val_loss: 10.6715\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7510 - val_loss: 10.3237\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4693 - val_loss: 12.5570\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5363 - val_loss: 10.9619\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6512 - val_loss: 10.9071\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7635 - val_loss: 10.5739\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5014 - val_loss: 10.1626\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6086 - val_loss: 10.4453\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5270 - val_loss: 10.4709\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7330 - val_loss: 11.0004\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9442 - val_loss: 11.7147\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1492 - val_loss: 10.1015\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7516 - val_loss: 11.3945\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6967 - val_loss: 10.5867\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1243 - val_loss: 10.8126\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7767 - val_loss: 10.8683\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8083 - val_loss: 10.2550\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6351 - val_loss: 11.7445\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0956 - val_loss: 11.3007\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8535 - val_loss: 10.8756\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6853 - val_loss: 10.6835\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0365 - val_loss: 10.9547\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6964 - val_loss: 10.4236\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3875 - val_loss: 12.1746\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4030 - val_loss: 12.1976\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0413 - val_loss: 10.6422\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1927 - val_loss: 11.0992\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8167 - val_loss: 10.6561\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 8.5726 - val_loss: 10.8142\n",
      "8.423985204865447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.9627422 ,  3.720286  , -0.2045466 ,  3.4614522 ,  2.397332  ],\n",
       "        [ 0.34341007, -0.3091803 , -0.25689313,  0.044903  , -0.19827989],\n",
       "        [ 0.2883909 ,  0.57452184, -0.36653545,  0.04839338, -0.0276359 ],\n",
       "        [ 0.05623429, -0.17904729,  0.0989675 ,  0.20756425, -0.1935187 ],\n",
       "        [-0.20686434,  0.4317331 , -0.19647674,  0.4245821 ,  3.0578465 ]],\n",
       "       dtype=float32),\n",
       " array([-1.365446  ,  4.573095  , -0.10281154,  4.3669934 ,  4.452761  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.18102863,  0.85815674, -0.6823412 , -1.1811129 , -0.01965414,\n",
       "         -1.1369356 , -1.0263681 , -0.04920809,  0.7137829 , -1.0292051 ],\n",
       "        [ 2.115924  ,  2.4788651 , -2.2932673 , -2.2789063 , -1.5644004 ,\n",
       "         -1.9995311 , -2.0674767 , -1.8962002 ,  1.9377713 , -1.2670631 ],\n",
       "        [ 0.703413  ,  0.7431646 , -0.92807215, -1.0678416 , -0.74138147,\n",
       "         -0.92932737, -1.0334527 , -0.76752645,  1.2805858 , -0.9856542 ],\n",
       "        [ 2.062931  ,  1.2860991 , -1.2365801 , -2.2647004 , -2.381544  ,\n",
       "         -1.4795095 , -2.171142  , -1.8761604 ,  1.9531376 , -1.7303399 ],\n",
       "        [ 1.1538576 ,  1.665828  , -1.0430665 , -1.097304  , -1.6871489 ,\n",
       "         -1.7511469 , -1.6329277 , -0.721883  ,  1.9167117 , -1.878144  ]],\n",
       "       dtype=float32),\n",
       " array([ 1.7398938,  1.8190547, -1.8517652, -1.8996104, -1.8559002,\n",
       "        -1.8382024, -1.7501098, -1.7288817,  1.724621 , -1.7695384],\n",
       "       dtype=float32),\n",
       " array([[ 2.2759778],\n",
       "        [ 1.8182971],\n",
       "        [-1.7065204],\n",
       "        [-1.6403735],\n",
       "        [-1.8628732],\n",
       "        [-1.6085644],\n",
       "        [-2.0571556],\n",
       "        [-2.1454363],\n",
       "        [ 2.1855354],\n",
       "        [-1.6013019]], dtype=float32),\n",
       " array([1.7349515], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_adam_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 164us/step - loss: 15408.7690 - val_loss: 15139.2924\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14388.5713 - val_loss: 13261.5902\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9903.0956 - val_loss: 4398.0037\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 1035.8830 - val_loss: 119.3441\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 58us/step - loss: 75.6578 - val_loss: 49.7901\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 46.3405 - val_loss: 41.3143\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 39.4686 - val_loss: 36.2327\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 35.1373 - val_loss: 33.2930\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 32.4374 - val_loss: 31.3629\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 30.3466 - val_loss: 30.0345\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 28.7593 - val_loss: 29.2678\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 27.6043 - val_loss: 28.4892\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 26.6839 - val_loss: 28.1241\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 25.9631 - val_loss: 27.5337\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 25.4663 - val_loss: 27.3428\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 24.9658 - val_loss: 27.1174\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 24.5481 - val_loss: 26.9991\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 24.3030 - val_loss: 27.0083\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 24.0624 - val_loss: 26.8070\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 23.7352 - val_loss: 26.8103\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.5826 - val_loss: 26.5559\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.4207 - val_loss: 26.6400\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 23.3009 - val_loss: 26.4698\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.0535 - val_loss: 26.4358\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.9529 - val_loss: 26.4676\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.7685 - val_loss: 26.3564\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.6568 - val_loss: 26.2843\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 22.5317 - val_loss: 26.2635\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.3984 - val_loss: 26.1229\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.3137 - val_loss: 26.1211\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 22.2111 - val_loss: 25.9693\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 22.1044 - val_loss: 26.0189\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.9791 - val_loss: 25.8753\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.9364 - val_loss: 26.0263\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.7963 - val_loss: 25.8333\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.6873 - val_loss: 25.7709\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.6165 - val_loss: 25.7755\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 21.5431 - val_loss: 25.7629\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.4689 - val_loss: 25.6393\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.3696 - val_loss: 25.6974\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.2899 - val_loss: 25.6643\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.2194 - val_loss: 25.6025\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.1798 - val_loss: 25.5496\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 21.1187 - val_loss: 25.5911\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 21.0538 - val_loss: 25.5170\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.9743 - val_loss: 25.5130\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.9324 - val_loss: 25.5766\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.8247 - val_loss: 25.4199\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.7694 - val_loss: 25.4947\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 20.7488 - val_loss: 25.4442\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.6511 - val_loss: 25.4713\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 20.6233 - val_loss: 25.4039\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.5575 - val_loss: 25.4042\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.5049 - val_loss: 25.4398\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.4450 - val_loss: 25.4218\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.3883 - val_loss: 25.4600\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.3394 - val_loss: 25.3947\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.2801 - val_loss: 25.3928\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.2343 - val_loss: 25.4108\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.2051 - val_loss: 25.3033\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.1369 - val_loss: 25.3574\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.1260 - val_loss: 25.3207\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.0733 - val_loss: 25.3623\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.0199 - val_loss: 25.4059\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.0252 - val_loss: 25.3522\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.9785 - val_loss: 25.2836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.9626 - val_loss: 25.2523\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.9111 - val_loss: 25.2522\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.8333 - val_loss: 25.2463\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.8077 - val_loss: 25.3171\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.7787 - val_loss: 25.2083\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.7857 - val_loss: 25.2545\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.7176 - val_loss: 25.2308\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.6779 - val_loss: 25.2065\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.6302 - val_loss: 25.1707\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.6038 - val_loss: 25.0996\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5652 - val_loss: 25.1151\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.5759 - val_loss: 25.0723\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 19.5121 - val_loss: 25.1244\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.5144 - val_loss: 25.0565\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.4920 - val_loss: 25.0854\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.4204 - val_loss: 24.9954\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.4071 - val_loss: 24.9938\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.3775 - val_loss: 24.9362\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.3654 - val_loss: 24.9543\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.3250 - val_loss: 24.9108\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.3349 - val_loss: 24.9198\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.2969 - val_loss: 24.9281\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.2676 - val_loss: 24.8278\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.2232 - val_loss: 24.8095\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.1967 - val_loss: 24.8109\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.1747 - val_loss: 24.8025\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.1591 - val_loss: 24.7533\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.1464 - val_loss: 24.7742\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.1148 - val_loss: 24.6852\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.1179 - val_loss: 24.7296\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.0926 - val_loss: 24.6563\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.0598 - val_loss: 24.7042\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0393 - val_loss: 24.5800\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 19.0257 - val_loss: 24.5773\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.0091 - val_loss: 24.5561\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.9688 - val_loss: 24.5863\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.9580 - val_loss: 24.5772\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.9326 - val_loss: 24.5222\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.9131 - val_loss: 24.5123\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.8973 - val_loss: 24.5241\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.9055 - val_loss: 24.4452\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.8796 - val_loss: 24.4127\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 18.8319 - val_loss: 24.4126\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8494 - val_loss: 24.4157\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8149 - val_loss: 24.3698\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.7987 - val_loss: 24.3667\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.7722 - val_loss: 24.3775\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.7977 - val_loss: 24.2916\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.7482 - val_loss: 24.3501\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.7418 - val_loss: 24.3016\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.7156 - val_loss: 24.2804\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.6998 - val_loss: 24.2683\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6911 - val_loss: 24.2940\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.6792 - val_loss: 24.2334\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6620 - val_loss: 24.2159\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6828 - val_loss: 24.2053\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6415 - val_loss: 24.1406\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6369 - val_loss: 24.1525\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6187 - val_loss: 24.1301\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.5948 - val_loss: 24.1487\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.5753 - val_loss: 24.0735\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5660 - val_loss: 24.0686\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.5735 - val_loss: 24.0462\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.5719 - val_loss: 24.0622\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5246 - val_loss: 24.1040\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5468 - val_loss: 24.0095\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5137 - val_loss: 23.9598\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5020 - val_loss: 23.9803\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.5015 - val_loss: 23.9750\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4726 - val_loss: 23.9787\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.4698 - val_loss: 23.9204\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.4726 - val_loss: 23.9163\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.4445 - val_loss: 23.9037\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4304 - val_loss: 23.9022\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4448 - val_loss: 23.9178\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.4192 - val_loss: 23.8490\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.4549 - val_loss: 23.8600\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.4050 - val_loss: 23.8352\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3924 - val_loss: 23.8268\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.3583 - val_loss: 23.8450\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3897 - val_loss: 23.8213\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.3461 - val_loss: 23.8039\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3286 - val_loss: 23.7757\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.3250 - val_loss: 23.7785\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.3638 - val_loss: 23.7489\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.3313 - val_loss: 23.7683\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.2919 - val_loss: 23.7113\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.2843 - val_loss: 23.7404\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.2907 - val_loss: 23.7095\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2912 - val_loss: 23.6667\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.2667 - val_loss: 23.6546\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2680 - val_loss: 23.6683\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2707 - val_loss: 23.6288\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.2787 - val_loss: 23.6174\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.2233 - val_loss: 23.6428\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2035 - val_loss: 23.6104\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2087 - val_loss: 23.5779\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1838 - val_loss: 23.5604\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.1664 - val_loss: 23.6295\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.2435 - val_loss: 23.5478\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1585 - val_loss: 23.6134\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.1460 - val_loss: 23.5009\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.1467 - val_loss: 23.4725\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.1228 - val_loss: 23.4824\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.1209 - val_loss: 23.4951\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.1075 - val_loss: 23.4749\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.0951 - val_loss: 23.4591\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1043 - val_loss: 23.4316\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.0994 - val_loss: 23.4921\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.0695 - val_loss: 23.4119\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0547 - val_loss: 23.4106\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0492 - val_loss: 23.3923\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.0608 - val_loss: 23.3833\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0320 - val_loss: 23.3480\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0206 - val_loss: 23.3591\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.0037 - val_loss: 23.3289\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0053 - val_loss: 23.3311\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0110 - val_loss: 23.3210\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9793 - val_loss: 23.2928\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9748 - val_loss: 23.2678\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9716 - val_loss: 23.2859\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9573 - val_loss: 23.2398\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.9551 - val_loss: 23.2536\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.9422 - val_loss: 23.2272\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.9243 - val_loss: 23.2275\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9384 - val_loss: 23.2385\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9239 - val_loss: 23.2326\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.8973 - val_loss: 23.1609\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8889 - val_loss: 23.1436\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.8721 - val_loss: 23.1386\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.8574 - val_loss: 23.1148\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.8534 - val_loss: 23.1299\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.8533 - val_loss: 23.1437\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 17.8414 - val_loss: 23.1266\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.8230 - val_loss: 23.0795\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.8180 - val_loss: 23.0705\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.8080 - val_loss: 23.0440\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.7924 - val_loss: 23.0217\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.7842 - val_loss: 23.0258\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.7760 - val_loss: 23.0056\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.7444 - val_loss: 22.9974\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.7909 - val_loss: 23.0020\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.7517 - val_loss: 22.9265\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 17.7168 - val_loss: 22.9541\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.7168 - val_loss: 22.9101\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.7122 - val_loss: 22.9437\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.6826 - val_loss: 22.8673\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 17.6840 - val_loss: 22.8880\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 17.6737 - val_loss: 22.8622\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6783 - val_loss: 22.8194\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.6393 - val_loss: 22.8230\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.6406 - val_loss: 22.8060\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6324 - val_loss: 22.7407\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6290 - val_loss: 22.7855\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5934 - val_loss: 22.7165\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.5712 - val_loss: 22.7424\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.5966 - val_loss: 22.6648\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.5821 - val_loss: 22.6585\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.5574 - val_loss: 22.6827\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.5439 - val_loss: 22.6409\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5280 - val_loss: 22.6265\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4976 - val_loss: 22.6211\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.4903 - val_loss: 22.5971\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.4776 - val_loss: 22.5784\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 17.4751 - val_loss: 22.5827\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.4610 - val_loss: 22.5330\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.4541 - val_loss: 22.5482\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4523 - val_loss: 22.4811\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.4265 - val_loss: 22.5138\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.4379 - val_loss: 22.4495\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3988 - val_loss: 22.4830\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.4002 - val_loss: 22.3803\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 17.3652 - val_loss: 22.4181\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.3565 - val_loss: 22.4088\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.3603 - val_loss: 22.3450\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.3417 - val_loss: 22.2940\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.3323 - val_loss: 22.2975\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2982 - val_loss: 22.3167\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2976 - val_loss: 22.2631\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2693 - val_loss: 22.2787\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2583 - val_loss: 22.2461\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.2351 - val_loss: 22.2060\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.2267 - val_loss: 22.1897\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.2190 - val_loss: 22.1559\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.2225 - val_loss: 22.1628\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.2167 - val_loss: 22.1204\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.1916 - val_loss: 22.0662\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.1512 - val_loss: 22.0744\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1637 - val_loss: 22.0712\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.1417 - val_loss: 22.0376\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.1283 - val_loss: 22.0267\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1018 - val_loss: 21.9747\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.1017 - val_loss: 21.9531\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.0927 - val_loss: 21.9240\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0527 - val_loss: 21.8992\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0420 - val_loss: 21.9059\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.0257 - val_loss: 21.8822\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.0079 - val_loss: 21.8416\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.9950 - val_loss: 21.8238\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9871 - val_loss: 21.8054\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.9684 - val_loss: 21.7386\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.9525 - val_loss: 21.7395\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9635 - val_loss: 21.7268\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9574 - val_loss: 21.6952\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9097 - val_loss: 21.6613\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9134 - val_loss: 21.6534\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.8833 - val_loss: 21.6090\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.8745 - val_loss: 21.5992\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.8507 - val_loss: 21.5649\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8401 - val_loss: 21.5450\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.8080 - val_loss: 21.5034\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8086 - val_loss: 21.5191\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.7851 - val_loss: 21.4946\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.7645 - val_loss: 21.4536\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7682 - val_loss: 21.4454\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7336 - val_loss: 21.3715\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7352 - val_loss: 21.3436\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7007 - val_loss: 21.3534\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.6836 - val_loss: 21.3445\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6829 - val_loss: 21.2698\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6448 - val_loss: 21.2658\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6292 - val_loss: 21.2115\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6139 - val_loss: 21.1809\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.5985 - val_loss: 21.1668\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5706 - val_loss: 21.1737\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.5730 - val_loss: 21.1125\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5490 - val_loss: 21.1186\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5298 - val_loss: 21.0653\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.5188 - val_loss: 21.0251\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4999 - val_loss: 21.0049\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.4924 - val_loss: 20.9882\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4581 - val_loss: 20.9624\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4406 - val_loss: 20.9234\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.4356 - val_loss: 20.8816\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.4129 - val_loss: 20.8318\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.3861 - val_loss: 20.8035\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3714 - val_loss: 20.8122\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.3514 - val_loss: 20.7891\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3486 - val_loss: 20.8239\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3236 - val_loss: 20.7123\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2921 - val_loss: 20.6982\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2811 - val_loss: 20.6679\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2832 - val_loss: 20.6279\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2537 - val_loss: 20.6201\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.2214 - val_loss: 20.5515\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2001 - val_loss: 20.5424\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.1830 - val_loss: 20.5227\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.1641 - val_loss: 20.4881\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.1502 - val_loss: 20.4422\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1259 - val_loss: 20.4382\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.1192 - val_loss: 20.3984\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0931 - val_loss: 20.3684\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 16.0774 - val_loss: 20.3829\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0637 - val_loss: 20.2813\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0399 - val_loss: 20.2970\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.0226 - val_loss: 20.2544\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.9923 - val_loss: 20.2121\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.9879 - val_loss: 20.1919\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.9629 - val_loss: 20.2170\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.9428 - val_loss: 20.1157\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.9155 - val_loss: 20.0834\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.8989 - val_loss: 20.0600\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8789 - val_loss: 20.0384\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8768 - val_loss: 20.0592\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.8696 - val_loss: 19.9352\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8309 - val_loss: 19.9825\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.8299 - val_loss: 19.9020\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7836 - val_loss: 19.9140\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7636 - val_loss: 19.8770\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7472 - val_loss: 19.8255\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7259 - val_loss: 19.7861\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7185 - val_loss: 19.7686\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.6905 - val_loss: 19.7236\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6673 - val_loss: 19.6960\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6606 - val_loss: 19.6687\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6329 - val_loss: 19.6379\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6046 - val_loss: 19.6351\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5954 - val_loss: 19.5931\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.5665 - val_loss: 19.5710\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5601 - val_loss: 19.5153\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5517 - val_loss: 19.5470\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5100 - val_loss: 19.4497\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4979 - val_loss: 19.4426\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4750 - val_loss: 19.4369\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4541 - val_loss: 19.3859\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4473 - val_loss: 19.4120\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4285 - val_loss: 19.3581\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4039 - val_loss: 19.2883\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3932 - val_loss: 19.3106\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3613 - val_loss: 19.2619\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3483 - val_loss: 19.2388\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3413 - val_loss: 19.2396\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.3194 - val_loss: 19.1547\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2846 - val_loss: 19.1089\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.2669 - val_loss: 19.1551\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2553 - val_loss: 19.1188\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2556 - val_loss: 19.0669\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2518 - val_loss: 19.0405\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1902 - val_loss: 19.0212\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1805 - val_loss: 19.0063\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1689 - val_loss: 18.9612\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1369 - val_loss: 18.9621\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1198 - val_loss: 18.9435\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1283 - val_loss: 18.9173\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0790 - val_loss: 18.8386\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0642 - val_loss: 18.8182\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0504 - val_loss: 18.8099\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0345 - val_loss: 18.7749\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0260 - val_loss: 18.7601\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0017 - val_loss: 18.7277\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9863 - val_loss: 18.7510\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9649 - val_loss: 18.6795\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9538 - val_loss: 18.6461\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9226 - val_loss: 18.6407\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.9074 - val_loss: 18.6059\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8906 - val_loss: 18.5591\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.8802 - val_loss: 18.5790\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8541 - val_loss: 18.5433\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8394 - val_loss: 18.4927\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8245 - val_loss: 18.5128\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8113 - val_loss: 18.4535\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7867 - val_loss: 18.4433\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7699 - val_loss: 18.4582\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.7618 - val_loss: 18.3715\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7322 - val_loss: 18.3988\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7184 - val_loss: 18.3460\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7074 - val_loss: 18.3592\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7000 - val_loss: 18.3251\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.6782 - val_loss: 18.2725\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6699 - val_loss: 18.2902\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.6376 - val_loss: 18.2466\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.6323 - val_loss: 18.2632\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6273 - val_loss: 18.2211\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5860 - val_loss: 18.2151\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5896 - val_loss: 18.1932\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5563 - val_loss: 18.1679\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5471 - val_loss: 18.1262\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5453 - val_loss: 18.1456\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.5248 - val_loss: 18.0701\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5059 - val_loss: 18.0637\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.4876 - val_loss: 18.0616\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4737 - val_loss: 17.9902\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4480 - val_loss: 18.0430\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.4474 - val_loss: 18.0088\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4197 - val_loss: 17.9887\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.4326 - val_loss: 17.9308\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.4130 - val_loss: 17.9551\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.3780 - val_loss: 17.8989\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.3639 - val_loss: 17.9051\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.3541 - val_loss: 17.8855\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.3348 - val_loss: 17.8870\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.3332 - val_loss: 17.8514\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.3039 - val_loss: 17.8192\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.2985 - val_loss: 17.8305\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.2813 - val_loss: 17.8024\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.2667 - val_loss: 17.7545\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.2538 - val_loss: 17.7821\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.2582 - val_loss: 17.7345\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.2319 - val_loss: 17.7587\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.2160 - val_loss: 17.7133\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.2126 - val_loss: 17.7088\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.1944 - val_loss: 17.6497\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.1671 - val_loss: 17.7040\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1507 - val_loss: 17.6266\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1414 - val_loss: 17.5981\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.1275 - val_loss: 17.6209\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.1185 - val_loss: 17.6027\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.0956 - val_loss: 17.6012\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.0872 - val_loss: 17.5787\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.0749 - val_loss: 17.5602\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.0598 - val_loss: 17.5435\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.0611 - val_loss: 17.5437\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.0288 - val_loss: 17.4848\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0194 - val_loss: 17.4866\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.0072 - val_loss: 17.4564\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.9977 - val_loss: 17.4170\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 13.9832 - val_loss: 17.4783\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.9642 - val_loss: 17.4171\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 13.9542 - val_loss: 17.4089\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.9379 - val_loss: 17.3841\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.9340 - val_loss: 17.3827\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.9184 - val_loss: 17.3704\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.9099 - val_loss: 17.3300\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 13.77 - 0s 71us/step - loss: 13.8986 - val_loss: 17.3820\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.8815 - val_loss: 17.2917\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.8673 - val_loss: 17.3046\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.8716 - val_loss: 17.3054\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.8489 - val_loss: 17.2741\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.8379 - val_loss: 17.2795\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.8151 - val_loss: 17.2255\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.8072 - val_loss: 17.2353\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.7955 - val_loss: 17.2410\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.7907 - val_loss: 17.2053\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.7662 - val_loss: 17.2046\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.7553 - val_loss: 17.1816\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.7801 - val_loss: 17.1577\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.7342 - val_loss: 17.1252\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.7252 - val_loss: 17.1280\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.7191 - val_loss: 17.1741\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.7126 - val_loss: 17.1368\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.6930 - val_loss: 17.1320\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.6841 - val_loss: 17.0673\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6738 - val_loss: 17.0647\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6667 - val_loss: 17.0902\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.6508 - val_loss: 17.0274\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.6540 - val_loss: 17.0323\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.6456 - val_loss: 17.0049\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.6351 - val_loss: 17.0375\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 13.6028 - val_loss: 16.9869\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.6004 - val_loss: 16.9815\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.5853 - val_loss: 16.9799\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.5763 - val_loss: 16.9722\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.5661 - val_loss: 16.9280\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.5496 - val_loss: 16.9630\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.5419 - val_loss: 16.9245\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5290 - val_loss: 16.9148\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.5168 - val_loss: 16.8998\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.5140 - val_loss: 16.9258\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.4888 - val_loss: 16.8790\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.4797 - val_loss: 16.8507\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.4777 - val_loss: 16.8574\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.4656 - val_loss: 16.8759\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.4598 - val_loss: 16.8299\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4402 - val_loss: 16.7982\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4340 - val_loss: 16.8294\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.4194 - val_loss: 16.8031\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.4172 - val_loss: 16.7837\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.4095 - val_loss: 16.7862\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.3884 - val_loss: 16.7651\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.3865 - val_loss: 16.7643\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.3989 - val_loss: 16.7053\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.3622 - val_loss: 16.7366\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3592 - val_loss: 16.7253\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.3454 - val_loss: 16.7000\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.3378 - val_loss: 16.7395\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.3273 - val_loss: 16.6738\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.3199 - val_loss: 16.6894\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.3115 - val_loss: 16.6698\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.3095 - val_loss: 16.6494\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.2885 - val_loss: 16.6164\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.2829 - val_loss: 16.6269\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2789 - val_loss: 16.5755\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.2698 - val_loss: 16.6310\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.2621 - val_loss: 16.5972\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.2377 - val_loss: 16.5757\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.2358 - val_loss: 16.5871\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2217 - val_loss: 16.5706\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2237 - val_loss: 16.5455\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.2144 - val_loss: 16.5680\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.2170 - val_loss: 16.5649\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.1821 - val_loss: 16.5069\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.1755 - val_loss: 16.4943\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.1658 - val_loss: 16.4921\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1597 - val_loss: 16.4854\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.1552 - val_loss: 16.5324\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.1428 - val_loss: 16.4928\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1380 - val_loss: 16.4974\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1267 - val_loss: 16.4270\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 13.1213 - val_loss: 16.4724\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.1132 - val_loss: 16.4185\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.1033 - val_loss: 16.4725\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.0953 - val_loss: 16.4091\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 13.0879 - val_loss: 16.3781\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.0742 - val_loss: 16.4091\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0721 - val_loss: 16.3573\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 13.0678 - val_loss: 16.3945\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0524 - val_loss: 16.3592\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 13.0492 - val_loss: 16.3784\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 13.0271 - val_loss: 16.3505\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 13.0244 - val_loss: 16.3488\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 13.0233 - val_loss: 16.2952\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.0217 - val_loss: 16.3331\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.9976 - val_loss: 16.2989\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 13.0005 - val_loss: 16.2868\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.9969 - val_loss: 16.3382\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.9719 - val_loss: 16.3091\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.9746 - val_loss: 16.2386\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9648 - val_loss: 16.2770\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.9580 - val_loss: 16.2357\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.9479 - val_loss: 16.2812\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.9393 - val_loss: 16.2201\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9256 - val_loss: 16.2793\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.9196 - val_loss: 16.2477\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.9142 - val_loss: 16.1931\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.9018 - val_loss: 16.2106\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.9097 - val_loss: 16.2003\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8951 - val_loss: 16.2260\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8921 - val_loss: 16.1675\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8830 - val_loss: 16.1428\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8691 - val_loss: 16.1718\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.8620 - val_loss: 16.1483\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.8749 - val_loss: 16.1605\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8460 - val_loss: 16.1085\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8499 - val_loss: 16.1215\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.8306 - val_loss: 16.0967\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.8249 - val_loss: 16.0994\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8257 - val_loss: 16.1012\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.8087 - val_loss: 16.0628\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.8029 - val_loss: 16.0630\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.8062 - val_loss: 16.0734\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7983 - val_loss: 16.0663\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.7772 - val_loss: 16.1008\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7756 - val_loss: 16.0278\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.7646 - val_loss: 16.0411\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7565 - val_loss: 16.0251\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7516 - val_loss: 16.0189\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.7491 - val_loss: 16.0265\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7455 - val_loss: 15.9802\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7221 - val_loss: 16.0383\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.7204 - val_loss: 16.0251\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7290 - val_loss: 15.9985\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.7146 - val_loss: 15.9775\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.7118 - val_loss: 15.9789\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6945 - val_loss: 15.9991\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.7051 - val_loss: 15.9885\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.6842 - val_loss: 15.9400\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6793 - val_loss: 15.9121\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.6713 - val_loss: 15.9222\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6554 - val_loss: 15.9004\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6606 - val_loss: 15.9238\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6545 - val_loss: 15.9076\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.6583 - val_loss: 15.8795\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.6375 - val_loss: 15.8724\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.6374 - val_loss: 15.8897\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6326 - val_loss: 15.8869\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.6209 - val_loss: 15.9053\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.6162 - val_loss: 15.8774\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.6174 - val_loss: 15.8603\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.6048 - val_loss: 15.8515\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.5911 - val_loss: 15.8481\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5867 - val_loss: 15.8542\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5800 - val_loss: 15.8230\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5794 - val_loss: 15.8167\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5688 - val_loss: 15.8051\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.5820 - val_loss: 15.8326\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5485 - val_loss: 15.7799\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.5626 - val_loss: 15.7821\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.5380 - val_loss: 15.7794\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5365 - val_loss: 15.7977\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.5253 - val_loss: 15.7572\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.5244 - val_loss: 15.7686\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.5126 - val_loss: 15.7476\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.5224 - val_loss: 15.7786\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.5222 - val_loss: 15.7521\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.4998 - val_loss: 15.6875\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.4968 - val_loss: 15.7236\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.4918 - val_loss: 15.7253\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.4947 - val_loss: 15.7239\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.4714 - val_loss: 15.6887\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4749 - val_loss: 15.7115\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.4723 - val_loss: 15.6857\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.4579 - val_loss: 15.6815\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.4552 - val_loss: 15.6767\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.4441 - val_loss: 15.6745\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.4435 - val_loss: 15.6471\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.4526 - val_loss: 15.7216\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.4392 - val_loss: 15.6251\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.4262 - val_loss: 15.6730\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.4279 - val_loss: 15.6095\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.4232 - val_loss: 15.6379\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.4256 - val_loss: 15.6204\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.4383 - val_loss: 15.5732\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.4055 - val_loss: 15.6492\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.4039 - val_loss: 15.6009\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.3858 - val_loss: 15.5745\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.3911 - val_loss: 15.5840\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.3735 - val_loss: 15.5761\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.3851 - val_loss: 15.5742\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.3643 - val_loss: 15.5979\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.3736 - val_loss: 15.5646\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.3525 - val_loss: 15.5692\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.3592 - val_loss: 15.5592\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.3442 - val_loss: 15.5456\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.3406 - val_loss: 15.5627\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.3343 - val_loss: 15.5534\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.3276 - val_loss: 15.5170\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.3261 - val_loss: 15.5268\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 12.3201 - val_loss: 15.5110\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.3283 - val_loss: 15.4387\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.3192 - val_loss: 15.5189\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.3047 - val_loss: 15.4752\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.2940 - val_loss: 15.5147\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.2926 - val_loss: 15.4997\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.2884 - val_loss: 15.4962\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.2813 - val_loss: 15.4462\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.2831 - val_loss: 15.4788\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.2680 - val_loss: 15.4459\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.2712 - val_loss: 15.4465\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.2653 - val_loss: 15.4490\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.2570 - val_loss: 15.4353\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.2525 - val_loss: 15.4412\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.2458 - val_loss: 15.4255\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.2418 - val_loss: 15.4525\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.2411 - val_loss: 15.4311\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.2287 - val_loss: 15.4099\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.2305 - val_loss: 15.4158\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.2209 - val_loss: 15.3763\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.2227 - val_loss: 15.3840\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.2211 - val_loss: 15.3787\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 12.2082 - val_loss: 15.3756\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1957 - val_loss: 15.3605\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.1998 - val_loss: 15.3567\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.1971 - val_loss: 15.3637\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1982 - val_loss: 15.3845\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.1915 - val_loss: 15.3100\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.1821 - val_loss: 15.3670\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.1744 - val_loss: 15.3550\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.1747 - val_loss: 15.3260\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.1672 - val_loss: 15.3273\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 12.1562 - val_loss: 15.3317\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.1704 - val_loss: 15.3446\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1559 - val_loss: 15.3097\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.1572 - val_loss: 15.2875\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.1583 - val_loss: 15.3127\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1461 - val_loss: 15.3145\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 12.1698 - val_loss: 15.2798\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1307 - val_loss: 15.2450\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1238 - val_loss: 15.2803\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.1230 - val_loss: 15.2801\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.1220 - val_loss: 15.2393\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.1137 - val_loss: 15.2687\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.1159 - val_loss: 15.2832\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.1311 - val_loss: 15.2213\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0998 - val_loss: 15.2950\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0971 - val_loss: 15.2343\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0861 - val_loss: 15.2330\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.0840 - val_loss: 15.2254\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.0776 - val_loss: 15.2101\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.0751 - val_loss: 15.2213\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0787 - val_loss: 15.2490\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0673 - val_loss: 15.1944\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0625 - val_loss: 15.2162\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.0548 - val_loss: 15.2245\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 12.0559 - val_loss: 15.1898\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 12.0636 - val_loss: 15.2464\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.0572 - val_loss: 15.1549\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 12.0441 - val_loss: 15.1715\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0369 - val_loss: 15.1896\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.0433 - val_loss: 15.1997\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0339 - val_loss: 15.1753\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0258 - val_loss: 15.1444\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.0223 - val_loss: 15.1481\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0167 - val_loss: 15.1380\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 12.0162 - val_loss: 15.1514\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 12.0151 - val_loss: 15.1196\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.0021 - val_loss: 15.1416\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0045 - val_loss: 15.1477\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 12.0023 - val_loss: 15.1244\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9988 - val_loss: 15.0849\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9911 - val_loss: 15.1341\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.9978 - val_loss: 15.0989\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9854 - val_loss: 15.1361\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.9737 - val_loss: 15.0986\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9906 - val_loss: 15.0700\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.9744 - val_loss: 15.1082\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.9712 - val_loss: 15.1212\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.9689 - val_loss: 15.0500\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.9777 - val_loss: 15.0399\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9657 - val_loss: 15.0778\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.9548 - val_loss: 15.0890\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9529 - val_loss: 15.0260\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.9422 - val_loss: 15.0385\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.9338 - val_loss: 15.0682\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9371 - val_loss: 15.0796\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.9481 - val_loss: 15.0297\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9396 - val_loss: 15.0422\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.9383 - val_loss: 14.9875\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9190 - val_loss: 15.0241\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.9277 - val_loss: 15.0743\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.9147 - val_loss: 15.0193\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.9131 - val_loss: 15.0120\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8998 - val_loss: 14.9986\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.9032 - val_loss: 15.0035\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.9007 - val_loss: 14.9855\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.8966 - val_loss: 14.9670\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8944 - val_loss: 14.9720\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.8943 - val_loss: 15.0051\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8854 - val_loss: 14.9418\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8824 - val_loss: 14.9921\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.8870 - val_loss: 14.9507\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8762 - val_loss: 14.9848\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8672 - val_loss: 14.9718\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.8618 - val_loss: 14.9660\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8674 - val_loss: 14.9587\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.8703 - val_loss: 14.9327\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8571 - val_loss: 14.9343\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.8630 - val_loss: 14.9475\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8549 - val_loss: 14.9050\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8409 - val_loss: 14.9526\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8515 - val_loss: 14.9198\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8538 - val_loss: 14.9401\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8396 - val_loss: 14.9189\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8345 - val_loss: 14.9109\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8232 - val_loss: 14.9203\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8235 - val_loss: 14.9208\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8218 - val_loss: 14.8884\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.8179 - val_loss: 14.8965\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8356 - val_loss: 14.8689\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8217 - val_loss: 14.8410\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.8073 - val_loss: 14.9175\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8021 - val_loss: 14.8721\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.8010 - val_loss: 14.8823\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.8084 - val_loss: 14.8869\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.7926 - val_loss: 14.8508\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.7923 - val_loss: 14.8642\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.8126 - val_loss: 14.8755\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.7820 - val_loss: 14.8083\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.7855 - val_loss: 14.8326\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7811 - val_loss: 14.8467\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.7775 - val_loss: 14.8329\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7736 - val_loss: 14.8359\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.7653 - val_loss: 14.8165\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7662 - val_loss: 14.8174\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.7657 - val_loss: 14.7968\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.7637 - val_loss: 14.8520\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7749 - val_loss: 14.8071\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7520 - val_loss: 14.8350\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.7499 - val_loss: 14.8160\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.7463 - val_loss: 14.7748\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.7565 - val_loss: 14.8012\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7432 - val_loss: 14.7872\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7548 - val_loss: 14.7982\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7385 - val_loss: 14.7423\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.7289 - val_loss: 14.7788\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.7296 - val_loss: 14.7482\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.7272 - val_loss: 14.7882\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7282 - val_loss: 14.7555\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7199 - val_loss: 14.7773\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.7248 - val_loss: 14.7840\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.7234 - val_loss: 14.7504\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7113 - val_loss: 14.7288\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.7136 - val_loss: 14.7496\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.7112 - val_loss: 14.7361\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.6980 - val_loss: 14.7428\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.6972 - val_loss: 14.7169\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.7024 - val_loss: 14.7224\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6928 - val_loss: 14.7104\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6960 - val_loss: 14.7537\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.6861 - val_loss: 14.7083\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6811 - val_loss: 14.7361\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6826 - val_loss: 14.7081\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6762 - val_loss: 14.6904\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6822 - val_loss: 14.7038\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6727 - val_loss: 14.6822\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6746 - val_loss: 14.6913\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6719 - val_loss: 14.6761\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6673 - val_loss: 14.6802\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.6671 - val_loss: 14.7227\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.6569 - val_loss: 14.6851\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6616 - val_loss: 14.6709\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.6606 - val_loss: 14.6577\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6486 - val_loss: 14.7028\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6442 - val_loss: 14.6631\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6480 - val_loss: 14.6623\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6450 - val_loss: 14.6701\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.6487 - val_loss: 14.6527\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6433 - val_loss: 14.6359\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.6357 - val_loss: 14.6387\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6290 - val_loss: 14.6769\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.6245 - val_loss: 14.6374\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6233 - val_loss: 14.6332\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.6238 - val_loss: 14.6171\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.6287 - val_loss: 14.6186\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6142 - val_loss: 14.6300\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6140 - val_loss: 14.6004\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6167 - val_loss: 14.6388\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.6171 - val_loss: 14.6181\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.6022 - val_loss: 14.6134\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.6134 - val_loss: 14.5950\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.6104 - val_loss: 14.5801\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.6021 - val_loss: 14.6399\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.5996 - val_loss: 14.5840\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5949 - val_loss: 14.5745\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.6111 - val_loss: 14.5842\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5862 - val_loss: 14.6132\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5918 - val_loss: 14.5936\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5825 - val_loss: 14.5770\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5900 - val_loss: 14.5718\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5794 - val_loss: 14.5696\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5810 - val_loss: 14.5947\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5682 - val_loss: 14.5674\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5804 - val_loss: 14.5282\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5816 - val_loss: 14.5689\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5751 - val_loss: 14.5390\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5658 - val_loss: 14.5159\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5625 - val_loss: 14.5422\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5662 - val_loss: 14.5787\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.5608 - val_loss: 14.5612\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.5545 - val_loss: 14.5335\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.5511 - val_loss: 14.5625\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5554 - val_loss: 14.5092\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5601 - val_loss: 14.5411\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.5522 - val_loss: 14.5074\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5471 - val_loss: 14.5046\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.5431 - val_loss: 14.5477\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5359 - val_loss: 14.4996\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5345 - val_loss: 14.4997\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.5347 - val_loss: 14.4999\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5345 - val_loss: 14.5059\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5276 - val_loss: 14.5176\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5324 - val_loss: 14.5095\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5311 - val_loss: 14.4499\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.5199 - val_loss: 14.5248\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.5248 - val_loss: 14.5040\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5171 - val_loss: 14.4597\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5142 - val_loss: 14.4641\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5147 - val_loss: 14.4743\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.5126 - val_loss: 14.5041\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5068 - val_loss: 14.4784\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5096 - val_loss: 14.4628\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.5015 - val_loss: 14.4504\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4962 - val_loss: 14.4367\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4988 - val_loss: 14.4460\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.5052 - val_loss: 14.4619\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4994 - val_loss: 14.4725\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.5114 - val_loss: 14.4366\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4866 - val_loss: 14.4461\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.4997 - val_loss: 14.4690\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.5025 - val_loss: 14.4490\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4952 - val_loss: 14.4676\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4792 - val_loss: 14.4161\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.4744 - val_loss: 14.4197\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4789 - val_loss: 14.3815\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4770 - val_loss: 14.4178\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4704 - val_loss: 14.4701\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4766 - val_loss: 14.4091\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.4812 - val_loss: 14.4320\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4682 - val_loss: 14.4252\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.4642 - val_loss: 14.3959\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4668 - val_loss: 14.4336\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.4616 - val_loss: 14.4041\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.4522 - val_loss: 14.3682\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4566 - val_loss: 14.3862\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.4591 - val_loss: 14.4249\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4503 - val_loss: 14.3865\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.4468 - val_loss: 14.3950\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4514 - val_loss: 14.3655\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4459 - val_loss: 14.3996\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4432 - val_loss: 14.3886\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.4402 - val_loss: 14.3612\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4400 - val_loss: 14.4251\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 11.4333 - val_loss: 14.3813\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4351 - val_loss: 14.3678\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4368 - val_loss: 14.3755\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4355 - val_loss: 14.3627\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4227 - val_loss: 14.3575\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4281 - val_loss: 14.3468\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.4163 - val_loss: 14.3642\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.4179 - val_loss: 14.3674\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.4340 - val_loss: 14.3902\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4151 - val_loss: 14.3438\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4189 - val_loss: 14.3200\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4140 - val_loss: 14.3342\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.4113 - val_loss: 14.3393\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 11.4106 - val_loss: 14.3408\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4137 - val_loss: 14.3098\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.4360 - val_loss: 14.3684\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.4189 - val_loss: 14.2988\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.4048 - val_loss: 14.3583\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.4000 - val_loss: 14.3142\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3890 - val_loss: 14.3020\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.4022 - val_loss: 14.2821\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.3891 - val_loss: 14.3366\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3888 - val_loss: 14.3407\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3959 - val_loss: 14.3135\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3974 - val_loss: 14.3027\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3825 - val_loss: 14.2982\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.3931 - val_loss: 14.3197\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.3799 - val_loss: 14.2936\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3805 - val_loss: 14.2815\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3820 - val_loss: 14.2675\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.3720 - val_loss: 14.3029\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3713 - val_loss: 14.3030\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3765 - val_loss: 14.2560\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3760 - val_loss: 14.3225\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3603 - val_loss: 14.2697\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.3666 - val_loss: 14.2531\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.3593 - val_loss: 14.2687\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.3636 - val_loss: 14.2819\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3648 - val_loss: 14.2851\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.3549 - val_loss: 14.2700\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3764 - val_loss: 14.2471\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 11.3559 - val_loss: 14.2815\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.3576 - val_loss: 14.2596\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3483 - val_loss: 14.2664\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.3573 - val_loss: 14.2536\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3513 - val_loss: 14.2662\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 57us/step - loss: 11.3456 - val_loss: 14.2297\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3451 - val_loss: 14.2167\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 11.3462 - val_loss: 14.2572\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3394 - val_loss: 14.2394\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.3409 - val_loss: 14.2621\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.3410 - val_loss: 14.2476\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.3341 - val_loss: 14.2358\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.3378 - val_loss: 14.2402\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3413 - val_loss: 14.2631\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3352 - val_loss: 14.2122\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3265 - val_loss: 14.1743\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3378 - val_loss: 14.1728\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3242 - val_loss: 14.2040\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3195 - val_loss: 14.2220\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3221 - val_loss: 14.2256\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3232 - val_loss: 14.2047\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3224 - val_loss: 14.2536\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3507 - val_loss: 14.2438\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3331 - val_loss: 14.1683\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.3335 - val_loss: 14.1969\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.3157 - val_loss: 14.2370\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3160 - val_loss: 14.2119\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.3140 - val_loss: 14.1781\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.3199 - val_loss: 14.2092\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3032 - val_loss: 14.2112\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3042 - val_loss: 14.1686\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 11.3001 - val_loss: 14.1955\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2959 - val_loss: 14.1879\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 11.3040 - val_loss: 14.1571\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.2874 - val_loss: 14.1911\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.2957 - val_loss: 14.1947\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.3019 - val_loss: 14.1644\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 11.2905 - val_loss: 14.1710\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.3012 - val_loss: 14.1464\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2962 - val_loss: 14.1886\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 11.2945 - val_loss: 14.1575\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2840 - val_loss: 14.1815\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2807 - val_loss: 14.1825\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 11.2784 - val_loss: 14.1344\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 11.2813 - val_loss: 14.1273\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2796 - val_loss: 14.1837\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2796 - val_loss: 14.1222\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2783 - val_loss: 14.1219\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2810 - val_loss: 14.1512\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 11.2738 - val_loss: 14.1464\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 11.2751 - val_loss: 14.1640\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 11.2747 - val_loss: 14.1221\n",
      "11.340037878899448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.6749653 ,  0.13568047,  0.987561  , -0.24620768,  0.1797436 ],\n",
       "        [-0.0511227 ,  0.21228284,  0.13723049, -0.11128951,  0.57686746],\n",
       "        [-0.38297492,  0.04553554,  0.6447571 , -0.16911775,  1.2377775 ],\n",
       "        [ 0.17827928,  0.08998913, -0.04293243,  0.31685758, -0.06332519],\n",
       "        [-0.30634502,  0.10743946,  0.3026511 , -0.19925404, -0.01468669]],\n",
       "       dtype=float32),\n",
       " array([-0.19855885, -1.8309008 ,  1.7523012 ,  1.8597533 ,  0.95310223],\n",
       "       dtype=float32),\n",
       " array([[ 0.10663555, -0.1547233 ,  0.9346577 , -0.43066826,  0.64625335,\n",
       "          0.09651201, -0.04987983,  0.04926179, -0.9887888 , -0.5506319 ],\n",
       "        [-1.0193207 , -1.5007395 , -1.5694028 , -0.00820394, -0.99245936,\n",
       "         -1.5969888 , -0.5979531 , -0.17724748,  1.8640554 ,  0.14391185],\n",
       "        [ 0.75803477,  1.5500326 ,  1.3832507 , -0.14690562,  0.21260327,\n",
       "          1.8946211 ,  1.1575102 , -0.30698153, -1.0721582 ,  0.19947913],\n",
       "        [ 0.04396914,  0.612629  ,  1.735404  ,  0.12304179,  0.20039381,\n",
       "          1.2292782 ,  1.6725601 , -1.0309896 , -1.6385596 ,  0.6010401 ],\n",
       "        [-0.14828357, -0.7036754 , -0.627604  , -0.1675388 , -0.6520927 ,\n",
       "         -0.0175405 , -0.25703987, -0.46959332,  0.6662171 , -0.08397543]],\n",
       "       dtype=float32),\n",
       " array([ 0.78804153,  2.0741205 ,  3.130815  , -0.4025475 ,  1.0363202 ,\n",
       "         2.6869557 ,  2.312644  , -0.953222  , -2.8164809 , -0.0989319 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.3064369 ],\n",
       "        [ 2.9718652 ],\n",
       "        [ 4.23928   ],\n",
       "        [-0.327257  ],\n",
       "        [ 1.4392515 ],\n",
       "        [ 3.770759  ],\n",
       "        [ 3.0008492 ],\n",
       "        [-1.0650258 ],\n",
       "        [-3.9816606 ],\n",
       "        [ 0.12606955]], dtype=float32),\n",
       " array([2.3820567], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, sgd, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sgd_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 181us/step - loss: 14484.5660 - val_loss: 12538.8120\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9289.9118 - val_loss: 5759.0215\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 3027.9904 - val_loss: 895.4889\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 243.3709 - val_loss: 29.5742\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9679 - val_loss: 26.7012\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.5230 - val_loss: 27.9152\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.4754 - val_loss: 32.4048\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.0613 - val_loss: 25.8388\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8150 - val_loss: 27.5223\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.6541 - val_loss: 28.3096\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.1618 - val_loss: 27.4321\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.8062 - val_loss: 26.3977\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.0737 - val_loss: 26.8066\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.7479 - val_loss: 27.8143\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 23.5134 - val_loss: 27.2699\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 23.3297 - val_loss: 25.8060\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.6814 - val_loss: 29.4786\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 23.8700 - val_loss: 39.5903\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.9916 - val_loss: 26.0385\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6162 - val_loss: 32.7197\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.5164 - val_loss: 26.3445\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 23.2889 - val_loss: 27.0199\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.1879 - val_loss: 29.7313\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.6294 - val_loss: 25.4343\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.7426 - val_loss: 25.1814\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5646 - val_loss: 27.2152\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.3344 - val_loss: 29.7350\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.8437 - val_loss: 25.1000\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3450 - val_loss: 28.3673\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.3831 - val_loss: 26.6802\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.6788 - val_loss: 26.7680\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5834 - val_loss: 26.5327\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.9978 - val_loss: 29.4764\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.5647 - val_loss: 26.1035\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.4249 - val_loss: 27.4959\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2531 - val_loss: 28.2593\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7924 - val_loss: 26.8317\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.9045 - val_loss: 26.6949\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.4119 - val_loss: 26.6661\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.7021 - val_loss: 34.6545\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.9170 - val_loss: 27.0065\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.4419 - val_loss: 26.0657\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4457 - val_loss: 27.5601\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.5172 - val_loss: 25.1666\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.3221 - val_loss: 25.4019\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.5201 - val_loss: 36.3232\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 23.2903 - val_loss: 25.9690\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.8689 - val_loss: 33.6845\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 24.0289 - val_loss: 25.9560\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.1236 - val_loss: 28.4977\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.6951 - val_loss: 28.1859\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.2213 - val_loss: 35.1579\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.0653 - val_loss: 25.8964\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.7665 - val_loss: 26.6851\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.5414 - val_loss: 25.6252\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.3509 - val_loss: 25.7304\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7661 - val_loss: 28.1149\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.4680 - val_loss: 26.0370\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.8600 - val_loss: 28.1352\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.1061 - val_loss: 25.0417\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1200 - val_loss: 29.5649\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.5365 - val_loss: 26.8675\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.8953 - val_loss: 25.3930\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.2799 - val_loss: 26.3379\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.5465 - val_loss: 25.5026\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.8463 - val_loss: 25.3231\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.0920 - val_loss: 28.0292\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.7194 - val_loss: 26.8861\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1872 - val_loss: 25.2917\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.0823 - val_loss: 29.0217\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.2337 - val_loss: 27.6560\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.9855 - val_loss: 26.9395\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.4469 - val_loss: 27.0372\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.8334 - val_loss: 29.1998\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.5689 - val_loss: 26.9401\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.0087 - val_loss: 26.9707\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.8538 - val_loss: 34.7214\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.3069 - val_loss: 25.9423\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.9505 - val_loss: 25.9425\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.3155 - val_loss: 25.2973\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0671 - val_loss: 25.4171\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 23.0331 - val_loss: 26.9059\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.3911 - val_loss: 27.7929\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.4468 - val_loss: 28.2748\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.2575 - val_loss: 28.0845\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1684 - val_loss: 25.2042\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.2992 - val_loss: 25.0351\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.9546 - val_loss: 26.9169\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.8543 - val_loss: 25.1984\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.8513 - val_loss: 25.1666\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.7528 - val_loss: 28.0871\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.9554 - val_loss: 29.9711\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.2129 - val_loss: 26.0657\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.9723 - val_loss: 25.3864\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.0899 - val_loss: 24.9423\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 22.0088 - val_loss: 24.9472\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.5626 - val_loss: 25.3434\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 20.8521 - val_loss: 32.3920\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2036 - val_loss: 25.3633\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 20.3719 - val_loss: 26.9435\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 20.9131 - val_loss: 26.5149\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.4261 - val_loss: 25.0621\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.6587 - val_loss: 26.5869\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.8237 - val_loss: 24.2480\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 20.0796 - val_loss: 23.4020\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 19.6848 - val_loss: 23.3631\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.3197 - val_loss: 22.7760\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.7381 - val_loss: 24.4734\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.3224 - val_loss: 21.9458\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 19.2213 - val_loss: 23.2235\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.6040 - val_loss: 23.6186\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.2943 - val_loss: 29.9161\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 18.4802 - val_loss: 24.2721\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.8609 - val_loss: 20.6455\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.6788 - val_loss: 24.6432\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.5211 - val_loss: 21.4603\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 18.3655 - val_loss: 22.3344\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.9976 - val_loss: 20.4499\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.7713 - val_loss: 19.2678\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.3887 - val_loss: 19.6862\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.4373 - val_loss: 18.7900\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 17.3917 - val_loss: 25.3020\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.7177 - val_loss: 20.1468\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.7614 - val_loss: 18.7119\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.8477 - val_loss: 19.7677\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.1123 - val_loss: 19.1069\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.8010 - val_loss: 19.8129\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.1852 - val_loss: 19.6477\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.4177 - val_loss: 19.0824\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2566 - val_loss: 18.7910\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.0886 - val_loss: 18.7801\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.9387 - val_loss: 17.7347\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.4992 - val_loss: 21.5645\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.2012 - val_loss: 19.6692\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9561 - val_loss: 17.5847\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.4699 - val_loss: 18.0790\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.9880 - val_loss: 20.3793\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.1380 - val_loss: 17.7474\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.6687 - val_loss: 17.6002\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.3380 - val_loss: 17.4460\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1493 - val_loss: 17.5966\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.2492 - val_loss: 17.8183\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6564 - val_loss: 19.3042\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.2765 - val_loss: 18.0124\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.6445 - val_loss: 17.6649\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.7383 - val_loss: 19.7796\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.9238 - val_loss: 17.0887\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.8421 - val_loss: 17.8914\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.7286 - val_loss: 18.1411\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.8900 - val_loss: 17.3264\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.8903 - val_loss: 19.6500\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.7734 - val_loss: 17.8648\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.7026 - val_loss: 17.8906\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.8379 - val_loss: 20.0577\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.6262 - val_loss: 18.4412\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.6288 - val_loss: 18.8741\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.9869 - val_loss: 18.3120\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.8430 - val_loss: 16.9186\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.1088 - val_loss: 18.5238\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.3648 - val_loss: 19.2117\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.2978 - val_loss: 18.0694\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2669 - val_loss: 16.9934\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.3350 - val_loss: 17.5984\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.5063 - val_loss: 16.9032\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.0096 - val_loss: 16.3064\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.6986 - val_loss: 16.4994\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.4636 - val_loss: 16.5425\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.2648 - val_loss: 19.4080\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.9307 - val_loss: 17.7022\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9933 - val_loss: 16.3206\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.6762 - val_loss: 17.4216\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.0292 - val_loss: 17.1692\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6922 - val_loss: 18.7310\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.9261 - val_loss: 17.5395\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.4558 - val_loss: 17.9951\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.5823 - val_loss: 16.3723\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.0138 - val_loss: 18.2567\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.6055 - val_loss: 16.1355\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.6118 - val_loss: 19.7201\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.6583 - val_loss: 19.3184\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.2466 - val_loss: 19.3707\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.2139 - val_loss: 19.2409\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.1932 - val_loss: 15.7812\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.9579 - val_loss: 19.5349\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.9337 - val_loss: 17.5825\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.5594 - val_loss: 21.1167\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9536 - val_loss: 20.0924\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.1273 - val_loss: 22.5544\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.2273 - val_loss: 16.5536\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.3495 - val_loss: 16.5322\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.0366 - val_loss: 19.7526\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.1250 - val_loss: 17.4322\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.1822 - val_loss: 15.5008\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.2266 - val_loss: 18.0922\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.4377 - val_loss: 21.7713\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.9724 - val_loss: 16.1106\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.7557 - val_loss: 17.0877\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.7969 - val_loss: 16.0972\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.8572 - val_loss: 16.5374\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.4623 - val_loss: 17.1329\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.5917 - val_loss: 21.1434\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.9245 - val_loss: 17.4530\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 13.4741 - val_loss: 15.5680\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.7784 - val_loss: 15.8745\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.3987 - val_loss: 19.5243\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.8367 - val_loss: 15.5154\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 13.3772 - val_loss: 21.4883\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9691 - val_loss: 15.0813\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 13.3187 - val_loss: 14.6160\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.4888 - val_loss: 15.6235\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 13.7403 - val_loss: 15.1011\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.5334 - val_loss: 16.8144\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.0514 - val_loss: 15.6813\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.2084 - val_loss: 17.3244\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.2345 - val_loss: 22.6002\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.0438 - val_loss: 15.7502\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.0998 - val_loss: 15.9631\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.3765 - val_loss: 14.9979\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.1134 - val_loss: 14.3080\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.8482 - val_loss: 16.8124\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.0431 - val_loss: 16.4284\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 13.1266 - val_loss: 15.4340\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.7608 - val_loss: 18.2980\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.3583 - val_loss: 15.9811\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.1329 - val_loss: 19.7969\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.9159 - val_loss: 14.7705\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.2800 - val_loss: 15.3532\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.7383 - val_loss: 16.4689\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.9509 - val_loss: 15.1214\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.1337 - val_loss: 14.9387\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.3744 - val_loss: 16.4875\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3874 - val_loss: 14.4647\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.0660 - val_loss: 16.4698\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.3782 - val_loss: 15.5199\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.6040 - val_loss: 20.2608\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.4056 - val_loss: 15.1518\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9727 - val_loss: 15.1996\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.8460 - val_loss: 13.9348\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.5542 - val_loss: 15.2090\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.3871 - val_loss: 15.0450\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.7914 - val_loss: 16.7961\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.8752 - val_loss: 18.6287\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.7633 - val_loss: 17.5345\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.4233 - val_loss: 15.6994\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.3688 - val_loss: 17.9983\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 12.6444 - val_loss: 14.1377\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.4333 - val_loss: 13.7208\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.1999 - val_loss: 14.5690\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1365 - val_loss: 15.6954\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.6300 - val_loss: 19.7948\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.4922 - val_loss: 13.2554\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3049 - val_loss: 14.8789\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.3392 - val_loss: 14.3523\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 12.1685 - val_loss: 17.4515\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.8063 - val_loss: 13.9819\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.9244 - val_loss: 13.0706\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8591 - val_loss: 14.3201\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.6872 - val_loss: 15.7128\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.9238 - val_loss: 14.3048\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.5645 - val_loss: 14.4190\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5569 - val_loss: 16.8667\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.7909 - val_loss: 13.3491\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.7246 - val_loss: 14.7218\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.7383 - val_loss: 22.9255\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.2939 - val_loss: 14.6360\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.2776 - val_loss: 18.1087\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.9629 - val_loss: 14.6043\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.7951 - val_loss: 14.7591\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.2404 - val_loss: 16.3435\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3510 - val_loss: 12.1717\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9088 - val_loss: 12.6630\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4951 - val_loss: 17.5714\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4771 - val_loss: 17.0048\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.4541 - val_loss: 12.9050\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 12.1850 - val_loss: 12.2876\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.3931 - val_loss: 19.4074\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.1281 - val_loss: 13.5544\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8728 - val_loss: 13.1928\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.2354 - val_loss: 14.7818\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4867 - val_loss: 12.6498\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.1976 - val_loss: 13.7923\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3197 - val_loss: 13.3000\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.9804 - val_loss: 12.9774\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.5554 - val_loss: 13.3319\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.2859 - val_loss: 14.8237\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.9017 - val_loss: 11.9514\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.4731 - val_loss: 12.5208\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.5414 - val_loss: 18.9013\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3382 - val_loss: 13.1407\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.3761 - val_loss: 12.6014\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.5676 - val_loss: 12.2930\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0820 - val_loss: 12.2233\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.8022 - val_loss: 12.4155\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.9581 - val_loss: 12.5409\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.1293 - val_loss: 14.9197\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3623 - val_loss: 12.5810\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.9233 - val_loss: 12.6173\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.2153 - val_loss: 14.3053\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.7709 - val_loss: 13.1236\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4735 - val_loss: 12.9278\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.7769 - val_loss: 15.8125\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.8569 - val_loss: 13.4798\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.9882 - val_loss: 16.8063\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4961 - val_loss: 13.4129\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.1135 - val_loss: 14.7830\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9704 - val_loss: 12.0105\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.8367 - val_loss: 13.2920\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.7141 - val_loss: 15.1982\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.3161 - val_loss: 12.0899\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8645 - val_loss: 18.3147\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.0777 - val_loss: 14.9176\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4396 - val_loss: 13.1532\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0440 - val_loss: 11.7920\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5674 - val_loss: 16.5496\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.0572 - val_loss: 11.4480\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6415 - val_loss: 11.6982\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.7083 - val_loss: 12.2494\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6639 - val_loss: 13.0573\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.6611 - val_loss: 11.5980\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 10.4629 - val_loss: 13.4029\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3376 - val_loss: 12.7587\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.6985 - val_loss: 11.7757\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.6936 - val_loss: 13.5185\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.3091 - val_loss: 11.4390\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.4589 - val_loss: 15.7965\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.8428 - val_loss: 11.2988\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.5348 - val_loss: 13.6227\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.3367 - val_loss: 12.4939\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9631 - val_loss: 13.3714\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.8858 - val_loss: 12.8108\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.0464 - val_loss: 12.0384\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1019 - val_loss: 12.1619\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.5515 - val_loss: 13.6286\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6723 - val_loss: 12.2425\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1399 - val_loss: 11.5998\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.2278 - val_loss: 12.9571\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.3046 - val_loss: 12.4731\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1125 - val_loss: 10.9261\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.3581 - val_loss: 12.1214\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.1319 - val_loss: 11.2290\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.0324 - val_loss: 16.5578\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.0530 - val_loss: 11.6503\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 10.2228 - val_loss: 11.9595\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.2828 - val_loss: 20.1467\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.8071 - val_loss: 11.0395\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7766 - val_loss: 16.2412\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.4069 - val_loss: 11.0798\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9356 - val_loss: 11.3654\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8560 - val_loss: 11.0491\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3712 - val_loss: 11.2719\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.1284 - val_loss: 11.0213\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8333 - val_loss: 13.1287\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2003 - val_loss: 13.8772\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7071 - val_loss: 12.7616\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1965 - val_loss: 11.9335\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7364 - val_loss: 10.7466\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1410 - val_loss: 10.7860\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6079 - val_loss: 11.5583\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9376 - val_loss: 13.4317\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6646 - val_loss: 15.8225\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.2717 - val_loss: 12.4222\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6142 - val_loss: 10.5956\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5128 - val_loss: 10.8873\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6351 - val_loss: 10.3610\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.3776 - val_loss: 11.3763\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3803 - val_loss: 12.0828\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5519 - val_loss: 15.5441\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5085 - val_loss: 10.7948\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4402 - val_loss: 11.9958\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4618 - val_loss: 13.6045\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1343 - val_loss: 12.1901\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7418 - val_loss: 10.4045\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 10.1241 - val_loss: 15.5128\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6002 - val_loss: 10.8732\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.7071 - val_loss: 11.3697\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4138 - val_loss: 10.9457\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4981 - val_loss: 10.9501\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8953 - val_loss: 10.3979\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5194 - val_loss: 10.2985\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.8021 - val_loss: 10.9555\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5952 - val_loss: 10.4229\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5503 - val_loss: 13.2289\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4148 - val_loss: 11.0377\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.3094 - val_loss: 10.1862\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1832 - val_loss: 13.5604\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4987 - val_loss: 13.0239\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8459 - val_loss: 14.6259\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7414 - val_loss: 10.1457\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5391 - val_loss: 11.4883\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.9272 - val_loss: 11.3572\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4929 - val_loss: 11.3328\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6827 - val_loss: 13.2735\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5477 - val_loss: 12.7896\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3765 - val_loss: 10.4434\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3949 - val_loss: 13.9015\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.6198 - val_loss: 10.3790\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 9.1719 - val_loss: 13.8621\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 9.1208 - val_loss: 10.3025\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 9.6534 - val_loss: 10.2721\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.3747 - val_loss: 10.4891\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7973 - val_loss: 12.1354\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1579 - val_loss: 12.2736\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8975 - val_loss: 14.8200\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4000 - val_loss: 10.6569\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5699 - val_loss: 13.5579\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6710 - val_loss: 12.6134\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0650 - val_loss: 10.0018\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5099 - val_loss: 10.5351\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6479 - val_loss: 10.3157\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5393 - val_loss: 10.7469\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2841 - val_loss: 10.8567\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0390 - val_loss: 10.2189\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4335 - val_loss: 10.9965\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1295 - val_loss: 10.5252\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6011 - val_loss: 10.3709\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6880 - val_loss: 10.0369\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2386 - val_loss: 10.0755\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8081 - val_loss: 12.3497\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6284 - val_loss: 10.2943\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 9.0316 - val_loss: 11.5202\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0397 - val_loss: 12.3841\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5177 - val_loss: 10.7302\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5002 - val_loss: 10.8346\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5801 - val_loss: 12.2413\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7249 - val_loss: 12.1206\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3137 - val_loss: 11.4089\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2177 - val_loss: 11.3690\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4127 - val_loss: 11.8035\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1972 - val_loss: 15.5238\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.7666 - val_loss: 10.7449\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1203 - val_loss: 13.1653\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3351 - val_loss: 14.1479\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6903 - val_loss: 11.7179\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0840 - val_loss: 9.8466\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6730 - val_loss: 9.9330\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1801 - val_loss: 13.7930\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4689 - val_loss: 11.5616\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1614 - val_loss: 10.3388\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4583 - val_loss: 12.2608\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1458 - val_loss: 10.5750\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.3989 - val_loss: 10.5739\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1721 - val_loss: 13.5908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2824 - val_loss: 12.5245\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6001 - val_loss: 10.4321\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0197 - val_loss: 13.2248\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4752 - val_loss: 10.8805\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4402 - val_loss: 10.4458\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2449 - val_loss: 11.0128\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4559 - val_loss: 9.9040\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3174 - val_loss: 9.7115\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5205 - val_loss: 10.6587\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5573 - val_loss: 10.7236\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9414 - val_loss: 12.9547\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4595 - val_loss: 10.6489\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 9.2457 - val_loss: 9.8649\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1420 - val_loss: 12.5275\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5015 - val_loss: 11.1800\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2019 - val_loss: 11.1201\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8922 - val_loss: 12.4054\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4167 - val_loss: 12.9505\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2462 - val_loss: 10.3948\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3252 - val_loss: 10.5709\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2213 - val_loss: 17.5397\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5688 - val_loss: 9.7690\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0352 - val_loss: 10.7360\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4856 - val_loss: 10.0785\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6863 - val_loss: 10.2215\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3928 - val_loss: 11.9837\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2132 - val_loss: 10.2112\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3754 - val_loss: 13.4467\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.7816 - val_loss: 9.8852\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7113 - val_loss: 10.0402\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7796 - val_loss: 11.6850\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5289 - val_loss: 9.7455\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1975 - val_loss: 10.1259\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3466 - val_loss: 11.0159\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1269 - val_loss: 14.0620\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3615 - val_loss: 14.0623\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0331 - val_loss: 9.8606\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1597 - val_loss: 11.2460\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5587 - val_loss: 10.2203\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1697 - val_loss: 14.2337\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6033 - val_loss: 13.9536\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4680 - val_loss: 9.6955\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1990 - val_loss: 10.0332\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5698 - val_loss: 10.0736\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4048 - val_loss: 11.1205\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9599 - val_loss: 13.0258\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5792 - val_loss: 11.8601\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2100 - val_loss: 14.0577\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2112 - val_loss: 9.8625\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1802 - val_loss: 10.7116\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4803 - val_loss: 12.9874\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2716 - val_loss: 10.9912\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5824 - val_loss: 11.1540\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1960 - val_loss: 9.8936\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5446 - val_loss: 10.8997\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3289 - val_loss: 10.1710\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3705 - val_loss: 11.2436\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4095 - val_loss: 12.2016\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3340 - val_loss: 10.8636\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2765 - val_loss: 10.8875\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3095 - val_loss: 10.9811\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1441 - val_loss: 10.5035\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7099 - val_loss: 9.9318\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1590 - val_loss: 11.0123\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1930 - val_loss: 9.3982\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6124 - val_loss: 10.9271\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1747 - val_loss: 13.7182\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3315 - val_loss: 11.2023\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6139 - val_loss: 10.8891\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0880 - val_loss: 10.4689\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1596 - val_loss: 16.9192\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3562 - val_loss: 9.6297\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3119 - val_loss: 12.8972\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9289 - val_loss: 10.9349\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3876 - val_loss: 12.2590\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0486 - val_loss: 10.2126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2188 - val_loss: 9.5182\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1233 - val_loss: 10.4185\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2678 - val_loss: 10.3945\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.3799 - val_loss: 12.7425\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0933 - val_loss: 10.6196\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9403 - val_loss: 15.7463\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2630 - val_loss: 10.1980\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4739 - val_loss: 9.4807\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0751 - val_loss: 10.0590\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1657 - val_loss: 10.5167\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9824 - val_loss: 10.7526\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3982 - val_loss: 11.3884\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0890 - val_loss: 10.0467\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3513 - val_loss: 10.0487\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3344 - val_loss: 10.5538\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4819 - val_loss: 10.3975\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2809 - val_loss: 11.9735\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1957 - val_loss: 10.0173\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5603 - val_loss: 10.4288\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2927 - val_loss: 15.1992\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4091 - val_loss: 10.2954\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2308 - val_loss: 10.0974\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2256 - val_loss: 16.2253\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1854 - val_loss: 10.1301\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9678 - val_loss: 15.5664\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3941 - val_loss: 10.4549\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5569 - val_loss: 15.7905\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0249 - val_loss: 10.1267\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1535 - val_loss: 10.9666\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3069 - val_loss: 10.3192\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4462 - val_loss: 11.3928\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1769 - val_loss: 15.8107\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3189 - val_loss: 9.9417\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1411 - val_loss: 11.9750\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5727 - val_loss: 9.8120\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1336 - val_loss: 13.3315\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.7754 - val_loss: 9.8882\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2602 - val_loss: 11.3547\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3360 - val_loss: 9.7573\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8669 - val_loss: 10.0647\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6489 - val_loss: 10.0714\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1548 - val_loss: 12.6332\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6986 - val_loss: 11.3922\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5655 - val_loss: 10.9929\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8277 - val_loss: 10.6938\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1773 - val_loss: 9.7842\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5114 - val_loss: 10.1190\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3696 - val_loss: 9.7797\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1203 - val_loss: 10.4698\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6762 - val_loss: 9.4198\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1638 - val_loss: 12.1246\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2427 - val_loss: 10.5101\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.010 - 0s 80us/step - loss: 9.1121 - val_loss: 14.7307\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5147 - val_loss: 12.1356\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1767 - val_loss: 10.0135\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2704 - val_loss: 9.7703\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8018 - val_loss: 10.1994\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0841 - val_loss: 10.1865\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0862 - val_loss: 12.9841\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2875 - val_loss: 12.6474\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5438 - val_loss: 10.5272\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4892 - val_loss: 9.9314\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8364 - val_loss: 10.2354\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0002 - val_loss: 11.5325\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4379 - val_loss: 10.9541\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4820 - val_loss: 10.0143\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0234 - val_loss: 9.9534\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5515 - val_loss: 10.3521\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4524 - val_loss: 13.9544\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2883 - val_loss: 9.5404\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2714 - val_loss: 10.1379\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5855 - val_loss: 12.6469\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0315 - val_loss: 11.3934\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2833 - val_loss: 11.1070\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1635 - val_loss: 9.6078\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0357 - val_loss: 10.4649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4085 - val_loss: 10.7509\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9856 - val_loss: 9.6659\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2301 - val_loss: 9.8468\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4249 - val_loss: 15.7270\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5901 - val_loss: 10.9570\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4260 - val_loss: 15.4051\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2994 - val_loss: 10.3365\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0370 - val_loss: 10.2602\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2999 - val_loss: 9.6939\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3901 - val_loss: 11.3743\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9680 - val_loss: 9.6615\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6851 - val_loss: 10.8485\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3589 - val_loss: 13.1202\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1240 - val_loss: 10.2034\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4100 - val_loss: 12.6368\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1755 - val_loss: 11.8089\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3128 - val_loss: 9.7916\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2030 - val_loss: 9.6091\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0191 - val_loss: 15.0952\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4018 - val_loss: 13.5218\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3224 - val_loss: 9.6279\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0293 - val_loss: 9.6637\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3281 - val_loss: 10.9505\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4548 - val_loss: 11.4127\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0009 - val_loss: 12.0482\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3690 - val_loss: 10.1155\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1652 - val_loss: 10.0358\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4810 - val_loss: 10.7234\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1447 - val_loss: 10.4376\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3844 - val_loss: 9.4633\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2271 - val_loss: 10.0696\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1524 - val_loss: 9.7457\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2119 - val_loss: 10.5074\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2190 - val_loss: 11.1669\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4803 - val_loss: 10.4626\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0375 - val_loss: 13.1996\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6014 - val_loss: 11.0037\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.0897 - val_loss: 10.5216\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5374 - val_loss: 11.5033\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4375 - val_loss: 14.5051\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1057 - val_loss: 9.7549\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5979 - val_loss: 10.3542\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7706 - val_loss: 11.4681\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3026 - val_loss: 9.8045\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0778 - val_loss: 9.6442\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8640 - val_loss: 10.1412\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8486 - val_loss: 10.5862\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9976 - val_loss: 13.1705\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2991 - val_loss: 13.1279\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8262 - val_loss: 9.7859\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1709 - val_loss: 9.9912\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2724 - val_loss: 9.6276\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3899 - val_loss: 12.1159\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0473 - val_loss: 14.4709\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5159 - val_loss: 10.4087\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0527 - val_loss: 15.6798\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9599 - val_loss: 9.7832\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9858 - val_loss: 17.4638\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8558 - val_loss: 11.4899\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2046 - val_loss: 9.6670\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7932 - val_loss: 10.7813\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2739 - val_loss: 12.5166\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0126 - val_loss: 12.5060\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5559 - val_loss: 14.7161\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7053 - val_loss: 9.7812\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6561 - val_loss: 10.6827\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7847 - val_loss: 11.0814\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4168 - val_loss: 9.7756\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4426 - val_loss: 9.9518\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9449 - val_loss: 10.2576\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2426 - val_loss: 11.4277\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2289 - val_loss: 10.8770\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4804 - val_loss: 9.8557\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2394 - val_loss: 11.6720\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1923 - val_loss: 10.2943\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3131 - val_loss: 11.0038\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3058 - val_loss: 9.9055\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.1869 - val_loss: 10.6135\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3825 - val_loss: 11.0281\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9365 - val_loss: 22.8806\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6716 - val_loss: 10.0787\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2119 - val_loss: 10.4738\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3178 - val_loss: 10.2255\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4441 - val_loss: 9.6761\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4100 - val_loss: 10.8214\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7332 - val_loss: 10.1657\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2310 - val_loss: 10.7633\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9240 - val_loss: 10.1511\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0643 - val_loss: 10.1520\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2925 - val_loss: 9.6417\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9373 - val_loss: 10.7976\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2114 - val_loss: 10.0740\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3305 - val_loss: 11.3476\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4234 - val_loss: 9.6228\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1374 - val_loss: 12.3508\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7973 - val_loss: 9.9626\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0524 - val_loss: 11.5995\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5669 - val_loss: 11.0451\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0692 - val_loss: 12.5767\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9867 - val_loss: 9.9086\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3201 - val_loss: 9.5552\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9688 - val_loss: 11.8639\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2663 - val_loss: 10.7171\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0405 - val_loss: 12.4157\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4311 - val_loss: 9.6736\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4298 - val_loss: 10.3446\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4036 - val_loss: 11.5722\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0601 - val_loss: 12.2499\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1420 - val_loss: 10.9551\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9479 - val_loss: 12.0887\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4035 - val_loss: 11.1316\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0719 - val_loss: 11.4581\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3233 - val_loss: 9.8641\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8057 - val_loss: 9.8182\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1191 - val_loss: 13.5591\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0766 - val_loss: 16.7897\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9979 - val_loss: 10.9529\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0789 - val_loss: 10.4633\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8559 - val_loss: 13.7835\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3711 - val_loss: 11.7141\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.6727 - val_loss: 9.7681\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2269 - val_loss: 10.1374\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9005 - val_loss: 9.9953\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.8869 - val_loss: 11.6132\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8580 - val_loss: 13.0931\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4033 - val_loss: 10.3156\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4537 - val_loss: 10.4381\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2325 - val_loss: 11.2089\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0089 - val_loss: 19.6927\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0868 - val_loss: 10.4435\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4974 - val_loss: 9.8384\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1133 - val_loss: 10.4300\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4569 - val_loss: 10.4593\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0575 - val_loss: 9.8091\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0941 - val_loss: 10.8820\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1955 - val_loss: 10.2404\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7566 - val_loss: 13.1456\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4555 - val_loss: 10.1485\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3196 - val_loss: 10.5660\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3814 - val_loss: 10.8159\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.5825 - val_loss: 13.9904\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3745 - val_loss: 12.4720\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3972 - val_loss: 10.1057\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3242 - val_loss: 20.9880\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1209 - val_loss: 14.3680\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6652 - val_loss: 12.4993\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3496 - val_loss: 10.3729\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2608 - val_loss: 9.5810\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1132 - val_loss: 11.0169\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7645 - val_loss: 10.5832\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2203 - val_loss: 10.0191\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3064 - val_loss: 10.2196\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9281 - val_loss: 12.9158\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5445 - val_loss: 9.7088\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2368 - val_loss: 10.7715\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0325 - val_loss: 10.1737\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.7112 - val_loss: 10.5287\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4554 - val_loss: 10.1885\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0091 - val_loss: 10.1888\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1782 - val_loss: 11.6999\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0419 - val_loss: 10.4734\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1916 - val_loss: 10.1128\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2095 - val_loss: 9.8402\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3113 - val_loss: 10.6192\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3089 - val_loss: 10.0352\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2172 - val_loss: 9.4590\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6649 - val_loss: 11.4008\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4325 - val_loss: 10.3682\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0720 - val_loss: 9.8261\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3355 - val_loss: 10.1276\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1295 - val_loss: 9.5739\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0683 - val_loss: 9.8447\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2577 - val_loss: 9.8069\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2215 - val_loss: 10.4462\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7203 - val_loss: 11.1973\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2410 - val_loss: 10.2257\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2095 - val_loss: 10.7478\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1199 - val_loss: 10.2646\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9422 - val_loss: 14.1406\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1273 - val_loss: 13.8283\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3595 - val_loss: 9.8938\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1531 - val_loss: 10.9668\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0837 - val_loss: 9.4959\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7258 - val_loss: 10.4691\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9889 - val_loss: 18.9420\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8339 - val_loss: 10.5090\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4150 - val_loss: 9.5349\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9660 - val_loss: 10.3561\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1978 - val_loss: 12.4327\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3454 - val_loss: 10.3654\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0212 - val_loss: 15.4174\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9996 - val_loss: 9.8456\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2969 - val_loss: 11.5963\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2816 - val_loss: 9.5441\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9306 - val_loss: 10.5739\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4178 - val_loss: 11.4796\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0359 - val_loss: 13.8269\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4046 - val_loss: 11.5315\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9375 - val_loss: 10.6481\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0131 - val_loss: 11.1501\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9603 - val_loss: 10.5164\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0404 - val_loss: 10.9414\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9665 - val_loss: 9.9619\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1312 - val_loss: 9.4426\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0112 - val_loss: 9.6233\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2424 - val_loss: 10.2353\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8623 - val_loss: 18.3337\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1300 - val_loss: 11.9252\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2517 - val_loss: 10.6082\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1203 - val_loss: 10.0480\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9987 - val_loss: 10.4000\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4255 - val_loss: 9.8799\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0674 - val_loss: 9.7669\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9376 - val_loss: 10.8130\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3249 - val_loss: 10.5066\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2662 - val_loss: 13.7510\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5705 - val_loss: 9.9181\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0516 - val_loss: 11.4049\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1649 - val_loss: 9.6638\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0031 - val_loss: 9.4900\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9898 - val_loss: 9.5222\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1776 - val_loss: 11.9063\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2850 - val_loss: 10.4614\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9285 - val_loss: 10.2309\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4161 - val_loss: 9.5190\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0789 - val_loss: 10.5938\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2338 - val_loss: 10.5250\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2065 - val_loss: 9.4692\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1732 - val_loss: 9.7932\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5069 - val_loss: 9.9144\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4481 - val_loss: 10.7344\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2470 - val_loss: 11.3505\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1195 - val_loss: 10.8675\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1108 - val_loss: 9.9300\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3577 - val_loss: 11.7961\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3824 - val_loss: 12.4562\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3861 - val_loss: 10.4210\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9684 - val_loss: 9.5894\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1562 - val_loss: 10.4369\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2347 - val_loss: 9.5474\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2596 - val_loss: 9.8481\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6654 - val_loss: 9.4572\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5820 - val_loss: 9.8480\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8755 - val_loss: 9.5303\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0368 - val_loss: 10.0701\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0546 - val_loss: 9.5168\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5769 - val_loss: 11.3360\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 8.8750 - val_loss: 12.3178\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0534 - val_loss: 10.0780\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1650 - val_loss: 9.6330\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2612 - val_loss: 9.4839\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2612 - val_loss: 10.8408\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3228 - val_loss: 13.1456\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2659 - val_loss: 10.6039\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4016 - val_loss: 13.3273\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3835 - val_loss: 11.0602\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1120 - val_loss: 9.4330\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1843 - val_loss: 11.3808\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1316 - val_loss: 10.4776\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1025 - val_loss: 14.9956\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3690 - val_loss: 10.4869\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.6979 - val_loss: 10.4000\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1850 - val_loss: 10.1285\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1090 - val_loss: 14.8188\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9236 - val_loss: 13.4539\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0548 - val_loss: 11.2596\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1645 - val_loss: 9.9623\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0748 - val_loss: 11.0529\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7534 - val_loss: 10.1955\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4870 - val_loss: 10.4874\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0073 - val_loss: 9.7091\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9263 - val_loss: 9.4146\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4616 - val_loss: 10.4681\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9797 - val_loss: 16.5399\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9488 - val_loss: 12.2372\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0909 - val_loss: 12.0073\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1150 - val_loss: 10.8114\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2945 - val_loss: 11.0764\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0937 - val_loss: 9.7711\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8293 - val_loss: 10.5104\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5485 - val_loss: 10.7462\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1885 - val_loss: 10.9859\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 8.6253 - val_loss: 13.4747\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1368 - val_loss: 10.2633\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0477 - val_loss: 17.3141\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1861 - val_loss: 11.7910\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9937 - val_loss: 9.9663\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7952 - val_loss: 11.2498\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.4927 - val_loss: 9.7986\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2535 - val_loss: 13.0421\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2655 - val_loss: 10.2806\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7084 - val_loss: 11.5674\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1030 - val_loss: 11.0813\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5318 - val_loss: 9.5414\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9953 - val_loss: 9.5248\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8148 - val_loss: 10.2349\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3002 - val_loss: 13.5729\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3135 - val_loss: 9.5545\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1248 - val_loss: 10.2916\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0632 - val_loss: 9.8525\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9076 - val_loss: 9.4146\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1248 - val_loss: 11.0692\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4003 - val_loss: 9.9380\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2539 - val_loss: 12.1736\n",
      "Epoch 899/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9654 - val_loss: 11.8301\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0119 - val_loss: 15.6884\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1378 - val_loss: 9.5108\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5677 - val_loss: 9.7005\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7915 - val_loss: 10.1109\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2523 - val_loss: 9.3128\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3259 - val_loss: 14.2389\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9833 - val_loss: 13.1988\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2991 - val_loss: 9.4324\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0863 - val_loss: 9.6209\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3213 - val_loss: 11.7541\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0442 - val_loss: 10.0758\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4952 - val_loss: 11.4433\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3048 - val_loss: 10.6040\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0959 - val_loss: 11.2860\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3380 - val_loss: 13.2184\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2215 - val_loss: 11.8779\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.6267 - val_loss: 9.6189\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1420 - val_loss: 12.1413\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1856 - val_loss: 11.2981\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8871 - val_loss: 11.2523\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3262 - val_loss: 9.6066\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3231 - val_loss: 10.4268\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9032 - val_loss: 9.6364\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9266 - val_loss: 9.4330\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6306 - val_loss: 10.7962\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0505 - val_loss: 10.0432\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2053 - val_loss: 10.5117\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3060 - val_loss: 10.9712\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1131 - val_loss: 9.9175\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2545 - val_loss: 12.4748\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1895 - val_loss: 11.1284\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7888 - val_loss: 9.7288\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8630 - val_loss: 10.3846\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5114 - val_loss: 9.5864\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1477 - val_loss: 9.7712\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3891 - val_loss: 9.9079\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7509 - val_loss: 12.9736\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3336 - val_loss: 11.6599\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0336 - val_loss: 10.1741\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2564 - val_loss: 9.4062\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1409 - val_loss: 9.4319\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5381 - val_loss: 10.1240\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1282 - val_loss: 9.8429\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2508 - val_loss: 15.8249\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3309 - val_loss: 10.4627\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2667 - val_loss: 9.8635\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.7152 - val_loss: 11.0552\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9943 - val_loss: 9.7383\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1411 - val_loss: 9.7868\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2286 - val_loss: 10.6586\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3566 - val_loss: 9.9507\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0096 - val_loss: 10.0821\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.8137 - val_loss: 11.9531\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.3640 - val_loss: 9.6957\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0791 - val_loss: 11.1254\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1141 - val_loss: 13.4617\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1113 - val_loss: 11.9594\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.4682 - val_loss: 9.3054\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.7103 - val_loss: 10.3315\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0763 - val_loss: 9.4147\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2877 - val_loss: 11.1284\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0236 - val_loss: 10.5085\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1346 - val_loss: 9.3949\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1210 - val_loss: 9.5798\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2655 - val_loss: 10.2782\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8187 - val_loss: 10.7435\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1233 - val_loss: 9.8647\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0986 - val_loss: 10.9601\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4153 - val_loss: 10.5127\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0001 - val_loss: 14.6347\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9404 - val_loss: 9.9375\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6208 - val_loss: 9.7248\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0170 - val_loss: 10.4614\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3855 - val_loss: 9.5137\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2191 - val_loss: 10.2170\n",
      "Epoch 975/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8881 - val_loss: 12.7450\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3232 - val_loss: 9.7385\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4502 - val_loss: 9.8853\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1014 - val_loss: 10.7154\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3419 - val_loss: 11.7185\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2038 - val_loss: 13.9335\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8544 - val_loss: 14.5448\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1853 - val_loss: 9.7879\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0099 - val_loss: 9.6723\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9726 - val_loss: 11.9465\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1262 - val_loss: 14.3110\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9819 - val_loss: 10.2710\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4155 - val_loss: 9.8933\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8858 - val_loss: 10.1329\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2836 - val_loss: 11.0855\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2605 - val_loss: 9.4243\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.7500 - val_loss: 10.3040\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4077 - val_loss: 11.4830\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4644 - val_loss: 9.5696\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7986 - val_loss: 11.5123\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1607 - val_loss: 15.1991\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1418 - val_loss: 11.8608\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3365 - val_loss: 11.2768\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9028 - val_loss: 9.9248\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8981 - val_loss: 9.3941\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1872 - val_loss: 11.0606\n",
      "8.704742878939198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-4.1340494 , -0.5423752 , -1.9246769 , -3.0257561 , -0.23880716],\n",
       "        [ 0.22393963, -0.89263916,  0.43099388,  0.07349765, -0.28461948],\n",
       "        [-0.73538846, -1.183267  ,  0.39100978, -0.02767474, -0.3983067 ],\n",
       "        [ 0.17476942,  0.21309479,  0.05278031,  0.03071608,  0.23384993],\n",
       "        [-0.388193  , -0.02713201, -0.27230966, -2.476717  , -0.24319181]],\n",
       "       dtype=float32),\n",
       " array([-5.0068893, -0.5993848, -1.2175783, -4.599301 ,  1.956449 ],\n",
       "       dtype=float32),\n",
       " array([[-1.3649524 ,  1.6944485 , -1.4146601 , -2.295778  , -1.7116433 ,\n",
       "         -2.0746205 ,  1.0422294 ,  1.3980467 ,  1.9370059 , -2.1361299 ],\n",
       "        [-0.34763578,  0.3017152 ,  0.9409002 ,  0.75136447,  0.7333163 ,\n",
       "          0.81774217, -0.22864446, -0.7503742 , -0.7624513 , -0.30675095],\n",
       "        [ 0.06575379, -0.22350077,  0.89081544,  0.54283416,  0.2821009 ,\n",
       "         -0.0905275 , -1.0448612 , -1.099719  , -0.880763  ,  1.0795995 ],\n",
       "        [-1.2549328 ,  1.2254385 , -1.6343043 , -2.0503776 , -1.6363338 ,\n",
       "         -2.3071094 ,  0.8427235 ,  1.5215987 ,  1.5569211 , -1.0051513 ],\n",
       "        [ 1.3569173 , -1.954405  ,  1.8998152 ,  1.5720422 ,  2.264967  ,\n",
       "          2.294545  , -1.2101066 , -1.2153002 , -2.1038375 ,  1.4152768 ]],\n",
       "       dtype=float32),\n",
       " array([ 2.0349057, -2.1107173,  1.9561868,  2.1309352,  2.1662376,\n",
       "         2.1826472, -1.9270632, -2.0070195, -2.1646025,  2.0128982],\n",
       "       dtype=float32),\n",
       " array([[ 1.7502537],\n",
       "        [-1.9737033],\n",
       "        [ 1.4339697],\n",
       "        [ 2.08334  ],\n",
       "        [ 2.2475488],\n",
       "        [ 2.332057 ],\n",
       "        [-1.2382843],\n",
       "        [-1.5410142],\n",
       "        [-2.2367516],\n",
       "        [ 1.6265208]], dtype=float32),\n",
       " array([2.662814], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, RMSprop, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_rmsprop_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 586us/step - loss: 495.2736 - val_loss: 260.5834\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 154.9828 - val_loss: 90.7490\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 63.6808 - val_loss: 35.2554\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 25.8853 - val_loss: 26.3165\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 23.3429 - val_loss: 19.4790\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 19.5341 - val_loss: 18.3936\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 17.5735 - val_loss: 17.1253\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.2219 - val_loss: 17.1050\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 14.9405 - val_loss: 16.9747\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 14.3849 - val_loss: 17.2985\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 13.4017 - val_loss: 17.3121\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 13.3255 - val_loss: 16.8617\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 12.0367 - val_loss: 17.0782\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 11.7795 - val_loss: 16.6819\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 11.5693 - val_loss: 16.4521\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.8664 - val_loss: 15.4396\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.7405 - val_loss: 15.3230\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 10.5468 - val_loss: 15.0822\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 10.0633 - val_loss: 14.9265\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.6942 - val_loss: 14.3625\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.5431 - val_loss: 14.1081\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 9.3200 - val_loss: 13.5865\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.6611 - val_loss: 12.9699\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.4328 - val_loss: 13.6599\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.8962 - val_loss: 13.0528\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6038 - val_loss: 12.6918\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4999 - val_loss: 12.7404\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3656 - val_loss: 12.5137\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3788 - val_loss: 11.9990\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2692 - val_loss: 12.2242\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2543 - val_loss: 12.2158\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3393 - val_loss: 12.0669\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.1732 - val_loss: 12.4970\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5561 - val_loss: 12.5561\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9241 - val_loss: 11.5546\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.3747 - val_loss: 12.6283\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0231 - val_loss: 11.0711\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.8394 - val_loss: 11.3044\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6845 - val_loss: 11.2414\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7757 - val_loss: 10.5375\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6026 - val_loss: 10.9622\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8455 - val_loss: 10.5575\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6104 - val_loss: 10.4890\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4634 - val_loss: 10.0515\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4817 - val_loss: 10.2221\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4315 - val_loss: 9.9308\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2304 - val_loss: 9.9764\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2361 - val_loss: 9.4131\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0604 - val_loss: 9.6559\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0921 - val_loss: 9.6875\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3268 - val_loss: 9.7104\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1099 - val_loss: 9.9596\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1919 - val_loss: 9.4490\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0486 - val_loss: 9.0342\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9636 - val_loss: 9.1548\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8767 - val_loss: 9.2219\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8125 - val_loss: 8.6157\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8644 - val_loss: 9.0369\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7796 - val_loss: 9.1713\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8929 - val_loss: 8.8440\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7245 - val_loss: 8.6933\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7358 - val_loss: 8.7222\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7873 - val_loss: 8.9189\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8103 - val_loss: 8.8622\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9269 - val_loss: 9.2575\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 7.2669 - val_loss: 9.0923\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7198 - val_loss: 8.8090\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.6998 - val_loss: 8.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7234 - val_loss: 8.7452\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6470 - val_loss: 8.5066\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6858 - val_loss: 8.7578\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.1143 - val_loss: 9.0477\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9774 - val_loss: 8.9867\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7534 - val_loss: 8.6095\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9065 - val_loss: 8.8270\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7294 - val_loss: 8.9848\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6952 - val_loss: 8.9580\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5754 - val_loss: 8.8187\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.8084 - val_loss: 8.7079\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.9821 - val_loss: 9.1752\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.6782 - val_loss: 8.9687\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9337 - val_loss: 9.1440\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.0200 - val_loss: 8.8352\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5733 - val_loss: 8.0806\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6668 - val_loss: 8.2770\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5779 - val_loss: 8.7277\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9249 - val_loss: 9.1115\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9874 - val_loss: 9.4058\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 7.2371 - val_loss: 9.1743\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.1271 - val_loss: 8.7297\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.7313 - val_loss: 8.4616\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6256 - val_loss: 8.7316\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3570 - val_loss: 8.5824\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5283 - val_loss: 8.6754\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5352 - val_loss: 8.7585\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4289 - val_loss: 8.2205\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.7847 - val_loss: 8.5582\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 131us/step - loss: 6.6270 - val_loss: 8.3284\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6461 - val_loss: 8.1050\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4970 - val_loss: 8.3794\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6244 - val_loss: 8.4163\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6460 - val_loss: 8.8018\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4612 - val_loss: 8.5283\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8888 - val_loss: 8.4167\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5826 - val_loss: 8.2797\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5798 - val_loss: 8.6372\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6486 - val_loss: 8.3057\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5352 - val_loss: 8.1594\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.6055 - val_loss: 8.1775\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6141 - val_loss: 8.3055\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7447 - val_loss: 8.6233\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7493 - val_loss: 8.7821\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.8584 - val_loss: 8.5594\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5806 - val_loss: 8.0532\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3807 - val_loss: 8.3172\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6526 - val_loss: 8.4446\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5169 - val_loss: 8.3984\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.5258 - val_loss: 7.8961\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4431 - val_loss: 8.1673\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.6353 - val_loss: 8.4158\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3993 - val_loss: 7.8903\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4255 - val_loss: 8.0805\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.3109 - val_loss: 8.3426\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3635 - val_loss: 8.1717\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2998 - val_loss: 7.9210\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2508 - val_loss: 8.1864\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2975 - val_loss: 7.9697\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3764 - val_loss: 8.2631\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4250 - val_loss: 7.7626\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2016 - val_loss: 7.9269\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2694 - val_loss: 7.9517\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2438 - val_loss: 8.1489\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.4341 - val_loss: 8.1414\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2951 - val_loss: 7.9364\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2306 - val_loss: 8.1878\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3448 - val_loss: 7.9812\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2635 - val_loss: 7.9461\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6097 - val_loss: 8.0361\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5505 - val_loss: 8.1273\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2226 - val_loss: 8.0874\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2689 - val_loss: 7.9914\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.4425 - val_loss: 7.8827\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2507 - val_loss: 8.0246\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6281 - val_loss: 9.0264\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4611 - val_loss: 9.1796\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6825 - val_loss: 8.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.4955 - val_loss: 8.0429\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4364 - val_loss: 8.3037\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.3809 - val_loss: 7.9521\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2636 - val_loss: 8.2835\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2055 - val_loss: 7.9917\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4069 - val_loss: 8.1047\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1609 - val_loss: 7.8708\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1599 - val_loss: 8.0165\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2539 - val_loss: 8.2186\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5652 - val_loss: 8.2583\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5043 - val_loss: 8.1355\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1300 - val_loss: 7.7365\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1393 - val_loss: 7.9125\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1947 - val_loss: 7.7778\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1938 - val_loss: 8.1121\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1316 - val_loss: 8.2240\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.2995 - val_loss: 8.3557\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1658 - val_loss: 8.1277\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1321 - val_loss: 7.9622\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1714 - val_loss: 7.8960\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1714 - val_loss: 8.1306\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4122 - val_loss: 7.9030\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2575 - val_loss: 7.9844\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1614 - val_loss: 8.1823\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0992 - val_loss: 8.2901\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1205 - val_loss: 7.9820\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1782 - val_loss: 8.1553\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 12.58 - 0s 102us/step - loss: 6.1927 - val_loss: 8.2446\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0015 - val_loss: 8.3137\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0238 - val_loss: 8.0397\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.0508 - val_loss: 8.0690\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0031 - val_loss: 8.1765\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0249 - val_loss: 8.0626\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.2153 - val_loss: 7.8916\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.1071 - val_loss: 8.5593\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0688 - val_loss: 8.0630\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9498 - val_loss: 8.3955\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2834 - val_loss: 8.2947\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5735 - val_loss: 8.3284\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9052 - val_loss: 9.2494\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8228 - val_loss: 9.0423\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2830 - val_loss: 8.5046\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1356 - val_loss: 8.3171\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0653 - val_loss: 8.2007\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0854 - val_loss: 8.1475\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9857 - val_loss: 8.5466\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0511 - val_loss: 8.4694\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0725 - val_loss: 8.1232\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0985 - val_loss: 8.2589\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9581 - val_loss: 8.4612\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1087 - val_loss: 8.3314\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.9454 - val_loss: 8.4656\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0364 - val_loss: 8.6370\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.2287 - val_loss: 8.3780\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0373 - val_loss: 8.3546\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9741 - val_loss: 8.4000\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0401 - val_loss: 8.6330\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0157 - val_loss: 8.4093\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0327 - val_loss: 8.4303\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.2330 - val_loss: 8.3869\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3406 - val_loss: 8.5639\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.2785 - val_loss: 8.6096\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3314 - val_loss: 8.4989\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0153 - val_loss: 8.3647\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0863 - val_loss: 8.8127\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0649 - val_loss: 8.4709\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.9852 - val_loss: 8.4285\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9932 - val_loss: 8.7608\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9950 - val_loss: 8.4698\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9375 - val_loss: 8.6544\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9679 - val_loss: 8.5592\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1417 - val_loss: 9.0169\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9738 - val_loss: 8.7505\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9441 - val_loss: 8.6318\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.9155 - val_loss: 8.3541\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8795 - val_loss: 8.3707\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8814 - val_loss: 8.4259\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.9358 - val_loss: 8.3693\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1695 - val_loss: 9.4821\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4401 - val_loss: 8.8950\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2864 - val_loss: 9.5369\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2472 - val_loss: 8.6305\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3103 - val_loss: 8.8690\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0689 - val_loss: 8.3283\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0035 - val_loss: 8.8260\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8993 - val_loss: 8.6846\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8807 - val_loss: 9.0908\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0155 - val_loss: 8.6551\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7994 - val_loss: 8.4630\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8660 - val_loss: 8.5420\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8617 - val_loss: 8.4377\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8067 - val_loss: 8.3998\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8689 - val_loss: 8.5602\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9174 - val_loss: 8.4695\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7658 - val_loss: 9.0232\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7999 - val_loss: 8.4832\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8239 - val_loss: 8.5895\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0753 - val_loss: 8.7920\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2220 - val_loss: 8.9154\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0021 - val_loss: 8.9688\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 9.660 - 0s 102us/step - loss: 5.9721 - val_loss: 8.5080\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8476 - val_loss: 8.9535\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9303 - val_loss: 8.7183\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8466 - val_loss: 8.2475\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8069 - val_loss: 8.8632\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8604 - val_loss: 8.5129\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7770 - val_loss: 8.4853\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8111 - val_loss: 8.7351\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0756 - val_loss: 9.2931\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3287 - val_loss: 8.7227\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5036 - val_loss: 9.3629\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8988 - val_loss: 8.6637\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8197 - val_loss: 8.9845\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.8378 - val_loss: 8.4566\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8696 - val_loss: 8.7090\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8851 - val_loss: 8.9216\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9311 - val_loss: 8.5105\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8585 - val_loss: 9.2054\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1176 - val_loss: 8.6979\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1745 - val_loss: 9.0027\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7477 - val_loss: 8.8634\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6857 - val_loss: 9.1406\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1054 - val_loss: 8.7646\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9151 - val_loss: 8.3912\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7257 - val_loss: 9.4790\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1818 - val_loss: 8.8223\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8340 - val_loss: 8.6484\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8750 - val_loss: 8.6868\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6497 - val_loss: 8.8818\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7114 - val_loss: 8.8333\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8260 - val_loss: 8.6756\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7445 - val_loss: 8.6713\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8134 - val_loss: 8.5941\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7734 - val_loss: 8.7017\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8055 - val_loss: 8.6903\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8442 - val_loss: 9.1879\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.1492 - val_loss: 8.7327\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8727 - val_loss: 9.6080\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9790 - val_loss: 8.5158\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8241 - val_loss: 9.0292\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8305 - val_loss: 8.9307\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6473 - val_loss: 8.9949\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6936 - val_loss: 8.5347\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6453 - val_loss: 8.6829\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6201 - val_loss: 8.4904\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0863 - val_loss: 9.5773\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0352 - val_loss: 8.6144\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7102 - val_loss: 9.2647\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.0635 - val_loss: 8.6338\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.8694 - val_loss: 8.4638\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8816 - val_loss: 9.2277\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7885 - val_loss: 8.9009\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6601 - val_loss: 8.8032\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6775 - val_loss: 8.8738\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.6497 - val_loss: 9.0096\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7660 - val_loss: 8.9470\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6320 - val_loss: 8.6387\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.7268 - val_loss: 9.0878\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7339 - val_loss: 9.2700\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.8993 - val_loss: 8.5724\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7384 - val_loss: 8.9630\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6346 - val_loss: 8.8199\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7410 - val_loss: 8.5651\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6001 - val_loss: 8.8436\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6696 - val_loss: 8.5430\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6072 - val_loss: 8.8688\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6419 - val_loss: 8.6989\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6937 - val_loss: 9.0014\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7640 - val_loss: 8.6532\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8056 - val_loss: 8.4151\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5733 - val_loss: 8.8629\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5804 - val_loss: 8.7069\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6960 - val_loss: 8.8530\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6712 - val_loss: 8.8241\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7062 - val_loss: 8.6388\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7915 - val_loss: 8.6437\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7346 - val_loss: 9.3086\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8303 - val_loss: 8.8173\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6274 - val_loss: 9.1608\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6773 - val_loss: 8.7446\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7842 - val_loss: 9.4784\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6924 - val_loss: 8.9894\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5450 - val_loss: 9.1290\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5546 - val_loss: 8.8547\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6247 - val_loss: 9.0434\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7073 - val_loss: 8.7030\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9678 - val_loss: 8.7492\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.0104 - val_loss: 9.5188\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9636 - val_loss: 9.6794\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7364 - val_loss: 8.8258\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5602 - val_loss: 8.5970\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5547 - val_loss: 9.1767\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6061 - val_loss: 8.7754\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7401 - val_loss: 9.0536\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6929 - val_loss: 8.8387\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5915 - val_loss: 9.1750\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5547 - val_loss: 8.8875\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5200 - val_loss: 8.8983\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6335 - val_loss: 8.6451\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5945 - val_loss: 9.5386\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6431 - val_loss: 9.1383\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5804 - val_loss: 8.7809\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6320 - val_loss: 8.5335\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5749 - val_loss: 8.9540\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5320 - val_loss: 9.0509\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5475 - val_loss: 8.9748\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5964 - val_loss: 8.7423\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4989 - val_loss: 8.8876\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5877 - val_loss: 8.9120\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5311 - val_loss: 8.7930\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.6170 - val_loss: 8.9032\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7822 - val_loss: 8.9148\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7213 - val_loss: 9.4015\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6947 - val_loss: 8.5899\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6544 - val_loss: 8.7239\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6633 - val_loss: 8.9400\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6884 - val_loss: 8.9273\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4738 - val_loss: 9.1641\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.7246 - val_loss: 8.6907\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4684 - val_loss: 9.6911\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6137 - val_loss: 8.7844\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4212 - val_loss: 9.9822\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7668 - val_loss: 8.9743\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.6203 - val_loss: 9.0635\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6392 - val_loss: 9.1820\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5295 - val_loss: 9.2358\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5726 - val_loss: 9.0417\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5393 - val_loss: 8.8086\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5850 - val_loss: 8.9203\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6381 - val_loss: 8.9061\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5256 - val_loss: 9.0459\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 102us/step - loss: 5.6631 - val_loss: 9.2261\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5374 - val_loss: 8.7776\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4189 - val_loss: 8.7895\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6000 - val_loss: 8.8264\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9354 - val_loss: 9.3569\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5026 - val_loss: 9.2852\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9335 - val_loss: 9.4873\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9722 - val_loss: 8.7896\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6378 - val_loss: 9.6026\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4987 - val_loss: 8.6863\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4506 - val_loss: 9.5449\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5147 - val_loss: 9.0363\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.6980 - val_loss: 9.0754\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4963 - val_loss: 9.0072\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5193 - val_loss: 9.4324\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5497 - val_loss: 8.8784\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5148 - val_loss: 9.4063\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7263 - val_loss: 8.7571\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9158 - val_loss: 10.8160\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0894 - val_loss: 8.7096\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8384 - val_loss: 9.1601\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4663 - val_loss: 8.8269\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4807 - val_loss: 9.4344\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5887 - val_loss: 8.5620\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5421 - val_loss: 9.6330\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5321 - val_loss: 8.8127\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5493 - val_loss: 9.1948\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4058 - val_loss: 8.5499\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4091 - val_loss: 8.9933\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4960 - val_loss: 9.1658\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4928 - val_loss: 8.9229\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4237 - val_loss: 8.8320\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3958 - val_loss: 9.0844\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4904 - val_loss: 8.7197\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5676 - val_loss: 10.8850\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0611 - val_loss: 9.1719\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8206 - val_loss: 11.1588\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3014 - val_loss: 8.6473\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3316 - val_loss: 9.1400\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4112 - val_loss: 9.5881\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1418 - val_loss: 9.0055\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6246 - val_loss: 9.6198\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1023 - val_loss: 8.5475\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0339 - val_loss: 10.3540\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7929 - val_loss: 9.0193\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4263 - val_loss: 9.9064\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8798 - val_loss: 9.1214\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9535 - val_loss: 8.7190\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7653 - val_loss: 8.8851\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8558 - val_loss: 9.0208\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5063 - val_loss: 9.5128\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4100 - val_loss: 9.0713\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4026 - val_loss: 8.9164\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4050 - val_loss: 8.9588\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4007 - val_loss: 9.3478\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4340 - val_loss: 9.0604\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4569 - val_loss: 9.3853\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5294 - val_loss: 9.0416\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7578 - val_loss: 10.0180\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5101 - val_loss: 8.7619\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6122 - val_loss: 9.8491\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5424 - val_loss: 8.8725\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5123 - val_loss: 10.0171\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6848 - val_loss: 8.8913\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5741 - val_loss: 8.8443\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4102 - val_loss: 9.1311\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6174 - val_loss: 8.9700\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4768 - val_loss: 8.9171\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4297 - val_loss: 9.1650\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6209 - val_loss: 9.2676\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5612 - val_loss: 9.1557\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7172 - val_loss: 9.6364\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4430 - val_loss: 8.7988\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4297 - val_loss: 8.9648\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4761 - val_loss: 9.5468\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5633 - val_loss: 8.9113\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5877 - val_loss: 9.4547\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6438 - val_loss: 9.6125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5964 - val_loss: 8.6267\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9883 - val_loss: 10.4222\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8573 - val_loss: 9.3057\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8717 - val_loss: 10.9821\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6682 - val_loss: 8.9057\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3885 - val_loss: 9.8269\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4857 - val_loss: 9.0283\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5085 - val_loss: 10.3176\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5922 - val_loss: 8.9172\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6235 - val_loss: 10.3271\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4980 - val_loss: 9.1600\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4398 - val_loss: 9.8901\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3991 - val_loss: 8.9313\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8309 - val_loss: 9.2021\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3956 - val_loss: 8.9840\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9030 - val_loss: 10.8788\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1272 - val_loss: 8.7588\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5357 - val_loss: 10.0286\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4273 - val_loss: 8.9018\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6170 - val_loss: 8.8586\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9103 - val_loss: 9.7309\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6623 - val_loss: 8.7933\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0325 - val_loss: 10.5709\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5974 - val_loss: 9.0241\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5443 - val_loss: 9.5736\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5629 - val_loss: 9.1231\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4489 - val_loss: 9.9798\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4704 - val_loss: 9.0616\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4245 - val_loss: 9.8398\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4598 - val_loss: 9.3340\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8074 - val_loss: 10.4946\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.7326 - val_loss: 9.0563\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3162 - val_loss: 9.2932\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7494 - val_loss: 9.6512\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8541 - val_loss: 9.2759\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4923 - val_loss: 9.8588\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6734 - val_loss: 8.8973\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5327 - val_loss: 10.2466\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7276 - val_loss: 9.1286\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5208 - val_loss: 9.4984\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4748 - val_loss: 9.3900\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3904 - val_loss: 9.0891\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4605 - val_loss: 9.5897\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3020 - val_loss: 9.2611\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3931 - val_loss: 9.9808\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7143 - val_loss: 8.9189\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8278 - val_loss: 11.4280\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8642 - val_loss: 8.8611\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6226 - val_loss: 10.4562\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4871 - val_loss: 9.1038\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6479 - val_loss: 10.3450\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4772 - val_loss: 9.0848\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5358 - val_loss: 9.3036\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5236 - val_loss: 9.5761\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4034 - val_loss: 9.2704\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6152 - val_loss: 9.2262\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5723 - val_loss: 10.0014\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6136 - val_loss: 9.5408\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9050 - val_loss: 9.0369\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6811 - val_loss: 10.4091\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0677 - val_loss: 8.9509\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6332 - val_loss: 10.1894\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5669 - val_loss: 8.9345\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4589 - val_loss: 9.8049\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3529 - val_loss: 8.6807\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5042 - val_loss: 9.8560\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5481 - val_loss: 9.2062\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4492 - val_loss: 9.2820\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4362 - val_loss: 9.2199\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4838 - val_loss: 10.0826\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5917 - val_loss: 9.5415\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5586 - val_loss: 9.3296\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3603 - val_loss: 9.8155\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5196 - val_loss: 9.2301\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4462 - val_loss: 9.2948\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3132 - val_loss: 9.5410\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3199 - val_loss: 9.6030\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 5.3670 - val_loss: 9.4935\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3479 - val_loss: 9.3072\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7579 - val_loss: 11.2024\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6305 - val_loss: 9.0391\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4578 - val_loss: 9.9522\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3714 - val_loss: 9.3302\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5039 - val_loss: 9.9623\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3998 - val_loss: 9.3563\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5069 - val_loss: 10.1615\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3420 - val_loss: 9.3129\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4428 - val_loss: 10.5756\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5931 - val_loss: 9.3986\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3640 - val_loss: 9.7933\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5989 - val_loss: 10.0434\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5651 - val_loss: 9.3538\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3614 - val_loss: 9.6071\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4190 - val_loss: 9.6825\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4794 - val_loss: 9.2833\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7075 - val_loss: 9.9180\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7500 - val_loss: 9.4802\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6012 - val_loss: 10.3658\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6047 - val_loss: 8.9767\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5856 - val_loss: 10.9902\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6538 - val_loss: 9.2513\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6002 - val_loss: 10.1454\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4671 - val_loss: 9.1461\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5410 - val_loss: 9.7408\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3464 - val_loss: 10.1133\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4308 - val_loss: 9.1751\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3948 - val_loss: 9.8135\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3409 - val_loss: 9.3887\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3851 - val_loss: 9.3667\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3936 - val_loss: 9.6101\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4018 - val_loss: 9.3667\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4197 - val_loss: 9.7489\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3515 - val_loss: 9.4637\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3904 - val_loss: 9.6330\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3451 - val_loss: 9.4806\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3446 - val_loss: 9.5971\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3165 - val_loss: 9.4021\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3347 - val_loss: 9.4502\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3945 - val_loss: 9.5631\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4313 - val_loss: 9.3971\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6891 - val_loss: 10.2207\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7009 - val_loss: 10.4226\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7562 - val_loss: 9.4023\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4989 - val_loss: 10.1825\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5054 - val_loss: 9.3289\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5577 - val_loss: 10.1901\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5208 - val_loss: 9.5311\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3187 - val_loss: 9.7908\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4196 - val_loss: 9.1918\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6205 - val_loss: 9.8303\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4182 - val_loss: 9.3891\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4800 - val_loss: 10.0238\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4114 - val_loss: 9.6782\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7144 - val_loss: 10.6588\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8511 - val_loss: 9.9211\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8694 - val_loss: 9.2883\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.4539 - val_loss: 9.8395\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3704 - val_loss: 9.6594\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5201 - val_loss: 9.5265\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4584 - val_loss: 9.6651\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3605 - val_loss: 9.8260\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4110 - val_loss: 9.5535\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3767 - val_loss: 9.3188\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5472 - val_loss: 9.8307\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6554 - val_loss: 10.6431\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4170 - val_loss: 9.6028\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4627 - val_loss: 10.1630\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5279 - val_loss: 9.6666\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5802 - val_loss: 10.2188\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5491 - val_loss: 9.7267\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3892 - val_loss: 9.5711\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2700 - val_loss: 9.8925\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3798 - val_loss: 10.0209\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3237 - val_loss: 9.7953\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 5.3841 - val_loss: 9.9481\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4112 - val_loss: 9.4366\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3202 - val_loss: 9.8407\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3374 - val_loss: 9.8552\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3612 - val_loss: 9.3928\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2750 - val_loss: 9.8216\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3402 - val_loss: 9.6148\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4256 - val_loss: 10.0494\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.5464 - val_loss: 10.1481\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5258 - val_loss: 9.4346\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3315 - val_loss: 10.0689\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5338 - val_loss: 9.8544\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3183 - val_loss: 9.8583\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2983 - val_loss: 9.5909\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4693 - val_loss: 9.5016\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5141 - val_loss: 9.6968\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5777 - val_loss: 10.7728\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4712 - val_loss: 9.4488\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3196 - val_loss: 9.8798\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3063 - val_loss: 9.8557\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3685 - val_loss: 9.9706\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3825 - val_loss: 9.8138\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2428 - val_loss: 9.6582\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3459 - val_loss: 9.8988\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3764 - val_loss: 9.6160\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4563 - val_loss: 10.4483\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5705 - val_loss: 9.8234\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4958 - val_loss: 9.6572\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2467 - val_loss: 10.2060\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5926 - val_loss: 9.4583\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3913 - val_loss: 10.2241\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2813 - val_loss: 9.4307\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5117 - val_loss: 9.5627\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2468 - val_loss: 9.7326\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2936 - val_loss: 9.9651\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4248 - val_loss: 9.4095\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7817 - val_loss: 10.3450\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5326 - val_loss: 9.3311\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5399 - val_loss: 9.7686\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4972 - val_loss: 10.6621\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4156 - val_loss: 9.5874\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3212 - val_loss: 9.8739\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4097 - val_loss: 9.9683\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2939 - val_loss: 9.8091\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4121 - val_loss: 9.7070\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3125 - val_loss: 10.0563\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4916 - val_loss: 10.0908\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4066 - val_loss: 9.4682\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.4082 - val_loss: 10.5040\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5021 - val_loss: 10.1952\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2781 - val_loss: 9.8692\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3831 - val_loss: 9.4969\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5153 - val_loss: 10.8279\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6067 - val_loss: 9.3199\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5939 - val_loss: 9.9976\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4148 - val_loss: 9.7125\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4494 - val_loss: 10.0761\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4328 - val_loss: 9.5385\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4799 - val_loss: 10.8526\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 3.522 - 0s 106us/step - loss: 5.5205 - val_loss: 9.6768\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5520 - val_loss: 10.7196\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3071 - val_loss: 9.4329\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3560 - val_loss: 9.7715\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4170 - val_loss: 9.6281\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5297 - val_loss: 9.6942\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4854 - val_loss: 9.7289\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3950 - val_loss: 10.2213\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.1095 - val_loss: 9.4084\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9007 - val_loss: 11.3436\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0339 - val_loss: 9.4940\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6278 - val_loss: 11.5986\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7174 - val_loss: 9.2637\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5928 - val_loss: 10.3956\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3392 - val_loss: 9.5616\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2949 - val_loss: 10.4361\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4404 - val_loss: 9.8290\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4776 - val_loss: 9.6573\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 5.3701 - val_loss: 10.4222\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7965 - val_loss: 9.5659\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8223 - val_loss: 10.6421\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5837 - val_loss: 10.2181\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6187 - val_loss: 9.5436\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9625 - val_loss: 11.0416\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6769 - val_loss: 9.3782\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9293 - val_loss: 11.7416\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6486 - val_loss: 9.6902\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3233 - val_loss: 9.7361\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2531 - val_loss: 9.7916\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4485 - val_loss: 10.0857\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2538 - val_loss: 9.9815\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3760 - val_loss: 9.2711\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4787 - val_loss: 10.2131\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4237 - val_loss: 10.2144\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3759 - val_loss: 10.2286\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2166 - val_loss: 9.7210\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2870 - val_loss: 10.0260\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3540 - val_loss: 9.6127\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2515 - val_loss: 9.9670\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2602 - val_loss: 10.1359\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2941 - val_loss: 10.2213\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4395 - val_loss: 9.7164\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2897 - val_loss: 10.2801\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3632 - val_loss: 10.2588\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2769 - val_loss: 9.8237\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3014 - val_loss: 9.6091\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2301 - val_loss: 9.9194\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4204 - val_loss: 9.5916\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5398 - val_loss: 10.2773\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3390 - val_loss: 10.0210\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2811 - val_loss: 10.1127\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3221 - val_loss: 9.6433\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2186 - val_loss: 10.1007\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2497 - val_loss: 9.6949\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.3793 - val_loss: 10.5763\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5206 - val_loss: 10.0079\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4291 - val_loss: 9.7816\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5212 - val_loss: 10.9419\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.6700 - val_loss: 9.5184\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4406 - val_loss: 11.5583\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7428 - val_loss: 9.4153\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5675 - val_loss: 10.9632\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3652 - val_loss: 9.5978\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4939 - val_loss: 11.3400\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4091 - val_loss: 9.7965\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4006 - val_loss: 9.7047\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3300 - val_loss: 10.4736\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4215 - val_loss: 9.7960\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2635 - val_loss: 10.3115\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4385 - val_loss: 10.2765\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2877 - val_loss: 10.0293\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3378 - val_loss: 10.3534\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.3405 - val_loss: 9.6103\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3217 - val_loss: 10.4413\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3413 - val_loss: 9.7857\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6354 - val_loss: 10.7549\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5291 - val_loss: 9.7904\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4533 - val_loss: 10.5938\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3658 - val_loss: 9.9505\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2897 - val_loss: 9.8297\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2979 - val_loss: 10.3807\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3812 - val_loss: 9.5082\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5548 - val_loss: 10.5994\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2890 - val_loss: 10.1638\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2932 - val_loss: 10.0547\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5421 - val_loss: 11.0786\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5321 - val_loss: 9.5949\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5694 - val_loss: 11.2752\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4373 - val_loss: 9.9132\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3428 - val_loss: 10.1421\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3373 - val_loss: 9.8324\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5018 - val_loss: 9.7809\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2886 - val_loss: 10.6428\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4080 - val_loss: 9.5127\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4772 - val_loss: 10.8170\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 98us/step - loss: 5.5851 - val_loss: 9.5621\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7585 - val_loss: 11.5815\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4959 - val_loss: 10.2567\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3012 - val_loss: 10.0022\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4047 - val_loss: 9.8445\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4091 - val_loss: 10.1243\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3924 - val_loss: 10.5695\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2693 - val_loss: 9.8081\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4975 - val_loss: 10.7874\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6457 - val_loss: 9.4604\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4702 - val_loss: 10.8895\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3942 - val_loss: 9.8517\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3495 - val_loss: 10.2328\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3317 - val_loss: 9.9266\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3177 - val_loss: 9.9994\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4337 - val_loss: 11.1937\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.4431 - val_loss: 9.8376\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2544 - val_loss: 10.4850\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3678 - val_loss: 9.9685\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5329 - val_loss: 9.7043\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2901 - val_loss: 10.7288\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5079 - val_loss: 9.9796\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5169 - val_loss: 10.0873\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3428 - val_loss: 9.6528\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2941 - val_loss: 11.0038\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4240 - val_loss: 9.8103\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2868 - val_loss: 10.0910\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3383 - val_loss: 10.2251\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2651 - val_loss: 9.8990\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3140 - val_loss: 9.9644\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2563 - val_loss: 10.4431\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2748 - val_loss: 10.1231\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4312 - val_loss: 10.5369\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2669 - val_loss: 10.0533\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3855 - val_loss: 10.0517\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5046 - val_loss: 11.0201\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4303 - val_loss: 9.8572\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3627 - val_loss: 10.6066\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2582 - val_loss: 9.7242\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3401 - val_loss: 10.5419\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4092 - val_loss: 10.2462\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4359 - val_loss: 9.7631\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2986 - val_loss: 10.1303\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3959 - val_loss: 9.8239\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7252 - val_loss: 10.7723\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5173 - val_loss: 10.5474\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3563 - val_loss: 9.8303\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4084 - val_loss: 10.4329\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3017 - val_loss: 9.9025\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6417 - val_loss: 10.8149\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4254 - val_loss: 9.7252\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2581 - val_loss: 10.4075\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1979 - val_loss: 9.9395\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4332 - val_loss: 10.7012\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4355 - val_loss: 9.8493\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6971 - val_loss: 11.6511\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6625 - val_loss: 9.9236\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7163 - val_loss: 9.6052\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4458 - val_loss: 11.4470\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.6167 - val_loss: 9.8095\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 5.3991 - val_loss: 11.5605\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 117us/step - loss: 6.3537 - val_loss: 9.7807\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5011 - val_loss: 10.9147\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5703 - val_loss: 9.9188\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3324 - val_loss: 10.5717\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3823 - val_loss: 9.9458\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2762 - val_loss: 10.5243\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2372 - val_loss: 10.0616\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3127 - val_loss: 10.5642\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2697 - val_loss: 9.9515\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6249 - val_loss: 11.4064\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2833 - val_loss: 9.8074\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5551 - val_loss: 10.2340\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3979 - val_loss: 10.4127\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3118 - val_loss: 10.1199\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3459 - val_loss: 9.8797\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4143 - val_loss: 9.9695\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 95us/step - loss: 5.4768 - val_loss: 11.4811\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4605 - val_loss: 9.8250\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5786 - val_loss: 10.5931\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3439 - val_loss: 10.1206\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2420 - val_loss: 10.5295\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4249 - val_loss: 9.7780\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2991 - val_loss: 10.3677\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3092 - val_loss: 10.0154\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3063 - val_loss: 9.7456\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3445 - val_loss: 10.6653\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5687 - val_loss: 9.7168\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2876 - val_loss: 10.1201\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5284 - val_loss: 10.3690\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4989 - val_loss: 10.1238\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2926 - val_loss: 10.2921\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4995 - val_loss: 10.2600\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8770 - val_loss: 10.1169\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8128 - val_loss: 11.3227\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2275 - val_loss: 9.8371\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2367 - val_loss: 10.8960\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2403 - val_loss: 9.5966\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.2732 - val_loss: 11.1439\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3886 - val_loss: 9.9882\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3562 - val_loss: 10.1216\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4272 - val_loss: 10.5976\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2533 - val_loss: 10.1796\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4125 - val_loss: 11.8184\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4790 - val_loss: 9.6373\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4653 - val_loss: 11.6238\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2580 - val_loss: 9.8909\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5201 - val_loss: 10.5845\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4424 - val_loss: 10.7607\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2209 - val_loss: 10.3029\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2790 - val_loss: 10.6191\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3256 - val_loss: 9.9976\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3639 - val_loss: 11.1281\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4910 - val_loss: 10.0692\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.4325 - val_loss: 10.6545\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3240 - val_loss: 10.1212\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4027 - val_loss: 10.2128\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3995 - val_loss: 10.6184\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2970 - val_loss: 10.4383\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2743 - val_loss: 10.4656\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3567 - val_loss: 10.3353\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.3881 - val_loss: 10.3658\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4832 - val_loss: 9.7081\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4815 - val_loss: 11.5003\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5244 - val_loss: 9.6495\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8231 - val_loss: 11.4688\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6783 - val_loss: 10.0024\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2906 - val_loss: 10.3364\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2592 - val_loss: 10.0288\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2993 - val_loss: 9.9455\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3077 - val_loss: 10.5359\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4290 - val_loss: 10.0500\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2901 - val_loss: 10.5029\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3208 - val_loss: 10.5274\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3325 - val_loss: 9.8526\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5116 - val_loss: 11.9805\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8754 - val_loss: 10.1136\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5682 - val_loss: 9.9194\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5162 - val_loss: 10.5991\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4435 - val_loss: 10.1015\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.3738 - val_loss: 10.3065\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2709 - val_loss: 9.9689\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2355 - val_loss: 10.7370\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4057 - val_loss: 10.9246\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2760 - val_loss: 9.5499\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2971 - val_loss: 10.3288\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2555 - val_loss: 10.0161\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2902 - val_loss: 10.0601\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3226 - val_loss: 10.5003\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2945 - val_loss: 10.3949\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4368 - val_loss: 10.5646\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2362 - val_loss: 10.1575\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1943 - val_loss: 10.0503\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3656 - val_loss: 10.8351\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 101us/step - loss: 5.2393 - val_loss: 9.8013\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2539 - val_loss: 11.8156\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.6309 - val_loss: 10.1462\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7144 - val_loss: 11.7137\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.9472 - val_loss: 9.8926\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2776 - val_loss: 10.7821\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9214 - val_loss: 11.1033\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8023 - val_loss: 9.8330\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9367 - val_loss: 11.7063\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4837 - val_loss: 9.5346\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4027 - val_loss: 11.1989\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4865 - val_loss: 9.7292\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4115 - val_loss: 10.3251\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4009 - val_loss: 10.2717\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3047 - val_loss: 10.2333\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2435 - val_loss: 10.4726\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4110 - val_loss: 10.2100\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2361 - val_loss: 10.6510\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3301 - val_loss: 10.1624\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2133 - val_loss: 10.2984\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4505 - val_loss: 10.0487\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3084 - val_loss: 10.6288\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2725 - val_loss: 9.6799\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3704 - val_loss: 10.6212\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3619 - val_loss: 10.1834\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4584 - val_loss: 10.7062\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3956 - val_loss: 10.0946\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3735 - val_loss: 10.7554\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2349 - val_loss: 9.8318\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.2988 - val_loss: 10.9500\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3338 - val_loss: 9.9802\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5239 - val_loss: 10.4034\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5229 - val_loss: 10.6452\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6493 - val_loss: 9.6653\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2599 - val_loss: 10.4376\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2418 - val_loss: 10.1843\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3205 - val_loss: 10.5644\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6083 - val_loss: 9.8350\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4800 - val_loss: 10.7436\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2514 - val_loss: 10.0140\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4172 - val_loss: 10.2670\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2025 - val_loss: 10.0325\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3201 - val_loss: 10.3966\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3032 - val_loss: 10.5799\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3328 - val_loss: 9.9964\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2447 - val_loss: 10.7715\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3227 - val_loss: 9.9296\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4091 - val_loss: 10.6296\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4507 - val_loss: 9.8127\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5496 - val_loss: 11.3526\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2506 - val_loss: 9.9137\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6036 - val_loss: 10.5653\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2218 - val_loss: 10.0133\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2973 - val_loss: 11.1413\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5707 - val_loss: 10.1118\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4127 - val_loss: 9.8261\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2565 - val_loss: 10.7453\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4468 - val_loss: 10.3723\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2533 - val_loss: 11.0549\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3010 - val_loss: 9.9983\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1873 - val_loss: 10.3691\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.3808 - val_loss: 10.7090\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3344 - val_loss: 10.4352\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3009 - val_loss: 10.8019\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3876 - val_loss: 10.1571\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3686 - val_loss: 10.3584\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3192 - val_loss: 10.1102\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3008 - val_loss: 10.9046\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4897 - val_loss: 10.1712\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5710 - val_loss: 11.6488\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5527 - val_loss: 9.9232\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5546 - val_loss: 10.2282\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3487 - val_loss: 10.6513\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3476 - val_loss: 10.5604\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2306 - val_loss: 10.4314\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4373 - val_loss: 9.6428\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3154 - val_loss: 10.3302\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 104us/step - loss: 5.2888 - val_loss: 10.6488\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2131 - val_loss: 10.4896\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3115 - val_loss: 10.2330\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2304 - val_loss: 10.3609\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2446 - val_loss: 10.4470\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3719 - val_loss: 9.9938\n",
      "6.785681579072596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.23527598,  0.18306047,  0.630229  ,  0.8335271 ,  0.16864413],\n",
       "        [-0.65516126,  0.09108444, -0.5733426 , -3.076668  , -2.27919   ],\n",
       "        [ 0.24807127, -0.601133  ,  0.22050197, -4.3621316 , -1.9919835 ],\n",
       "        [ 0.8391864 , -0.05638067, -0.5408989 ,  1.3992935 ,  1.1614571 ],\n",
       "        [ 0.08347924,  0.49276072, -1.1711944 , -1.2726746 , -0.8501271 ],\n",
       "        [-1.0115194 , -0.4390346 ,  1.3667979 , -0.35400954, -0.50223213],\n",
       "        [ 0.04465767, -0.03045928,  0.9625578 ,  1.9132023 ,  0.40727934]],\n",
       "       dtype=float32),\n",
       " array([ 0.9730627 , -0.86702555,  2.3616784 ,  0.6365921 , -0.2114679 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.4725439 , -0.9842037 ,  0.63340497, -0.3650821 , -0.6513353 ,\n",
       "          0.21806085,  0.94043946, -0.26007622, -0.2119163 , -0.8563147 ],\n",
       "        [-0.8652151 ,  0.2767465 ,  0.07263525,  0.67462254,  1.1010232 ,\n",
       "         -0.6880427 , -0.27892098,  0.4513003 ,  0.05095565,  0.9372603 ],\n",
       "        [-0.5553656 , -0.14808664,  0.04055563,  0.08967166,  0.43042585,\n",
       "          0.04391629, -0.21659173,  0.3669418 ,  0.73496336,  0.7242884 ],\n",
       "        [ 1.2982441 , -0.35696226,  0.219033  ,  0.02975122, -0.39484707,\n",
       "          0.7156144 ,  0.44489813, -0.81571645, -0.03510338, -0.43399692],\n",
       "        [-0.6752401 ,  0.5353796 , -0.81867063,  0.09198087,  0.70174325,\n",
       "         -0.6036886 , -0.8409507 ,  1.142349  ,  1.2762508 ,  0.15830387]],\n",
       "       dtype=float32),\n",
       " array([-2.0376508,  1.8835396, -1.9075036,  1.7723131,  1.8857509,\n",
       "        -1.9392184, -1.918776 ,  1.8233342,  1.8501006,  1.8902525],\n",
       "       dtype=float32),\n",
       " array([[-1.4753923],\n",
       "        [ 1.694672 ],\n",
       "        [-1.2249676],\n",
       "        [ 0.9993425],\n",
       "        [ 1.5466877],\n",
       "        [-0.9871599],\n",
       "        [-1.3383372],\n",
       "        [ 1.5137507],\n",
       "        [ 1.4287447],\n",
       "        [ 1.6582668]], dtype=float32),\n",
       " array([1.7712945], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_adam_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 509us/step - loss: 612.6696 - val_loss: 652.0219\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 611.0200 - val_loss: 649.7622\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 608.7844 - val_loss: 647.1057\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 606.3529 - val_loss: 644.3152\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 603.7739 - val_loss: 641.5470\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 601.2520 - val_loss: 638.7526\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 598.7132 - val_loss: 635.9537\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 596.1625 - val_loss: 633.1833\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 593.6916 - val_loss: 630.3638\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 591.1399 - val_loss: 627.5848\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 588.6325 - val_loss: 624.8169\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 586.0793 - val_loss: 622.1411\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 583.6116 - val_loss: 619.4377\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 581.1293 - val_loss: 616.7089\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 578.6427 - val_loss: 613.9543\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 576.1290 - val_loss: 611.1841\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 573.5953 - val_loss: 608.4627\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 571.0963 - val_loss: 605.7004\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 568.5425 - val_loss: 602.9519\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 566.0286 - val_loss: 600.1671\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 563.5109 - val_loss: 597.3598\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 560.8910 - val_loss: 594.6426\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 558.3750 - val_loss: 591.8058\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 555.7186 - val_loss: 589.0047\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 553.1168 - val_loss: 586.1662\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 550.5015 - val_loss: 583.2891\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 547.8992 - val_loss: 580.3451\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 545.1947 - val_loss: 577.4476\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 542.4919 - val_loss: 574.5735\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 539.8244 - val_loss: 571.6892\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 537.1564 - val_loss: 568.7461\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 534.3751 - val_loss: 565.8519\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 531.6962 - val_loss: 562.8211\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 528.8974 - val_loss: 559.8038\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 526.0889 - val_loss: 556.7864\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 523.2638 - val_loss: 553.7144\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 520.4013 - val_loss: 550.5453\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 517.4265 - val_loss: 547.4271\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 514.5372 - val_loss: 544.2478\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 511.5613 - val_loss: 541.0379\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 508.5587 - val_loss: 537.7924\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 505.5363 - val_loss: 534.4877\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 502.4702 - val_loss: 531.1300\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 499.3791 - val_loss: 527.7474\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 496.2107 - val_loss: 524.3799\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 493.0819 - val_loss: 520.9574\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 489.8037 - val_loss: 517.5852\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 486.6499 - val_loss: 513.9922\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 483.2649 - val_loss: 510.4272\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 480.0461 - val_loss: 506.6885\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 476.5978 - val_loss: 503.0040\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 473.1690 - val_loss: 499.3138\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 469.6626 - val_loss: 495.6598\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 466.2353 - val_loss: 491.8793\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 462.7360 - val_loss: 488.0082\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 459.1063 - val_loss: 484.1041\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 455.5046 - val_loss: 480.1147\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 451.7569 - val_loss: 476.1714\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 448.1068 - val_loss: 472.1073\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 444.2945 - val_loss: 468.0557\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 440.5007 - val_loss: 463.9021\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 436.6459 - val_loss: 459.6592\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 432.6530 - val_loss: 455.4760\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 428.7409 - val_loss: 451.1718\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 424.7792 - val_loss: 446.7685\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 420.6235 - val_loss: 442.4180\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 416.5824 - val_loss: 437.9178\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 412.3758 - val_loss: 433.4041\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 408.1419 - val_loss: 428.8218\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 403.8501 - val_loss: 424.1724\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 399.4738 - val_loss: 419.4849\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 395.0726 - val_loss: 414.7162\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 390.6288 - val_loss: 409.8833\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 386.1241 - val_loss: 404.9686\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 381.5279 - val_loss: 400.0697\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 376.9061 - val_loss: 395.1244\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 372.2360 - val_loss: 390.1173\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 367.5141 - val_loss: 385.0040\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 362.6918 - val_loss: 379.8430\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 357.8673 - val_loss: 374.6157\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 352.9427 - val_loss: 369.3561\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 347.9757 - val_loss: 364.0429\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 342.9919 - val_loss: 358.6639\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 337.9055 - val_loss: 353.2621\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 332.7614 - val_loss: 347.8688\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 327.6198 - val_loss: 342.4066\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 322.4149 - val_loss: 336.8623\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 317.1427 - val_loss: 331.2030\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 311.8164 - val_loss: 325.4795\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 306.3788 - val_loss: 319.8029\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 300.9971 - val_loss: 314.1088\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 295.5928 - val_loss: 308.3807\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 290.1458 - val_loss: 302.6036\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 284.6209 - val_loss: 296.8428\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 279.1179 - val_loss: 291.0206\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 273.5049 - val_loss: 285.2194\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 267.9071 - val_loss: 279.3966\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 262.3005 - val_loss: 273.5123\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 256.6253 - val_loss: 267.5690\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 250.9201 - val_loss: 261.6391\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 245.2449 - val_loss: 255.6900\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 239.4107 - val_loss: 249.7944\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 233.7343 - val_loss: 243.8307\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 227.9465 - val_loss: 237.8479\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 222.1430 - val_loss: 231.8595\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 216.3695 - val_loss: 225.8509\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 210.5959 - val_loss: 219.8361\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 204.8449 - val_loss: 213.9020\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 199.0805 - val_loss: 208.0061\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 193.3847 - val_loss: 202.1383\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 187.6812 - val_loss: 196.3558\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 182.0582 - val_loss: 190.5957\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 176.5179 - val_loss: 184.8575\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 170.9712 - val_loss: 179.1712\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 165.4935 - val_loss: 173.5231\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 160.0874 - val_loss: 168.0007\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 154.7638 - val_loss: 162.5795\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 149.5782 - val_loss: 157.2380\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 144.3790 - val_loss: 152.0163\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 139.4292 - val_loss: 146.8633\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 134.4714 - val_loss: 141.8107\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 129.6152 - val_loss: 136.8649\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 124.9093 - val_loss: 131.9656\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 120.2215 - val_loss: 127.2448\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 115.7278 - val_loss: 122.5601\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 111.2949 - val_loss: 118.0307\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 107.0169 - val_loss: 113.6092\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 102.9079 - val_loss: 109.3364\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 98.8918 - val_loss: 105.2359\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 95.0428 - val_loss: 101.2541\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 91.2873 - val_loss: 97.3951\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 87.6769 - val_loss: 93.6846\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 84.2262 - val_loss: 90.0695\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 80.9128 - val_loss: 86.5818\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 77.6717 - val_loss: 83.2848\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 74.6267 - val_loss: 80.0490\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 71.6462 - val_loss: 76.9725\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 68.8266 - val_loss: 73.9891\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 66.0779 - val_loss: 71.1373\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 63.4988 - val_loss: 68.3859\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 60.9746 - val_loss: 65.7824\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 58.6088 - val_loss: 63.2691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 56.3745 - val_loss: 60.8549\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 54.1235 - val_loss: 58.6303\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 52.1164 - val_loss: 56.4309\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 50.1644 - val_loss: 54.3407\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 48.3065 - val_loss: 52.3800\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 46.5359 - val_loss: 50.5511\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 44.8812 - val_loss: 48.7982\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 43.3284 - val_loss: 47.1012\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 41.8442 - val_loss: 45.4683\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 40.4006 - val_loss: 43.9313\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 39.0034 - val_loss: 42.4989\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 37.7493 - val_loss: 41.0975\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 36.5251 - val_loss: 39.7806\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 35.3771 - val_loss: 38.5361\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 34.3083 - val_loss: 37.3652\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 33.2773 - val_loss: 36.2979\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 32.3494 - val_loss: 35.2655\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 31.4406 - val_loss: 34.2975\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 30.6163 - val_loss: 33.3616\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 29.8135 - val_loss: 32.4819\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 29.0492 - val_loss: 31.6524\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 28.3223 - val_loss: 30.8868\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 27.6868 - val_loss: 30.1353\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 27.0281 - val_loss: 29.4707\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 26.4757 - val_loss: 28.7877\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 25.9128 - val_loss: 28.1666\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 25.3866 - val_loss: 27.6016\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 24.9147 - val_loss: 27.0472\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.4484 - val_loss: 26.5283\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.0013 - val_loss: 26.0575\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 23.6016 - val_loss: 25.5892\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 23.2232 - val_loss: 25.1512\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 22.8541 - val_loss: 24.7484\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.5218 - val_loss: 24.3537\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 22.1819 - val_loss: 23.9945\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.8922 - val_loss: 23.6453\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.6288 - val_loss: 23.2968\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.3360 - val_loss: 23.0084\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 21.0885 - val_loss: 22.7300\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.8748 - val_loss: 22.4519\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 20.6510 - val_loss: 22.1914\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 20.4330 - val_loss: 21.9606\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.2492 - val_loss: 21.7303\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.0602 - val_loss: 21.5221\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.8924 - val_loss: 21.3223\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.7351 - val_loss: 21.1310\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.5790 - val_loss: 20.9587\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.4379 - val_loss: 20.7918\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.3092 - val_loss: 20.6259\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.1770 - val_loss: 20.4716\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.0590 - val_loss: 20.3246\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.9460 - val_loss: 20.1855\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.8338 - val_loss: 20.0573\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.7348 - val_loss: 19.9355\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.6356 - val_loss: 19.8229\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.5392 - val_loss: 19.7190\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4635 - val_loss: 19.6058\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 18.3658 - val_loss: 19.5113\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.3005 - val_loss: 19.4070\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.2146 - val_loss: 19.3153\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 18.1376 - val_loss: 19.2284\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.0695 - val_loss: 19.1422\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.0005 - val_loss: 19.0573\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.9372 - val_loss: 18.9776\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.8778 - val_loss: 18.9035\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.8177 - val_loss: 18.8377\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.7618 - val_loss: 18.7720\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7120 - val_loss: 18.7035\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6543 - val_loss: 18.6424\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6025 - val_loss: 18.5830\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 17.5542 - val_loss: 18.5196\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.5038 - val_loss: 18.4575\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.4558 - val_loss: 18.3979\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.4084 - val_loss: 18.3413\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.3642 - val_loss: 18.2890\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3244 - val_loss: 18.2344\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 17.2805 - val_loss: 18.1820\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.2390 - val_loss: 18.1359\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.1983 - val_loss: 18.0957\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1651 - val_loss: 18.0498\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 17.1264 - val_loss: 18.0053\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0877 - val_loss: 17.9642\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0565 - val_loss: 17.9235\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.0234 - val_loss: 17.8799\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9852 - val_loss: 17.8426\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9545 - val_loss: 17.8062\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9222 - val_loss: 17.7717\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8899 - val_loss: 17.7379\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8580 - val_loss: 17.7043\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.8279 - val_loss: 17.6642\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7975 - val_loss: 17.6249\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7687 - val_loss: 17.5894\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7367 - val_loss: 17.5580\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7067 - val_loss: 17.5313\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6849 - val_loss: 17.4943\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.6507 - val_loss: 17.4678\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6239 - val_loss: 17.4375\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5954 - val_loss: 17.4061\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.5701 - val_loss: 17.3750\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.5440 - val_loss: 17.3440\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.5147 - val_loss: 17.3197\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4919 - val_loss: 17.2943\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.4652 - val_loss: 17.2667\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.4397 - val_loss: 17.2403\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4136 - val_loss: 17.2149\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 16.3885 - val_loss: 17.1894\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 16.3665 - val_loss: 17.1596\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 16.3388 - val_loss: 17.1348\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.3148 - val_loss: 17.1123\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2919 - val_loss: 17.0888\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2680 - val_loss: 17.0684\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2446 - val_loss: 17.0460\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.2228 - val_loss: 17.0245\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1985 - val_loss: 17.0015\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1783 - val_loss: 16.9756\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1527 - val_loss: 16.9548\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1295 - val_loss: 16.9319\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1077 - val_loss: 16.9096\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0868 - val_loss: 16.8849\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0613 - val_loss: 16.8636\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0398 - val_loss: 16.8428\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0184 - val_loss: 16.8219\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9955 - val_loss: 16.8011\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9747 - val_loss: 16.7777\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9530 - val_loss: 16.7583\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9296 - val_loss: 16.7392\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9110 - val_loss: 16.7135\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.8870 - val_loss: 16.6939\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 15.8650 - val_loss: 16.6737\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8444 - val_loss: 16.6535\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8231 - val_loss: 16.6353\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8033 - val_loss: 16.6147\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7828 - val_loss: 16.5949\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7618 - val_loss: 16.5772\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 15.7439 - val_loss: 16.5561\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.7227 - val_loss: 16.5382\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7023 - val_loss: 16.5209\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6828 - val_loss: 16.5030\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.6662 - val_loss: 16.4803\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6422 - val_loss: 16.4646\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.6230 - val_loss: 16.4479\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6034 - val_loss: 16.4290\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 15.5832 - val_loss: 16.4098\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 15.5644 - val_loss: 16.3911\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5443 - val_loss: 16.3735\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.5247 - val_loss: 16.3550\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.5057 - val_loss: 16.3359\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4873 - val_loss: 16.3188\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4681 - val_loss: 16.3012\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.4507 - val_loss: 16.2829\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.4314 - val_loss: 16.2670\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.4123 - val_loss: 16.2539\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 15.3947 - val_loss: 16.2358\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3760 - val_loss: 16.2212\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.3578 - val_loss: 16.2072\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.3398 - val_loss: 16.1898\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3229 - val_loss: 16.1732\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3042 - val_loss: 16.1590\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.2861 - val_loss: 16.1438\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.2697 - val_loss: 16.1297\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2519 - val_loss: 16.1139\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.2350 - val_loss: 16.1012\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2174 - val_loss: 16.0857\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2013 - val_loss: 16.0738\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.1847 - val_loss: 16.0598\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.1678 - val_loss: 16.0476\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 15.1509 - val_loss: 16.0276\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 15.1318 - val_loss: 16.0115\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.1147 - val_loss: 15.9970\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.0969 - val_loss: 15.9835\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.0807 - val_loss: 15.9694\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0642 - val_loss: 15.9570\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.0500 - val_loss: 15.9409\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 15.0316 - val_loss: 15.9287\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.0157 - val_loss: 15.9159\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.9999 - val_loss: 15.9021\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9833 - val_loss: 15.8890\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9677 - val_loss: 15.8761\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9515 - val_loss: 15.8621\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.9360 - val_loss: 15.8448\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9199 - val_loss: 15.8298\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9034 - val_loss: 15.8188\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.8880 - val_loss: 15.8058\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8715 - val_loss: 15.7893\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8553 - val_loss: 15.7752\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8414 - val_loss: 15.7600\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.8244 - val_loss: 15.7482\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.8088 - val_loss: 15.7366\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7943 - val_loss: 15.7256\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7790 - val_loss: 15.7137\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 14.7660 - val_loss: 15.6996\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.7488 - val_loss: 15.6874\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7353 - val_loss: 15.6775\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7199 - val_loss: 15.6635\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7055 - val_loss: 15.6499\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6892 - val_loss: 15.6386\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6757 - val_loss: 15.6277\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6603 - val_loss: 15.6151\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.6464 - val_loss: 15.6028\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6317 - val_loss: 15.5932\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 14.6182 - val_loss: 15.5809\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6034 - val_loss: 15.5686\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5887 - val_loss: 15.5554\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.5754 - val_loss: 15.5428\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5601 - val_loss: 15.5339\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5470 - val_loss: 15.5209\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.5322 - val_loss: 15.5100\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5199 - val_loss: 15.4967\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.5046 - val_loss: 15.4858\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4906 - val_loss: 15.4761\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 14.4763 - val_loss: 15.4661\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4632 - val_loss: 15.4563\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4499 - val_loss: 15.4442\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4364 - val_loss: 15.4336\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.4242 - val_loss: 15.4204\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4109 - val_loss: 15.4109\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3960 - val_loss: 15.4011\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3829 - val_loss: 15.3910\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.3698 - val_loss: 15.3825\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3573 - val_loss: 15.3726\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.3436 - val_loss: 15.3627\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 14.3323 - val_loss: 15.3530\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3180 - val_loss: 15.3437\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.3051 - val_loss: 15.3340\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.2924 - val_loss: 15.3199\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.2786 - val_loss: 15.3087\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2661 - val_loss: 15.2994\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2541 - val_loss: 15.2886\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 14.2411 - val_loss: 15.2763\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2282 - val_loss: 15.2653\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2151 - val_loss: 15.2561\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.2041 - val_loss: 15.2484\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.1900 - val_loss: 15.2403\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1780 - val_loss: 15.2318\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1668 - val_loss: 15.2232\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1530 - val_loss: 15.2112\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1406 - val_loss: 15.2005\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.1286 - val_loss: 15.1885\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1153 - val_loss: 15.1789\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.1042 - val_loss: 15.1692\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0917 - val_loss: 15.1587\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0806 - val_loss: 15.1473\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0700 - val_loss: 15.1369\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0562 - val_loss: 15.1297\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0448 - val_loss: 15.1199\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0324 - val_loss: 15.1121\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.0208 - val_loss: 15.1030\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.0091 - val_loss: 15.0950\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9981 - val_loss: 15.0875\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9855 - val_loss: 15.0812\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9753 - val_loss: 15.0749\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9633 - val_loss: 15.0657\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9532 - val_loss: 15.0551\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9405 - val_loss: 15.0472\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9294 - val_loss: 15.0396\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9185 - val_loss: 15.0304\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9087 - val_loss: 15.0214\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8961 - val_loss: 15.0151\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8842 - val_loss: 15.0076\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8746 - val_loss: 15.0005\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8630 - val_loss: 14.9914\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8511 - val_loss: 14.9831\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8397 - val_loss: 14.9735\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.8301 - val_loss: 14.9626\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8181 - val_loss: 14.9570\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8079 - val_loss: 14.9491\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7965 - val_loss: 14.9423\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7868 - val_loss: 14.9344\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7746 - val_loss: 14.9270\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7649 - val_loss: 14.9166\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7559 - val_loss: 14.9059\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7415 - val_loss: 14.9003\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7331 - val_loss: 14.8902\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7212 - val_loss: 14.8826\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7118 - val_loss: 14.8769\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7000 - val_loss: 14.8692\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6891 - val_loss: 14.8601\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6796 - val_loss: 14.8504\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6690 - val_loss: 14.8419\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6592 - val_loss: 14.8322\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6483 - val_loss: 14.8250\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6377 - val_loss: 14.8188\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.6275 - val_loss: 14.8142\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6175 - val_loss: 14.8059\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6067 - val_loss: 14.7972\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5979 - val_loss: 14.7853\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5865 - val_loss: 14.7777\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5756 - val_loss: 14.7716\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5662 - val_loss: 14.7650\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5572 - val_loss: 14.7595\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5464 - val_loss: 14.7503\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5372 - val_loss: 14.7418\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.5270 - val_loss: 14.7350\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5162 - val_loss: 14.7261\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5053 - val_loss: 14.7186\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4959 - val_loss: 14.7115\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4863 - val_loss: 14.7045\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4767 - val_loss: 14.6961\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.4678 - val_loss: 14.6885\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4573 - val_loss: 14.6807\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4479 - val_loss: 14.6744\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 13.4381 - val_loss: 14.6690\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4299 - val_loss: 14.6644\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4196 - val_loss: 14.6534\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 13.4089 - val_loss: 14.6450\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4005 - val_loss: 14.6354\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3893 - val_loss: 14.6293\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3808 - val_loss: 14.6221\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3708 - val_loss: 14.6160\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3621 - val_loss: 14.6076\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3526 - val_loss: 14.5986\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3429 - val_loss: 14.5933\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3335 - val_loss: 14.5843\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3225 - val_loss: 14.5758\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.3143 - val_loss: 14.5672\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3055 - val_loss: 14.5594\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2967 - val_loss: 14.5547\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.2870 - val_loss: 14.5458\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2772 - val_loss: 14.5384\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.2678 - val_loss: 14.5333\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2588 - val_loss: 14.5255\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2485 - val_loss: 14.5207\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2406 - val_loss: 14.5155\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.2313 - val_loss: 14.5102\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 13.2218 - val_loss: 14.5047\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2131 - val_loss: 14.4985\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.2046 - val_loss: 14.4936\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 13.1947 - val_loss: 14.4869\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1870 - val_loss: 14.4810\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1780 - val_loss: 14.4734\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 13.1686 - val_loss: 14.4656\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1609 - val_loss: 14.4631\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1515 - val_loss: 14.4558\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.1464 - val_loss: 14.4536\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1338 - val_loss: 14.4437\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1251 - val_loss: 14.4369\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.1158 - val_loss: 14.4291\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1087 - val_loss: 14.4194\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0989 - val_loss: 14.4114\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0934 - val_loss: 14.4032\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0816 - val_loss: 14.4001\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0737 - val_loss: 14.3936\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0653 - val_loss: 14.3883\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0558 - val_loss: 14.3830\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0475 - val_loss: 14.3766\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0392 - val_loss: 14.3706\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0306 - val_loss: 14.3656\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.0218 - val_loss: 14.3581\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0132 - val_loss: 14.3503\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0049 - val_loss: 14.3432\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9980 - val_loss: 14.3382\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9886 - val_loss: 14.3287\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9794 - val_loss: 14.3221\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9716 - val_loss: 14.3155\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9631 - val_loss: 14.3093\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.9547 - val_loss: 14.3052\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9470 - val_loss: 14.3005\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9381 - val_loss: 14.2948\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9300 - val_loss: 14.2881\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9215 - val_loss: 14.2835\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.9134 - val_loss: 14.2769\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9057 - val_loss: 14.2715\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8978 - val_loss: 14.2650\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8886 - val_loss: 14.2585\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8811 - val_loss: 14.2543\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.8720 - val_loss: 14.2480\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8642 - val_loss: 14.2398\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8555 - val_loss: 14.2321\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8477 - val_loss: 14.2251\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8414 - val_loss: 14.2220\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8315 - val_loss: 14.2152\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8236 - val_loss: 14.2084\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8157 - val_loss: 14.2031\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.8074 - val_loss: 14.1976\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7998 - val_loss: 14.1916\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7922 - val_loss: 14.1864\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7843 - val_loss: 14.1814\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7764 - val_loss: 14.1779\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.7682 - val_loss: 14.1723\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7608 - val_loss: 14.1684\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 73us/step - loss: 12.7530 - val_loss: 14.1616\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7454 - val_loss: 14.1558\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7387 - val_loss: 14.1521\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7299 - val_loss: 14.1444\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7220 - val_loss: 14.1392\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7142 - val_loss: 14.1339\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7064 - val_loss: 14.1292\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6985 - val_loss: 14.1260\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6925 - val_loss: 14.1202\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6847 - val_loss: 14.1167\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6778 - val_loss: 14.1140\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 12.6690 - val_loss: 14.1074\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.6615 - val_loss: 14.1005\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6550 - val_loss: 14.0950\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6461 - val_loss: 14.0906\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6389 - val_loss: 14.0834\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.6310 - val_loss: 14.0798\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6264 - val_loss: 14.0713\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6156 - val_loss: 14.0666\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6084 - val_loss: 14.0626\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.6023 - val_loss: 14.0543\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5933 - val_loss: 14.0488\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5869 - val_loss: 14.0430\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.5785 - val_loss: 14.0365\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.5708 - val_loss: 14.0324\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5636 - val_loss: 14.0279\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5561 - val_loss: 14.0215\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5490 - val_loss: 14.0164\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5404 - val_loss: 14.0130\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5345 - val_loss: 14.0079\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5265 - val_loss: 14.0032\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5197 - val_loss: 14.0011\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.5117 - val_loss: 13.9957\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5046 - val_loss: 13.9907\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.4975 - val_loss: 13.9852\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4912 - val_loss: 13.9814\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4835 - val_loss: 13.9767\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4778 - val_loss: 13.9715\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4693 - val_loss: 13.9680\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 12.4637 - val_loss: 13.9643\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4555 - val_loss: 13.9574\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4487 - val_loss: 13.9499\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4409 - val_loss: 13.9457\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4329 - val_loss: 13.9377\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.4268 - val_loss: 13.9309\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.4186 - val_loss: 13.9267\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4120 - val_loss: 13.9221\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4047 - val_loss: 13.9147\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3984 - val_loss: 13.9121\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3913 - val_loss: 13.9040\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3829 - val_loss: 13.8976\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3762 - val_loss: 13.8914\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3694 - val_loss: 13.8879\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3616 - val_loss: 13.8833\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3555 - val_loss: 13.8790\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3474 - val_loss: 13.8742\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3411 - val_loss: 13.8704\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3340 - val_loss: 13.8671\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3283 - val_loss: 13.8618\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3206 - val_loss: 13.8581\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3142 - val_loss: 13.8515\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3082 - val_loss: 13.8439\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2997 - val_loss: 13.8401\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2942 - val_loss: 13.8356\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.2875 - val_loss: 13.8310\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.2804 - val_loss: 13.8237\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.2722 - val_loss: 13.8189\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2662 - val_loss: 13.8153\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2598 - val_loss: 13.8112\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2530 - val_loss: 13.8071\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2466 - val_loss: 13.8020\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2401 - val_loss: 13.7962\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 12.2321 - val_loss: 13.7915\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.2254 - val_loss: 13.7876\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.2189 - val_loss: 13.7843\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2128 - val_loss: 13.7783\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 12.2057 - val_loss: 13.7750\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1986 - val_loss: 13.7697\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1938 - val_loss: 13.7673\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.1863 - val_loss: 13.7590\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 12.1823 - val_loss: 13.7531\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.1727 - val_loss: 13.7503\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.1660 - val_loss: 13.7472\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1593 - val_loss: 13.7445\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1543 - val_loss: 13.7415\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1474 - val_loss: 13.7382\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1412 - val_loss: 13.7349\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1351 - val_loss: 13.7320\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1286 - val_loss: 13.7256\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1226 - val_loss: 13.7206\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1156 - val_loss: 13.7168\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1088 - val_loss: 13.7122\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1029 - val_loss: 13.7063\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0964 - val_loss: 13.7003\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0900 - val_loss: 13.6943\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0833 - val_loss: 13.6898\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0772 - val_loss: 13.6857\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0707 - val_loss: 13.6812\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0647 - val_loss: 13.6764\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0576 - val_loss: 13.6709\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0513 - val_loss: 13.6657\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.0446 - val_loss: 13.6610\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0404 - val_loss: 13.6528\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0323 - val_loss: 13.6487\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.0254 - val_loss: 13.6451\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.0193 - val_loss: 13.6411\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0124 - val_loss: 13.6367\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0063 - val_loss: 13.6338\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0004 - val_loss: 13.6285\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9943 - val_loss: 13.6251\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9887 - val_loss: 13.6190\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.9822 - val_loss: 13.6163\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.9765 - val_loss: 13.6137\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 11.9715 - val_loss: 13.6102\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.9634 - val_loss: 13.6064\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.9576 - val_loss: 13.6034\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.9521 - val_loss: 13.5998\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.9454 - val_loss: 13.5943\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9392 - val_loss: 13.5900\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9334 - val_loss: 13.5868\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9286 - val_loss: 13.5805\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9210 - val_loss: 13.5763\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9145 - val_loss: 13.5714\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9100 - val_loss: 13.5642\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9029 - val_loss: 13.5594\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8976 - val_loss: 13.5531\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8901 - val_loss: 13.5461\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8849 - val_loss: 13.5407\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8779 - val_loss: 13.5357\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.8725 - val_loss: 13.5292\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8664 - val_loss: 13.5266\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8603 - val_loss: 13.5221\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8553 - val_loss: 13.5135\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8478 - val_loss: 13.5090\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8418 - val_loss: 13.5046\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8361 - val_loss: 13.4992\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8303 - val_loss: 13.4958\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.8236 - val_loss: 13.4917\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8184 - val_loss: 13.4891\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8127 - val_loss: 13.4855\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8066 - val_loss: 13.4815\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8003 - val_loss: 13.4756\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7950 - val_loss: 13.4719\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.7895 - val_loss: 13.4677\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7834 - val_loss: 13.4612\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7772 - val_loss: 13.4576\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7711 - val_loss: 13.4543\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 11.7670 - val_loss: 13.4495\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 10.84 - 0s 81us/step - loss: 11.7605 - val_loss: 13.4449\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7543 - val_loss: 13.4414\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7487 - val_loss: 13.4371\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.7446 - val_loss: 13.4344\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 80us/step - loss: 11.7379 - val_loss: 13.4266\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7312 - val_loss: 13.4220\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.7253 - val_loss: 13.4192\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.7195 - val_loss: 13.4157\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.7138 - val_loss: 13.4123\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.7077 - val_loss: 13.4076\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.7029 - val_loss: 13.4024\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.6965 - val_loss: 13.3966\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6921 - val_loss: 13.3947\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6848 - val_loss: 13.3886\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6796 - val_loss: 13.3833\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6743 - val_loss: 13.3785\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6679 - val_loss: 13.3761\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6629 - val_loss: 13.3730\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6568 - val_loss: 13.3698\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6514 - val_loss: 13.3657\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6455 - val_loss: 13.3633\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6407 - val_loss: 13.3601\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6359 - val_loss: 13.3573\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.6309 - val_loss: 13.3490\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6243 - val_loss: 13.3468\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.6194 - val_loss: 13.3409\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6121 - val_loss: 13.3390\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6082 - val_loss: 13.3332\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6010 - val_loss: 13.3297\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5955 - val_loss: 13.3235\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5914 - val_loss: 13.3191\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.5847 - val_loss: 13.3154\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5795 - val_loss: 13.3114\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5744 - val_loss: 13.3062\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5688 - val_loss: 13.3027\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5653 - val_loss: 13.2952\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5581 - val_loss: 13.2920\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5522 - val_loss: 13.2902\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5475 - val_loss: 13.2876\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5415 - val_loss: 13.2828\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.5374 - val_loss: 13.2789\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5320 - val_loss: 13.2729\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5262 - val_loss: 13.2706\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5216 - val_loss: 13.2657\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.5158 - val_loss: 13.2609\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5103 - val_loss: 13.2554\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5059 - val_loss: 13.2543\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4995 - val_loss: 13.2485\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4945 - val_loss: 13.2440\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4888 - val_loss: 13.2397\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.4835 - val_loss: 13.2352\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4778 - val_loss: 13.2317\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4732 - val_loss: 13.2296\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4674 - val_loss: 13.2261\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4624 - val_loss: 13.2241\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 40us/step - loss: 11.4579 - val_loss: 13.2187\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 115us/step - loss: 11.4521 - val_loss: 13.2158\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4470 - val_loss: 13.2129\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4415 - val_loss: 13.2100\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4373 - val_loss: 13.2068\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4313 - val_loss: 13.2024\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.4263 - val_loss: 13.1986\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.4220 - val_loss: 13.1934\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.4160 - val_loss: 13.1898\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4108 - val_loss: 13.1859\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.4069 - val_loss: 13.1800\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.4007 - val_loss: 13.1760\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.3952 - val_loss: 13.1749\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3908 - val_loss: 13.1720\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 11.3849 - val_loss: 13.1705\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.3803 - val_loss: 13.1684\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3751 - val_loss: 13.1654\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.3703 - val_loss: 13.1590\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3654 - val_loss: 13.1560\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3595 - val_loss: 13.1510\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3547 - val_loss: 13.1479\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.3509 - val_loss: 13.1445\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.3456 - val_loss: 13.1384\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3400 - val_loss: 13.1336\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.3350 - val_loss: 13.1296\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 11.3295 - val_loss: 13.1256\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3242 - val_loss: 13.1202\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.3196 - val_loss: 13.1154\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.3149 - val_loss: 13.1125\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 11.3093 - val_loss: 13.1071\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 11.3044 - val_loss: 13.1011\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 11.2993 - val_loss: 13.0981\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.2956 - val_loss: 13.0909\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2899 - val_loss: 13.0865\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2853 - val_loss: 13.0783\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 11.2792 - val_loss: 13.0738\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.2741 - val_loss: 13.0692\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.2690 - val_loss: 13.0650\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2651 - val_loss: 13.0611\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2594 - val_loss: 13.0549\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2545 - val_loss: 13.0511\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2502 - val_loss: 13.0452\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2448 - val_loss: 13.0406\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2402 - val_loss: 13.0371\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 11.2351 - val_loss: 13.0340\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2297 - val_loss: 13.0299\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2251 - val_loss: 13.0259\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2208 - val_loss: 13.0200\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.2159 - val_loss: 13.0168\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2119 - val_loss: 13.0096\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2064 - val_loss: 13.0067\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 11.2019 - val_loss: 13.0047\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1969 - val_loss: 12.9994\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1914 - val_loss: 12.9955\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1866 - val_loss: 12.9930\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.1822 - val_loss: 12.9907\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.1769 - val_loss: 12.9875\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.1724 - val_loss: 12.9848\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1672 - val_loss: 12.9832\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1632 - val_loss: 12.9813\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.1583 - val_loss: 12.9763\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1546 - val_loss: 12.9714\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.1489 - val_loss: 12.9680\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1448 - val_loss: 12.9669\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.1396 - val_loss: 12.9654\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1351 - val_loss: 12.9594\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1296 - val_loss: 12.9558\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 11.1263 - val_loss: 12.9528\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.1209 - val_loss: 12.9497\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 11.1164 - val_loss: 12.9441\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1114 - val_loss: 12.9399\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1067 - val_loss: 12.9388\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.1023 - val_loss: 12.9365\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0971 - val_loss: 12.9336\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.0933 - val_loss: 12.9302\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0881 - val_loss: 12.9255\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0839 - val_loss: 12.9201\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.0785 - val_loss: 12.9141\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0745 - val_loss: 12.9115\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0714 - val_loss: 12.9058\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 11.0654 - val_loss: 12.9021\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0605 - val_loss: 12.8984\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0557 - val_loss: 12.8948\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.0512 - val_loss: 12.8909\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0471 - val_loss: 12.8867\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0437 - val_loss: 12.8803\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0385 - val_loss: 12.8775\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0342 - val_loss: 12.8763\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0300 - val_loss: 12.8700\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0266 - val_loss: 12.8642\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.0202 - val_loss: 12.8603\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.0163 - val_loss: 12.8575\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.0114 - val_loss: 12.8531\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.0073 - val_loss: 12.8481\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.0021 - val_loss: 12.8449\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.9977 - val_loss: 12.8426\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.9944 - val_loss: 12.8375\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.9896 - val_loss: 12.8324\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9851 - val_loss: 12.8303\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.9808 - val_loss: 12.8266\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.9763 - val_loss: 12.8190\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 10.9708 - val_loss: 12.8164\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.9669 - val_loss: 12.8130\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.9627 - val_loss: 12.8085\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.9575 - val_loss: 12.8057\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9531 - val_loss: 12.8037\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.9492 - val_loss: 12.8011\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9443 - val_loss: 12.7970\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 10.9412 - val_loss: 12.7923\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9375 - val_loss: 12.7870\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.9312 - val_loss: 12.7841\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.9278 - val_loss: 12.7817\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 10.9225 - val_loss: 12.7757\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9186 - val_loss: 12.7727\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9148 - val_loss: 12.7672\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9096 - val_loss: 12.7639\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.9058 - val_loss: 12.7588\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.9006 - val_loss: 12.7554\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.8973 - val_loss: 12.7518\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.8924 - val_loss: 12.7483\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8879 - val_loss: 12.7469\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8836 - val_loss: 12.7434\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8798 - val_loss: 12.7411\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.8753 - val_loss: 12.7373\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.8719 - val_loss: 12.7366\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.8676 - val_loss: 12.7349\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.8631 - val_loss: 12.7315\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8587 - val_loss: 12.7253\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.8550 - val_loss: 12.7216\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.8507 - val_loss: 12.7178\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.8459 - val_loss: 12.7128\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.8416 - val_loss: 12.7083\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.8374 - val_loss: 12.7041\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8341 - val_loss: 12.6975\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8295 - val_loss: 12.6949\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8249 - val_loss: 12.6911\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.8215 - val_loss: 12.6891\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8173 - val_loss: 12.6855\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8126 - val_loss: 12.6820\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.8087 - val_loss: 12.6779\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.8039 - val_loss: 12.6748\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.8002 - val_loss: 12.6707\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7966 - val_loss: 12.6679\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.7919 - val_loss: 12.6639\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.7884 - val_loss: 12.6599\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7842 - val_loss: 12.6578\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 10.7799 - val_loss: 12.6537\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7762 - val_loss: 12.6488\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7713 - val_loss: 12.6459\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7686 - val_loss: 12.6446\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7632 - val_loss: 12.6396\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.7600 - val_loss: 12.6354\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7576 - val_loss: 12.6352\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7525 - val_loss: 12.6297\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.7477 - val_loss: 12.6277\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7435 - val_loss: 12.6229\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7406 - val_loss: 12.6174\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.7359 - val_loss: 12.6138\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.7316 - val_loss: 12.6074\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7278 - val_loss: 12.6024\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7254 - val_loss: 12.5967\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7195 - val_loss: 12.5941\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.7156 - val_loss: 12.5907\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.7116 - val_loss: 12.5895\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.7091 - val_loss: 12.5859\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.7030 - val_loss: 12.5847\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.6993 - val_loss: 12.5826\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6958 - val_loss: 12.5810\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.6928 - val_loss: 12.5777\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6879 - val_loss: 12.5726\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6845 - val_loss: 12.5704\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6808 - val_loss: 12.5652\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.6766 - val_loss: 12.5624\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.6725 - val_loss: 12.5602\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6685 - val_loss: 12.5557\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.6647 - val_loss: 12.5523\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.6611 - val_loss: 12.5498\n",
      "Epoch 903/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 10.6573 - val_loss: 12.5455\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.6532 - val_loss: 12.5415\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6499 - val_loss: 12.5340\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6459 - val_loss: 12.5313\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.6422 - val_loss: 12.5276\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.6385 - val_loss: 12.5257\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.6352 - val_loss: 12.5218\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6321 - val_loss: 12.5192\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.6280 - val_loss: 12.5143\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6229 - val_loss: 12.5125\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.6205 - val_loss: 12.5090\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6156 - val_loss: 12.5058\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.6122 - val_loss: 12.5050\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.6086 - val_loss: 12.5009\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.6046 - val_loss: 12.4963\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.6009 - val_loss: 12.4945\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5969 - val_loss: 12.4932\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5931 - val_loss: 12.4910\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.5897 - val_loss: 12.4882\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 10.5868 - val_loss: 12.4856\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.5828 - val_loss: 12.4846\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5788 - val_loss: 12.4821\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.5757 - val_loss: 12.4766\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5723 - val_loss: 12.4765\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5679 - val_loss: 12.4739\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5647 - val_loss: 12.4736\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5618 - val_loss: 12.4701\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5569 - val_loss: 12.4654\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.5527 - val_loss: 12.4621\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.5504 - val_loss: 12.4604\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5470 - val_loss: 12.4568\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.5429 - val_loss: 12.4558\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.5393 - val_loss: 12.4546\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5364 - val_loss: 12.4536\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.5333 - val_loss: 12.4502\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5279 - val_loss: 12.4495\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5251 - val_loss: 12.4484\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5213 - val_loss: 12.4452\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5175 - val_loss: 12.4431\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5142 - val_loss: 12.4387\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5117 - val_loss: 12.4337\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.5077 - val_loss: 12.4327\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.5064 - val_loss: 12.4273\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.5004 - val_loss: 12.4271\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.4963 - val_loss: 12.4264\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.4934 - val_loss: 12.4251\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.4894 - val_loss: 12.4221\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4860 - val_loss: 12.4184\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4828 - val_loss: 12.4155\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4796 - val_loss: 12.4109\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4753 - val_loss: 12.4087\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4719 - val_loss: 12.4065\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4682 - val_loss: 12.4029\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4644 - val_loss: 12.3989\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 10.4626 - val_loss: 12.3965\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4582 - val_loss: 12.3921\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4551 - val_loss: 12.3900\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4511 - val_loss: 12.3882\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4478 - val_loss: 12.3860\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4448 - val_loss: 12.3831\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4411 - val_loss: 12.3804\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4383 - val_loss: 12.3756\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4346 - val_loss: 12.3730\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4309 - val_loss: 12.3715\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4275 - val_loss: 12.3712\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4263 - val_loss: 12.3716\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4218 - val_loss: 12.3653\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4174 - val_loss: 12.3629\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4149 - val_loss: 12.3569\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.4096 - val_loss: 12.3537\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4073 - val_loss: 12.3516\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.4045 - val_loss: 12.3460\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.4002 - val_loss: 12.3430\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3967 - val_loss: 12.3393\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3938 - val_loss: 12.3361\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.3898 - val_loss: 12.3328\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 10.3872 - val_loss: 12.3313\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.3836 - val_loss: 12.3295\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3805 - val_loss: 12.3258\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3773 - val_loss: 12.3221\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3740 - val_loss: 12.3211\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3697 - val_loss: 12.3170\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.3675 - val_loss: 12.3109\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3630 - val_loss: 12.3092\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.3605 - val_loss: 12.3053\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3571 - val_loss: 12.3049\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3537 - val_loss: 12.3017\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3507 - val_loss: 12.2980\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 10.3468 - val_loss: 12.2975\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 10.3438 - val_loss: 12.2941\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3403 - val_loss: 12.2926\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.3366 - val_loss: 12.2882\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3338 - val_loss: 12.2833\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3307 - val_loss: 12.2778\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 10.3275 - val_loss: 12.2739\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3237 - val_loss: 12.2697\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 10.3206 - val_loss: 12.2675\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 10.3167 - val_loss: 12.2639\n",
      "10.073096687510862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.05231114,  0.12651244,  0.1263762 ,  0.19615713, -0.02172406],\n",
       "        [-0.19536307,  0.69421196,  0.2664603 , -0.282068  , -0.4209428 ],\n",
       "        [-0.22388889,  0.19541124, -0.00980441, -0.27860108,  0.0907437 ],\n",
       "        [-0.54777503,  0.50613326, -0.14097813, -0.09462523,  0.44924748],\n",
       "        [ 0.24199961, -0.07165147, -0.03769145, -0.17112769,  0.08668526],\n",
       "        [ 0.3684564 , -0.3578332 ,  0.42051533, -0.10433065,  0.06810463],\n",
       "        [-0.17008634,  0.41319373,  0.41348305, -0.10338556, -0.42596078]],\n",
       "       dtype=float32),\n",
       " array([-0.28607512,  0.07373808,  0.7021193 ,  1.445035  , -0.82618344],\n",
       "       dtype=float32),\n",
       " array([[ 0.11193867,  0.25450215,  0.15796387,  0.4847849 ,  0.01999067,\n",
       "          0.5958489 ,  0.50807947, -0.87742466,  0.65304977, -0.07690794],\n",
       "        [ 0.95312995,  0.44104365,  0.7380521 , -0.70703155, -0.26138154,\n",
       "          0.33032554, -0.35604367, -0.29163462, -0.42266688, -0.17106968],\n",
       "        [-0.64252096, -0.1818912 , -0.7343772 ,  0.3193106 , -0.649778  ,\n",
       "          0.7469605 ,  0.6082771 , -0.18303865,  0.71662676, -0.07038613],\n",
       "        [-0.62602335,  0.25636065, -0.858987  ,  0.47229233,  0.2281236 ,\n",
       "          0.2661527 ,  0.8412944 , -0.3959351 ,  0.7729779 , -0.99096584],\n",
       "        [ 0.88982356,  0.0876577 ,  0.5066807 , -0.70093   ,  0.07352924,\n",
       "         -0.2194846 , -0.0975003 ,  0.25702035, -0.6070028 ,  0.9413627 ]],\n",
       "       dtype=float32),\n",
       " array([-1.0405158 , -0.13161059, -0.9465011 ,  0.6901916 , -0.11809179,\n",
       "         0.34289694,  0.86513996, -0.8154302 ,  0.6121733 , -0.97649926],\n",
       "       dtype=float32),\n",
       " array([[-1.7542486 ],\n",
       "        [-0.17753135],\n",
       "        [-1.5854979 ],\n",
       "        [ 1.3186901 ],\n",
       "        [-0.17787087],\n",
       "        [ 0.70414495],\n",
       "        [ 1.4568658 ],\n",
       "        [-1.2092538 ],\n",
       "        [ 1.3413916 ],\n",
       "        [-1.4686502 ]], dtype=float32),\n",
       " array([1.0920008], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, sgd, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sgd_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 585us/step - loss: 563.9529 - val_loss: 523.3949\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 442.0267 - val_loss: 382.9288\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 316.8969 - val_loss: 247.2256\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 184.2915 - val_loss: 120.0522\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 83.4987 - val_loss: 49.9510\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 33.1059 - val_loss: 25.7548\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 20.9350 - val_loss: 25.6820\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 18.3247 - val_loss: 19.8766\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 16.5954 - val_loss: 17.4331\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 15.6978 - val_loss: 16.7722\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.3734 - val_loss: 16.2420\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 13.7466 - val_loss: 15.7160\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3231 - val_loss: 14.2059\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.8546 - val_loss: 13.0773\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.9569 - val_loss: 13.2498\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.5250 - val_loss: 15.2474\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.5750 - val_loss: 13.2128\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.9298 - val_loss: 12.3791\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.3952 - val_loss: 11.4348\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.5102 - val_loss: 12.2228\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.9168 - val_loss: 12.2534\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.4737 - val_loss: 12.0978\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 10.1142 - val_loss: 11.2710\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.4790 - val_loss: 15.0338\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.0274 - val_loss: 11.8511\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9819 - val_loss: 11.2470\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.2657 - val_loss: 11.7882\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.6714 - val_loss: 11.6569\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7106 - val_loss: 12.4498\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4964 - val_loss: 11.7860\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.2971 - val_loss: 10.5380\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5491 - val_loss: 11.7484\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 9.0948 - val_loss: 14.1858\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5228 - val_loss: 11.7729\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2959 - val_loss: 11.3555\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.1248 - val_loss: 13.5957\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4718 - val_loss: 12.5959\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.1171 - val_loss: 12.3210\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5287 - val_loss: 11.8420\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.0597 - val_loss: 12.5336\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6261 - val_loss: 12.0857\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.6823 - val_loss: 13.7850\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.2292 - val_loss: 11.4558\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2804 - val_loss: 11.6368\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1904 - val_loss: 11.6641\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9492 - val_loss: 11.5982\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.8127 - val_loss: 16.4789\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4571 - val_loss: 14.2900\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.7745 - val_loss: 14.0237\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4409 - val_loss: 11.5111\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5726 - val_loss: 12.4011\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2086 - val_loss: 11.8348\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0075 - val_loss: 13.6898\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.7123 - val_loss: 11.8293\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3477 - val_loss: 11.6745\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.5060 - val_loss: 14.8535\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2750 - val_loss: 12.0411\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.1465 - val_loss: 11.8403\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9565 - val_loss: 11.3048\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0508 - val_loss: 11.0096\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1369 - val_loss: 11.6096\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1186 - val_loss: 12.0864\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9361 - val_loss: 12.0047\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2878 - val_loss: 11.5085\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7053 - val_loss: 12.0525\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.5553 - val_loss: 11.4967\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.8138 - val_loss: 12.4353\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 89us/step - loss: 8.1536 - val_loss: 11.1927\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3945 - val_loss: 11.0135\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1429 - val_loss: 11.8989\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4501 - val_loss: 11.5466\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0887 - val_loss: 12.2431\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8116 - val_loss: 12.6843\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2651 - val_loss: 10.6980\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.8563 - val_loss: 12.1037\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.7567 - val_loss: 12.3213\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5834 - val_loss: 11.3661\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6433 - val_loss: 13.3878\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.0132 - val_loss: 11.2609\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9896 - val_loss: 11.1490\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4155 - val_loss: 11.6283\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2636 - val_loss: 10.4672\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7175 - val_loss: 11.6159\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.8149 - val_loss: 11.6663\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9125 - val_loss: 11.4689\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8508 - val_loss: 11.8784\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.2863 - val_loss: 11.1093\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8239 - val_loss: 11.0648\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2596 - val_loss: 11.3780\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6141 - val_loss: 11.3480\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5165 - val_loss: 11.9704\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9295 - val_loss: 10.5977\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.8988 - val_loss: 10.5282\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1672 - val_loss: 10.9782\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6434 - val_loss: 10.4390\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.1733 - val_loss: 10.4277\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9006 - val_loss: 10.8282\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.5639 - val_loss: 10.8692\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.9467 - val_loss: 10.3132\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.4616 - val_loss: 12.0454\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.3577 - val_loss: 9.9729\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6473 - val_loss: 10.7263\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6997 - val_loss: 11.9610\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7747 - val_loss: 10.8679\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8998 - val_loss: 11.3958\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0182 - val_loss: 10.9708\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9286 - val_loss: 11.1345\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4778 - val_loss: 11.4337\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0616 - val_loss: 13.9768\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7621 - val_loss: 10.9986\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7800 - val_loss: 10.9153\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8878 - val_loss: 16.7460\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 8.2139 - val_loss: 12.9274\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0348 - val_loss: 11.9561\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0898 - val_loss: 11.2770\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0388 - val_loss: 11.0414\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1364 - val_loss: 10.1710\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8367 - val_loss: 9.6045\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6744 - val_loss: 9.8191\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6209 - val_loss: 12.8837\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1001 - val_loss: 11.8076\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.9140 - val_loss: 10.6437\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6066 - val_loss: 13.1196\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1685 - val_loss: 10.2039\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9090 - val_loss: 11.6970\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4684 - val_loss: 12.9622\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9008 - val_loss: 11.7424\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4689 - val_loss: 11.6406\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3981 - val_loss: 11.3472\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8570 - val_loss: 10.3929\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5636 - val_loss: 11.2056\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7126 - val_loss: 10.3324\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.8746 - val_loss: 13.4083\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.1846 - val_loss: 10.5958\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1723 - val_loss: 10.0862\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8145 - val_loss: 10.8056\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5652 - val_loss: 11.3322\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5158 - val_loss: 10.6276\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7201 - val_loss: 11.6528\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1906 - val_loss: 10.5149\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6666 - val_loss: 12.5882\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2717 - val_loss: 11.5289\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6536 - val_loss: 10.8968\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.3214 - val_loss: 11.3773\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 8.3127 - val_loss: 10.3626\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6044 - val_loss: 9.6959\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 7.6634 - val_loss: 10.3698\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8976 - val_loss: 13.8011\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7619 - val_loss: 10.9651\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6176 - val_loss: 10.3348\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9526 - val_loss: 9.9125\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7723 - val_loss: 10.3410\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7698 - val_loss: 10.0305\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.8953 - val_loss: 9.8171\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2105 - val_loss: 13.2587\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.3866 - val_loss: 9.7636\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7298 - val_loss: 10.2094\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3984 - val_loss: 9.6611\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.7234 - val_loss: 11.0256\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6366 - val_loss: 14.1784\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.1166 - val_loss: 10.5571\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2440 - val_loss: 9.7054\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6816 - val_loss: 11.5277\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0191 - val_loss: 10.7673\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5533 - val_loss: 10.1344\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4125 - val_loss: 9.8202\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.5608 - val_loss: 10.0137\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6207 - val_loss: 10.8278\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3287 - val_loss: 10.9464\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.0036 - val_loss: 10.5136\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3685 - val_loss: 10.6350\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1300 - val_loss: 12.8014\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6420 - val_loss: 9.6135\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6847 - val_loss: 10.9015\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7802 - val_loss: 9.6206\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.0831 - val_loss: 9.9914\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3797 - val_loss: 10.1966\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6000 - val_loss: 10.8344\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4522 - val_loss: 12.8918\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8784 - val_loss: 9.9549\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2460 - val_loss: 9.9356\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4625 - val_loss: 10.9768\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9263 - val_loss: 11.0909\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3222 - val_loss: 10.5689\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1319 - val_loss: 10.8353\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1756 - val_loss: 9.9504\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7994 - val_loss: 9.6000\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2571 - val_loss: 9.9029\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1532 - val_loss: 9.8114\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5651 - val_loss: 9.8842\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6298 - val_loss: 9.5337\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4236 - val_loss: 9.6906\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2898 - val_loss: 10.0715\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.8101 - val_loss: 12.1352\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5418 - val_loss: 10.7119\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2303 - val_loss: 9.2937\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7769 - val_loss: 9.7437\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8074 - val_loss: 9.2938\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 7.2452 - val_loss: 11.0522\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3161 - val_loss: 12.3740\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1946 - val_loss: 9.6918\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0245 - val_loss: 9.6610\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.7002 - val_loss: 11.1840\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6531 - val_loss: 9.4968\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0254 - val_loss: 9.8614\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 7.5976 - val_loss: 10.2570\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.4280 - val_loss: 10.4774\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6603 - val_loss: 9.9465\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5438 - val_loss: 9.9129\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4408 - val_loss: 10.5422\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6918 - val_loss: 9.9455\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8012 - val_loss: 9.7692\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6216 - val_loss: 10.6596\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4227 - val_loss: 9.5785\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6659 - val_loss: 10.8327\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 135us/step - loss: 7.2956 - val_loss: 10.0772\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0404 - val_loss: 12.8191\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.0377 - val_loss: 10.2455\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2703 - val_loss: 9.9659\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.3223 - val_loss: 15.0347\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8911 - val_loss: 9.6247\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 124us/step - loss: 7.5207 - val_loss: 9.6800\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5797 - val_loss: 9.6567\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1556 - val_loss: 10.8420\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4360 - val_loss: 11.8280\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6266 - val_loss: 9.7713\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 7.3211 - val_loss: 10.6839\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4949 - val_loss: 9.0796\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9389 - val_loss: 11.1518\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0828 - val_loss: 9.2905\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5274 - val_loss: 9.3306\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2149 - val_loss: 9.9487\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.7697 - val_loss: 9.3125\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4981 - val_loss: 9.2839\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4498 - val_loss: 8.9812\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9882 - val_loss: 9.7641\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3596 - val_loss: 9.6235\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5992 - val_loss: 10.0716\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.5653 - val_loss: 10.6740\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7442 - val_loss: 9.4658\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2220 - val_loss: 9.2146\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.3587 - val_loss: 9.0740\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3809 - val_loss: 9.6297\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.4956 - val_loss: 9.3140\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4397 - val_loss: 9.2184\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2282 - val_loss: 9.9401\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3095 - val_loss: 9.5708\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2426 - val_loss: 10.5376\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4384 - val_loss: 10.7377\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9567 - val_loss: 9.5033\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1481 - val_loss: 9.2495\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6070 - val_loss: 9.6593\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0116 - val_loss: 9.7906\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6596 - val_loss: 9.6951\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.6459 - val_loss: 10.1787\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1857 - val_loss: 9.0491\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0944 - val_loss: 9.5467\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1462 - val_loss: 9.1664\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7058 - val_loss: 10.0584\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2150 - val_loss: 9.0823\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7573 - val_loss: 10.1671\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3787 - val_loss: 9.7940\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5518 - val_loss: 10.6761\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5130 - val_loss: 9.4836\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3883 - val_loss: 10.2640\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5646 - val_loss: 10.0434\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6236 - val_loss: 9.2395\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.1785 - val_loss: 10.2567\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.0368 - val_loss: 9.5315\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5335 - val_loss: 9.6067\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2760 - val_loss: 9.5522\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6540 - val_loss: 9.4906\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5022 - val_loss: 9.3785\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4143 - val_loss: 9.6796\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4225 - val_loss: 9.1263\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5167 - val_loss: 10.4270\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3982 - val_loss: 9.1928\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.5543 - val_loss: 9.2204\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3648 - val_loss: 8.9247\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0695 - val_loss: 10.4973\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1073 - val_loss: 9.1311\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1960 - val_loss: 13.1137\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4996 - val_loss: 9.7499\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6594 - val_loss: 10.5348\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6469 - val_loss: 9.4285\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4013 - val_loss: 11.6071\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0682 - val_loss: 9.8645\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.3804 - val_loss: 8.7728\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1321 - val_loss: 8.9928\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1806 - val_loss: 9.5554\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1769 - val_loss: 9.4735\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0794 - val_loss: 9.2725\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.3577 - val_loss: 9.0852\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4425 - val_loss: 9.6669\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4338 - val_loss: 10.2771\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1064 - val_loss: 11.0109\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5887 - val_loss: 10.8375\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5121 - val_loss: 9.2210\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9856 - val_loss: 10.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3837 - val_loss: 11.1868\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.9123 - val_loss: 8.9870\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3049 - val_loss: 11.6140\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0606 - val_loss: 10.8742\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2317 - val_loss: 10.4831\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2852 - val_loss: 10.2954\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2045 - val_loss: 9.5540\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 63us/step - loss: 7.3731 - val_loss: 9.5298\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 132us/step - loss: 6.9836 - val_loss: 8.7036\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2521 - val_loss: 10.3781\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3272 - val_loss: 10.4503\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2685 - val_loss: 9.0695\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3357 - val_loss: 8.9751\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2535 - val_loss: 10.4123\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3786 - val_loss: 9.1889\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9114 - val_loss: 10.7421\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5226 - val_loss: 9.8991\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0477 - val_loss: 9.4645\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3191 - val_loss: 9.3576\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0030 - val_loss: 9.4796\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2903 - val_loss: 9.2612\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3817 - val_loss: 9.3201\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0239 - val_loss: 10.4890\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0198 - val_loss: 11.1191\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.5005 - val_loss: 8.9635\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9801 - val_loss: 9.2735\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1066 - val_loss: 9.6315\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7853 - val_loss: 9.2793\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0746 - val_loss: 10.5589\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7315 - val_loss: 9.3874\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8674 - val_loss: 9.4792\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0243 - val_loss: 10.8246\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3971 - val_loss: 9.2327\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9266 - val_loss: 10.1561\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.2700 - val_loss: 9.6276\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.0002 - val_loss: 14.4653\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4726 - val_loss: 9.2647\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.6651 - val_loss: 10.3401\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9710 - val_loss: 12.0835\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5309 - val_loss: 10.0819\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2622 - val_loss: 9.6821\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1128 - val_loss: 10.0543\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9659 - val_loss: 10.2954\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2336 - val_loss: 9.4100\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1177 - val_loss: 9.5588\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8897 - val_loss: 9.9952\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.4468 - val_loss: 9.2213\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9889 - val_loss: 9.5277\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1834 - val_loss: 10.4308\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2044 - val_loss: 9.3399\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1190 - val_loss: 9.2124\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1004 - val_loss: 10.9321\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4067 - val_loss: 9.6707\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9441 - val_loss: 9.3300\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.6013 - val_loss: 9.2307\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1921 - val_loss: 9.5888\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9672 - val_loss: 9.4962\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4282 - val_loss: 10.7224\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0999 - val_loss: 9.7793\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7643 - val_loss: 9.9870\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0354 - val_loss: 10.2163\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9587 - val_loss: 8.9472\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4755 - val_loss: 8.8801\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.2814 - val_loss: 9.4967\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8881 - val_loss: 9.4771\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8443 - val_loss: 9.2849\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9815 - val_loss: 10.6525\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2072 - val_loss: 9.7638\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0771 - val_loss: 9.0769\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8420 - val_loss: 9.2686\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.6498 - val_loss: 9.1258\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7612 - val_loss: 9.5766\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.6993 - val_loss: 9.7807\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.3116 - val_loss: 9.5384\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8689 - val_loss: 10.1498\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2322 - val_loss: 10.0217\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2845 - val_loss: 9.1659\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 91us/step - loss: 6.9401 - val_loss: 9.0632\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1505 - val_loss: 9.0736\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9015 - val_loss: 10.3157\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.4777 - val_loss: 8.8245\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.9265 - val_loss: 8.9874\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.0996 - val_loss: 9.1564\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.0809 - val_loss: 9.7130\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.3790 - val_loss: 8.9451\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8252 - val_loss: 9.9889\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8702 - val_loss: 10.5209\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5340 - val_loss: 9.2216\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2672 - val_loss: 8.9967\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2867 - val_loss: 8.7936\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9707 - val_loss: 8.5021\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7053 - val_loss: 9.5377\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.1785 - val_loss: 8.9626\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.1422 - val_loss: 8.9801\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8758 - val_loss: 9.4092\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.9477 - val_loss: 8.6869\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9537 - val_loss: 9.5753\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8647 - val_loss: 8.9835\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.2604 - val_loss: 8.7647\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1611 - val_loss: 9.5020\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8504 - val_loss: 9.5590\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9784 - val_loss: 9.1259\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0160 - val_loss: 9.1843\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9159 - val_loss: 9.6104\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7784 - val_loss: 10.5535\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 7.1826 - val_loss: 11.1010\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.0303 - val_loss: 9.0778\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7689 - val_loss: 11.6912\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0823 - val_loss: 10.7625\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7852 - val_loss: 9.7102\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7906 - val_loss: 12.4506\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5223 - val_loss: 9.7299\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7997 - val_loss: 9.0477\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7167 - val_loss: 8.8978\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0425 - val_loss: 9.5351\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.8930 - val_loss: 10.2644\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.9701 - val_loss: 9.6109\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2064 - val_loss: 9.7345\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.1230 - val_loss: 9.3689\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8575 - val_loss: 9.1053\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.8645 - val_loss: 9.1729\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.7035 - val_loss: 10.0961\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8197 - val_loss: 9.6681\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1198 - val_loss: 9.9494\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6121 - val_loss: 9.5933\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8926 - val_loss: 10.7076\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7226 - val_loss: 8.8482\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.0197 - val_loss: 10.8204\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0168 - val_loss: 11.5341\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0337 - val_loss: 9.3559\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6696 - val_loss: 9.2045\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8686 - val_loss: 10.6301\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1124 - val_loss: 9.2538\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5206 - val_loss: 9.3220\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2333 - val_loss: 9.0608\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8892 - val_loss: 9.2111\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8920 - val_loss: 8.9276\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8395 - val_loss: 8.9725\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7621 - val_loss: 8.9540\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5529 - val_loss: 8.8770\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0691 - val_loss: 9.4763\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 7.0424 - val_loss: 9.2368\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5819 - val_loss: 9.3763\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9010 - val_loss: 10.0379\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0876 - val_loss: 9.8409\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9366 - val_loss: 9.6508\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8289 - val_loss: 10.0315\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.9603 - val_loss: 9.6612\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2118 - val_loss: 9.4954\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7000 - val_loss: 9.2815\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6048 - val_loss: 9.4037\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.9595 - val_loss: 10.3432\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.4707 - val_loss: 9.0121\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7387 - val_loss: 10.0516\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6930 - val_loss: 9.6824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0131 - val_loss: 9.3937\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8327 - val_loss: 9.7561\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6760 - val_loss: 11.0809\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9890 - val_loss: 9.7224\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8614 - val_loss: 9.6312\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4506 - val_loss: 11.8565\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7551 - val_loss: 9.0940\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9318 - val_loss: 8.8370\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.8148 - val_loss: 9.1859\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0231 - val_loss: 8.5029\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9029 - val_loss: 9.0172\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6262 - val_loss: 9.8041\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7562 - val_loss: 9.2076\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4461 - val_loss: 9.0025\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7426 - val_loss: 8.8839\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7265 - val_loss: 9.9590\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.9621 - val_loss: 9.9896\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.6332 - val_loss: 9.6784\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5917 - val_loss: 9.0178\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6860 - val_loss: 9.1139\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.6930 - val_loss: 9.5921\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8512 - val_loss: 9.1565\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4862 - val_loss: 9.4741\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8167 - val_loss: 8.8486\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7857 - val_loss: 9.3584\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3300 - val_loss: 11.8248\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1659 - val_loss: 9.1360\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5189 - val_loss: 8.7907\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4680 - val_loss: 8.6696\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5450 - val_loss: 8.7579\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8546 - val_loss: 9.5471\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7508 - val_loss: 9.0407\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.4227 - val_loss: 9.2247\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5499 - val_loss: 9.5973\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5069 - val_loss: 9.3706\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5046 - val_loss: 10.0335\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6395 - val_loss: 8.9742\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5603 - val_loss: 8.8274\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3826 - val_loss: 9.9305\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5492 - val_loss: 10.5620\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.1111 - val_loss: 9.5434\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9123 - val_loss: 8.8461\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7692 - val_loss: 9.3332\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.8478 - val_loss: 8.8748\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.5244 - val_loss: 9.1799\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5996 - val_loss: 10.6813\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.2156 - val_loss: 8.8182\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4126 - val_loss: 9.2216\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.5076 - val_loss: 9.1789\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6086 - val_loss: 9.9465\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.1937 - val_loss: 8.7690\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4365 - val_loss: 8.7967\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.8169 - val_loss: 9.2058\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.4391 - val_loss: 9.5580\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.3615 - val_loss: 9.3342\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2337 - val_loss: 10.4687\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8243 - val_loss: 10.1403\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5489 - val_loss: 9.3661\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4767 - val_loss: 8.9063\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.3229 - val_loss: 8.6931\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4061 - val_loss: 9.6257\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9474 - val_loss: 9.6778\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.7333 - val_loss: 9.8247\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.4921 - val_loss: 9.3462\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4652 - val_loss: 9.1498\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2821 - val_loss: 9.5529\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4954 - val_loss: 10.4086\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6565 - val_loss: 9.4453\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.9467 - val_loss: 9.7772\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5994 - val_loss: 8.9580\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5973 - val_loss: 8.9638\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5532 - val_loss: 8.8158\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7018 - val_loss: 9.4197\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7007 - val_loss: 9.1359\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6585 - val_loss: 9.4332\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3778 - val_loss: 8.7214\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6260 - val_loss: 9.0084\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0483 - val_loss: 9.4363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3599 - val_loss: 9.1517\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3089 - val_loss: 9.4734\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.9016 - val_loss: 10.0568\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.7621 - val_loss: 8.5754\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3735 - val_loss: 9.8883\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7815 - val_loss: 10.0728\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5276 - val_loss: 8.9675\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2912 - val_loss: 8.9887\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 6.4250 - val_loss: 8.6021\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3900 - val_loss: 10.0389\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5812 - val_loss: 9.2233\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.7544 - val_loss: 9.7487\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.6340 - val_loss: 8.6537\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4175 - val_loss: 9.0124\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.7146 - val_loss: 8.9716\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.9184 - val_loss: 8.9589\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.4594 - val_loss: 8.5719\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5366 - val_loss: 8.9638\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.5872 - val_loss: 8.6907\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4761 - val_loss: 9.6082\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4065 - val_loss: 8.5979\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.8219 - val_loss: 8.4992\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.2021 - val_loss: 8.8919\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4525 - val_loss: 9.4310\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4985 - val_loss: 8.7309\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.7565 - val_loss: 8.8712\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3990 - val_loss: 9.6243\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.7231 - val_loss: 8.5125\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2690 - val_loss: 8.5508\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3043 - val_loss: 9.1487\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3397 - val_loss: 10.2513\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7497 - val_loss: 9.7380\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3995 - val_loss: 8.5988\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0772 - val_loss: 8.5731\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1594 - val_loss: 10.6129\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5441 - val_loss: 8.4291\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3115 - val_loss: 8.8803\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2227 - val_loss: 9.8633\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4866 - val_loss: 9.6848\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.7567 - val_loss: 8.9005\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.8269 - val_loss: 8.6821\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6613 - val_loss: 9.2725\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2928 - val_loss: 9.2132\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2082 - val_loss: 9.3682\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5748 - val_loss: 9.1355\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1037 - val_loss: 9.4829\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6567 - val_loss: 9.4404\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3597 - val_loss: 8.8731\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1726 - val_loss: 8.5655\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6322 - val_loss: 8.9452\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2073 - val_loss: 8.7221\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5222 - val_loss: 9.5473\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1111 - val_loss: 8.9116\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5363 - val_loss: 8.8593\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.5355 - val_loss: 8.5672\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.6468 - val_loss: 8.7435\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5418 - val_loss: 8.7836\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2467 - val_loss: 9.7393\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4290 - val_loss: 9.2286\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4414 - val_loss: 9.0074\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.6557 - val_loss: 9.7326\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0161 - val_loss: 8.7673\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4966 - val_loss: 8.8043\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.1271 - val_loss: 8.9201\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5731 - val_loss: 9.3430\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2365 - val_loss: 8.8670\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2044 - val_loss: 9.2240\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5099 - val_loss: 8.5991\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2246 - val_loss: 9.5342\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2492 - val_loss: 8.5498\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.4596 - val_loss: 8.7850\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3321 - val_loss: 8.9591\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8667 - val_loss: 8.7162\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.8786 - val_loss: 8.9884\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1984 - val_loss: 8.8183\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.6541 - val_loss: 8.9396\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4715 - val_loss: 8.4262\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0904 - val_loss: 9.0708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.3825 - val_loss: 8.6977\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5118 - val_loss: 10.1850\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2610 - val_loss: 8.6202\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2366 - val_loss: 9.5745\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.1958 - val_loss: 9.2700\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0333 - val_loss: 10.5865\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0328 - val_loss: 9.0028\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0443 - val_loss: 9.0682\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2767 - val_loss: 9.1564\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9446 - val_loss: 8.6887\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1813 - val_loss: 12.2586\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8398 - val_loss: 8.5071\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.4389 - val_loss: 8.6174\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0451 - val_loss: 11.0202\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5948 - val_loss: 10.0844\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4633 - val_loss: 8.6984\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8451 - val_loss: 9.2826\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5925 - val_loss: 8.6413\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0177 - val_loss: 8.9700\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7924 - val_loss: 8.6696\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3094 - val_loss: 9.2061\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3707 - val_loss: 9.1700\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0822 - val_loss: 9.1061\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.9457 - val_loss: 9.7314\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.0009 - val_loss: 9.4002\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0414 - val_loss: 8.5492\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.2345 - val_loss: 9.0738\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2874 - val_loss: 8.8637\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4204 - val_loss: 8.3625\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0087 - val_loss: 9.2060\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0905 - val_loss: 8.8857\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7263 - val_loss: 8.7270\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1325 - val_loss: 9.0545\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0577 - val_loss: 9.4742\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6112 - val_loss: 8.4483\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1886 - val_loss: 9.5745\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.4541 - val_loss: 8.5147\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.1328 - val_loss: 8.8023\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0589 - val_loss: 8.6430\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.0783 - val_loss: 9.4187\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1607 - val_loss: 9.3365\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.8182 - val_loss: 11.7238\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.3770 - val_loss: 8.9921\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.9940 - val_loss: 8.8278\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1470 - val_loss: 9.0142\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0589 - val_loss: 9.1958\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1105 - val_loss: 9.9209\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.2866 - val_loss: 8.7576\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.1491 - val_loss: 9.1646\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0793 - val_loss: 9.1685\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2877 - val_loss: 8.4994\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3865 - val_loss: 8.3667\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2626 - val_loss: 9.1621\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0525 - val_loss: 10.7587\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2054 - val_loss: 9.7166\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1462 - val_loss: 9.8569\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3495 - val_loss: 11.8964\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2627 - val_loss: 8.2027\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.0231 - val_loss: 8.5503\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1050 - val_loss: 8.6569\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2659 - val_loss: 8.7181\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3060 - val_loss: 9.5941\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4429 - val_loss: 9.2700\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1558 - val_loss: 8.8810\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2110 - val_loss: 8.8206\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4456 - val_loss: 8.4653\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 6.0938 - val_loss: 8.3301\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2268 - val_loss: 8.3765\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8383 - val_loss: 9.6108\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9018 - val_loss: 9.1699\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2703 - val_loss: 9.6137\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5263 - val_loss: 9.4765\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0046 - val_loss: 8.5610\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2455 - val_loss: 9.1609\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8774 - val_loss: 9.5452\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3734 - val_loss: 8.6216\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0705 - val_loss: 8.8389\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0967 - val_loss: 8.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.4517 - val_loss: 8.8296\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.6018 - val_loss: 9.0556\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.3805 - val_loss: 9.0875\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1380 - val_loss: 10.4106\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3126 - val_loss: 9.2176\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1215 - val_loss: 9.3163\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2146 - val_loss: 9.0573\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8060 - val_loss: 8.9518\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9493 - val_loss: 8.7605\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.8862 - val_loss: 9.9291\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 6.3206 - val_loss: 9.4025\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9433 - val_loss: 8.6538\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1484 - val_loss: 8.3972\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0820 - val_loss: 9.4472\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0004 - val_loss: 9.2026\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9408 - val_loss: 9.5307\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0821 - val_loss: 9.1129\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.3064 - val_loss: 9.7094\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9918 - val_loss: 9.2587\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5371 - val_loss: 8.5083\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.4668 - val_loss: 8.4760\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9411 - val_loss: 9.1538\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1949 - val_loss: 9.1464\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8564 - val_loss: 8.8560\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 6.1687 - val_loss: 10.2646\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.2695 - val_loss: 10.1791\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.2142 - val_loss: 8.8331\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.1093 - val_loss: 9.5946\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7742 - val_loss: 8.8731\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.0993 - val_loss: 8.6339\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1967 - val_loss: 9.4103\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0313 - val_loss: 8.7721\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0618 - val_loss: 8.7900\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.6396 - val_loss: 9.4409\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2952 - val_loss: 9.5370\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0035 - val_loss: 8.8868\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.0717 - val_loss: 8.4249\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.2940 - val_loss: 9.2910\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1454 - val_loss: 8.8775\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.0120 - val_loss: 8.6220\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2566 - val_loss: 9.3944\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9239 - val_loss: 8.8641\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9575 - val_loss: 8.5901\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0866 - val_loss: 8.9060\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1892 - val_loss: 9.7406\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3008 - val_loss: 10.1375\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9700 - val_loss: 9.0585\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9045 - val_loss: 8.8101\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3818 - val_loss: 9.7043\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8620 - val_loss: 9.5125\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1243 - val_loss: 8.9979\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8854 - val_loss: 9.1722\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2956 - val_loss: 8.9397\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1549 - val_loss: 9.0460\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.0010 - val_loss: 9.5998\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9562 - val_loss: 9.0221\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2122 - val_loss: 9.3880\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0051 - val_loss: 8.9427\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9922 - val_loss: 9.0067\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.1204 - val_loss: 8.9742\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8425 - val_loss: 8.9302\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 6.2421 - val_loss: 10.7788\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9263 - val_loss: 9.6234\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9898 - val_loss: 9.2535\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1209 - val_loss: 11.1705\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.3490 - val_loss: 9.3499\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1063 - val_loss: 9.3598\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8165 - val_loss: 9.0921\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1830 - val_loss: 8.5830\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8071 - val_loss: 9.0153\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0399 - val_loss: 8.9539\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7996 - val_loss: 8.9626\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.5370 - val_loss: 8.6620\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8252 - val_loss: 8.9149\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.3312 - val_loss: 8.8121\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0531 - val_loss: 9.8094\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1105 - val_loss: 8.8322\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1162 - val_loss: 9.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0168 - val_loss: 9.1157\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8510 - val_loss: 9.0286\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0009 - val_loss: 9.7244\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9414 - val_loss: 8.4992\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2210 - val_loss: 8.7234\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9653 - val_loss: 8.5936\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0024 - val_loss: 9.1151\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 6.2824 - val_loss: 8.8959\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7683 - val_loss: 8.6190\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9741 - val_loss: 9.0141\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 5.9985 - val_loss: 9.1101\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 6.3023 - val_loss: 8.7142\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1785 - val_loss: 9.8801\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8482 - val_loss: 8.5441\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0551 - val_loss: 8.6748\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9915 - val_loss: 9.6710\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9159 - val_loss: 8.8165\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2019 - val_loss: 9.6648\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8091 - val_loss: 10.4564\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1503 - val_loss: 9.0956\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0756 - val_loss: 8.9211\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8492 - val_loss: 9.9021\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.5581 - val_loss: 9.2762\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 5.8560 - val_loss: 11.2949\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.8640 - val_loss: 8.9461\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0631 - val_loss: 8.5289\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9203 - val_loss: 8.9851\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0135 - val_loss: 8.7907\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8273 - val_loss: 9.1684\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8661 - val_loss: 9.0344\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9833 - val_loss: 9.1918\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7726 - val_loss: 8.8669\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9630 - val_loss: 9.1262\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9174 - val_loss: 8.8902\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1417 - val_loss: 10.6259\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0332 - val_loss: 8.6286\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8760 - val_loss: 8.8361\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4051 - val_loss: 8.8409\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.7882 - val_loss: 8.9075\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.3189 - val_loss: 8.4170\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8718 - val_loss: 9.1974\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0821 - val_loss: 10.1985\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1004 - val_loss: 9.3815\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0323 - val_loss: 9.0688\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7560 - val_loss: 9.2387\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3515 - val_loss: 9.0165\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7925 - val_loss: 10.6894\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9528 - val_loss: 8.7521\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8424 - val_loss: 10.2512\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9628 - val_loss: 11.1787\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2256 - val_loss: 8.8316\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0780 - val_loss: 9.3144\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0191 - val_loss: 8.9543\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8440 - val_loss: 8.9321\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7746 - val_loss: 8.9678\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9018 - val_loss: 9.7195\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0795 - val_loss: 8.9010\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.8145 - val_loss: 9.0998\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9541 - val_loss: 8.9545\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9881 - val_loss: 9.0098\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8974 - val_loss: 8.8402\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8657 - val_loss: 9.2253\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9755 - val_loss: 9.6293\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8582 - val_loss: 8.6834\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9055 - val_loss: 9.2541\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0978 - val_loss: 8.9755\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.7547 - val_loss: 9.6550\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1078 - val_loss: 9.3379\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.8137 - val_loss: 10.2858\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7173 - val_loss: 8.9320\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8336 - val_loss: 8.9264\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8621 - val_loss: 8.9927\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8997 - val_loss: 9.2300\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8545 - val_loss: 10.2745\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0730 - val_loss: 8.9022\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.9164 - val_loss: 8.5723\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8585 - val_loss: 8.7823\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1019 - val_loss: 8.8495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7782 - val_loss: 8.9968\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9879 - val_loss: 9.1026\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.1445 - val_loss: 8.7132\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8693 - val_loss: 9.1141\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0380 - val_loss: 9.5194\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9198 - val_loss: 8.9863\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8172 - val_loss: 8.8852\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.7758 - val_loss: 10.6400\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.3044 - val_loss: 8.7398\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6781 - val_loss: 8.8560\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9202 - val_loss: 9.2052\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8342 - val_loss: 10.0494\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.9879 - val_loss: 9.4282\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0318 - val_loss: 8.7789\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1856 - val_loss: 8.5932\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8976 - val_loss: 9.5047\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9959 - val_loss: 9.2800\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6297 - val_loss: 9.0056\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7544 - val_loss: 9.5649\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1054 - val_loss: 9.6393\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.6488 - val_loss: 9.0709\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7758 - val_loss: 8.5947\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9067 - val_loss: 8.8733\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0693 - val_loss: 8.7820\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6564 - val_loss: 9.4377\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6991 - val_loss: 9.4635\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2185 - val_loss: 8.8658\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9300 - val_loss: 11.3046\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9160 - val_loss: 9.1576\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0725 - val_loss: 9.5339\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8420 - val_loss: 9.3197\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8954 - val_loss: 8.6554\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.0774 - val_loss: 8.7296\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8276 - val_loss: 8.8817\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0433 - val_loss: 9.0904\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0435 - val_loss: 8.9544\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5898 - val_loss: 12.4457\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4109 - val_loss: 8.6446\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6103 - val_loss: 8.8291\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0035 - val_loss: 8.7513\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.0836 - val_loss: 9.0944\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0049 - val_loss: 10.2359\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0469 - val_loss: 8.9621\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0515 - val_loss: 8.7793\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0405 - val_loss: 8.8249\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.8883 - val_loss: 8.6097\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 5.6820 - val_loss: 8.6770\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9422 - val_loss: 9.4152\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9757 - val_loss: 9.1976\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6482 - val_loss: 9.3435\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0556 - val_loss: 8.8234\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8143 - val_loss: 9.2137\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0060 - val_loss: 9.4166\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.1279 - val_loss: 8.3666\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8217 - val_loss: 8.8962\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7543 - val_loss: 8.5426\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.5506 - val_loss: 9.9468\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2336 - val_loss: 8.9799\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.0020 - val_loss: 9.1280\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8675 - val_loss: 8.9981\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.9404 - val_loss: 9.3619\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1289 - val_loss: 9.5121\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9163 - val_loss: 9.1288\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.1723 - val_loss: 9.0009\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8403 - val_loss: 9.3688\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4809 - val_loss: 9.7762\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0085 - val_loss: 9.0419\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.2549 - val_loss: 8.9809\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8192 - val_loss: 8.7486\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5901 - val_loss: 8.5321\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0514 - val_loss: 8.7782\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7567 - val_loss: 8.4467\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8292 - val_loss: 8.6352\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.8236 - val_loss: 8.7321\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8393 - val_loss: 8.9716\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6671 - val_loss: 8.5580\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0881 - val_loss: 9.4861\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7380 - val_loss: 9.3016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 6.0737 - val_loss: 8.3528\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5648 - val_loss: 10.0440\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.6979 - val_loss: 8.5921\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8982 - val_loss: 8.6531\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0072 - val_loss: 9.5390\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0086 - val_loss: 9.1932\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6976 - val_loss: 10.7205\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2003 - val_loss: 9.6708\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.0743 - val_loss: 9.2470\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8991 - val_loss: 8.8816\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6886 - val_loss: 8.5589\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6013 - val_loss: 8.1893\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7491 - val_loss: 8.8486\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7782 - val_loss: 9.2391\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0010 - val_loss: 9.5288\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.0054 - val_loss: 9.4377\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7006 - val_loss: 9.2461\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9370 - val_loss: 9.9440\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.8293 - val_loss: 8.9258\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6813 - val_loss: 9.1456\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6670 - val_loss: 9.4019\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1660 - val_loss: 8.9305\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0660 - val_loss: 9.7946\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8789 - val_loss: 9.0948\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.1256 - val_loss: 9.1792\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.7337 - val_loss: 10.7177\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9935 - val_loss: 9.5570\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.7868 - val_loss: 8.8191\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 5.8475 - val_loss: 8.5967\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8968 - val_loss: 9.8849\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.9142 - val_loss: 8.7808\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 6.0241 - val_loss: 8.9140\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7654 - val_loss: 9.0283\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9154 - val_loss: 8.8541\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 5.7327 - val_loss: 9.4610\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8345 - val_loss: 8.9764\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.9981 - val_loss: 9.4573\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2440 - val_loss: 9.4142\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8149 - val_loss: 8.9241\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7907 - val_loss: 8.9737\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 5.7218 - val_loss: 10.2305\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.8973 - val_loss: 8.7137\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1411 - val_loss: 9.8403\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8150 - val_loss: 9.6537\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.8887 - val_loss: 9.1418\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1114 - val_loss: 8.9343\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.9681 - val_loss: 9.1399\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7979 - val_loss: 8.9724\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.2010 - val_loss: 8.8886\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7722 - val_loss: 8.8159\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0588 - val_loss: 9.1405\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7353 - val_loss: 10.0924\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7918 - val_loss: 9.2453\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.0637 - val_loss: 9.9216\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8591 - val_loss: 9.1707\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7041 - val_loss: 8.9406\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7003 - val_loss: 8.9065\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 6.0713 - val_loss: 8.7676\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7019 - val_loss: 8.8500\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6888 - val_loss: 10.0870\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 6.1889 - val_loss: 9.3824\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6575 - val_loss: 8.7534\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.9616 - val_loss: 8.6394\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9988 - val_loss: 9.5787\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7687 - val_loss: 9.4821\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8835 - val_loss: 9.1014\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.7098 - val_loss: 10.3845\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9519 - val_loss: 9.0475\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.7355 - val_loss: 9.0867\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.6807 - val_loss: 11.3693\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2919 - val_loss: 9.0549\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.6801 - val_loss: 9.4243\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4785 - val_loss: 8.7683\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7627 - val_loss: 9.2655\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9712 - val_loss: 8.6678\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.8535 - val_loss: 8.7739\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1855 - val_loss: 10.2763\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.9277 - val_loss: 9.2766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.051487356929456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.6690612e+00, -1.3844771e+00,  4.2985344e+00, -6.1107439e-01,\n",
       "          1.9184650e+00],\n",
       "        [ 4.4172913e-01,  2.2681342e-01, -2.5795622e+00, -4.1228724e-01,\n",
       "          8.9761323e-01],\n",
       "        [-6.0513115e-01,  1.8272872e-01, -4.1284120e-01,  9.2792642e-01,\n",
       "         -9.2501849e-01],\n",
       "        [-4.8817584e-01,  7.3982441e-01,  3.3558922e+00,  4.8050916e-01,\n",
       "         -4.2854241e-01],\n",
       "        [-2.4726285e-01,  7.5060654e-01, -1.6467766e-01, -6.7938668e-01,\n",
       "          1.0342709e-01],\n",
       "        [ 1.3066553e+00, -3.7906799e-03, -1.1319046e+00,  5.8794641e-01,\n",
       "         -2.0383933e+00],\n",
       "        [-2.1709418e-01, -1.6860880e+00, -3.3433771e-01,  7.6606721e-02,\n",
       "         -7.8307325e-01]], dtype=float32),\n",
       " array([ 1.6809769 , -1.7781898 ,  0.82567185,  0.5865976 , -2.1910431 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.5663346 , -0.75370795, -0.90363955, -0.8124399 ,  0.33290014,\n",
       "         -0.16958655, -0.7285154 ,  0.8905484 ,  0.08870707,  0.82570344],\n",
       "        [ 0.04166774,  0.60063064,  0.2096875 ,  0.12203244, -0.40455312,\n",
       "          0.37990096,  1.0089191 , -0.43815422,  0.95675564, -0.13465649],\n",
       "        [-0.91737384,  0.7799924 ,  0.71551675,  0.86950564, -1.0467477 ,\n",
       "          0.43817246,  0.0640247 , -0.9464588 ,  0.05269189, -0.96829784],\n",
       "        [-0.5360232 ,  0.40541232,  0.33136746,  0.6403685 , -0.36857402,\n",
       "          0.41014028,  0.50619227, -0.28441408,  0.7344552 , -0.46651512],\n",
       "        [-0.4005537 ,  0.5819832 ,  0.07429712,  0.33733365, -0.5824817 ,\n",
       "          0.60591793,  0.8052315 ,  0.22843497, -0.18068577, -0.19437884]],\n",
       "       dtype=float32),\n",
       " array([ 1.5103413, -1.5514299, -1.477421 , -1.5103637,  1.5298676,\n",
       "        -1.4680467, -1.5340438,  1.5804003, -1.5009568,  1.567827 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.8999078 ],\n",
       "        [-1.1926988 ],\n",
       "        [-0.78424007],\n",
       "        [-0.92053425],\n",
       "        [ 0.98454875],\n",
       "        [-0.7650755 ],\n",
       "        [-1.1326878 ],\n",
       "        [ 1.4115849 ],\n",
       "        [-0.8369216 ],\n",
       "        [ 1.2682991 ]], dtype=float32),\n",
       " array([1.7730858], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, RMSprop, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_rmsprop_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1805 - val_loss: 0.0288\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0654 - val_loss: 0.0877\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0688 - val_loss: 0.0233\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0505 - val_loss: 0.0509\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0424 - val_loss: 0.0375\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0328 - val_loss: 0.0202\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0293 - val_loss: 0.0125\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0212 - val_loss: 0.0096\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0175 - val_loss: 0.0100\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0153 - val_loss: 0.0097\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0069\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0025 - val_loss: 0.0077\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 112us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 112us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0056\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 98us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.001 - 0s 105us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0022 - val_loss: 0.0052\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 128us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 127us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 121us/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0047\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0014 - val_loss: 0.0046\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "0.01863112300634384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0959928 , -0.17459916, -0.3729455 ,  0.62501806,  0.31459203],\n",
       "        [-0.5917074 ,  0.49819738, -0.18975246,  0.3700388 , -0.3825755 ],\n",
       "        [-1.2930732 , -0.13203529,  0.6449758 , -0.09866732,  0.0682577 ],\n",
       "        [-0.7899486 ,  0.47234327, -0.41956103,  0.7610962 , -0.23974106],\n",
       "        [-0.6984903 , -0.26560292,  0.16276215,  0.7598041 , -0.06150069],\n",
       "        [ 0.9282308 , -0.5278945 , -0.17230275,  0.37509197, -0.5026838 ],\n",
       "        [-0.3230234 , -0.21592306, -0.26587492,  0.54431283, -0.52996653],\n",
       "        [-0.06379219,  0.29524288, -0.47673675,  0.30279356,  0.10567314],\n",
       "        [ 0.36372826, -0.75964344,  0.6751306 ,  0.45946944,  0.11237138],\n",
       "        [ 0.18515678,  0.4450676 , -0.18133095,  0.11029539,  0.16288354],\n",
       "        [-0.60335475,  0.18922828,  1.0872743 , -0.9395155 ,  0.04866156],\n",
       "        [ 0.1514007 ,  0.4431238 ,  0.1500728 , -0.6002698 ,  0.10987886],\n",
       "        [ 0.21136391,  0.27824438,  0.04943134, -1.0458444 ,  0.3623466 ],\n",
       "        [ 2.2048602 , -0.05115204,  1.978957  ,  0.02310776,  0.10783893],\n",
       "        [-0.12445077,  0.5214717 , -0.46871614, -0.0145336 , -0.24877977],\n",
       "        [ 0.4496964 ,  0.10468486, -0.2771776 , -0.28247392,  0.05749227],\n",
       "        [-0.5828262 ,  0.28175026, -1.3746415 ,  1.1543846 , -0.16926067],\n",
       "        [-0.07496443,  1.482138  ,  0.3564837 ,  1.2007304 , -0.27732423],\n",
       "        [-0.09793037, -0.62799484,  2.327837  , -0.81996775,  0.27684224],\n",
       "        [ 0.45322472, -0.01976753,  0.3501308 , -0.18611035,  0.14520182],\n",
       "        [-2.342187  ,  0.2432631 , -0.55764514,  1.0424792 ,  0.5980175 ],\n",
       "        [-0.8066131 , -0.24737987,  0.89402664, -0.3865667 , -0.05842169]],\n",
       "       dtype=float32),\n",
       " array([-0.7185731 ,  0.04775778,  0.16859378,  0.21641313,  0.08829997],\n",
       "       dtype=float32),\n",
       " array([[ 5.06424248e-01,  4.39471044e-02, -6.58541679e-01,\n",
       "          2.56468989e-02, -2.15367347e-01, -3.53899837e-01,\n",
       "          4.33475338e-02, -6.28691196e-01, -6.93852127e-01,\n",
       "         -4.26103294e-01],\n",
       "        [ 6.03444695e-01, -1.19322315e-01, -1.80642292e-01,\n",
       "          3.35489474e-02, -5.22391438e-01, -2.24255286e-02,\n",
       "          6.49719596e-01, -2.62448847e-01, -3.94077569e-01,\n",
       "         -3.81255925e-01],\n",
       "        [ 4.26277876e-01,  7.84754038e-01, -2.99872130e-01,\n",
       "         -4.05043624e-02, -6.30580634e-02, -4.49415505e-01,\n",
       "          1.53763950e-01, -5.60188472e-01, -1.42003536e-01,\n",
       "         -3.04386228e-01],\n",
       "        [-1.01627782e-01, -3.38083208e-01, -5.06763935e-01,\n",
       "         -8.87502357e-02,  2.25264400e-01, -2.08504170e-01,\n",
       "         -3.28545481e-01,  1.68582853e-02, -5.53453684e-01,\n",
       "          1.53800532e-01],\n",
       "        [ 3.36770028e-01,  1.93174109e-01,  3.42250407e-01,\n",
       "         -4.45671558e-01, -6.54334053e-02,  1.55661941e-01,\n",
       "         -3.86965126e-02,  7.35013932e-02,  1.41816796e-04,\n",
       "         -2.09189132e-01]], dtype=float32),\n",
       " array([ 0.05178273,  0.0096305 , -0.00944446,  0.11800347, -0.13867775,\n",
       "         0.10965405, -0.01684099, -0.16848102, -0.01088723, -0.18302399],\n",
       "       dtype=float32),\n",
       " array([[ 0.06890523],\n",
       "        [ 0.08222633],\n",
       "        [-0.40089995],\n",
       "        [ 0.00310975],\n",
       "        [-0.02849612],\n",
       "        [-0.05512939],\n",
       "        [ 0.0064694 ],\n",
       "        [-0.08825779],\n",
       "        [-0.36771396],\n",
       "        [-0.04572617]], dtype=float32),\n",
       " array([0.12625669], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_adam_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.7602 - val_loss: 0.6579\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.7589 - val_loss: 0.6563\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.7570 - val_loss: 0.6544\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.7547 - val_loss: 0.6523\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.7524 - val_loss: 0.6499\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7497 - val_loss: 0.6476\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7471 - val_loss: 0.6452\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7444 - val_loss: 0.6428\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.7418 - val_loss: 0.6404\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.7391 - val_loss: 0.6380\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.7364 - val_loss: 0.6356\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.7337 - val_loss: 0.6332\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.7310 - val_loss: 0.6308\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7284 - val_loss: 0.6285\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7258 - val_loss: 0.6261\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7232 - val_loss: 0.6238\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7206 - val_loss: 0.6215\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7179 - val_loss: 0.6191\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7154 - val_loss: 0.6168\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.7128 - val_loss: 0.6145\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7102 - val_loss: 0.6122\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7077 - val_loss: 0.6100\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.7051 - val_loss: 0.6077\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7027 - val_loss: 0.6055\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.7001 - val_loss: 0.6032\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.6976 - val_loss: 0.6010\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6951 - val_loss: 0.5987\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.6926 - val_loss: 0.5965\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6901 - val_loss: 0.5943\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.6876 - val_loss: 0.5921\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.6852 - val_loss: 0.5899\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.6828 - val_loss: 0.5877\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6803 - val_loss: 0.5856\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.6779 - val_loss: 0.5834\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6755 - val_loss: 0.5813\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.6731 - val_loss: 0.5791\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6707 - val_loss: 0.5770\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6684 - val_loss: 0.5749\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6660 - val_loss: 0.5728\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6637 - val_loss: 0.5707\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6613 - val_loss: 0.5687\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6591 - val_loss: 0.5666\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6568 - val_loss: 0.5646\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.6545 - val_loss: 0.5626\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6522 - val_loss: 0.5605\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6499 - val_loss: 0.5585\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6477 - val_loss: 0.5565\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6454 - val_loss: 0.5545\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6432 - val_loss: 0.5525\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6410 - val_loss: 0.5506\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6388 - val_loss: 0.5486\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6365 - val_loss: 0.5466\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6343 - val_loss: 0.5446\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6322 - val_loss: 0.5427\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6300 - val_loss: 0.5408\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.6279 - val_loss: 0.5389\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6257 - val_loss: 0.5370\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6235 - val_loss: 0.5351\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.6214 - val_loss: 0.5332\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6192 - val_loss: 0.5313\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6172 - val_loss: 0.5294\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.6150 - val_loss: 0.5275\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6129 - val_loss: 0.5256\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6108 - val_loss: 0.5238\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.6088 - val_loss: 0.5219\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6067 - val_loss: 0.5201\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.6047 - val_loss: 0.5183\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.6026 - val_loss: 0.5165\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.6006 - val_loss: 0.5147\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5986 - val_loss: 0.5129\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5966 - val_loss: 0.5112\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5946 - val_loss: 0.5094\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5926 - val_loss: 0.5076\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5906 - val_loss: 0.5059\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.5886 - val_loss: 0.5041\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5867 - val_loss: 0.5024\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5847 - val_loss: 0.5007\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5828 - val_loss: 0.4990\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5809 - val_loss: 0.4972\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5789 - val_loss: 0.4955\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5770 - val_loss: 0.4938\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5750 - val_loss: 0.4921\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.5731 - val_loss: 0.4904\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5712 - val_loss: 0.4887\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5694 - val_loss: 0.4870\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.5674 - val_loss: 0.4854\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.5656 - val_loss: 0.4837\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.5638 - val_loss: 0.4821\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5619 - val_loss: 0.4805\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5601 - val_loss: 0.4789\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5583 - val_loss: 0.4773\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5565 - val_loss: 0.4757\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.5547 - val_loss: 0.4741\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.5528 - val_loss: 0.4725\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5511 - val_loss: 0.4709\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5493 - val_loss: 0.4693\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5475 - val_loss: 0.4677\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5457 - val_loss: 0.4662\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5439 - val_loss: 0.4646\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5422 - val_loss: 0.4631\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5404 - val_loss: 0.4615\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5387 - val_loss: 0.4600\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.5369 - val_loss: 0.4584\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5353 - val_loss: 0.4569\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5335 - val_loss: 0.4554\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5318 - val_loss: 0.4539\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5301 - val_loss: 0.4523\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.5283 - val_loss: 0.4508\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.5266 - val_loss: 0.4493\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.5250 - val_loss: 0.4478\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.5233 - val_loss: 0.4463\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.5215 - val_loss: 0.4448\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5199 - val_loss: 0.4433\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.5182 - val_loss: 0.4419\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5165 - val_loss: 0.4404\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5149 - val_loss: 0.4390\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5132 - val_loss: 0.4375\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5116 - val_loss: 0.4361\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5100 - val_loss: 0.4347\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5084 - val_loss: 0.4333\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5052 - val_loss: 0.4305\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.5036 - val_loss: 0.4291\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.5021 - val_loss: 0.4277\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.5005 - val_loss: 0.4263\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4989 - val_loss: 0.4249\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4973 - val_loss: 0.4235\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4958 - val_loss: 0.4221\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4942 - val_loss: 0.4208\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4926 - val_loss: 0.4194\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4911 - val_loss: 0.4180\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4895 - val_loss: 0.4167\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4880 - val_loss: 0.4153\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.4865 - val_loss: 0.4140\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.4850 - val_loss: 0.4127\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.4835 - val_loss: 0.4114\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.4820 - val_loss: 0.4100\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.4805 - val_loss: 0.4087\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4790 - val_loss: 0.4074\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4775 - val_loss: 0.4061\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4761 - val_loss: 0.4048\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4746 - val_loss: 0.4036\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4732 - val_loss: 0.4023\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4717 - val_loss: 0.4010\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4703 - val_loss: 0.3998\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4689 - val_loss: 0.3985\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.4674 - val_loss: 0.3973\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4660 - val_loss: 0.3960\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4646 - val_loss: 0.3948\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4632 - val_loss: 0.3936\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4618 - val_loss: 0.3923\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4604 - val_loss: 0.3911\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4590 - val_loss: 0.3899\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4576 - val_loss: 0.3887\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4563 - val_loss: 0.3875\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4549 - val_loss: 0.3863\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4536 - val_loss: 0.3851\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4522 - val_loss: 0.3840\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4509 - val_loss: 0.3828\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4495 - val_loss: 0.3816\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.4482 - val_loss: 0.3804\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4469 - val_loss: 0.3793\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4456 - val_loss: 0.3782\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4443 - val_loss: 0.3770\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4430 - val_loss: 0.3759\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4417 - val_loss: 0.3747\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4404 - val_loss: 0.3736\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4391 - val_loss: 0.3725\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.4378 - val_loss: 0.3713\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4365 - val_loss: 0.3702\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4352 - val_loss: 0.3691\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4339 - val_loss: 0.3679\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4327 - val_loss: 0.3668\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4313 - val_loss: 0.3657\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4301 - val_loss: 0.3646\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.4289 - val_loss: 0.3636\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4276 - val_loss: 0.3625\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4264 - val_loss: 0.3614\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4252 - val_loss: 0.3604\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4240 - val_loss: 0.3593\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4227 - val_loss: 0.3582\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4215 - val_loss: 0.3571\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4203 - val_loss: 0.3561\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4191 - val_loss: 0.3550\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4179 - val_loss: 0.3540\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4166 - val_loss: 0.3529\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4155 - val_loss: 0.3519\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4142 - val_loss: 0.3508\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4131 - val_loss: 0.3498\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4119 - val_loss: 0.3488\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.4108 - val_loss: 0.3478\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4096 - val_loss: 0.3468\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4084 - val_loss: 0.3458\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4073 - val_loss: 0.3448\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.4062 - val_loss: 0.3438\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.4050 - val_loss: 0.3428\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.4039 - val_loss: 0.3418\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4028 - val_loss: 0.3408\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.4016 - val_loss: 0.3398\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.4005 - val_loss: 0.3389\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3994 - val_loss: 0.3379\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3983 - val_loss: 0.3369\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3971 - val_loss: 0.3359\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3960 - val_loss: 0.3350\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3949 - val_loss: 0.3340\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.3938 - val_loss: 0.3331\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3927 - val_loss: 0.3321\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3916 - val_loss: 0.3312\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3905 - val_loss: 0.3302\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3895 - val_loss: 0.3293\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3884 - val_loss: 0.3284\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.3873 - val_loss: 0.3274\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.3863 - val_loss: 0.3265\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.3852 - val_loss: 0.3256\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3842 - val_loss: 0.3247\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3831 - val_loss: 0.3238\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3821 - val_loss: 0.3229\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3810 - val_loss: 0.3219\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.3800 - val_loss: 0.3210\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3789 - val_loss: 0.3201\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3779 - val_loss: 0.3192\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3769 - val_loss: 0.3184\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3759 - val_loss: 0.3175\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3749 - val_loss: 0.3167\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 84us/step - loss: 0.3739 - val_loss: 0.3158\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3729 - val_loss: 0.3149\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3719 - val_loss: 0.3141\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3709 - val_loss: 0.3132\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3699 - val_loss: 0.3124\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3689 - val_loss: 0.3115\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3680 - val_loss: 0.3106\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3669 - val_loss: 0.3098\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.3660 - val_loss: 0.3089\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.3650 - val_loss: 0.3081\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3640 - val_loss: 0.3073\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3631 - val_loss: 0.3065\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3622 - val_loss: 0.3056\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3612 - val_loss: 0.3048\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3602 - val_loss: 0.3040\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3593 - val_loss: 0.3032\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.3583 - val_loss: 0.3024\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3574 - val_loss: 0.3016\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3565 - val_loss: 0.3007\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3556 - val_loss: 0.2999\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.3547 - val_loss: 0.2991\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3537 - val_loss: 0.2984\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3528 - val_loss: 0.2976\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3519 - val_loss: 0.2968\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3510 - val_loss: 0.2961\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3502 - val_loss: 0.2953\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3493 - val_loss: 0.2945\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3484 - val_loss: 0.2938\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.3475 - val_loss: 0.2930\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.3466 - val_loss: 0.2922\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.3457 - val_loss: 0.2915\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3448 - val_loss: 0.2907\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3440 - val_loss: 0.2899\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3431 - val_loss: 0.2892\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3422 - val_loss: 0.2885\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3414 - val_loss: 0.2877\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3405 - val_loss: 0.2870\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3397 - val_loss: 0.2863\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3389 - val_loss: 0.2856\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3380 - val_loss: 0.2849\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3372 - val_loss: 0.2841\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3364 - val_loss: 0.2834\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3355 - val_loss: 0.2827\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3346 - val_loss: 0.2820\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3338 - val_loss: 0.2812\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3330 - val_loss: 0.2805\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3322 - val_loss: 0.2798\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3313 - val_loss: 0.2791\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3305 - val_loss: 0.2784\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3297 - val_loss: 0.2777\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3289 - val_loss: 0.2770\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3280 - val_loss: 0.2763\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3272 - val_loss: 0.2756\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3264 - val_loss: 0.2749\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3256 - val_loss: 0.2742\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3248 - val_loss: 0.2735\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3240 - val_loss: 0.2728\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3232 - val_loss: 0.2722\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3225 - val_loss: 0.2715\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3217 - val_loss: 0.2708\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3209 - val_loss: 0.2702\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3202 - val_loss: 0.2695\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.3194 - val_loss: 0.2689\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3186 - val_loss: 0.2682\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3178 - val_loss: 0.2676\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3171 - val_loss: 0.2669\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3164 - val_loss: 0.2663\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3156 - val_loss: 0.2656\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3148 - val_loss: 0.2650\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.3141 - val_loss: 0.2643\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3134 - val_loss: 0.2637\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3126 - val_loss: 0.2631\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.3119 - val_loss: 0.2625\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3112 - val_loss: 0.2618\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3104 - val_loss: 0.2612\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3097 - val_loss: 0.2606\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3090 - val_loss: 0.2600\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3082 - val_loss: 0.2593\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.3075 - val_loss: 0.2587\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.3068 - val_loss: 0.2581\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3061 - val_loss: 0.2575\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3053 - val_loss: 0.2569\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3046 - val_loss: 0.2563\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3039 - val_loss: 0.2556\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3032 - val_loss: 0.2550\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3025 - val_loss: 0.2544\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.3018 - val_loss: 0.2538\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3011 - val_loss: 0.2532\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.3004 - val_loss: 0.2527\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2997 - val_loss: 0.2521\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2990 - val_loss: 0.2515\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2983 - val_loss: 0.2509\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2977 - val_loss: 0.2503\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2970 - val_loss: 0.2498\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2963 - val_loss: 0.2492\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2957 - val_loss: 0.2486\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2950 - val_loss: 0.2481\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2943 - val_loss: 0.2475\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2937 - val_loss: 0.2469\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2930 - val_loss: 0.2464\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2923 - val_loss: 0.2458\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.2917 - val_loss: 0.2453\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2911 - val_loss: 0.2447\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2904 - val_loss: 0.2442\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2898 - val_loss: 0.2436\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2891 - val_loss: 0.2431\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2885 - val_loss: 0.2425\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2878 - val_loss: 0.2420\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2872 - val_loss: 0.2414\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2866 - val_loss: 0.2409\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2860 - val_loss: 0.2404\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2853 - val_loss: 0.2399\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2847 - val_loss: 0.2393\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2841 - val_loss: 0.2388\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2835 - val_loss: 0.2383\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2828 - val_loss: 0.2377\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2822 - val_loss: 0.2372\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2816 - val_loss: 0.2367\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.2810 - val_loss: 0.2362\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2804 - val_loss: 0.2357\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2798 - val_loss: 0.2352\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.2792 - val_loss: 0.2347\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2786 - val_loss: 0.2342\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.2780 - val_loss: 0.2337\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2775 - val_loss: 0.2332\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2769 - val_loss: 0.2327\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2763 - val_loss: 0.2322\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2757 - val_loss: 0.2317\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2751 - val_loss: 0.2312\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2745 - val_loss: 0.2307\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2740 - val_loss: 0.2302\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2734 - val_loss: 0.2297\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2728 - val_loss: 0.2293\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2722 - val_loss: 0.2288\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2717 - val_loss: 0.2283\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2711 - val_loss: 0.2279\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2706 - val_loss: 0.2274\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2700 - val_loss: 0.2269\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2694 - val_loss: 0.2264\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2689 - val_loss: 0.2259\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2683 - val_loss: 0.2255\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2677 - val_loss: 0.2250\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2672 - val_loss: 0.2245\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2666 - val_loss: 0.2240\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2661 - val_loss: 0.2236\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2656 - val_loss: 0.2231\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2650 - val_loss: 0.2227\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2645 - val_loss: 0.2222\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2640 - val_loss: 0.2218\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2634 - val_loss: 0.2214\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.2629 - val_loss: 0.2209\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2624 - val_loss: 0.2205\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2618 - val_loss: 0.2200\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2613 - val_loss: 0.2196\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2608 - val_loss: 0.2191\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2602 - val_loss: 0.2187\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.2597 - val_loss: 0.2182\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2592 - val_loss: 0.2178\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.2587 - val_loss: 0.2174\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2581 - val_loss: 0.2169\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2577 - val_loss: 0.2165\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2571 - val_loss: 0.2161\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2566 - val_loss: 0.2157\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2562 - val_loss: 0.2153\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2557 - val_loss: 0.2148\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2552 - val_loss: 0.2144\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2547 - val_loss: 0.2140\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.2542 - val_loss: 0.2136\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2537 - val_loss: 0.2132\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2532 - val_loss: 0.2128\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2527 - val_loss: 0.2124\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2522 - val_loss: 0.2120\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2517 - val_loss: 0.2115\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2512 - val_loss: 0.2111\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2508 - val_loss: 0.2107\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2503 - val_loss: 0.2103\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2498 - val_loss: 0.2099\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2493 - val_loss: 0.2095\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2488 - val_loss: 0.2091\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2483 - val_loss: 0.2087\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2479 - val_loss: 0.2083\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2474 - val_loss: 0.2079\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2469 - val_loss: 0.2075\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2464 - val_loss: 0.2071\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2460 - val_loss: 0.2067\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2455 - val_loss: 0.2063\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2450 - val_loss: 0.2059\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2445 - val_loss: 0.2055\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2441 - val_loss: 0.2051\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2436 - val_loss: 0.2048\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2432 - val_loss: 0.2044\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2427 - val_loss: 0.2040\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2423 - val_loss: 0.2036\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2418 - val_loss: 0.2033\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2414 - val_loss: 0.2029\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2409 - val_loss: 0.2025\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2405 - val_loss: 0.2022\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2401 - val_loss: 0.2018\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2396 - val_loss: 0.2014\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2392 - val_loss: 0.2011\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2388 - val_loss: 0.2007\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.2383 - val_loss: 0.2003\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2379 - val_loss: 0.2000\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.2374 - val_loss: 0.1996\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2370 - val_loss: 0.1993\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2366 - val_loss: 0.1989\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2361 - val_loss: 0.1985\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.300 - 0s 91us/step - loss: 0.2357 - val_loss: 0.1982\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2353 - val_loss: 0.1978\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2349 - val_loss: 0.1975\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2345 - val_loss: 0.1971\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2341 - val_loss: 0.1968\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2336 - val_loss: 0.1964\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2332 - val_loss: 0.1961\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2328 - val_loss: 0.1958\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2324 - val_loss: 0.1954\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2320 - val_loss: 0.1951\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2315 - val_loss: 0.1947\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2311 - val_loss: 0.1944\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2307 - val_loss: 0.1940\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2303 - val_loss: 0.1937\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2299 - val_loss: 0.1934\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2295 - val_loss: 0.1931\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2291 - val_loss: 0.1927\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2287 - val_loss: 0.1924\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2283 - val_loss: 0.1921\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2279 - val_loss: 0.1917\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2275 - val_loss: 0.1914\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2271 - val_loss: 0.1911\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2268 - val_loss: 0.1908\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2264 - val_loss: 0.1904\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2260 - val_loss: 0.1901\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2256 - val_loss: 0.1898\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2252 - val_loss: 0.1895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2249 - val_loss: 0.1892\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2245 - val_loss: 0.1889\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2241 - val_loss: 0.1885\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2237 - val_loss: 0.1882\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2233 - val_loss: 0.1879\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2230 - val_loss: 0.1876\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.2226 - val_loss: 0.1873\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2222 - val_loss: 0.1870\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2218 - val_loss: 0.1867\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2215 - val_loss: 0.1864\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2211 - val_loss: 0.1861\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2207 - val_loss: 0.1858\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.2204 - val_loss: 0.1855\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2200 - val_loss: 0.1852\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2196 - val_loss: 0.1849\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2193 - val_loss: 0.1846\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2189 - val_loss: 0.1843\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2185 - val_loss: 0.1840\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2182 - val_loss: 0.1837\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2178 - val_loss: 0.1834\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2175 - val_loss: 0.1831\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.2171 - val_loss: 0.1828\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2168 - val_loss: 0.1825\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.2164 - val_loss: 0.1822\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2161 - val_loss: 0.1819\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2157 - val_loss: 0.1817\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2154 - val_loss: 0.1814\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2150 - val_loss: 0.1811\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2147 - val_loss: 0.1808\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2144 - val_loss: 0.1805\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2140 - val_loss: 0.1802\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2137 - val_loss: 0.1800\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2133 - val_loss: 0.1797\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2130 - val_loss: 0.1794\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2127 - val_loss: 0.1791\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2123 - val_loss: 0.1789\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2120 - val_loss: 0.1786\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2117 - val_loss: 0.1783\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2113 - val_loss: 0.1781\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2110 - val_loss: 0.1778\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2107 - val_loss: 0.1776\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2104 - val_loss: 0.1773\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2101 - val_loss: 0.1770\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2098 - val_loss: 0.1768\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2094 - val_loss: 0.1765\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2091 - val_loss: 0.1763\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2088 - val_loss: 0.1760\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2085 - val_loss: 0.1757\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2082 - val_loss: 0.1755\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2079 - val_loss: 0.1752\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2076 - val_loss: 0.1750\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2073 - val_loss: 0.1747\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2069 - val_loss: 0.1745\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2066 - val_loss: 0.1742\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2063 - val_loss: 0.1740\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2060 - val_loss: 0.1737\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2057 - val_loss: 0.1735\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2054 - val_loss: 0.1732\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2051 - val_loss: 0.1730\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2048 - val_loss: 0.1727\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2045 - val_loss: 0.1725\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2042 - val_loss: 0.1723\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2039 - val_loss: 0.1720\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2036 - val_loss: 0.1718\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.304 - 0s 91us/step - loss: 0.2033 - val_loss: 0.1715\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2030 - val_loss: 0.1713\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2027 - val_loss: 0.1710\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2025 - val_loss: 0.1708\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2022 - val_loss: 0.1706\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2019 - val_loss: 0.1703\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2016 - val_loss: 0.1701\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2013 - val_loss: 0.1699\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.2010 - val_loss: 0.1696\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2007 - val_loss: 0.1694\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2004 - val_loss: 0.1691\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2001 - val_loss: 0.1689\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1998 - val_loss: 0.1687\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1996 - val_loss: 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1993 - val_loss: 0.1683\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1990 - val_loss: 0.1680\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1988 - val_loss: 0.1678\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1985 - val_loss: 0.1676\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1982 - val_loss: 0.1674\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1979 - val_loss: 0.1671\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1977 - val_loss: 0.1669\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1974 - val_loss: 0.1667\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1971 - val_loss: 0.1665\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1968 - val_loss: 0.1663\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1966 - val_loss: 0.1660\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1963 - val_loss: 0.1658\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1960 - val_loss: 0.1656\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1958 - val_loss: 0.1654\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1955 - val_loss: 0.1652\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1952 - val_loss: 0.1650\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1950 - val_loss: 0.1647\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1947 - val_loss: 0.1645\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1945 - val_loss: 0.1643\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1942 - val_loss: 0.1641\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1939 - val_loss: 0.1639\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1937 - val_loss: 0.1637\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1934 - val_loss: 0.1635\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1932 - val_loss: 0.1633\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1929 - val_loss: 0.1631\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1927 - val_loss: 0.1629\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1924 - val_loss: 0.1627\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1922 - val_loss: 0.1625\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1919 - val_loss: 0.1623\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1917 - val_loss: 0.1621\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1914 - val_loss: 0.1619\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1912 - val_loss: 0.1617\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1909 - val_loss: 0.1615\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1907 - val_loss: 0.1613\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1904 - val_loss: 0.1611\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1901 - val_loss: 0.1609\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1899 - val_loss: 0.1606\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1896 - val_loss: 0.1604\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1894 - val_loss: 0.1602\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1892 - val_loss: 0.1600\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1889 - val_loss: 0.1599\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1887 - val_loss: 0.1597\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1884 - val_loss: 0.1595\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1882 - val_loss: 0.1593\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1879 - val_loss: 0.1591\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1877 - val_loss: 0.1589\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1874 - val_loss: 0.1587\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1872 - val_loss: 0.1585\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1870 - val_loss: 0.1583\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1867 - val_loss: 0.1581\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1865 - val_loss: 0.1579\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1863 - val_loss: 0.1577\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1860 - val_loss: 0.1576\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1858 - val_loss: 0.1574\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1856 - val_loss: 0.1572\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1854 - val_loss: 0.1570\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1851 - val_loss: 0.1568\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1849 - val_loss: 0.1566\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1847 - val_loss: 0.1565\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1844 - val_loss: 0.1563\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1842 - val_loss: 0.1561\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1840 - val_loss: 0.1559\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1838 - val_loss: 0.1557\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1836 - val_loss: 0.1555\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1833 - val_loss: 0.1554\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1831 - val_loss: 0.1552\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1829 - val_loss: 0.1550\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.200 - 0s 105us/step - loss: 0.1827 - val_loss: 0.1548\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1824 - val_loss: 0.1547\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1822 - val_loss: 0.1545\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1820 - val_loss: 0.1543\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1818 - val_loss: 0.1541\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.1816 - val_loss: 0.1540\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.1813 - val_loss: 0.1538\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.1811 - val_loss: 0.1536\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1809 - val_loss: 0.1535\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1807 - val_loss: 0.1533\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 119us/step - loss: 0.1805 - val_loss: 0.1531\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1803 - val_loss: 0.1530\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1801 - val_loss: 0.1528\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1799 - val_loss: 0.1527\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1797 - val_loss: 0.1525\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1795 - val_loss: 0.1523\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1793 - val_loss: 0.1522\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1791 - val_loss: 0.1520\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1789 - val_loss: 0.1518\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1787 - val_loss: 0.1517\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1785 - val_loss: 0.1515\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1783 - val_loss: 0.1513\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1781 - val_loss: 0.1512\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1778 - val_loss: 0.1510\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.1776 - val_loss: 0.1509\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1774 - val_loss: 0.1507\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1772 - val_loss: 0.1505\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1770 - val_loss: 0.1504\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1768 - val_loss: 0.1502\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1766 - val_loss: 0.1501\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1764 - val_loss: 0.1499\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1762 - val_loss: 0.1497\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1760 - val_loss: 0.1496\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1758 - val_loss: 0.1494\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1756 - val_loss: 0.1493\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1754 - val_loss: 0.1491\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1752 - val_loss: 0.1489\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1750 - val_loss: 0.1488\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1748 - val_loss: 0.1486\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1747 - val_loss: 0.1485\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1745 - val_loss: 0.1483\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 167us/step - loss: 0.1743 - val_loss: 0.1482\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1741 - val_loss: 0.1480\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1739 - val_loss: 0.1479\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1737 - val_loss: 0.1477\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1735 - val_loss: 0.1476\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1733 - val_loss: 0.1474\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1731 - val_loss: 0.1473\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1730 - val_loss: 0.1471\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1728 - val_loss: 0.1470\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.1726 - val_loss: 0.1469\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1724 - val_loss: 0.1467\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1722 - val_loss: 0.1466\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1720 - val_loss: 0.1464\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1719 - val_loss: 0.1463\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1717 - val_loss: 0.1461\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1715 - val_loss: 0.1460\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1713 - val_loss: 0.1458\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1711 - val_loss: 0.1457\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1709 - val_loss: 0.1456\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1708 - val_loss: 0.1454\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1706 - val_loss: 0.1453\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1704 - val_loss: 0.1451\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1702 - val_loss: 0.1450\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1700 - val_loss: 0.1449\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1699 - val_loss: 0.1447\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1697 - val_loss: 0.1446\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1695 - val_loss: 0.1444\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1693 - val_loss: 0.1443\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1692 - val_loss: 0.1442\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1690 - val_loss: 0.1440\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1688 - val_loss: 0.1439\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1686 - val_loss: 0.1438\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1685 - val_loss: 0.1436\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1683 - val_loss: 0.1435\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1681 - val_loss: 0.1434\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1680 - val_loss: 0.1432\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1678 - val_loss: 0.1431\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1676 - val_loss: 0.1430\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1675 - val_loss: 0.1428\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1673 - val_loss: 0.1427\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1671 - val_loss: 0.1426\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1670 - val_loss: 0.1424\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1668 - val_loss: 0.1423\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1666 - val_loss: 0.1422\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1665 - val_loss: 0.1420\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1663 - val_loss: 0.1419\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1661 - val_loss: 0.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1660 - val_loss: 0.1417\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1658 - val_loss: 0.1415\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1657 - val_loss: 0.1414\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1655 - val_loss: 0.1413\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1653 - val_loss: 0.1412\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1652 - val_loss: 0.1410\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1650 - val_loss: 0.1409\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1648 - val_loss: 0.1408\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1647 - val_loss: 0.1407\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1645 - val_loss: 0.1405\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1644 - val_loss: 0.1404\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1642 - val_loss: 0.1403\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1641 - val_loss: 0.1402\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1639 - val_loss: 0.1401\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.1638 - val_loss: 0.1400\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1636 - val_loss: 0.1399\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1635 - val_loss: 0.1397\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1633 - val_loss: 0.1396\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1632 - val_loss: 0.1395\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 88us/step - loss: 0.1630 - val_loss: 0.1394\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1629 - val_loss: 0.1393\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1627 - val_loss: 0.1391\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1626 - val_loss: 0.1390\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1624 - val_loss: 0.1389\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1623 - val_loss: 0.1388\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1622 - val_loss: 0.1387\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1620 - val_loss: 0.1386\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1619 - val_loss: 0.1385\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1617 - val_loss: 0.1383\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.1616 - val_loss: 0.1382\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1614 - val_loss: 0.1381\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1613 - val_loss: 0.1380\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1611 - val_loss: 0.1379\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1610 - val_loss: 0.1378\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1608 - val_loss: 0.1377\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.1607 - val_loss: 0.1376\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 87us/step - loss: 0.1606 - val_loss: 0.1375\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1604 - val_loss: 0.1374\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1603 - val_loss: 0.1373\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1602 - val_loss: 0.1372\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1600 - val_loss: 0.1371\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1599 - val_loss: 0.1369\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1598 - val_loss: 0.1368\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1596 - val_loss: 0.1367\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1595 - val_loss: 0.1366\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1594 - val_loss: 0.1365\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1592 - val_loss: 0.1364\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1591 - val_loss: 0.1363\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1590 - val_loss: 0.1362\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1588 - val_loss: 0.1361\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1587 - val_loss: 0.1360\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1586 - val_loss: 0.1359\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1584 - val_loss: 0.1358\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1583 - val_loss: 0.1357\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1581 - val_loss: 0.1356\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1580 - val_loss: 0.1355\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1579 - val_loss: 0.1354\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1578 - val_loss: 0.1353\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1576 - val_loss: 0.1352\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1575 - val_loss: 0.1351\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1574 - val_loss: 0.1350\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1573 - val_loss: 0.1349\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.1571 - val_loss: 0.1348\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1570 - val_loss: 0.1347\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.1569 - val_loss: 0.1346\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1567 - val_loss: 0.1345\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1566 - val_loss: 0.1344\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1565 - val_loss: 0.1343\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1564 - val_loss: 0.1342\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.1562 - val_loss: 0.1341\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1561 - val_loss: 0.1340\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1560 - val_loss: 0.1339\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1559 - val_loss: 0.1338\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1557 - val_loss: 0.1337\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1556 - val_loss: 0.1337\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1555 - val_loss: 0.1336\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1554 - val_loss: 0.1335\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1552 - val_loss: 0.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1551 - val_loss: 0.1333\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1550 - val_loss: 0.1332\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1549 - val_loss: 0.1331\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1548 - val_loss: 0.1330\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1546 - val_loss: 0.1329\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1545 - val_loss: 0.1328\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1544 - val_loss: 0.1327\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1543 - val_loss: 0.1326\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1542 - val_loss: 0.1325\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1540 - val_loss: 0.1325\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1539 - val_loss: 0.1324\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1538 - val_loss: 0.1323\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1537 - val_loss: 0.1322\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1536 - val_loss: 0.1321\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1535 - val_loss: 0.1320\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1534 - val_loss: 0.1319\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1532 - val_loss: 0.1318\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1531 - val_loss: 0.1317\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1530 - val_loss: 0.1317\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1529 - val_loss: 0.1316\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1528 - val_loss: 0.1315\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1527 - val_loss: 0.1314\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1526 - val_loss: 0.1313\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1524 - val_loss: 0.1312\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1523 - val_loss: 0.1311\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1522 - val_loss: 0.1310\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1521 - val_loss: 0.1310\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1520 - val_loss: 0.1309\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1519 - val_loss: 0.1308\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1518 - val_loss: 0.1307\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1516 - val_loss: 0.1306\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1515 - val_loss: 0.1305\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1514 - val_loss: 0.1304\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1513 - val_loss: 0.1304\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1512 - val_loss: 0.1303\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1511 - val_loss: 0.1302\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1510 - val_loss: 0.1301\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1509 - val_loss: 0.1300\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1508 - val_loss: 0.1299\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1506 - val_loss: 0.1299\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1505 - val_loss: 0.1298\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1504 - val_loss: 0.1297\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1503 - val_loss: 0.1296\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1502 - val_loss: 0.1295\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1501 - val_loss: 0.1294\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1500 - val_loss: 0.1294\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1499 - val_loss: 0.1293\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1498 - val_loss: 0.1292\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1497 - val_loss: 0.1291\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1496 - val_loss: 0.1290\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1494 - val_loss: 0.1290\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1493 - val_loss: 0.1289\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1492 - val_loss: 0.1288\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1491 - val_loss: 0.1287\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1490 - val_loss: 0.1286\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1489 - val_loss: 0.1286\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1488 - val_loss: 0.1285\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1487 - val_loss: 0.1284\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1486 - val_loss: 0.1283\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1485 - val_loss: 0.1283\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1484 - val_loss: 0.1282\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1483 - val_loss: 0.1281\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1482 - val_loss: 0.1280\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1481 - val_loss: 0.1280\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1480 - val_loss: 0.1279\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1479 - val_loss: 0.1278\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1478 - val_loss: 0.1277\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1477 - val_loss: 0.1277\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1477 - val_loss: 0.1276\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.1476 - val_loss: 0.1275\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1475 - val_loss: 0.1275\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1474 - val_loss: 0.1274\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1473 - val_loss: 0.1273\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1472 - val_loss: 0.1272\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1471 - val_loss: 0.1272\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1470 - val_loss: 0.1271\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1469 - val_loss: 0.1270\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1468 - val_loss: 0.1270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1467 - val_loss: 0.1269\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1466 - val_loss: 0.1268\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1465 - val_loss: 0.1268\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1464 - val_loss: 0.1267\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1463 - val_loss: 0.1266\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1462 - val_loss: 0.1265\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1462 - val_loss: 0.1265\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1461 - val_loss: 0.1264\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1460 - val_loss: 0.1263\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1459 - val_loss: 0.1263\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1458 - val_loss: 0.1262\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1457 - val_loss: 0.1261\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1456 - val_loss: 0.1261\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1455 - val_loss: 0.1260\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1454 - val_loss: 0.1259\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1453 - val_loss: 0.1259\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1453 - val_loss: 0.1258\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.1452 - val_loss: 0.1257\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1451 - val_loss: 0.1257\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1450 - val_loss: 0.1256\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1449 - val_loss: 0.1255\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1448 - val_loss: 0.1255\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1447 - val_loss: 0.1254\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1447 - val_loss: 0.1254\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1446 - val_loss: 0.1253\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1445 - val_loss: 0.1252\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1444 - val_loss: 0.1252\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1443 - val_loss: 0.1251\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1442 - val_loss: 0.1250\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1441 - val_loss: 0.1250\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1441 - val_loss: 0.1249\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.1440 - val_loss: 0.1248\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1439 - val_loss: 0.1248\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1438 - val_loss: 0.1247\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1437 - val_loss: 0.1246\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1436 - val_loss: 0.1246\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1435 - val_loss: 0.1245\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1434 - val_loss: 0.1244\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1434 - val_loss: 0.1244\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1433 - val_loss: 0.1243\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1432 - val_loss: 0.1242\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1431 - val_loss: 0.1242\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1430 - val_loss: 0.1241\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1429 - val_loss: 0.1241\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1429 - val_loss: 0.1240\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1428 - val_loss: 0.1239\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1427 - val_loss: 0.1239\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1426 - val_loss: 0.1238\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1425 - val_loss: 0.1238\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1425 - val_loss: 0.1237\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1424 - val_loss: 0.1236\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1423 - val_loss: 0.1236\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1422 - val_loss: 0.1235\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1421 - val_loss: 0.1235\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1421 - val_loss: 0.1234\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1420 - val_loss: 0.1233\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1419 - val_loss: 0.1233\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1418 - val_loss: 0.1232\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1417 - val_loss: 0.1232\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1417 - val_loss: 0.1231\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1416 - val_loss: 0.1231\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1415 - val_loss: 0.1230\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1414 - val_loss: 0.1229\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1413 - val_loss: 0.1229\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1413 - val_loss: 0.1228\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1412 - val_loss: 0.1228\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1411 - val_loss: 0.1227\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1410 - val_loss: 0.1226\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1409 - val_loss: 0.1226\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1409 - val_loss: 0.1225\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1408 - val_loss: 0.1225\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1407 - val_loss: 0.1224\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1407 - val_loss: 0.1224\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1406 - val_loss: 0.1223\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1405 - val_loss: 0.1223\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1404 - val_loss: 0.1222\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1404 - val_loss: 0.1222\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1403 - val_loss: 0.1221\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.1402 - val_loss: 0.1220\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1401 - val_loss: 0.1220\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1401 - val_loss: 0.1219\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1400 - val_loss: 0.1219\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1399 - val_loss: 0.1218\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1399 - val_loss: 0.1218\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1398 - val_loss: 0.1217\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1397 - val_loss: 0.1217\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1396 - val_loss: 0.1216\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1396 - val_loss: 0.1216\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1395 - val_loss: 0.1215\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1394 - val_loss: 0.1215\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1394 - val_loss: 0.1214\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1393 - val_loss: 0.1214\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1392 - val_loss: 0.1213\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1392 - val_loss: 0.1213\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1391 - val_loss: 0.1212\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1390 - val_loss: 0.1212\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1390 - val_loss: 0.1211\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1389 - val_loss: 0.1211\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1388 - val_loss: 0.1210\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1387 - val_loss: 0.1210\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1387 - val_loss: 0.1209\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1386 - val_loss: 0.1208\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1385 - val_loss: 0.1208\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1385 - val_loss: 0.1207\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1384 - val_loss: 0.1207\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1383 - val_loss: 0.1206\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1383 - val_loss: 0.1206\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1382 - val_loss: 0.1205\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1381 - val_loss: 0.1205\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1380 - val_loss: 0.1204\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1380 - val_loss: 0.1204\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.1379 - val_loss: 0.1203\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.1378 - val_loss: 0.1203\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1378 - val_loss: 0.1202\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1377 - val_loss: 0.1202\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1376 - val_loss: 0.1201\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1376 - val_loss: 0.1201\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1375 - val_loss: 0.1200\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1374 - val_loss: 0.1200\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1374 - val_loss: 0.1199\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1373 - val_loss: 0.1199\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1372 - val_loss: 0.1198\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1372 - val_loss: 0.1198\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1371 - val_loss: 0.1197\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1370 - val_loss: 0.1197\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1370 - val_loss: 0.1196\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1369 - val_loss: 0.1196\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1368 - val_loss: 0.1195\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1368 - val_loss: 0.1195\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1367 - val_loss: 0.1194\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.1366 - val_loss: 0.1194\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1365 - val_loss: 0.1194\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.200 - 0s 91us/step - loss: 0.1365 - val_loss: 0.1193\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1364 - val_loss: 0.1193\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1364 - val_loss: 0.1192\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1363 - val_loss: 0.1192\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1362 - val_loss: 0.1191\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1362 - val_loss: 0.1191\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1361 - val_loss: 0.1190\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1360 - val_loss: 0.1190\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1360 - val_loss: 0.1189\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1359 - val_loss: 0.1189\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1359 - val_loss: 0.1188\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1358 - val_loss: 0.1188\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.1357 - val_loss: 0.1187\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1357 - val_loss: 0.1187\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1356 - val_loss: 0.1187\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1355 - val_loss: 0.1186\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.1355 - val_loss: 0.1186\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1354 - val_loss: 0.1185\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1353 - val_loss: 0.1185\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1353 - val_loss: 0.1184\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1352 - val_loss: 0.1184\n",
      "0.10740172117948532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.44749817,  0.43058276, -0.0732604 , -0.2730294 , -0.2135475 ],\n",
       "        [ 0.273385  , -0.43561307,  0.11358029,  0.1775234 ,  0.22403076],\n",
       "        [-0.13714333, -0.07853865, -0.23490739, -0.26359332, -0.31931153],\n",
       "        [-0.15491037, -0.20108978,  0.4479912 , -0.25765964,  0.3646802 ],\n",
       "        [ 0.17188923,  0.44070795,  0.32161576, -0.0662131 ,  0.04318114],\n",
       "        [ 0.39512783,  0.34095925, -0.15394492,  0.3282869 , -0.39534953],\n",
       "        [-0.13171232,  0.12497909, -0.09154812,  0.185897  , -0.43011597],\n",
       "        [-0.430862  , -0.05901862, -0.23249988, -0.05399773,  0.09468611],\n",
       "        [ 0.22293434, -0.40188164,  0.19425711,  0.04249582, -0.00817109],\n",
       "        [-0.1899536 ,  0.22039177,  0.40363556,  0.413685  , -0.02618048],\n",
       "        [ 0.42016235, -0.389917  ,  0.05256459, -0.3238426 ,  0.22722284],\n",
       "        [ 0.27789575,  0.17032982,  0.47112378, -0.16949576,  0.31125602],\n",
       "        [ 0.09705093, -0.25332695,  0.27044493, -0.26531658, -0.32624438],\n",
       "        [ 0.25816163, -0.16742595,  0.2967204 ,  0.2830767 , -0.4176015 ],\n",
       "        [ 0.42914754,  0.42629412, -0.02365405, -0.39179134,  0.2944389 ],\n",
       "        [ 0.38224295,  0.03348037,  0.02060541, -0.17013879, -0.29371944],\n",
       "        [ 0.08723904, -0.1465306 , -0.33813274,  0.25866383, -0.11733582],\n",
       "        [ 0.21827361, -0.05345615, -0.31256342,  0.06133932,  0.06166142],\n",
       "        [ 0.11199359, -0.00129305, -0.3604361 ,  0.09225786,  0.3620015 ],\n",
       "        [ 0.263134  , -0.30295753, -0.27571645, -0.43032992,  0.21611533],\n",
       "        [ 0.2710607 , -0.40073663, -0.13031383, -0.37033162,  0.3936012 ],\n",
       "        [-0.39364323, -0.14471842,  0.18512464,  0.35972688, -0.2047696 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.00244259, -0.0366614 ,  0.02210508,  0.02228178,  0.01255384],\n",
       "       dtype=float32),\n",
       " array([[-0.5503888 ,  0.35928237, -0.5889275 , -0.2619924 ,  0.19793157,\n",
       "         -0.08414068,  0.6356921 , -0.1697156 ,  0.01546597, -0.44692984],\n",
       "        [ 0.47718358, -0.28454366, -0.5696588 ,  0.55824053, -0.515122  ,\n",
       "          0.40675324, -0.35805562,  0.07722138, -0.2277732 , -0.22034527],\n",
       "        [-0.55806446, -0.57675433,  0.5737843 ,  0.44919738,  0.31430116,\n",
       "         -0.58398277,  0.07244257, -0.05707783, -0.00868229, -0.54174316],\n",
       "        [ 0.0645242 ,  0.11108316,  0.4969623 ,  0.55010563,  0.41106752,\n",
       "          0.01478508, -0.3442905 ,  0.5350366 ,  0.26042527,  0.06839553],\n",
       "        [-0.475357  ,  0.3182448 , -0.03566286,  0.31107745,  0.08821706,\n",
       "         -0.2571252 , -0.28844705, -0.1016179 ,  0.2538463 ,  0.36753055]],\n",
       "       dtype=float32),\n",
       " array([ 0.00652448,  0.02473125,  0.00817632,  0.00993826,  0.03122034,\n",
       "        -0.03629486,  0.02117903,  0.01907365,  0.02188711, -0.00130088],\n",
       "       dtype=float32),\n",
       " array([[ 0.11173068],\n",
       "        [ 0.42883274],\n",
       "        [ 0.10874544],\n",
       "        [ 0.15775037],\n",
       "        [ 0.5310517 ],\n",
       "        [-0.6225264 ],\n",
       "        [ 0.39091247],\n",
       "        [ 0.3194198 ],\n",
       "        [ 0.36853024],\n",
       "        [-0.04434201]], dtype=float32),\n",
       " array([0.05759541], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, sgd, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sgd_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0113\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0226 - val_loss: 0.0096\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0178 - val_loss: 0.0208\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0321 - val_loss: 0.0205\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0192 - val_loss: 0.0087\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0179 - val_loss: 0.0306\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0202 - val_loss: 0.0082\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0142 - val_loss: 0.0170\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0272 - val_loss: 0.0131\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0208 - val_loss: 0.0165\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0211 - val_loss: 0.0077\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0248 - val_loss: 0.0079\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0219 - val_loss: 0.0112\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0156 - val_loss: 0.0184\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0162 - val_loss: 0.0210\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0156 - val_loss: 0.0095\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0268 - val_loss: 0.0069\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0161 - val_loss: 0.0077\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0147 - val_loss: 0.0305\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0194 - val_loss: 0.0068\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0103 - val_loss: 0.0080\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0146 - val_loss: 0.0071\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0170 - val_loss: 0.0082\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0136 - val_loss: 0.0062\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0274 - val_loss: 0.0083\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0158 - val_loss: 0.0078\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0159 - val_loss: 0.0130\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0106 - val_loss: 0.0074\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0167 - val_loss: 0.0073\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0112 - val_loss: 0.0066\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0098 - val_loss: 0.0274\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0160 - val_loss: 0.0069\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0162 - val_loss: 0.0066\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0124 - val_loss: 0.0127\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0114 - val_loss: 0.0192\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0124 - val_loss: 0.0073\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0140 - val_loss: 0.0096\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 104us/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0106 - val_loss: 0.0061\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0118 - val_loss: 0.0059\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0105 - val_loss: 0.0208\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0072 - val_loss: 0.0093\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0077 - val_loss: 0.0220\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0175 - val_loss: 0.0072\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0104 - val_loss: 0.0058\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0099 - val_loss: 0.0063\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0074 - val_loss: 0.0105\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0147 - val_loss: 0.0061\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0079 - val_loss: 0.0164\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 153us/step - loss: 0.0073 - val_loss: 0.0067\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0094\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0070 - val_loss: 0.0100\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0127 - val_loss: 0.0064\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0122 - val_loss: 0.0064\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0092\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0118 - val_loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0133 - val_loss: 0.0050\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0125 - val_loss: 0.0067\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0104 - val_loss: 0.0058\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0081 - val_loss: 0.0118\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0104 - val_loss: 0.0071\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0074 - val_loss: 0.0084\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0078 - val_loss: 0.0139\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0112 - val_loss: 0.0058\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0083 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0075\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 90us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0057 - val_loss: 0.0115\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0082 - val_loss: 0.0048\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0053 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0080\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0112\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 104us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0106\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 116us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0092\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0084 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0124\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0102\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0068\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0051 - val_loss: 0.0072\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0041 - val_loss: 0.0083\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0132\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0044 - val_loss: 0.0087\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0108\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0083\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0051 - val_loss: 0.0070\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0088\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0087\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0071\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 110us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0074\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0100\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0034 - val_loss: 0.0073\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0095\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0029 - val_loss: 0.0089\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.007 - 0s 119us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 181us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 0.0091\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 133us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 126us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0078\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0094\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0058\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 98us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0022 - val_loss: 0.0078\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 100us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 115us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 107us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 119us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 108us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 113us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "0.005499137099832296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-8.44852448e-01, -2.16377243e-01, -1.11470468e-01,\n",
       "          1.09479591e-01, -7.87591636e-01],\n",
       "        [-7.06230164e-01,  5.11918426e-01,  9.60715294e-01,\n",
       "          5.50078094e-01,  1.02761352e+00],\n",
       "        [ 1.04486799e+00,  2.19814852e-02,  5.33250690e-01,\n",
       "         -3.00145239e-01, -4.94944394e-01],\n",
       "        [ 1.86738908e+00,  6.04151972e-02, -6.11161351e-01,\n",
       "         -2.71324009e-01, -2.63228249e-02],\n",
       "        [ 2.30691861e-03,  4.33336169e-01, -3.64422798e-01,\n",
       "          4.72512633e-01, -6.25574470e-01],\n",
       "        [-1.22539437e+00,  3.97608638e-01,  1.43978879e-01,\n",
       "          6.79039657e-02,  2.70576477e-01],\n",
       "        [-4.96059805e-02,  1.62686482e-01,  7.62848675e-01,\n",
       "         -1.41359538e-01,  1.72733426e+00],\n",
       "        [ 7.34506994e-02, -2.67147481e-01,  2.16184035e-01,\n",
       "         -5.52709438e-02,  1.65337563e-01],\n",
       "        [ 5.28005123e-01,  1.11413610e+00, -1.62987697e+00,\n",
       "          1.13631152e-01,  5.28747737e-01],\n",
       "        [ 1.32993206e-01, -2.01109052e+00,  6.06104076e-01,\n",
       "         -1.82057351e-01,  7.79313564e-01],\n",
       "        [ 2.69686580e-01,  4.07472461e-01, -5.35096705e-01,\n",
       "          5.05255520e-01,  7.64189288e-02],\n",
       "        [-3.73349786e-02, -1.66171134e+00,  7.30273962e-01,\n",
       "          2.74448544e-01, -2.43560225e-01],\n",
       "        [-6.59759104e-01, -7.30785310e-01,  1.09745705e+00,\n",
       "         -1.62022442e-01, -4.52973962e-01],\n",
       "        [-2.20486403e+00, -1.64056909e+00, -2.31406021e+00,\n",
       "          1.78215730e+00,  6.63446486e-01],\n",
       "        [-6.62564278e-01,  5.66181578e-02,  2.16128275e-01,\n",
       "          5.05691171e-01,  6.03850245e-01],\n",
       "        [ 2.42299154e-01, -7.27779269e-02, -3.53959471e-01,\n",
       "         -6.88627303e-01, -1.40316993e-01],\n",
       "        [ 3.64689022e-01, -9.35011283e-02,  6.79014981e-01,\n",
       "         -1.00916855e-01, -4.83204424e-01],\n",
       "        [-2.96202868e-01, -4.79449451e-01, -7.06827939e-01,\n",
       "         -1.46722168e-01, -8.93638432e-01],\n",
       "        [ 1.37618884e-01,  1.96488535e+00, -1.03971362e+00,\n",
       "         -6.75535858e-01, -1.48422110e+00],\n",
       "        [ 8.52155387e-01, -3.90087008e-01, -1.79015017e+00,\n",
       "          6.50104225e-01,  1.96540236e-01],\n",
       "        [ 1.69966817e+00, -3.31898183e-01,  1.75173128e+00,\n",
       "          7.55485967e-02, -3.51816475e-01],\n",
       "        [ 9.92044508e-01, -9.13467586e-01,  4.68299568e-01,\n",
       "         -7.52794445e-02,  2.06959099e-01]], dtype=float32),\n",
       " array([ 0.8505954 , -0.13797209,  0.47255254, -0.4874418 , -0.3989976 ],\n",
       "       dtype=float32),\n",
       " array([[ 1.5993478e-02, -7.0854807e-03, -2.7525359e-01,  2.0001770e-03,\n",
       "         -1.4974149e-02, -1.8970696e-02, -1.7983060e-02, -3.9302953e-02,\n",
       "          7.1462500e-01,  3.1730516e-03],\n",
       "        [ 1.5936520e-02,  4.3576327e-04, -4.9388275e-01, -1.1853080e-02,\n",
       "         -5.4777144e-03, -2.2289369e-02,  1.3666741e-02,  9.5208432e-04,\n",
       "          8.6040914e-01, -3.9532438e-02],\n",
       "        [ 7.5050644e-03,  1.9025339e-02, -1.9976108e-01,  1.7774930e-02,\n",
       "          1.5077639e-03,  1.7415440e-02,  8.9727081e-03, -6.8418309e-03,\n",
       "          9.9359101e-01, -3.6510561e-02],\n",
       "        [-5.6973719e-03,  7.6529495e-03, -1.8669006e-01,  7.6169288e-04,\n",
       "         -9.3608722e-03,  2.1165747e-02, -3.0271530e-02,  8.5384687e-03,\n",
       "         -5.8737006e-02,  1.7162461e-02],\n",
       "        [ 7.6336889e-03, -1.8610909e-03, -1.7237291e-01,  1.6280852e-02,\n",
       "         -3.9664684e-03, -2.9255287e-03, -6.6353935e-03,  7.8343907e-03,\n",
       "         -2.8192788e-01, -2.4303328e-03]], dtype=float32),\n",
       " array([-0.00158974, -0.00217687, -0.10930725, -0.02256451,  0.00479727,\n",
       "        -0.0167435 ,  0.03460888,  0.03541479, -0.23060851, -0.01835191],\n",
       "       dtype=float32),\n",
       " array([[ 5.0141243e-05],\n",
       "        [-2.3779434e-03],\n",
       "        [-1.9173077e-03],\n",
       "        [-2.1829386e-03],\n",
       "        [-4.2571194e-04],\n",
       "        [-2.6700506e-03],\n",
       "        [-1.5675924e-03],\n",
       "        [ 3.3882447e-03],\n",
       "        [-2.7239251e-01],\n",
       "        [ 1.1657318e-03]], dtype=float32),\n",
       " array([0.26522753], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, RMSprop, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_rmsprop_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 36.2797 - val_loss: 33.5606\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.7405 - val_loss: 30.7935\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 30.2744 - val_loss: 25.9119\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 25.4923 - val_loss: 19.2028\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 19.3715 - val_loss: 11.7370\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 12.3923 - val_loss: 5.5430\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 5.7360 - val_loss: 2.9457\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5427 - val_loss: 5.1092\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 2.4423 - val_loss: 7.8074\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3645 - val_loss: 6.7492\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0338 - val_loss: 4.1879\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0351 - val_loss: 2.1578\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 2.7253 - val_loss: 1.0744\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.1833 - val_loss: 0.7554\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.5490 - val_loss: 0.9156\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.5951 - val_loss: 1.2704\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9859 - val_loss: 1.5932\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.4136 - val_loss: 1.7518\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.6821 - val_loss: 1.7036\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.7178 - val_loss: 1.4707\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 1.5358 - val_loss: 1.1157\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 1.2025 - val_loss: 0.7221\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.8097 - val_loss: 0.3765\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4537 - val_loss: 0.1494\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2135 - val_loss: 0.0735\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.1274 - val_loss: 0.1299\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1772 - val_loss: 0.2523\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2948 - val_loss: 0.3589\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.3978 - val_loss: 0.3943\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.4340 - val_loss: 0.3522\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4008 - val_loss: 0.2648\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 188us/step - loss: 0.3292 - val_loss: 0.1744\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.2538 - val_loss: 0.1097\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1937 - val_loss: 0.0788\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.1528 - val_loss: 0.0746\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1284 - val_loss: 0.0837\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1169 - val_loss: 0.0932\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.1144 - val_loss: 0.0943\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1158 - val_loss: 0.0845\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.1158 - val_loss: 0.0673\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1112 - val_loss: 0.0503\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1020 - val_loss: 0.0414\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0915 - val_loss: 0.0450\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0833 - val_loss: 0.0596\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0795 - val_loss: 0.0779\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0787 - val_loss: 0.0902\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0768 - val_loss: 0.0895\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0701 - val_loss: 0.0750\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0578 - val_loss: 0.0524\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0423 - val_loss: 0.0304\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0285 - val_loss: 0.0162\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0225 - val_loss: 0.0292\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0391\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0340 - val_loss: 0.0450\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0367 - val_loss: 0.0460\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0361 - val_loss: 0.0426\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0325 - val_loss: 0.0365\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0271 - val_loss: 0.0294\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0153 - val_loss: 0.0174\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0173 - val_loss: 0.0107\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 140us/step - loss: 0.0177 - val_loss: 0.0106\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0166 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.0104\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0089 - val_loss: 0.0122\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0095 - val_loss: 0.0123\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0043 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0027 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.9804e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.9377e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.8953e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.8531e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.8112e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.7699e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.7284e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.6873e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 9.6465e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.6058e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.5656e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.5255e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 9.4856e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.4461e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.4068e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 9.3675e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.3288e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0012 - val_loss: 9.2902e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0012 - val_loss: 9.2517e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 9.2137e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.1755e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 9.1380e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.1006e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 9.0632e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 9.0263e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.9896e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0011 - val_loss: 8.9530e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 8.9168e-04\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.8807e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.8449e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 8.8092e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 8.7738e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 8.7384e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.7034e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.6688e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.6341e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.5999e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.5658e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.5318e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.4981e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 8.4645e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0011 - val_loss: 8.4313e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.3982e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 8.3654e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0011 - val_loss: 8.3326e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.3002e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 8.2678e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0011 - val_loss: 8.2356e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0011 - val_loss: 8.2037e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.1721e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 8.1406e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.1093e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 8.0781e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0010 - val_loss: 8.0474e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 8.0165e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.9858e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.9554e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.9253e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.8954e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.8654e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0010 - val_loss: 7.8357e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.8064e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.7770e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0010 - val_loss: 7.7478e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.7190e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 7.6902e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.9717e-04 - val_loss: 7.6614e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9427e-04 - val_loss: 7.6331e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.9141e-04 - val_loss: 7.6049e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8854e-04 - val_loss: 7.5768e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8570e-04 - val_loss: 7.5490e-04\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.8286e-04 - val_loss: 7.5211e-04\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.8003e-04 - val_loss: 7.4936e-04\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.7723e-04 - val_loss: 7.4661e-04\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.7443e-04 - val_loss: 7.4391e-04\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.7163e-04 - val_loss: 7.4119e-04\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.6886e-04 - val_loss: 7.3850e-04\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.6610e-04 - val_loss: 7.3583e-04\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.6336e-04 - val_loss: 7.3317e-04\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 9.6060e-04 - val_loss: 7.3053e-04\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 9.5788e-04 - val_loss: 7.2789e-04\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.5515e-04 - val_loss: 7.2528e-04\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.5246e-04 - val_loss: 7.2268e-04\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4976e-04 - val_loss: 7.2011e-04\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.4708e-04 - val_loss: 7.1754e-04\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.4441e-04 - val_loss: 7.1498e-04\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.4175e-04 - val_loss: 7.1246e-04\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3910e-04 - val_loss: 7.0995e-04\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.3648e-04 - val_loss: 7.0744e-04\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.3385e-04 - val_loss: 7.0495e-04\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.3123e-04 - val_loss: 7.0248e-04\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2863e-04 - val_loss: 7.0001e-04\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.2604e-04 - val_loss: 6.9758e-04\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 9.2346e-04 - val_loss: 6.9514e-04\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.2090e-04 - val_loss: 6.9273e-04\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.1834e-04 - val_loss: 6.9034e-04\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 9.1579e-04 - val_loss: 6.8794e-04\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1325e-04 - val_loss: 6.8557e-04\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.1073e-04 - val_loss: 6.8322e-04\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 9.0820e-04 - val_loss: 6.8087e-04\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0571e-04 - val_loss: 6.7854e-04\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 9.0321e-04 - val_loss: 6.7624e-04\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0073e-04 - val_loss: 6.7393e-04\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9825e-04 - val_loss: 6.7164e-04\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9579e-04 - val_loss: 6.6937e-04\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.9334e-04 - val_loss: 6.6710e-04\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.9090e-04 - val_loss: 6.6485e-04\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8847e-04 - val_loss: 6.6260e-04\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.8603e-04 - val_loss: 6.6040e-04\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.8362e-04 - val_loss: 6.5819e-04\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.8122e-04 - val_loss: 6.5600e-04\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7884e-04 - val_loss: 6.5381e-04\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7644e-04 - val_loss: 6.5165e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.7408e-04 - val_loss: 6.4951e-04\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.7172e-04 - val_loss: 6.4735e-04\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.6936e-04 - val_loss: 6.4521e-04\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6701e-04 - val_loss: 6.4310e-04\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6469e-04 - val_loss: 6.4100e-04\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.6236e-04 - val_loss: 6.3890e-04\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.6004e-04 - val_loss: 6.3682e-04\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.5774e-04 - val_loss: 6.3476e-04\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5544e-04 - val_loss: 6.3270e-04\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5316e-04 - val_loss: 6.3067e-04\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.5088e-04 - val_loss: 6.2863e-04\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4861e-04 - val_loss: 6.2661e-04\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.4635e-04 - val_loss: 6.2460e-04\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.4410e-04 - val_loss: 6.2261e-04\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.4186e-04 - val_loss: 6.2062e-04\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3963e-04 - val_loss: 6.1865e-04\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.3741e-04 - val_loss: 6.1669e-04\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.3519e-04 - val_loss: 6.1475e-04\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.3299e-04 - val_loss: 6.1282e-04\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 8.3080e-04 - val_loss: 6.1088e-04\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2860e-04 - val_loss: 6.0897e-04\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2643e-04 - val_loss: 6.0705e-04\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.2426e-04 - val_loss: 6.0518e-04\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.2210e-04 - val_loss: 6.0329e-04\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 8.1995e-04 - val_loss: 6.0143e-04\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1779e-04 - val_loss: 5.9957e-04\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1567e-04 - val_loss: 5.9772e-04\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.1354e-04 - val_loss: 5.9588e-04\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.1141e-04 - val_loss: 5.9405e-04\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 8.0931e-04 - val_loss: 5.9224e-04\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0720e-04 - val_loss: 5.9044e-04\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 8.0512e-04 - val_loss: 5.8864e-04\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0303e-04 - val_loss: 5.8686e-04\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 8.0095e-04 - val_loss: 5.8507e-04\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9888e-04 - val_loss: 5.8333e-04\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.9682e-04 - val_loss: 5.8156e-04\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9477e-04 - val_loss: 5.7982e-04\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.9272e-04 - val_loss: 5.7810e-04\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.9068e-04 - val_loss: 5.7638e-04\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8866e-04 - val_loss: 5.7466e-04\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.8663e-04 - val_loss: 5.7296e-04\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8462e-04 - val_loss: 5.7127e-04\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.8262e-04 - val_loss: 5.6960e-04\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.8063e-04 - val_loss: 5.6791e-04\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7862e-04 - val_loss: 5.6625e-04\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7665e-04 - val_loss: 5.6460e-04\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7468e-04 - val_loss: 5.6293e-04\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.7270e-04 - val_loss: 5.6132e-04\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.7075e-04 - val_loss: 5.5970e-04\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.6880e-04 - val_loss: 5.5809e-04\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6686e-04 - val_loss: 5.5648e-04\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6492e-04 - val_loss: 5.5488e-04\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6299e-04 - val_loss: 5.5329e-04\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.6107e-04 - val_loss: 5.5171e-04\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5915e-04 - val_loss: 5.5015e-04\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5725e-04 - val_loss: 5.4860e-04\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.5535e-04 - val_loss: 5.4703e-04\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.5346e-04 - val_loss: 5.4550e-04\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.5157e-04 - val_loss: 5.4397e-04\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 7.4969e-04 - val_loss: 5.4245e-04\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4782e-04 - val_loss: 5.4094e-04\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4596e-04 - val_loss: 5.3943e-04\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4410e-04 - val_loss: 5.3793e-04\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.4225e-04 - val_loss: 5.3645e-04\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.4041e-04 - val_loss: 5.3496e-04\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.3857e-04 - val_loss: 5.3349e-04\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3675e-04 - val_loss: 5.3204e-04\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 7.3492e-04 - val_loss: 5.3058e-04\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.3311e-04 - val_loss: 5.2914e-04\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 7.3129e-04 - val_loss: 5.2769e-04\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2949e-04 - val_loss: 5.2627e-04\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2770e-04 - val_loss: 5.2485e-04\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 7.2591e-04 - val_loss: 5.2344e-04\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2413e-04 - val_loss: 5.2203e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2236e-04 - val_loss: 5.2062e-04\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.2059e-04 - val_loss: 5.1924e-04\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1883e-04 - val_loss: 5.1786e-04\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1707e-04 - val_loss: 5.1650e-04\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1532e-04 - val_loss: 5.1514e-04\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 7.1358e-04 - val_loss: 5.1377e-04\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.1185e-04 - val_loss: 5.1243e-04\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.1011e-04 - val_loss: 5.1108e-04\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0839e-04 - val_loss: 5.0975e-04\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0668e-04 - val_loss: 5.0843e-04\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 7.0498e-04 - val_loss: 5.0711e-04\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 7.0327e-04 - val_loss: 5.0580e-04\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 7.0156e-04 - val_loss: 5.0449e-04\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9987e-04 - val_loss: 5.0320e-04\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9819e-04 - val_loss: 5.0191e-04\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9651e-04 - val_loss: 5.0063e-04\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.9484e-04 - val_loss: 4.9937e-04\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9318e-04 - val_loss: 4.9809e-04\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.9151e-04 - val_loss: 4.9684e-04\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8987e-04 - val_loss: 4.9559e-04\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8821e-04 - val_loss: 4.9434e-04\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8657e-04 - val_loss: 4.9311e-04\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8494e-04 - val_loss: 4.9188e-04\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.8330e-04 - val_loss: 4.9065e-04\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.8167e-04 - val_loss: 4.8943e-04\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.8006e-04 - val_loss: 4.8822e-04\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7844e-04 - val_loss: 4.8702e-04\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7684e-04 - val_loss: 4.8583e-04\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7524e-04 - val_loss: 4.8466e-04\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.7365e-04 - val_loss: 4.8345e-04\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7205e-04 - val_loss: 4.8228e-04\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.7047e-04 - val_loss: 4.8112e-04\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.6889e-04 - val_loss: 4.7996e-04\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6732e-04 - val_loss: 4.7880e-04\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.6575e-04 - val_loss: 4.7764e-04\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6419e-04 - val_loss: 4.7651e-04\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6263e-04 - val_loss: 4.7537e-04\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.6108e-04 - val_loss: 4.7425e-04\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5954e-04 - val_loss: 4.7313e-04\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.5800e-04 - val_loss: 4.7202e-04\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5647e-04 - val_loss: 4.7091e-04\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5493e-04 - val_loss: 4.6981e-04\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5342e-04 - val_loss: 4.6872e-04\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.5190e-04 - val_loss: 4.6762e-04\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.5039e-04 - val_loss: 4.6653e-04\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.4888e-04 - val_loss: 4.6545e-04\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4738e-04 - val_loss: 4.6437e-04\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4588e-04 - val_loss: 4.6330e-04\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.4440e-04 - val_loss: 4.6225e-04\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.4291e-04 - val_loss: 4.6120e-04\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.4143e-04 - val_loss: 4.6015e-04\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3995e-04 - val_loss: 4.5911e-04\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3848e-04 - val_loss: 4.5808e-04\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3702e-04 - val_loss: 4.5706e-04\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3556e-04 - val_loss: 4.5602e-04\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.3410e-04 - val_loss: 4.5500e-04\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3265e-04 - val_loss: 4.5400e-04\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.3121e-04 - val_loss: 4.5298e-04\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2977e-04 - val_loss: 4.5197e-04\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.2833e-04 - val_loss: 4.5098e-04\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2690e-04 - val_loss: 4.5000e-04\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2548e-04 - val_loss: 4.4901e-04\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2407e-04 - val_loss: 4.4803e-04\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.2265e-04 - val_loss: 4.4707e-04\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.2124e-04 - val_loss: 4.4609e-04\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1984e-04 - val_loss: 4.4513e-04\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1843e-04 - val_loss: 4.4417e-04\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1703e-04 - val_loss: 4.4322e-04\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.1565e-04 - val_loss: 4.4227e-04\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1426e-04 - val_loss: 4.4133e-04\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.1288e-04 - val_loss: 4.4039e-04\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1151e-04 - val_loss: 4.3946e-04\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.1013e-04 - val_loss: 4.3855e-04\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0876e-04 - val_loss: 4.3763e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 6.0741e-04 - val_loss: 4.3672e-04\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0606e-04 - val_loss: 4.3579e-04\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0470e-04 - val_loss: 4.3489e-04\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 6.0335e-04 - val_loss: 4.3399e-04\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 6.0201e-04 - val_loss: 4.3310e-04\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 6.0067e-04 - val_loss: 4.3220e-04\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 5.9933e-04 - val_loss: 4.3132e-04\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9800e-04 - val_loss: 4.3045e-04\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9668e-04 - val_loss: 4.2957e-04\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.9535e-04 - val_loss: 4.2870e-04\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9405e-04 - val_loss: 4.2785e-04\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9273e-04 - val_loss: 4.2697e-04\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.9142e-04 - val_loss: 4.2611e-04\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.9012e-04 - val_loss: 4.2526e-04\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8882e-04 - val_loss: 4.2443e-04\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8753e-04 - val_loss: 4.2359e-04\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 5.8624e-04 - val_loss: 4.2274e-04\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.8495e-04 - val_loss: 4.2192e-04\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.8367e-04 - val_loss: 4.2109e-04\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.8240e-04 - val_loss: 4.2027e-04\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.8112e-04 - val_loss: 4.1945e-04\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.7985e-04 - val_loss: 4.1864e-04\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7860e-04 - val_loss: 4.1782e-04\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7733e-04 - val_loss: 4.1703e-04\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7608e-04 - val_loss: 4.1623e-04\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 5.7483e-04 - val_loss: 4.1543e-04\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.7358e-04 - val_loss: 4.1464e-04\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.7234e-04 - val_loss: 4.1385e-04\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.7110e-04 - val_loss: 4.1307e-04\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6986e-04 - val_loss: 4.1229e-04\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6863e-04 - val_loss: 4.1151e-04\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.6740e-04 - val_loss: 4.1076e-04\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6618e-04 - val_loss: 4.0998e-04\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.6496e-04 - val_loss: 4.0923e-04\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.6375e-04 - val_loss: 4.0847e-04\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 5.6254e-04 - val_loss: 4.0772e-04\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6133e-04 - val_loss: 4.0698e-04\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.6013e-04 - val_loss: 4.0623e-04\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5893e-04 - val_loss: 4.0549e-04\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5774e-04 - val_loss: 4.0475e-04\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5654e-04 - val_loss: 4.0402e-04\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.5535e-04 - val_loss: 4.0330e-04\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 5.5418e-04 - val_loss: 4.0257e-04\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5300e-04 - val_loss: 4.0185e-04\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.5182e-04 - val_loss: 4.0114e-04\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.5065e-04 - val_loss: 4.0043e-04\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4949e-04 - val_loss: 3.9972e-04\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4832e-04 - val_loss: 3.9902e-04\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4716e-04 - val_loss: 3.9831e-04\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4601e-04 - val_loss: 3.9762e-04\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4485e-04 - val_loss: 3.9692e-04\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4370e-04 - val_loss: 3.9624e-04\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4256e-04 - val_loss: 3.9556e-04\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.4142e-04 - val_loss: 3.9488e-04\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.4028e-04 - val_loss: 3.9420e-04\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3915e-04 - val_loss: 3.9353e-04\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3801e-04 - val_loss: 3.9286e-04\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.3689e-04 - val_loss: 3.9219e-04\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 5.3577e-04 - val_loss: 3.9153e-04\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.3465e-04 - val_loss: 3.9087e-04\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3354e-04 - val_loss: 3.9022e-04\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.3242e-04 - val_loss: 3.8956e-04\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3131e-04 - val_loss: 3.8892e-04\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.3021e-04 - val_loss: 3.8828e-04\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2911e-04 - val_loss: 3.8763e-04\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2801e-04 - val_loss: 3.8700e-04\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2692e-04 - val_loss: 3.8636e-04\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2583e-04 - val_loss: 3.8573e-04\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2474e-04 - val_loss: 3.8512e-04\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2365e-04 - val_loss: 3.8449e-04\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2258e-04 - val_loss: 3.8387e-04\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.2149e-04 - val_loss: 3.8326e-04\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.2043e-04 - val_loss: 3.8265e-04\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.1935e-04 - val_loss: 3.8203e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1829e-04 - val_loss: 3.8143e-04\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1723e-04 - val_loss: 3.8082e-04\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1616e-04 - val_loss: 3.8022e-04\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1511e-04 - val_loss: 3.7963e-04\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1405e-04 - val_loss: 3.7903e-04\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.1300e-04 - val_loss: 3.7845e-04\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1196e-04 - val_loss: 3.7786e-04\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.1091e-04 - val_loss: 3.7728e-04\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0988e-04 - val_loss: 3.7669e-04\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0883e-04 - val_loss: 3.7613e-04\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0780e-04 - val_loss: 3.7555e-04\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0678e-04 - val_loss: 3.7499e-04\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 5.0575e-04 - val_loss: 3.7441e-04\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0472e-04 - val_loss: 3.7384e-04\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 5.0370e-04 - val_loss: 3.7328e-04\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0268e-04 - val_loss: 3.7273e-04\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 5.0168e-04 - val_loss: 3.7217e-04\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.0066e-04 - val_loss: 3.7161e-04\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9965e-04 - val_loss: 3.7107e-04\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.9865e-04 - val_loss: 3.7052e-04\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9764e-04 - val_loss: 3.6998e-04\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9665e-04 - val_loss: 3.6944e-04\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9565e-04 - val_loss: 3.6890e-04\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9466e-04 - val_loss: 3.6837e-04\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9367e-04 - val_loss: 3.6784e-04\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.9269e-04 - val_loss: 3.6731e-04\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9170e-04 - val_loss: 3.6678e-04\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.9072e-04 - val_loss: 3.6625e-04\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8975e-04 - val_loss: 3.6574e-04\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8877e-04 - val_loss: 3.6523e-04\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8780e-04 - val_loss: 3.6471e-04\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8683e-04 - val_loss: 3.6419e-04\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.8587e-04 - val_loss: 3.6369e-04\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8491e-04 - val_loss: 3.6317e-04\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8395e-04 - val_loss: 3.6268e-04\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8299e-04 - val_loss: 3.6218e-04\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8204e-04 - val_loss: 3.6168e-04\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.8109e-04 - val_loss: 3.6118e-04\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.8015e-04 - val_loss: 3.6068e-04\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7919e-04 - val_loss: 3.6020e-04\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7825e-04 - val_loss: 3.5972e-04\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.7732e-04 - val_loss: 3.5923e-04\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7637e-04 - val_loss: 3.5875e-04\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7544e-04 - val_loss: 3.5827e-04\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7452e-04 - val_loss: 3.5779e-04\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7359e-04 - val_loss: 3.5730e-04\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.7266e-04 - val_loss: 3.5684e-04\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7174e-04 - val_loss: 3.5637e-04\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.7083e-04 - val_loss: 3.5591e-04\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6991e-04 - val_loss: 3.5544e-04\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6899e-04 - val_loss: 3.5498e-04\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.6808e-04 - val_loss: 3.5452e-04\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6718e-04 - val_loss: 3.5407e-04\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6627e-04 - val_loss: 3.5361e-04\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.6537e-04 - val_loss: 3.5316e-04\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6446e-04 - val_loss: 3.5271e-04\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6357e-04 - val_loss: 3.5226e-04\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6268e-04 - val_loss: 3.5182e-04\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6178e-04 - val_loss: 3.5137e-04\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.6090e-04 - val_loss: 3.5093e-04\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6001e-04 - val_loss: 3.5049e-04\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5913e-04 - val_loss: 3.5005e-04\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5824e-04 - val_loss: 3.4963e-04\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5737e-04 - val_loss: 3.4920e-04\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.5649e-04 - val_loss: 3.4876e-04\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5562e-04 - val_loss: 3.4834e-04\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5474e-04 - val_loss: 3.4791e-04\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5388e-04 - val_loss: 3.4749e-04\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5301e-04 - val_loss: 3.4707e-04\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.5215e-04 - val_loss: 3.4665e-04\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.5130e-04 - val_loss: 3.4624e-04\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.5044e-04 - val_loss: 3.4583e-04\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4958e-04 - val_loss: 3.4542e-04\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4873e-04 - val_loss: 3.4501e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4788e-04 - val_loss: 3.4461e-04\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4703e-04 - val_loss: 3.4420e-04\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4619e-04 - val_loss: 3.4379e-04\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4534e-04 - val_loss: 3.4340e-04\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4450e-04 - val_loss: 3.4300e-04\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4367e-04 - val_loss: 3.4260e-04\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4283e-04 - val_loss: 3.4220e-04\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4200e-04 - val_loss: 3.4182e-04\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.4117e-04 - val_loss: 3.4143e-04\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.4034e-04 - val_loss: 3.4104e-04\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3952e-04 - val_loss: 3.4064e-04\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3869e-04 - val_loss: 3.4027e-04\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3788e-04 - val_loss: 3.3987e-04\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3705e-04 - val_loss: 3.3950e-04\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3624e-04 - val_loss: 3.3913e-04\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.3543e-04 - val_loss: 3.3874e-04\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3461e-04 - val_loss: 3.3838e-04\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3381e-04 - val_loss: 3.3801e-04\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3300e-04 - val_loss: 3.3764e-04\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.3220e-04 - val_loss: 3.3728e-04\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.3139e-04 - val_loss: 3.3692e-04\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.3060e-04 - val_loss: 3.3654e-04\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2980e-04 - val_loss: 3.3618e-04\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2901e-04 - val_loss: 3.3582e-04\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2821e-04 - val_loss: 3.3546e-04\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2742e-04 - val_loss: 3.3509e-04\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2663e-04 - val_loss: 3.3474e-04\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.2585e-04 - val_loss: 3.3441e-04\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2507e-04 - val_loss: 3.3404e-04\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.2429e-04 - val_loss: 3.3370e-04\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2351e-04 - val_loss: 3.3335e-04\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2273e-04 - val_loss: 3.3300e-04\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2196e-04 - val_loss: 3.3267e-04\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.2119e-04 - val_loss: 3.3233e-04\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.2042e-04 - val_loss: 3.3198e-04\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.1965e-04 - val_loss: 3.3164e-04\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1888e-04 - val_loss: 3.3131e-04\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1812e-04 - val_loss: 3.3097e-04\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1736e-04 - val_loss: 3.3064e-04\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1660e-04 - val_loss: 3.3030e-04\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1585e-04 - val_loss: 3.2997e-04\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.1509e-04 - val_loss: 3.2964e-04\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1434e-04 - val_loss: 3.2932e-04\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1359e-04 - val_loss: 3.2900e-04\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1284e-04 - val_loss: 3.2867e-04\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 4.1209e-04 - val_loss: 3.2835e-04\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.1135e-04 - val_loss: 3.2803e-04\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.1061e-04 - val_loss: 3.2771e-04\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0987e-04 - val_loss: 3.2739e-04\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0913e-04 - val_loss: 3.2708e-04\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0840e-04 - val_loss: 3.2677e-04\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0766e-04 - val_loss: 3.2646e-04\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0693e-04 - val_loss: 3.2615e-04\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 4.0621e-04 - val_loss: 3.2584e-04\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0548e-04 - val_loss: 3.2553e-04\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0475e-04 - val_loss: 3.2522e-04\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0403e-04 - val_loss: 3.2492e-04\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0331e-04 - val_loss: 3.2461e-04\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 4.0259e-04 - val_loss: 3.2431e-04\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.0187e-04 - val_loss: 3.2402e-04\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 4.0116e-04 - val_loss: 3.2372e-04\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 4.0044e-04 - val_loss: 3.2343e-04\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9974e-04 - val_loss: 3.2312e-04\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9903e-04 - val_loss: 3.2283e-04\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9831e-04 - val_loss: 3.2255e-04\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9762e-04 - val_loss: 3.2226e-04\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9691e-04 - val_loss: 3.2197e-04\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9621e-04 - val_loss: 3.2169e-04\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.9551e-04 - val_loss: 3.2139e-04\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9481e-04 - val_loss: 3.2111e-04\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9412e-04 - val_loss: 3.2082e-04\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9343e-04 - val_loss: 3.2054e-04\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9274e-04 - val_loss: 3.2026e-04\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.9205e-04 - val_loss: 3.1998e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9136e-04 - val_loss: 3.1970e-04\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.9067e-04 - val_loss: 3.1942e-04\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8999e-04 - val_loss: 3.1916e-04\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8931e-04 - val_loss: 3.1888e-04\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8863e-04 - val_loss: 3.1861e-04\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.8795e-04 - val_loss: 3.1834e-04\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8728e-04 - val_loss: 3.1807e-04\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8660e-04 - val_loss: 3.1781e-04\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8593e-04 - val_loss: 3.1754e-04\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8526e-04 - val_loss: 3.1727e-04\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.8459e-04 - val_loss: 3.1701e-04\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8392e-04 - val_loss: 3.1675e-04\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8326e-04 - val_loss: 3.1648e-04\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8260e-04 - val_loss: 3.1622e-04\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8193e-04 - val_loss: 3.1596e-04\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.8128e-04 - val_loss: 3.1571e-04\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.8062e-04 - val_loss: 3.1543e-04\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7996e-04 - val_loss: 3.1519e-04\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7930e-04 - val_loss: 3.1494e-04\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7865e-04 - val_loss: 3.1468e-04\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7800e-04 - val_loss: 3.1443e-04\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7736e-04 - val_loss: 3.1418e-04\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7671e-04 - val_loss: 3.1395e-04\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7607e-04 - val_loss: 3.1370e-04\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7542e-04 - val_loss: 3.1343e-04\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7478e-04 - val_loss: 3.1320e-04\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.7414e-04 - val_loss: 3.1294e-04\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.7351e-04 - val_loss: 3.1271e-04\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 3.7286e-04 - val_loss: 3.1246e-04\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.7223e-04 - val_loss: 3.1223e-04\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 3.7160e-04 - val_loss: 3.1199e-04\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 3.7096e-04 - val_loss: 3.1175e-04\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.7034e-04 - val_loss: 3.1151e-04\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6971e-04 - val_loss: 3.1127e-04\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6908e-04 - val_loss: 3.1104e-04\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6846e-04 - val_loss: 3.1080e-04\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6783e-04 - val_loss: 3.1057e-04\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 3.6721e-04 - val_loss: 3.1033e-04\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6659e-04 - val_loss: 3.1010e-04\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6597e-04 - val_loss: 3.0988e-04\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.6535e-04 - val_loss: 3.0966e-04\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6475e-04 - val_loss: 3.0942e-04\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6413e-04 - val_loss: 3.0920e-04\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6352e-04 - val_loss: 3.0897e-04\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6292e-04 - val_loss: 3.0875e-04\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.6231e-04 - val_loss: 3.0852e-04\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6170e-04 - val_loss: 3.0830e-04\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.6109e-04 - val_loss: 3.0808e-04\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.6049e-04 - val_loss: 3.0786e-04\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5988e-04 - val_loss: 3.0764e-04\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5929e-04 - val_loss: 3.0742e-04\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5868e-04 - val_loss: 3.0720e-04\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5808e-04 - val_loss: 3.0699e-04\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5749e-04 - val_loss: 3.0677e-04\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5691e-04 - val_loss: 3.0657e-04\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5631e-04 - val_loss: 3.0636e-04\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5572e-04 - val_loss: 3.0615e-04\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5513e-04 - val_loss: 3.0594e-04\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.5454e-04 - val_loss: 3.0572e-04\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5396e-04 - val_loss: 3.0550e-04\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 3.5337e-04 - val_loss: 3.0531e-04\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5279e-04 - val_loss: 3.0510e-04\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5221e-04 - val_loss: 3.0488e-04\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5163e-04 - val_loss: 3.0468e-04\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5105e-04 - val_loss: 3.0448e-04\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5047e-04 - val_loss: 3.0427e-04\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4990e-04 - val_loss: 3.0407e-04\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4932e-04 - val_loss: 3.0387e-04\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4875e-04 - val_loss: 3.0367e-04\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4818e-04 - val_loss: 3.0348e-04\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4762e-04 - val_loss: 3.0328e-04\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4705e-04 - val_loss: 3.0308e-04\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4648e-04 - val_loss: 3.0289e-04\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4592e-04 - val_loss: 3.0268e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4535e-04 - val_loss: 3.0250e-04\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4479e-04 - val_loss: 3.0230e-04\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 158us/step - loss: 3.4423e-04 - val_loss: 3.0211e-04\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4367e-04 - val_loss: 3.0191e-04\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4312e-04 - val_loss: 3.0171e-04\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4256e-04 - val_loss: 3.0152e-04\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4200e-04 - val_loss: 3.0134e-04\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 3.4145e-04 - val_loss: 3.0115e-04\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4090e-04 - val_loss: 3.0095e-04\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.4035e-04 - val_loss: 3.0077e-04\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3980e-04 - val_loss: 3.0059e-04\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3926e-04 - val_loss: 3.0039e-04\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 3.3871e-04 - val_loss: 3.0021e-04\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3816e-04 - val_loss: 3.0003e-04\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.3762e-04 - val_loss: 2.9985e-04\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 3.3708e-04 - val_loss: 2.9966e-04\n",
      "0.000403041485697031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.08077129, -0.40693408, -0.31906602, -0.4938172 , -0.17201525],\n",
       "        [-0.9847686 , -0.7185617 ,  1.0327723 , -0.27676013, -0.42201003],\n",
       "        [ 0.56733036, -0.37597203, -0.5528961 , -1.0427204 ,  0.5739549 ]],\n",
       "       dtype=float32),\n",
       " array([-0.45390186,  0.3492151 ,  0.09672013, -0.39901376, -0.48546174],\n",
       "       dtype=float32),\n",
       " array([[ 0.04652176, -0.45594093, -0.35062853,  0.41902417, -0.31988424,\n",
       "          0.38528275, -0.44016388,  0.14218436,  0.3370115 ,  0.5326976 ],\n",
       "        [ 0.38115975, -0.16807574,  0.27257282,  0.39710453, -0.20314553,\n",
       "          0.25999096,  0.399251  , -0.7723029 , -0.19338493, -0.456151  ],\n",
       "        [ 0.4294598 ,  0.04155463, -0.47621205,  0.45750394, -0.05033705,\n",
       "          0.26229903,  0.25685695, -0.16242959,  0.15237947, -0.2903632 ],\n",
       "        [ 0.38639814,  0.07010184, -0.36703777, -0.11167523,  0.22573768,\n",
       "          0.03253043, -0.53213   ,  0.07817455, -0.5644139 ,  0.34562764],\n",
       "        [-0.22079974,  0.20360617, -0.37770274,  0.42570364, -0.1042766 ,\n",
       "          0.10502162, -0.49098524,  0.66957563,  0.37107623, -0.46303326]],\n",
       "       dtype=float32),\n",
       " array([-0.58243316, -0.7418511 ,  0.62994534, -0.7374188 , -0.65328723,\n",
       "         0.78201026,  0.7431061 , -0.74033487,  0.65712607, -0.61188316],\n",
       "       dtype=float32),\n",
       " array([[-0.28024146],\n",
       "        [-0.9847556 ],\n",
       "        [ 0.37925476],\n",
       "        [-0.79431134],\n",
       "        [-0.4351881 ],\n",
       "        [ 0.5423191 ],\n",
       "        [ 0.8562061 ],\n",
       "        [-0.87043345],\n",
       "        [ 0.39908847],\n",
       "        [-0.2783341 ]], dtype=float32),\n",
       " array([0.79503006], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_adam_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 35.9295 - val_loss: 35.6743\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 441us/step - loss: 35.9281 - val_loss: 35.6723\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9261 - val_loss: 35.6697\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.9236 - val_loss: 35.6666\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 35.9206 - val_loss: 35.6631\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.9171 - val_loss: 35.6592\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.9133 - val_loss: 35.6550\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 35.9091 - val_loss: 35.6504\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.9046 - val_loss: 35.6455\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.8999 - val_loss: 35.6403\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.8948 - val_loss: 35.6350\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8896 - val_loss: 35.6294\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 35.8841 - val_loss: 35.6236\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8785 - val_loss: 35.6177\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 35.8727 - val_loss: 35.6116\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.8667 - val_loss: 35.6053\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8606 - val_loss: 35.5990\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8544 - val_loss: 35.5925\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8481 - val_loss: 35.5859\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.8416 - val_loss: 35.5793\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8351 - val_loss: 35.5725\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.8285 - val_loss: 35.5657\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.8219 - val_loss: 35.5588\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8151 - val_loss: 35.5519\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.8084 - val_loss: 35.5449\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.8015 - val_loss: 35.5379\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.7946 - val_loss: 35.5308\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7877 - val_loss: 35.5237\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7808 - val_loss: 35.5165\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7738 - val_loss: 35.5094\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7667 - val_loss: 35.5021\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.7597 - val_loss: 35.4949\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.7526 - val_loss: 35.4877\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.7455 - val_loss: 35.4804\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7384 - val_loss: 35.4731\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7313 - val_loss: 35.4658\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7242 - val_loss: 35.4585\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7170 - val_loss: 35.4512\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7098 - val_loss: 35.4438\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.7027 - val_loss: 35.4365\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6955 - val_loss: 35.4291\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6883 - val_loss: 35.4218\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6811 - val_loss: 35.4144\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6739 - val_loss: 35.4070\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6667 - val_loss: 35.3996\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6594 - val_loss: 35.3922\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6522 - val_loss: 35.3848\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6450 - val_loss: 35.3775\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6378 - val_loss: 35.3701\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.6305 - val_loss: 35.3627\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.6233 - val_loss: 35.3553\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 35.6161 - val_loss: 35.3479\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.6088 - val_loss: 35.3405\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.6016 - val_loss: 35.3331\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5943 - val_loss: 35.3256\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5871 - val_loss: 35.3182\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5799 - val_loss: 35.3108\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5726 - val_loss: 35.3034\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.5654 - val_loss: 35.2960\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5581 - val_loss: 35.2886\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5509 - val_loss: 35.2812\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5437 - val_loss: 35.2738\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5364 - val_loss: 35.2664\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.5292 - val_loss: 35.2590\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.5219 - val_loss: 35.2516\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.5147 - val_loss: 35.2442\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 35.5075 - val_loss: 35.2368\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.5002 - val_loss: 35.2294\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.4930 - val_loss: 35.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4858 - val_loss: 35.2146\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4785 - val_loss: 35.2072\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4713 - val_loss: 35.1998\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4641 - val_loss: 35.1925\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.4569 - val_loss: 35.1851\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4496 - val_loss: 35.1777\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4424 - val_loss: 35.1703\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.4352 - val_loss: 35.1629\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.4280 - val_loss: 35.1555\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 122us/step - loss: 35.4207 - val_loss: 35.1481\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 35.4135 - val_loss: 35.1408\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.4063 - val_loss: 35.1334\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.3991 - val_loss: 35.1260\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.3919 - val_loss: 35.1186\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3847 - val_loss: 35.1112\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.3774 - val_loss: 35.1039\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3702 - val_loss: 35.0965\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.3630 - val_loss: 35.0891\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3558 - val_loss: 35.0817\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3486 - val_loss: 35.0744\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3414 - val_loss: 35.0670\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.3342 - val_loss: 35.0597\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3270 - val_loss: 35.0523\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3198 - val_loss: 35.0449\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.3126 - val_loss: 35.0376\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.3054 - val_loss: 35.0302\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2982 - val_loss: 35.0228\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2910 - val_loss: 35.0155\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2838 - val_loss: 35.0081\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.2766 - val_loss: 35.0008\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.2694 - val_loss: 34.9934\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.2623 - val_loss: 34.9861\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2551 - val_loss: 34.9787\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2479 - val_loss: 34.9714\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2407 - val_loss: 34.9640\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.2335 - val_loss: 34.9567\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2263 - val_loss: 34.9494\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2192 - val_loss: 34.9420\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 35.2120 - val_loss: 34.9347\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.2048 - val_loss: 34.9273\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1976 - val_loss: 34.9200\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1905 - val_loss: 34.9127\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1833 - val_loss: 34.9053\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1761 - val_loss: 34.8980\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.1689 - val_loss: 34.8907\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1618 - val_loss: 34.8834\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1546 - val_loss: 34.8760\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1475 - val_loss: 34.8687\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1403 - val_loss: 34.8614\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1331 - val_loss: 34.8541\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.1260 - val_loss: 34.8467\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.1188 - val_loss: 34.8394\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.1117 - val_loss: 34.8321\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 35.1045 - val_loss: 34.8248\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0974 - val_loss: 34.8175\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 35.0902 - val_loss: 34.8102\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0831 - val_loss: 34.8028\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0759 - val_loss: 34.7955\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0688 - val_loss: 34.7882\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0616 - val_loss: 34.7809\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0545 - val_loss: 34.7736\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 35.0473 - val_loss: 34.7663\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 35.0402 - val_loss: 34.7590\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 35.0330 - val_loss: 34.7517\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0259 - val_loss: 34.7444\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0188 - val_loss: 34.7371\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 35.0116 - val_loss: 34.7298\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.0045 - val_loss: 34.7225\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9974 - val_loss: 34.7152\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9902 - val_loss: 34.7079\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9831 - val_loss: 34.7007\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9760 - val_loss: 34.6934\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9689 - val_loss: 34.6861\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9617 - val_loss: 34.6788\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9546 - val_loss: 34.6715\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.9475 - val_loss: 34.6642\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9404 - val_loss: 34.6569\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9333 - val_loss: 34.6497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.9261 - val_loss: 34.6424\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9190 - val_loss: 34.6351\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9119 - val_loss: 34.6278\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.9048 - val_loss: 34.6206\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8977 - val_loss: 34.6133\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8906 - val_loss: 34.6060\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8835 - val_loss: 34.5988\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8764 - val_loss: 34.5915\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8693 - val_loss: 34.5842\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8622 - val_loss: 34.5770\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8551 - val_loss: 34.5697\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.8480 - val_loss: 34.5624\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.8409 - val_loss: 34.5552\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.8338 - val_loss: 34.5479\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8267 - val_loss: 34.5407\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8196 - val_loss: 34.5334\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.8125 - val_loss: 34.5261\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.8054 - val_loss: 34.5189\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7983 - val_loss: 34.5116\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7912 - val_loss: 34.5044\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7841 - val_loss: 34.4972\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7770 - val_loss: 34.4899\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7699 - val_loss: 34.4827\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7629 - val_loss: 34.4754\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7558 - val_loss: 34.4682\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7487 - val_loss: 34.4609\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.7416 - val_loss: 34.4537\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7345 - val_loss: 34.4465\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7275 - val_loss: 34.4392\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.7204 - val_loss: 34.4320\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.7133 - val_loss: 34.4247\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.7063 - val_loss: 34.4175\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.6992 - val_loss: 34.4103\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6921 - val_loss: 34.4031\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6851 - val_loss: 34.3958\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6780 - val_loss: 34.3886\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.6709 - val_loss: 34.3814\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6639 - val_loss: 34.3742\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6568 - val_loss: 34.3669\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 34.6497 - val_loss: 34.3597\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6427 - val_loss: 34.3525\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6356 - val_loss: 34.3453\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6286 - val_loss: 34.3381\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 34.6215 - val_loss: 34.3308\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.6145 - val_loss: 34.3236\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6074 - val_loss: 34.3164\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.6004 - val_loss: 34.3092\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5933 - val_loss: 34.3020\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5863 - val_loss: 34.2948\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5792 - val_loss: 34.2876\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5722 - val_loss: 34.2804\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5651 - val_loss: 34.2732\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5581 - val_loss: 34.2660\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5510 - val_loss: 34.2588\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5440 - val_loss: 34.2516\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5370 - val_loss: 34.2444\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.5299 - val_loss: 34.2372\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5229 - val_loss: 34.2300\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.5159 - val_loss: 34.2228\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.5088 - val_loss: 34.2156\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5018 - val_loss: 34.2084\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4948 - val_loss: 34.2012\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4877 - val_loss: 34.1940\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4807 - val_loss: 34.1868\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4737 - val_loss: 34.1797\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4667 - val_loss: 34.1725\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.4596 - val_loss: 34.1653\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4526 - val_loss: 34.1581\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4456 - val_loss: 34.1509\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.4386 - val_loss: 34.1438\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4316 - val_loss: 34.1366\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.4246 - val_loss: 34.1294\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.4175 - val_loss: 34.1222\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.4105 - val_loss: 34.1151\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.4035 - val_loss: 34.1079\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 34.3965 - val_loss: 34.1007\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3895 - val_loss: 34.0935\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3825 - val_loss: 34.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.3755 - val_loss: 34.0792\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3685 - val_loss: 34.0720\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3615 - val_loss: 34.0649\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3545 - val_loss: 34.0577\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3475 - val_loss: 34.0506\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.3405 - val_loss: 34.0434\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3335 - val_loss: 34.0363\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3265 - val_loss: 34.0291\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3195 - val_loss: 34.0219\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.3125 - val_loss: 34.0148\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.3055 - val_loss: 34.0076\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2985 - val_loss: 34.0005\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2915 - val_loss: 33.9933\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2845 - val_loss: 33.9862\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2775 - val_loss: 33.9790\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2706 - val_loss: 33.9719\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2636 - val_loss: 33.9647\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.2566 - val_loss: 33.9576\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.2496 - val_loss: 33.9505\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2426 - val_loss: 33.9433\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2357 - val_loss: 33.9362\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2287 - val_loss: 33.9290\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2217 - val_loss: 33.9219\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2147 - val_loss: 33.9148\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.2078 - val_loss: 33.9076\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.2008 - val_loss: 33.9005\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1938 - val_loss: 33.8934\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 34.1868 - val_loss: 33.8862\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.1799 - val_loss: 33.8791\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1729 - val_loss: 33.8720\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1659 - val_loss: 33.8649\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1590 - val_loss: 33.8577\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.1520 - val_loss: 33.8506\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1451 - val_loss: 33.8435\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 34.1381 - val_loss: 33.8364\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.1311 - val_loss: 33.8293\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1242 - val_loss: 33.8221\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.1172 - val_loss: 33.8150\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.1103 - val_loss: 33.8079\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.1033 - val_loss: 33.8008\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0964 - val_loss: 33.7937\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0894 - val_loss: 33.7866\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 34.0825 - val_loss: 33.7795\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0755 - val_loss: 33.7724\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0686 - val_loss: 33.7652\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 34.0616 - val_loss: 33.7581\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.0547 - val_loss: 33.7510\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 95us/step - loss: 34.0477 - val_loss: 33.7439\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.0408 - val_loss: 33.7368\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0338 - val_loss: 33.7297\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0269 - val_loss: 33.7226\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0200 - val_loss: 33.7155\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0130 - val_loss: 33.7084\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.0061 - val_loss: 33.7013\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9992 - val_loss: 33.6943\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9922 - val_loss: 33.6872\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9853 - val_loss: 33.6801\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9784 - val_loss: 33.6730\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 33.9714 - val_loss: 33.6659\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.9645 - val_loss: 33.6588\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.9576 - val_loss: 33.6517\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9507 - val_loss: 33.6446\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9437 - val_loss: 33.6375\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9368 - val_loss: 33.6305\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9299 - val_loss: 33.6234\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.9230 - val_loss: 33.6163\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9160 - val_loss: 33.6092\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.9091 - val_loss: 33.6021\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.9022 - val_loss: 33.5951\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.8953 - val_loss: 33.5880\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8884 - val_loss: 33.5809\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8815 - val_loss: 33.5738\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8746 - val_loss: 33.5668\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8676 - val_loss: 33.5597\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8607 - val_loss: 33.5526\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8538 - val_loss: 33.5456\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8469 - val_loss: 33.5385\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8400 - val_loss: 33.5314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.8331 - val_loss: 33.5244\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8262 - val_loss: 33.5173\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8193 - val_loss: 33.5103\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.8124 - val_loss: 33.5032\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.8055 - val_loss: 33.4961\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7986 - val_loss: 33.4891\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.7917 - val_loss: 33.4820\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7848 - val_loss: 33.4750\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7779 - val_loss: 33.4679\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7710 - val_loss: 33.4609\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.7641 - val_loss: 33.4538\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7573 - val_loss: 33.4468\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7504 - val_loss: 33.4397\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7435 - val_loss: 33.4327\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7366 - val_loss: 33.4256\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7297 - val_loss: 33.4186\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7228 - val_loss: 33.4115\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.7159 - val_loss: 33.4045\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.7091 - val_loss: 33.3975\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.7022 - val_loss: 33.3904\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6953 - val_loss: 33.3834\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.6884 - val_loss: 33.3763\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6815 - val_loss: 33.3693\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6747 - val_loss: 33.3623\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6678 - val_loss: 33.3552\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6609 - val_loss: 33.3482\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6541 - val_loss: 33.3412\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6472 - val_loss: 33.3341\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.6403 - val_loss: 33.3271\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6334 - val_loss: 33.3201\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6266 - val_loss: 33.3131\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.6197 - val_loss: 33.3060\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.6129 - val_loss: 33.2990\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.6060 - val_loss: 33.2920\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5991 - val_loss: 33.2850\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.5923 - val_loss: 33.2779\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.5854 - val_loss: 33.2709\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5785 - val_loss: 33.2639\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5717 - val_loss: 33.2569\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5648 - val_loss: 33.2499\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5580 - val_loss: 33.2429\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.5511 - val_loss: 33.2358\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5443 - val_loss: 33.2288\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5374 - val_loss: 33.2218\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5306 - val_loss: 33.2148\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5237 - val_loss: 33.2078\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5169 - val_loss: 33.2008\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.5100 - val_loss: 33.1938\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.5032 - val_loss: 33.1868\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.4963 - val_loss: 33.1798\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 33.4895 - val_loss: 33.1728\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4827 - val_loss: 33.1658\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4758 - val_loss: 33.1588\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4690 - val_loss: 33.1518\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4621 - val_loss: 33.1448\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.4553 - val_loss: 33.1378\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.4485 - val_loss: 33.1308\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4416 - val_loss: 33.1238\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4348 - val_loss: 33.1168\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4280 - val_loss: 33.1098\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4211 - val_loss: 33.1028\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4143 - val_loss: 33.0958\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4075 - val_loss: 33.0889\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.4006 - val_loss: 33.0819\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3938 - val_loss: 33.0749\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3870 - val_loss: 33.0679\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3802 - val_loss: 33.0609\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3733 - val_loss: 33.0539\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3665 - val_loss: 33.0469\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3597 - val_loss: 33.0400\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3529 - val_loss: 33.0330\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3461 - val_loss: 33.0260\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3392 - val_loss: 33.0190\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3324 - val_loss: 33.0121\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3256 - val_loss: 33.0051\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3188 - val_loss: 32.9981\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.3120 - val_loss: 32.9911\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.3052 - val_loss: 32.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2984 - val_loss: 32.9772\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2916 - val_loss: 32.9702\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2848 - val_loss: 32.9633\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.2779 - val_loss: 32.9563\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2711 - val_loss: 32.9493\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2643 - val_loss: 32.9424\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2575 - val_loss: 32.9354\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2507 - val_loss: 32.9284\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2439 - val_loss: 32.9215\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2371 - val_loss: 32.9145\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2303 - val_loss: 32.9076\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.2235 - val_loss: 32.9006\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 33.2167 - val_loss: 32.8937\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.2099 - val_loss: 32.8867\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.2031 - val_loss: 32.8797\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.1964 - val_loss: 32.8728\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1896 - val_loss: 32.8658\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1828 - val_loss: 32.8589\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1760 - val_loss: 32.8519\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1692 - val_loss: 32.8450\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1624 - val_loss: 32.8381\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1556 - val_loss: 32.8311\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.1488 - val_loss: 32.8242\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.1420 - val_loss: 32.8172\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1353 - val_loss: 32.8103\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1285 - val_loss: 32.8033\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1217 - val_loss: 32.7964\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.1149 - val_loss: 32.7895\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 33.1081 - val_loss: 32.7825\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.1014 - val_loss: 32.7756\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0946 - val_loss: 32.7687\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0878 - val_loss: 32.7617\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 33.0810 - val_loss: 32.7548\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0743 - val_loss: 32.7478\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.0675 - val_loss: 32.7409\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0607 - val_loss: 32.7340\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 33.0540 - val_loss: 32.7271\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0472 - val_loss: 32.7201\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0404 - val_loss: 32.7132\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0337 - val_loss: 32.7063\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.0269 - val_loss: 32.6994\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0201 - val_loss: 32.6924\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 33.0134 - val_loss: 32.6855\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 33.0066 - val_loss: 32.6786\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.9998 - val_loss: 32.6717\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.9931 - val_loss: 32.6647\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9863 - val_loss: 32.6578\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9796 - val_loss: 32.6509\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9728 - val_loss: 32.6440\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 32.9660 - val_loss: 32.6371\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9593 - val_loss: 32.6302\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9525 - val_loss: 32.6233\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9458 - val_loss: 32.6163\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9390 - val_loss: 32.6094\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9323 - val_loss: 32.6025\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9255 - val_loss: 32.5956\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9188 - val_loss: 32.5887\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.9120 - val_loss: 32.5818\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.9053 - val_loss: 32.5749\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8986 - val_loss: 32.5680\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8918 - val_loss: 32.5611\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8851 - val_loss: 32.5542\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8783 - val_loss: 32.5473\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8716 - val_loss: 32.5404\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8648 - val_loss: 32.5335\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8581 - val_loss: 32.5266\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8514 - val_loss: 32.5197\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.8446 - val_loss: 32.5128\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8379 - val_loss: 32.5059\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.8312 - val_loss: 32.4990\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.8244 - val_loss: 32.4921\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8177 - val_loss: 32.4852\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.8110 - val_loss: 32.4783\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.8042 - val_loss: 32.4714\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7975 - val_loss: 32.4646\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7908 - val_loss: 32.4577\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7841 - val_loss: 32.4508\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.7773 - val_loss: 32.4439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7706 - val_loss: 32.4370\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7639 - val_loss: 32.4301\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7572 - val_loss: 32.4233\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.7504 - val_loss: 32.4164\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7437 - val_loss: 32.4095\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 32.7370 - val_loss: 32.4026\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.7303 - val_loss: 32.3957\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 32.7236 - val_loss: 32.3889\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7169 - val_loss: 32.3820\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.7101 - val_loss: 32.3751\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.7034 - val_loss: 32.3682\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6967 - val_loss: 32.3614\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.6900 - val_loss: 32.3545\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6833 - val_loss: 32.3476\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6766 - val_loss: 32.3408\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6699 - val_loss: 32.3339\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.6632 - val_loss: 32.3270\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6565 - val_loss: 32.3202\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6498 - val_loss: 32.3133\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6431 - val_loss: 32.3064\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6363 - val_loss: 32.2996\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.6296 - val_loss: 32.2927\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.6229 - val_loss: 32.2858\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6162 - val_loss: 32.2790\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.6095 - val_loss: 32.2721\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 117us/step - loss: 32.6028 - val_loss: 32.2653\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5961 - val_loss: 32.2584\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5895 - val_loss: 32.2516\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5828 - val_loss: 32.2447\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5761 - val_loss: 32.2378\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5694 - val_loss: 32.2310\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5627 - val_loss: 32.2241\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.5560 - val_loss: 32.2173\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5493 - val_loss: 32.2104\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5426 - val_loss: 32.2036\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.5359 - val_loss: 32.1967\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.5292 - val_loss: 32.1899\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5225 - val_loss: 32.1831\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.5159 - val_loss: 32.1762\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5092 - val_loss: 32.1694\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.5025 - val_loss: 32.1625\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4958 - val_loss: 32.1557\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4891 - val_loss: 32.1488\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4825 - val_loss: 32.1420\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4758 - val_loss: 32.1352\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.4691 - val_loss: 32.1283\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4624 - val_loss: 32.1215\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4557 - val_loss: 32.1147\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4491 - val_loss: 32.1078\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4424 - val_loss: 32.1010\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4357 - val_loss: 32.0942\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.4290 - val_loss: 32.0873\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4224 - val_loss: 32.0805\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4157 - val_loss: 32.0737\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.4090 - val_loss: 32.0668\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.4024 - val_loss: 32.0600\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 32.3957 - val_loss: 32.0532\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3890 - val_loss: 32.0464\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 32.3824 - val_loss: 32.0395\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3757 - val_loss: 32.0327\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3690 - val_loss: 32.0259\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3624 - val_loss: 32.0191\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.3557 - val_loss: 32.0122\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3491 - val_loss: 32.0054\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.3424 - val_loss: 31.9986\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 32.3357 - val_loss: 31.9918\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.3291 - val_loss: 31.9850\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3224 - val_loss: 31.9782\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.3158 - val_loss: 31.9713\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.3091 - val_loss: 31.9645\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.3025 - val_loss: 31.9577\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2958 - val_loss: 31.9509\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2892 - val_loss: 31.9441\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2825 - val_loss: 31.9373\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2759 - val_loss: 31.9305\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2692 - val_loss: 31.9237\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2626 - val_loss: 31.9169\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2559 - val_loss: 31.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2493 - val_loss: 31.9032\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2426 - val_loss: 31.8964\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2360 - val_loss: 31.8896\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2293 - val_loss: 31.8828\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.2227 - val_loss: 31.8760\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2161 - val_loss: 31.8692\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.2094 - val_loss: 31.8624\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.2028 - val_loss: 31.8556\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1961 - val_loss: 31.8488\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1895 - val_loss: 31.8420\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1829 - val_loss: 31.8352\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1762 - val_loss: 31.8284\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1696 - val_loss: 31.8217\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1630 - val_loss: 31.8149\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1563 - val_loss: 31.8081\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1497 - val_loss: 31.8013\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1431 - val_loss: 31.7945\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1365 - val_loss: 31.7877\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.1298 - val_loss: 31.7809\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 32.1232 - val_loss: 31.7741\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1166 - val_loss: 31.7673\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.1099 - val_loss: 31.7606\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.1033 - val_loss: 31.7538\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0967 - val_loss: 31.7470\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0901 - val_loss: 31.7402\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0835 - val_loss: 31.7334\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0768 - val_loss: 31.7266\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0702 - val_loss: 31.7199\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0636 - val_loss: 31.7131\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 32.0570 - val_loss: 31.7063\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0504 - val_loss: 31.6995\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0437 - val_loss: 31.6928\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0371 - val_loss: 31.6860\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0305 - val_loss: 31.6792\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0239 - val_loss: 31.6724\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 32.0173 - val_loss: 31.6657\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0107 - val_loss: 31.6589\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 32.0041 - val_loss: 31.6521\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.9975 - val_loss: 31.6454\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9909 - val_loss: 31.6386\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9842 - val_loss: 31.6318\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9776 - val_loss: 31.6251\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 31.9710 - val_loss: 31.6183\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9644 - val_loss: 31.6115\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9578 - val_loss: 31.6048\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9512 - val_loss: 31.5980\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9446 - val_loss: 31.5912\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9380 - val_loss: 31.5845\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.9314 - val_loss: 31.5777\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9248 - val_loss: 31.5710\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9182 - val_loss: 31.5642\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.9116 - val_loss: 31.5574\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.9050 - val_loss: 31.5507\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8984 - val_loss: 31.5439\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.8918 - val_loss: 31.5372\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8852 - val_loss: 31.5304\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8786 - val_loss: 31.5237\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8721 - val_loss: 31.5169\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8655 - val_loss: 31.5102\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8589 - val_loss: 31.5034\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8523 - val_loss: 31.4967\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8457 - val_loss: 31.4899\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8391 - val_loss: 31.4832\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8325 - val_loss: 31.4764\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8259 - val_loss: 31.4697\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8194 - val_loss: 31.4629\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8128 - val_loss: 31.4562\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.8062 - val_loss: 31.4494\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7996 - val_loss: 31.4427\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7930 - val_loss: 31.4360\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7864 - val_loss: 31.4292\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7799 - val_loss: 31.4225\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7733 - val_loss: 31.4158\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7667 - val_loss: 31.4090\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.7601 - val_loss: 31.4023\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7536 - val_loss: 31.3955\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7470 - val_loss: 31.3888\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.7404 - val_loss: 31.3821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7338 - val_loss: 31.3753\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7273 - val_loss: 31.3686\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7207 - val_loss: 31.3619\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7141 - val_loss: 31.3551\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7076 - val_loss: 31.3484\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.7010 - val_loss: 31.3417\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6944 - val_loss: 31.3350\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6879 - val_loss: 31.3282\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6813 - val_loss: 31.3215\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6747 - val_loss: 31.3148\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6682 - val_loss: 31.3081\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6616 - val_loss: 31.3013\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6550 - val_loss: 31.2946\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6485 - val_loss: 31.2879\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6419 - val_loss: 31.2812\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6354 - val_loss: 31.2744\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6288 - val_loss: 31.2677\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6222 - val_loss: 31.2610\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.6157 - val_loss: 31.2543\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6091 - val_loss: 31.2476\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.6026 - val_loss: 31.2409\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5960 - val_loss: 31.2341\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5895 - val_loss: 31.2274\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5829 - val_loss: 31.2207\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5764 - val_loss: 31.2140\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5698 - val_loss: 31.2073\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5633 - val_loss: 31.2006\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5567 - val_loss: 31.1939\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5502 - val_loss: 31.1872\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.5436 - val_loss: 31.1805\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5371 - val_loss: 31.1738\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5305 - val_loss: 31.1670\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5240 - val_loss: 31.1603\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.5174 - val_loss: 31.1536\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5109 - val_loss: 31.1469\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.5043 - val_loss: 31.1402\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4978 - val_loss: 31.1335\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.4913 - val_loss: 31.1268\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4847 - val_loss: 31.1201\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4782 - val_loss: 31.1134\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4716 - val_loss: 31.1067\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.4651 - val_loss: 31.1000\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4586 - val_loss: 31.0933\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4520 - val_loss: 31.0866\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4455 - val_loss: 31.0799\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4390 - val_loss: 31.0733\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4324 - val_loss: 31.0666\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4259 - val_loss: 31.0599\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.4194 - val_loss: 31.0532\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.4128 - val_loss: 31.0465\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.4063 - val_loss: 31.0398\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3998 - val_loss: 31.0331\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3932 - val_loss: 31.0264\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3867 - val_loss: 31.0197\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3802 - val_loss: 31.0130\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3737 - val_loss: 31.0064\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3671 - val_loss: 30.9997\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3606 - val_loss: 30.9930\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3541 - val_loss: 30.9863\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3476 - val_loss: 30.9796\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3411 - val_loss: 30.9729\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3345 - val_loss: 30.9663\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3280 - val_loss: 30.9596\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3215 - val_loss: 30.9529\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.3150 - val_loss: 30.9462\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.3085 - val_loss: 30.9395\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.3019 - val_loss: 30.9329\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2954 - val_loss: 30.9262\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2889 - val_loss: 30.9195\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2824 - val_loss: 30.9128\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2759 - val_loss: 30.9062\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2694 - val_loss: 30.8995\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2629 - val_loss: 30.8928\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2564 - val_loss: 30.8861\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 31.2498 - val_loss: 30.8795\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 31.2433 - val_loss: 30.8728\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2368 - val_loss: 30.8661\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 218us/step - loss: 31.2303 - val_loss: 30.8595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.2238 - val_loss: 30.8528\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2173 - val_loss: 30.8461\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2108 - val_loss: 30.8395\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.2043 - val_loss: 30.8328\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1978 - val_loss: 30.8261\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.1913 - val_loss: 30.8195\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1848 - val_loss: 30.8128\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.1783 - val_loss: 30.8062\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1718 - val_loss: 30.7995\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1653 - val_loss: 30.7928\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1588 - val_loss: 30.7862\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1523 - val_loss: 30.7795\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1458 - val_loss: 30.7729\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1393 - val_loss: 30.7662\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1328 - val_loss: 30.7595\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1263 - val_loss: 30.7529\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1198 - val_loss: 30.7462\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.1133 - val_loss: 30.7396\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1068 - val_loss: 30.7329\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.1003 - val_loss: 30.7263\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 31.0939 - val_loss: 30.7196\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0874 - val_loss: 30.7130\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0809 - val_loss: 30.7063\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0744 - val_loss: 30.6997\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0679 - val_loss: 30.6930\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0614 - val_loss: 30.6864\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0549 - val_loss: 30.6797\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 31.0484 - val_loss: 30.6731\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0420 - val_loss: 30.6664\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0355 - val_loss: 30.6598\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0290 - val_loss: 30.6532\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0225 - val_loss: 30.6465\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0160 - val_loss: 30.6399\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 31.0096 - val_loss: 30.6332\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.0031 - val_loss: 30.6266\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.9966 - val_loss: 30.6199\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9901 - val_loss: 30.6133\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.9836 - val_loss: 30.6067\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9772 - val_loss: 30.6000\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9707 - val_loss: 30.5934\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9642 - val_loss: 30.5868\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9577 - val_loss: 30.5801\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9513 - val_loss: 30.5735\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9448 - val_loss: 30.5669\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.9383 - val_loss: 30.5602\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.9319 - val_loss: 30.5536\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.9254 - val_loss: 30.5470\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.9189 - val_loss: 30.5403\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.9124 - val_loss: 30.5337\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.9060 - val_loss: 30.5271\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8995 - val_loss: 30.5204\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.8930 - val_loss: 30.5138\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8866 - val_loss: 30.5072\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8801 - val_loss: 30.5006\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8737 - val_loss: 30.4939\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8672 - val_loss: 30.4873\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8607 - val_loss: 30.4807\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8543 - val_loss: 30.4741\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.8478 - val_loss: 30.4675\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8413 - val_loss: 30.4608\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8349 - val_loss: 30.4542\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8284 - val_loss: 30.4476\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8220 - val_loss: 30.4410\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8155 - val_loss: 30.4343\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.8091 - val_loss: 30.4277\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.8026 - val_loss: 30.4211\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7962 - val_loss: 30.4145\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7897 - val_loss: 30.4079\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.7832 - val_loss: 30.4013\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7768 - val_loss: 30.3947\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7703 - val_loss: 30.3880\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7639 - val_loss: 30.3814\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7574 - val_loss: 30.3748\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7510 - val_loss: 30.3682\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7445 - val_loss: 30.3616\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7381 - val_loss: 30.3550\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7316 - val_loss: 30.3484\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.7252 - val_loss: 30.3418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.7188 - val_loss: 30.3352\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.7123 - val_loss: 30.3286\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.7059 - val_loss: 30.3220\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.6994 - val_loss: 30.3154\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.6930 - val_loss: 30.3087\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6865 - val_loss: 30.3021\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6801 - val_loss: 30.2955\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6737 - val_loss: 30.2889\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6672 - val_loss: 30.2823\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6608 - val_loss: 30.2757\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.6543 - val_loss: 30.2691\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.6479 - val_loss: 30.2625\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6415 - val_loss: 30.2559\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.6350 - val_loss: 30.2493\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.6286 - val_loss: 30.2427\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6222 - val_loss: 30.2361\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6157 - val_loss: 30.2296\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6093 - val_loss: 30.2230\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.6029 - val_loss: 30.2164\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5964 - val_loss: 30.2098\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.5900 - val_loss: 30.2032\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5836 - val_loss: 30.1966\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5771 - val_loss: 30.1900\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.5707 - val_loss: 30.1834\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.5643 - val_loss: 30.1768\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5579 - val_loss: 30.1702\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5514 - val_loss: 30.1636\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.5450 - val_loss: 30.1571\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5386 - val_loss: 30.1505\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5322 - val_loss: 30.1439\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.5257 - val_loss: 30.1373\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.5193 - val_loss: 30.1307\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.5129 - val_loss: 30.1241\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.5065 - val_loss: 30.1175\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.5001 - val_loss: 30.1110\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.4936 - val_loss: 30.1044\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.4872 - val_loss: 30.0978\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.4808 - val_loss: 30.0912\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.4744 - val_loss: 30.0846\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4680 - val_loss: 30.0781\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4615 - val_loss: 30.0715\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4551 - val_loss: 30.0649\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4487 - val_loss: 30.0583\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4423 - val_loss: 30.0518\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.4359 - val_loss: 30.0452\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.4295 - val_loss: 30.0386\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4231 - val_loss: 30.0320\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4167 - val_loss: 30.0255\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4102 - val_loss: 30.0189\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.4038 - val_loss: 30.0123\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3974 - val_loss: 30.0057\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3910 - val_loss: 29.9992\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3846 - val_loss: 29.9926\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3782 - val_loss: 29.9860\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.3718 - val_loss: 29.9795\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3654 - val_loss: 29.9729\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3590 - val_loss: 29.9663\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3526 - val_loss: 29.9598\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3462 - val_loss: 29.9532\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.3398 - val_loss: 29.9466\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3334 - val_loss: 29.9401\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3270 - val_loss: 29.9335\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3206 - val_loss: 29.9269\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.3142 - val_loss: 29.9204\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.3078 - val_loss: 29.9138\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.3014 - val_loss: 29.9073\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 30.2950 - val_loss: 29.9007\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.2886 - val_loss: 29.8941\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.2822 - val_loss: 29.8876\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2758 - val_loss: 29.8810\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2694 - val_loss: 29.8745\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2630 - val_loss: 29.8679\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.2566 - val_loss: 29.8613\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2502 - val_loss: 29.8548\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2438 - val_loss: 29.8482\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2374 - val_loss: 29.8417\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2310 - val_loss: 29.8351\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2246 - val_loss: 29.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2183 - val_loss: 29.8220\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.2119 - val_loss: 29.8155\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.2055 - val_loss: 29.8089\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1991 - val_loss: 29.8024\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1927 - val_loss: 29.7958\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 30.1863 - val_loss: 29.7893\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1799 - val_loss: 29.7827\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1736 - val_loss: 29.7762\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1672 - val_loss: 29.7696\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1608 - val_loss: 29.7631\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1544 - val_loss: 29.7565\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1480 - val_loss: 29.7500\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.1416 - val_loss: 29.7435\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.1353 - val_loss: 29.7369\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1289 - val_loss: 29.7304\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1225 - val_loss: 29.7238\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1161 - val_loss: 29.7173\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1097 - val_loss: 29.7107\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.1034 - val_loss: 29.7042\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0970 - val_loss: 29.6977\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0906 - val_loss: 29.6911\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0842 - val_loss: 29.6846\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0779 - val_loss: 29.6781\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0715 - val_loss: 29.6715\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0651 - val_loss: 29.6650\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0587 - val_loss: 29.6585\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0524 - val_loss: 29.6519\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 30.0460 - val_loss: 29.6454\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0396 - val_loss: 29.6389\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0333 - val_loss: 29.6323\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0269 - val_loss: 29.6258\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0205 - val_loss: 29.6193\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 30.0142 - val_loss: 29.6127\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.0078 - val_loss: 29.6062\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 30.0014 - val_loss: 29.5997\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9951 - val_loss: 29.5931\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9887 - val_loss: 29.5866\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9823 - val_loss: 29.5801\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9760 - val_loss: 29.5736\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.9696 - val_loss: 29.5670\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.9632 - val_loss: 29.5605\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9569 - val_loss: 29.5540\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9505 - val_loss: 29.5475\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9442 - val_loss: 29.5409\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9378 - val_loss: 29.5344\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.9314 - val_loss: 29.5279\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9251 - val_loss: 29.5214\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9187 - val_loss: 29.5148\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9124 - val_loss: 29.5083\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.9060 - val_loss: 29.5018\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8997 - val_loss: 29.4953\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8933 - val_loss: 29.4888\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8869 - val_loss: 29.4822\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8806 - val_loss: 29.4757\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.8742 - val_loss: 29.4692\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8679 - val_loss: 29.4627\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8615 - val_loss: 29.4562\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8552 - val_loss: 29.4497\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.8488 - val_loss: 29.4432\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8425 - val_loss: 29.4366\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.8361 - val_loss: 29.4301\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8298 - val_loss: 29.4236\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8234 - val_loss: 29.4171\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.8171 - val_loss: 29.4106\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8107 - val_loss: 29.4041\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.8044 - val_loss: 29.3976\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7980 - val_loss: 29.3911\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.7917 - val_loss: 29.3846\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.7854 - val_loss: 29.3781\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7790 - val_loss: 29.3715\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.7727 - val_loss: 29.3650\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7663 - val_loss: 29.3585\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7600 - val_loss: 29.3520\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7536 - val_loss: 29.3455\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7473 - val_loss: 29.3390\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7410 - val_loss: 29.3325\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7346 - val_loss: 29.3260\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.7283 - val_loss: 29.3195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7220 - val_loss: 29.3130\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7156 - val_loss: 29.3065\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.7093 - val_loss: 29.3000\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.7029 - val_loss: 29.2935\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6966 - val_loss: 29.2870\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.6903 - val_loss: 29.2805\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.6839 - val_loss: 29.2740\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6776 - val_loss: 29.2675\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6713 - val_loss: 29.2610\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6649 - val_loss: 29.2545\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.6586 - val_loss: 29.2480\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.6523 - val_loss: 29.2415\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6459 - val_loss: 29.2350\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6396 - val_loss: 29.2285\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6333 - val_loss: 29.2221\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6270 - val_loss: 29.2156\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.6206 - val_loss: 29.2091\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.6143 - val_loss: 29.2026\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 29.6080 - val_loss: 29.1961\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.6017 - val_loss: 29.1896\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.5953 - val_loss: 29.1831\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5890 - val_loss: 29.1766\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.5827 - val_loss: 29.1701\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.5764 - val_loss: 29.1636\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5700 - val_loss: 29.1572\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5637 - val_loss: 29.1507\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5574 - val_loss: 29.1442\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5511 - val_loss: 29.1377\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5447 - val_loss: 29.1312\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.5384 - val_loss: 29.1247\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5321 - val_loss: 29.1183\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5258 - val_loss: 29.1118\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5195 - val_loss: 29.1053\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.5131 - val_loss: 29.0988\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.5068 - val_loss: 29.0923\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.5005 - val_loss: 29.0858\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4942 - val_loss: 29.0794\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4879 - val_loss: 29.0729\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4816 - val_loss: 29.0664\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4753 - val_loss: 29.0599\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4689 - val_loss: 29.0535\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4626 - val_loss: 29.0470\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4563 - val_loss: 29.0405\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4500 - val_loss: 29.0340\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4437 - val_loss: 29.0276\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 29.4374 - val_loss: 29.0211\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4311 - val_loss: 29.0146\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.4248 - val_loss: 29.0081\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4185 - val_loss: 29.0017\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.4122 - val_loss: 28.9952\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.4058 - val_loss: 28.9887\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3995 - val_loss: 28.9823\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3932 - val_loss: 28.9758\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3869 - val_loss: 28.9693\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3806 - val_loss: 28.9628\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3743 - val_loss: 28.9564\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3680 - val_loss: 28.9499\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3617 - val_loss: 28.9434\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.3554 - val_loss: 28.9370\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3491 - val_loss: 28.9305\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 29.3428 - val_loss: 28.9240\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3365 - val_loss: 28.9176\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 29.3302 - val_loss: 28.9111\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3239 - val_loss: 28.9046\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3176 - val_loss: 28.8982\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3113 - val_loss: 28.8917\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.3050 - val_loss: 28.8853\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2987 - val_loss: 28.8788\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2924 - val_loss: 28.8723\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2861 - val_loss: 28.8659\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2798 - val_loss: 28.8594\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 29.2735 - val_loss: 28.8530\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 29.2672 - val_loss: 28.8465\n",
      "26.799942016601562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.53952616, -0.59826696,  0.5644748 , -0.29888788, -0.04832367],\n",
       "        [ 0.00756492,  0.25885287,  0.61467445, -0.82407767, -0.31862628],\n",
       "        [ 0.67316675, -0.44051468,  0.3385642 ,  0.76385105, -0.56279504]],\n",
       "       dtype=float32),\n",
       " array([-0.04846346,  0.01743151, -0.02789615, -0.03060336, -0.09740838],\n",
       "       dtype=float32),\n",
       " array([[ 0.387891  ,  0.37094423,  0.4332685 , -0.17098673, -0.45252723,\n",
       "          0.6216626 ,  0.6156873 ,  0.28232935,  0.25684056, -0.15465258],\n",
       "        [ 0.1340369 , -0.114769  , -0.1210269 , -0.5154139 ,  0.45345712,\n",
       "          0.04828865,  0.17190395,  0.15790547,  0.2997108 ,  0.0544431 ],\n",
       "        [ 0.5853485 , -0.06022786,  0.14791024,  0.0783567 , -0.52164745,\n",
       "          0.5962962 , -0.42832097,  0.60805064, -0.37891352, -0.4445496 ],\n",
       "        [-0.0065888 ,  0.04226655,  0.21924162,  0.5073278 , -0.3401079 ,\n",
       "          0.26190537,  0.20450655, -0.53362095,  0.12633921, -0.38349697],\n",
       "        [-0.4868068 ,  0.09785797, -0.55011773, -0.4023399 , -0.5838749 ,\n",
       "          0.18312755,  0.5972358 ,  0.47244218, -0.5858737 , -0.4387141 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.07728606,  0.06684272, -0.10962022, -0.0026347 ,  0.08565556,\n",
       "         0.06041607, -0.08457968, -0.08043949, -0.01504545,  0.10780787],\n",
       "       dtype=float32),\n",
       " array([[ 0.40287685],\n",
       "        [ 0.34540296],\n",
       "        [-0.5625859 ],\n",
       "        [-0.01519556],\n",
       "        [ 0.44720677],\n",
       "        [ 0.31188676],\n",
       "        [-0.43712357],\n",
       "        [-0.41602454],\n",
       "        [-0.07210475],\n",
       "        [ 0.5602255 ]], dtype=float32),\n",
       " array([0.196141], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, sgd, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sgd_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 39.3040 - val_loss: 36.3880\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 35.6295 - val_loss: 34.6653\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 33.5982 - val_loss: 33.1923\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 31.8727 - val_loss: 31.7942\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 30.1939 - val_loss: 30.3022\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 28.4716 - val_loss: 28.6372\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 26.6749 - val_loss: 26.7816\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 24.8058 - val_loss: 24.7747\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 22.8804 - val_loss: 22.6378\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 20.9135 - val_loss: 20.3341\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 18.9125 - val_loss: 17.8741\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 16.8795 - val_loss: 15.3747\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 14.8344 - val_loss: 12.9683\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 12.8193 - val_loss: 10.7297\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 10.8830 - val_loss: 8.6984\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 9.0705 - val_loss: 6.9011\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 7.4160 - val_loss: 5.3568\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 5.9424 - val_loss: 4.0671\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 4.6619 - val_loss: 3.0182\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 3.5766 - val_loss: 2.1878\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 2.6804 - val_loss: 1.5480\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 1.9600 - val_loss: 1.0689\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 1.3972 - val_loss: 0.7206\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.9706 - val_loss: 0.4752\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.6577 - val_loss: 0.3083\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.4362 - val_loss: 0.1991\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.2853 - val_loss: 0.1307\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1867 - val_loss: 0.0899\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1248 - val_loss: 0.0666\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0875 - val_loss: 0.0539\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0658 - val_loss: 0.0472\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0534 - val_loss: 0.0434\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0463 - val_loss: 0.0411\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0419 - val_loss: 0.0393\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0390 - val_loss: 0.0376\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0359\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0341\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0324\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0321 - val_loss: 0.0307\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0291\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0276\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0261\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0248\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0265 - val_loss: 0.0234\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0223\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0207\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0238 - val_loss: 0.0208\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0230 - val_loss: 0.0163\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0226 - val_loss: 0.0278\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0076\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0559 - val_loss: 0.0896\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1223 - val_loss: 0.0334\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1243 - val_loss: 0.0625\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0709 - val_loss: 0.0105\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0423 - val_loss: 0.0295\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0090\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0217\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0091\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0212 - val_loss: 0.0201\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0208 - val_loss: 0.0084\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0073\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0306\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0315 - val_loss: 0.0094\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0524\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0617 - val_loss: 0.0194\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0783 - val_loss: 0.0620\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0779 - val_loss: 0.0235\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0716 - val_loss: 0.0496\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0596 - val_loss: 0.0273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0564 - val_loss: 0.0441\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0512 - val_loss: 0.0342\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0447\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0507 - val_loss: 0.0403\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0539 - val_loss: 0.0463\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0509 - val_loss: 0.0435\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0539 - val_loss: 0.0472\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0505 - val_loss: 0.0440\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0535 - val_loss: 0.0473\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0506 - val_loss: 0.0415\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0542 - val_loss: 0.0456\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0521 - val_loss: 0.0325\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0573 - val_loss: 0.0420\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0587 - val_loss: 0.0177\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0699 - val_loss: 0.0431\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0697 - val_loss: 0.0148\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0636 - val_loss: 0.0353\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0509 - val_loss: 0.0202\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0464 - val_loss: 0.0334\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0335\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0478 - val_loss: 0.0426\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0512 - val_loss: 0.0561\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0611 - val_loss: 0.0554\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0598 - val_loss: 0.0697\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0631 - val_loss: 0.0568\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0541 - val_loss: 0.0670\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0532 - val_loss: 0.0515\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0453 - val_loss: 0.0602\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0450 - val_loss: 0.0470\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0563\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0420 - val_loss: 0.0464\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0402 - val_loss: 0.0566\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0443 - val_loss: 0.0494\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0576\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0518 - val_loss: 0.0506\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0537 - val_loss: 0.0467\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0650 - val_loss: 0.0429\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0721 - val_loss: 0.0260\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0887 - val_loss: 0.0381\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0748 - val_loss: 0.0192\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0586 - val_loss: 0.0257\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0416 - val_loss: 0.0199\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0227\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0328 - val_loss: 0.0284\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0294\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0392 - val_loss: 0.0455\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0476 - val_loss: 0.0423\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0497 - val_loss: 0.0615\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0560 - val_loss: 0.0512\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 0.0519 - val_loss: 0.0661\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 165us/step - loss: 0.0544 - val_loss: 0.0526\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0482 - val_loss: 0.0620\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0494 - val_loss: 0.0485\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0439 - val_loss: 0.0541\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0451 - val_loss: 0.0423\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0412 - val_loss: 0.0448\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0352\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0431 - val_loss: 0.0307\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0519 - val_loss: 0.0306\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0627 - val_loss: 0.0215\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0794 - val_loss: 0.0306\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0662 - val_loss: 0.0202\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0528 - val_loss: 0.0239\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0402 - val_loss: 0.0260\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0386 - val_loss: 0.0263\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0379 - val_loss: 0.0410\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0371\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0470 - val_loss: 0.0574\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0448\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0488 - val_loss: 0.0615\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0500 - val_loss: 0.0458\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0433 - val_loss: 0.0590\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0440 - val_loss: 0.0452\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0567\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0451\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0390 - val_loss: 0.0552\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0425 - val_loss: 0.0445\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0413 - val_loss: 0.0517\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0465 - val_loss: 0.0399\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0465 - val_loss: 0.0390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0556 - val_loss: 0.0307\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0629 - val_loss: 0.0252\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0785 - val_loss: 0.0280\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0665 - val_loss: 0.0203\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0526 - val_loss: 0.0203\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 135us/step - loss: 0.0381 - val_loss: 0.0224\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0346 - val_loss: 0.0207\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0325 - val_loss: 0.0333\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0375 - val_loss: 0.0300\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0405 - val_loss: 0.0508\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0416\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0476 - val_loss: 0.0617\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0513 - val_loss: 0.0469\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0455 - val_loss: 0.0626\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0475\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0411 - val_loss: 0.0597\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0424 - val_loss: 0.0459\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0384 - val_loss: 0.0562\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0406 - val_loss: 0.0438\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0529\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0408\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0405 - val_loss: 0.0463\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0465 - val_loss: 0.0331\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0488 - val_loss: 0.0306\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0646 - val_loss: 0.0291\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0745 - val_loss: 0.0238\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0724 - val_loss: 0.0221\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0500 - val_loss: 0.0205\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0394 - val_loss: 0.0180\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0315 - val_loss: 0.0260\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0324 - val_loss: 0.0227\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0335 - val_loss: 0.0406\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0408 - val_loss: 0.0344\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0563\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0495 - val_loss: 0.0435\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0458 - val_loss: 0.0617\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0477 - val_loss: 0.0463\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0417 - val_loss: 0.0605\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0429 - val_loss: 0.0462\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0382 - val_loss: 0.0576\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0401 - val_loss: 0.0447\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0370 - val_loss: 0.0544\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0399 - val_loss: 0.0423\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0383 - val_loss: 0.0496\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0430 - val_loss: 0.0364\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0431 - val_loss: 0.0372\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0528 - val_loss: 0.0268\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0616 - val_loss: 0.0262\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0768 - val_loss: 0.0239\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 186us/step - loss: 0.0625 - val_loss: 0.0208\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0486 - val_loss: 0.0174\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0348 - val_loss: 0.0227\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0191\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0306 - val_loss: 0.0338\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0360 - val_loss: 0.0289\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0389 - val_loss: 0.0502\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0462 - val_loss: 0.0398\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0447 - val_loss: 0.0593\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0478 - val_loss: 0.0445\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0420 - val_loss: 0.0601\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0431 - val_loss: 0.0456\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0583\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0396 - val_loss: 0.0451\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0361 - val_loss: 0.0561\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0385 - val_loss: 0.0439\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0364 - val_loss: 0.0535\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0411\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.0470\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0458 - val_loss: 0.0322\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0481 - val_loss: 0.0312\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0632 - val_loss: 0.0260\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0708 - val_loss: 0.0240\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0680 - val_loss: 0.0189\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0466 - val_loss: 0.0199\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0367 - val_loss: 0.0157\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0292 - val_loss: 0.0249\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0303 - val_loss: 0.0209\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0316 - val_loss: 0.0390\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0412 - val_loss: 0.0544\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0474 - val_loss: 0.0420\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0438 - val_loss: 0.0600\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0457 - val_loss: 0.0451\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0398 - val_loss: 0.0593\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0408 - val_loss: 0.0454\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0571\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0379 - val_loss: 0.0443\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0348 - val_loss: 0.0546\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0376 - val_loss: 0.0428\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0360 - val_loss: 0.0517\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0407 - val_loss: 0.0389\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0408 - val_loss: 0.0424\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0491 - val_loss: 0.0278\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0546 - val_loss: 0.0281\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0721 - val_loss: 0.0235\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0666 - val_loss: 0.0215\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0538 - val_loss: 0.0159\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0203\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0312 - val_loss: 0.0159\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0284\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0241\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0341 - val_loss: 0.0442\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0417 - val_loss: 0.0361\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0423 - val_loss: 0.0565\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0430\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0417 - val_loss: 0.0594\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0451\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0375 - val_loss: 0.0582\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0387 - val_loss: 0.0448\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0558\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0365 - val_loss: 0.0434\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0339 - val_loss: 0.0535\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0373 - val_loss: 0.0421\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0502\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0364\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0440 - val_loss: 0.0373\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0555 - val_loss: 0.0252\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0632 - val_loss: 0.0263\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0721 - val_loss: 0.0194\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0539 - val_loss: 0.0196\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0413 - val_loss: 0.0141\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0300 - val_loss: 0.0214\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0172\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0280 - val_loss: 0.0326\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0277\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0368 - val_loss: 0.0486\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0439 - val_loss: 0.0387\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0424 - val_loss: 0.0575\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0453 - val_loss: 0.0437\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0396 - val_loss: 0.0588\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0407 - val_loss: 0.0450\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0357 - val_loss: 0.0571\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0370 - val_loss: 0.0440\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0333 - val_loss: 0.0544\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0353 - val_loss: 0.0425\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0332 - val_loss: 0.0525\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0372 - val_loss: 0.0414\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0375 - val_loss: 0.0486\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0451 - val_loss: 0.0338\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0482 - val_loss: 0.0334\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0627 - val_loss: 0.0239\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0669 - val_loss: 0.0240\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0638 - val_loss: 0.0162\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0432 - val_loss: 0.0187\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0339 - val_loss: 0.0134\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0230\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0188\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0290 - val_loss: 0.0361\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0305\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0384 - val_loss: 0.0512\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0446 - val_loss: 0.0403\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0416 - val_loss: 0.0580\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0437 - val_loss: 0.0443\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0381 - val_loss: 0.0584\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0391 - val_loss: 0.0448\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0344 - val_loss: 0.0559\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0356 - val_loss: 0.0428\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0413\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0327 - val_loss: 0.0514\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0375 - val_loss: 0.0407\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0391 - val_loss: 0.0466\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0310\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0537 - val_loss: 0.0306\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0687 - val_loss: 0.0219\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0637 - val_loss: 0.0215\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0529 - val_loss: 0.0139\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0352 - val_loss: 0.0185\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0294 - val_loss: 0.0135\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0283 - val_loss: 0.0210\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0306 - val_loss: 0.0395\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0379 - val_loss: 0.0331\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0531\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0446 - val_loss: 0.0415\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0405 - val_loss: 0.0581\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0421 - val_loss: 0.0447\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0366 - val_loss: 0.0577\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0376 - val_loss: 0.0441\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0331 - val_loss: 0.0542\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0413\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.0508\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0332 - val_loss: 0.0403\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0506\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0385 - val_loss: 0.0403\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0417 - val_loss: 0.0448\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0541 - val_loss: 0.0287\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0595 - val_loss: 0.0286\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0704 - val_loss: 0.0192\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0561 - val_loss: 0.0194\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0434 - val_loss: 0.0124\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0298 - val_loss: 0.0186\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0267 - val_loss: 0.0140\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0249 - val_loss: 0.0270\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0292 - val_loss: 0.0231\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0321 - val_loss: 0.0424\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0352\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0545\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0442 - val_loss: 0.0426\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0395 - val_loss: 0.0583\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0408 - val_loss: 0.0450\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0568\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0363 - val_loss: 0.0429\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0520\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0327 - val_loss: 0.0394\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0297 - val_loss: 0.0489\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0322 - val_loss: 0.0393\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.0501\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0404\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0449 - val_loss: 0.0435\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0595 - val_loss: 0.0272\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0634 - val_loss: 0.0270\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0679 - val_loss: 0.0168\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0180\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0370 - val_loss: 0.0114\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0187\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0144\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0246 - val_loss: 0.0284\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0297 - val_loss: 0.0245\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0330 - val_loss: 0.0442\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0403 - val_loss: 0.0367\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0402 - val_loss: 0.0556\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0439 - val_loss: 0.0436\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0388 - val_loss: 0.0585\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0400 - val_loss: 0.0450\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0347 - val_loss: 0.0556\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0352 - val_loss: 0.0414\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0306 - val_loss: 0.0496\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0312 - val_loss: 0.0374\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0468\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0311 - val_loss: 0.0383\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0318 - val_loss: 0.0499\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0406 - val_loss: 0.0411\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0477 - val_loss: 0.0437\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0639 - val_loss: 0.0266\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0651 - val_loss: 0.0259\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0647 - val_loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0441 - val_loss: 0.0171\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0333 - val_loss: 0.0108\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0245 - val_loss: 0.0185\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0240 - val_loss: 0.0145\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0241 - val_loss: 0.0287\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0296 - val_loss: 0.0251\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0331 - val_loss: 0.0448\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0405 - val_loss: 0.0376\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0401 - val_loss: 0.0562\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0437 - val_loss: 0.0445\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0386 - val_loss: 0.0589\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0397 - val_loss: 0.0450\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0342 - val_loss: 0.0545\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0344 - val_loss: 0.0399\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0295 - val_loss: 0.0473\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0299 - val_loss: 0.0353\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 330us/step - loss: 0.0271 - val_loss: 0.0447\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0297 - val_loss: 0.0369\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0307 - val_loss: 0.0495\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0399 - val_loss: 0.0425\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0487 - val_loss: 0.0460\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0666 - val_loss: 0.0274\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0661 - val_loss: 0.0259\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0638 - val_loss: 0.0146\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0165\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0319 - val_loss: 0.0102\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0176\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0228 - val_loss: 0.0137\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0230 - val_loss: 0.0274\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0243\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0320 - val_loss: 0.0438\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0397 - val_loss: 0.0375\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0399 - val_loss: 0.0564\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0440 - val_loss: 0.0451\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0390 - val_loss: 0.0594\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0401 - val_loss: 0.0452\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0342 - val_loss: 0.0538\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0340 - val_loss: 0.0388\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0454\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0288 - val_loss: 0.0334\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0258 - val_loss: 0.0422\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0280 - val_loss: 0.0347\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0286 - val_loss: 0.0478\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0368 - val_loss: 0.0435\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0460 - val_loss: 0.0510\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0661 - val_loss: 0.0310\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0674 - val_loss: 0.0281\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0673 - val_loss: 0.0154\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0453 - val_loss: 0.0165\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0097\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0233 - val_loss: 0.0161\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0217 - val_loss: 0.0121\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0212 - val_loss: 0.0243\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0257 - val_loss: 0.0217\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0294 - val_loss: 0.0405\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0374 - val_loss: 0.0359\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0392 - val_loss: 0.0555\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0444 - val_loss: 0.0453\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0399 - val_loss: 0.0602\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0413 - val_loss: 0.0460\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0351 - val_loss: 0.0544\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0388\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0289 - val_loss: 0.0445\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0283 - val_loss: 0.0320\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0248 - val_loss: 0.0398\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0262 - val_loss: 0.0318\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0259 - val_loss: 0.0440\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0318 - val_loss: 0.0411\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0384 - val_loss: 0.0555\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0584 - val_loss: 0.0400\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0675 - val_loss: 0.0351\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0747 - val_loss: 0.0186\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0541 - val_loss: 0.0180\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0400 - val_loss: 0.0097\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0257 - val_loss: 0.0144\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0216 - val_loss: 0.0100\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0220 - val_loss: 0.0171\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0249 - val_loss: 0.0337\n",
      "Epoch 467/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 125us/step - loss: 0.0325 - val_loss: 0.0312\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0364 - val_loss: 0.0518\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0437 - val_loss: 0.0442\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0413 - val_loss: 0.0611\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0438 - val_loss: 0.0477\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0374 - val_loss: 0.0572\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0370 - val_loss: 0.0408\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0304 - val_loss: 0.0457\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0291 - val_loss: 0.0319\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0246 - val_loss: 0.0381\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0250 - val_loss: 0.0289\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0235 - val_loss: 0.0390\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0345\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0295 - val_loss: 0.0507\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0417 - val_loss: 0.0485\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 110us/step - loss: 0.0564 - val_loss: 0.0520\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0777 - val_loss: 0.0273\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0674 - val_loss: 0.0239\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0575 - val_loss: 0.0121\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0352 - val_loss: 0.0139\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0258 - val_loss: 0.0083\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0191 - val_loss: 0.0147\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0188 - val_loss: 0.0116\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0248 - val_loss: 0.0226\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0295 - val_loss: 0.0420\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0385 - val_loss: 0.0388\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0407 - val_loss: 0.0587\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0461 - val_loss: 0.0484\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0409 - val_loss: 0.0614\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0455\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0341 - val_loss: 0.0509\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0350\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0264 - val_loss: 0.0393\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0255 - val_loss: 0.0279\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0224 - val_loss: 0.0351\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0278\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0395\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0279 - val_loss: 0.0367\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0317 - val_loss: 0.0554\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0466 - val_loss: 0.0534\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0638 - val_loss: 0.0528\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0829 - val_loss: 0.0252\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0651 - val_loss: 0.0213\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0515 - val_loss: 0.0104\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0305 - val_loss: 0.0121\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0222 - val_loss: 0.0072\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0167 - val_loss: 0.0130\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0178 - val_loss: 0.0222\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0290 - val_loss: 0.0422\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0393 - val_loss: 0.0403\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0425 - val_loss: 0.0608\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0501\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0422 - val_loss: 0.0622\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0422 - val_loss: 0.0456\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0338 - val_loss: 0.0498\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0318 - val_loss: 0.0341\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0255 - val_loss: 0.0377\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0244 - val_loss: 0.0268\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0214 - val_loss: 0.0334\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0264\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0224 - val_loss: 0.0371\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0263 - val_loss: 0.0328\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0283 - val_loss: 0.0488\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0363 - val_loss: 0.0489\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0444 - val_loss: 0.0683\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0700 - val_loss: 0.0461\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0758 - val_loss: 0.0347\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 0.0747 - val_loss: 0.0159\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0474 - val_loss: 0.0140\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 157us/step - loss: 0.0321 - val_loss: 0.0069\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0196 - val_loss: 0.0098\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0157 - val_loss: 0.0065\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0159 - val_loss: 0.0124\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0193 - val_loss: 0.0271\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0277 - val_loss: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0518\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0465 - val_loss: 0.0648\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0492 - val_loss: 0.0501\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0398 - val_loss: 0.0576\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0380 - val_loss: 0.0407\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0436\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0226 - val_loss: 0.0346\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0224 - val_loss: 0.0259\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0207 - val_loss: 0.0336\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0230 - val_loss: 0.0279\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0238 - val_loss: 0.0398\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0286 - val_loss: 0.0355\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0308 - val_loss: 0.0515\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0383 - val_loss: 0.0493\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0437 - val_loss: 0.0677\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0658 - val_loss: 0.0477\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0738 - val_loss: 0.0356\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0751 - val_loss: 0.0162\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0485 - val_loss: 0.0136\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0327 - val_loss: 0.0067\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0194 - val_loss: 0.0089\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0150 - val_loss: 0.0058\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0145 - val_loss: 0.0110\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0177 - val_loss: 0.0245\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.0271\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0341 - val_loss: 0.0501\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0467 - val_loss: 0.0468\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0475 - val_loss: 0.0642\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0505 - val_loss: 0.0494\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0568\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0380 - val_loss: 0.0406\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0295 - val_loss: 0.0436\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0275 - val_loss: 0.0309\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0226 - val_loss: 0.0349\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0224 - val_loss: 0.0263\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0206 - val_loss: 0.0335\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0227 - val_loss: 0.0275\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0234 - val_loss: 0.0382\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0279 - val_loss: 0.0323\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0295 - val_loss: 0.0447\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0345 - val_loss: 0.0352\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0447\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0354 - val_loss: 0.0313\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0371\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0304 - val_loss: 0.0231\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0268 - val_loss: 0.0281\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0320 - val_loss: 0.0234\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0516 - val_loss: 0.0454\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0789 - val_loss: 0.0244\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0564 - val_loss: 0.0132\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0074\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0157 - val_loss: 0.0068\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.0160\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0338 - val_loss: 0.0554\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0596 - val_loss: 0.0564\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0678 - val_loss: 0.0680\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0675 - val_loss: 0.0378\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0424 - val_loss: 0.0343\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0182\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0212 - val_loss: 0.0182\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 99us/step - loss: 0.0180 - val_loss: 0.0112\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0161 - val_loss: 0.0100\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0178 - val_loss: 0.0139\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0126\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0188\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0456 - val_loss: 0.0170\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0471 - val_loss: 0.0230\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0467 - val_loss: 0.0191\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0389 - val_loss: 0.0298\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0400 - val_loss: 0.0261\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0371 - val_loss: 0.0396\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0404 - val_loss: 0.0324\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0359 - val_loss: 0.0441\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0367 - val_loss: 0.0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0461\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0324 - val_loss: 0.0373\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0451\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0305 - val_loss: 0.0330\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0270 - val_loss: 0.0374\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0272 - val_loss: 0.0254\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0240 - val_loss: 0.0303\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0248 - val_loss: 0.0203\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0235 - val_loss: 0.0268\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0261 - val_loss: 0.0181\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0347 - val_loss: 0.0202\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0396 - val_loss: 0.0274\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0415 - val_loss: 0.0159\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0339 - val_loss: 0.0155\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0243 - val_loss: 0.0072\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0167 - val_loss: 0.0077\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0120 - val_loss: 0.0038\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0230 - val_loss: 0.0444\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0651 - val_loss: 0.1285\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.1497 - val_loss: 0.0903\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1083 - val_loss: 0.0672\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0666 - val_loss: 0.0231\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0253 - val_loss: 0.0164\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0141 - val_loss: 0.0074\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0152\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0099 - val_loss: 0.0227\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0167 - val_loss: 0.0522\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0328 - val_loss: 0.0721\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0516 - val_loss: 0.0945\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0672 - val_loss: 0.0628\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0539 - val_loss: 0.0573\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0457 - val_loss: 0.0316\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0297 - val_loss: 0.0323\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0262 - val_loss: 0.0261\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0272 - val_loss: 0.0365\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0446 - val_loss: 0.0324\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0571 - val_loss: 0.0289\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0596 - val_loss: 0.0153\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0398 - val_loss: 0.0144\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0298 - val_loss: 0.0087\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0207 - val_loss: 0.0126\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0189 - val_loss: 0.0101\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0180 - val_loss: 0.0183\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0216 - val_loss: 0.0179\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0250 - val_loss: 0.0317\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0326 - val_loss: 0.0310\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0358 - val_loss: 0.0463\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0419 - val_loss: 0.0397\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0382 - val_loss: 0.0509\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0394 - val_loss: 0.0410\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0329 - val_loss: 0.0488\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0330 - val_loss: 0.0387\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0281 - val_loss: 0.0439\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0284 - val_loss: 0.0334\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0249 - val_loss: 0.0375\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0237 - val_loss: 0.0330\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0239\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0261 - val_loss: 0.0305\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0310 - val_loss: 0.0217\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0349 - val_loss: 0.0308\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0441 - val_loss: 0.0220\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0230\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0372 - val_loss: 0.0112\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0250 - val_loss: 0.0096\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0160 - val_loss: 0.0044\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0082 - val_loss: 0.0055\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0109 - val_loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0233 - val_loss: 0.0421\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0596 - val_loss: 0.1048\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1211 - val_loss: 0.0791\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0949 - val_loss: 0.0638\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0650 - val_loss: 0.0244\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0279 - val_loss: 0.0176\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0082\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.0080\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0258 - val_loss: 0.0171\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0458 - val_loss: 0.0191\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0270\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0549 - val_loss: 0.0256\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0463 - val_loss: 0.0410\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0502 - val_loss: 0.0365\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0448 - val_loss: 0.0477\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0447 - val_loss: 0.0349\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0341 - val_loss: 0.0405\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0311 - val_loss: 0.0298\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0248 - val_loss: 0.0348\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0266\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0216 - val_loss: 0.0317\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0226 - val_loss: 0.0244\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.0301\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 131us/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0228 - val_loss: 0.0297\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0254 - val_loss: 0.0223\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 128us/step - loss: 0.0254 - val_loss: 0.0291\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0284 - val_loss: 0.0207\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0288 - val_loss: 0.0278\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0334 - val_loss: 0.0201\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0357 - val_loss: 0.0264\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0385 - val_loss: 0.0167\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0336 - val_loss: 0.0163\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0257 - val_loss: 0.0083\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0182 - val_loss: 0.0080\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0131 - val_loss: 0.0042\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0319\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0423 - val_loss: 0.0790\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.1024 - val_loss: 0.1248\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1371 - val_loss: 0.0567\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0640 - val_loss: 0.0382\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0363 - val_loss: 0.0153\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0071 - val_loss: 0.0123\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0098 - val_loss: 0.0260\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0168 - val_loss: 0.0405\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0287 - val_loss: 0.0722\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0484 - val_loss: 0.0695\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0542 - val_loss: 0.0725\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0561 - val_loss: 0.0435\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0394 - val_loss: 0.0404\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0327 - val_loss: 0.0267\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0249 - val_loss: 0.0320\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0299 - val_loss: 0.0320\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0413 - val_loss: 0.0363\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0590 - val_loss: 0.0221\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0497 - val_loss: 0.0186\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0410 - val_loss: 0.0105\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0265 - val_loss: 0.0117\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0212 - val_loss: 0.0084\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0171 - val_loss: 0.0131\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0244 - val_loss: 0.0226\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0286 - val_loss: 0.0368\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0367 - val_loss: 0.0355\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 0.0376 - val_loss: 0.0483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0410\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0359 - val_loss: 0.0497\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0362 - val_loss: 0.0404\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0302 - val_loss: 0.0456\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0302 - val_loss: 0.0352\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0257 - val_loss: 0.0375\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.0273\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0228 - val_loss: 0.0302\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0217\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0236 - val_loss: 0.0264\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0274 - val_loss: 0.0193\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0303 - val_loss: 0.0263\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0371 - val_loss: 0.0193\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0378 - val_loss: 0.0210\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0115\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0104\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0052\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0117 - val_loss: 0.0059\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.0033\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0135 - val_loss: 0.0256\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0267 - val_loss: 0.0597\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0667 - val_loss: 0.1295\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1228 - val_loss: 0.0910\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0859 - val_loss: 0.0790\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0682 - val_loss: 0.0407\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0430 - val_loss: 0.0291\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0365 - val_loss: 0.0141\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0250 - val_loss: 0.0112\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0214 - val_loss: 0.0070\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0170 - val_loss: 0.0072\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0160 - val_loss: 0.0056\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0145 - val_loss: 0.0072\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0155 - val_loss: 0.0067\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0163 - val_loss: 0.0107\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0241 - val_loss: 0.0217\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 343us/step - loss: 0.0333 - val_loss: 0.0250\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0401 - val_loss: 0.0398\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0512 - val_loss: 0.0345\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0471 - val_loss: 0.0407\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0461 - val_loss: 0.0273\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0332 - val_loss: 0.0288\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0288 - val_loss: 0.0202\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0216 - val_loss: 0.0242\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 187us/step - loss: 0.0205 - val_loss: 0.0220\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0188 - val_loss: 0.0334\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0227 - val_loss: 0.0395\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0560\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0375 - val_loss: 0.0458\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0370 - val_loss: 0.0449\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0369 - val_loss: 0.0276\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0294 - val_loss: 0.0275\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0221 - val_loss: 0.0191\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0216 - val_loss: 0.0126\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0211 - val_loss: 0.0174\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0241 - val_loss: 0.0134\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0265 - val_loss: 0.0174\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0117\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0251 - val_loss: 0.0116\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0201 - val_loss: 0.0067\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0156 - val_loss: 0.0064\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0132 - val_loss: 0.0183\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0269 - val_loss: 0.0509\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0692 - val_loss: 0.1125\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.1274 - val_loss: 0.0724\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0818 - val_loss: 0.0534\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0514 - val_loss: 0.0215\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0220 - val_loss: 0.0157\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0059 - val_loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.0211\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0314\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0225 - val_loss: 0.0562\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0380 - val_loss: 0.0602\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0468 - val_loss: 0.0683\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0530 - val_loss: 0.0457\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0409 - val_loss: 0.0432\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0355 - val_loss: 0.0289\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0265 - val_loss: 0.0330\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0296 - val_loss: 0.0324\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0384 - val_loss: 0.0374\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0560 - val_loss: 0.0232\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0488 - val_loss: 0.0192\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0416 - val_loss: 0.0107\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0267 - val_loss: 0.0111\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0211 - val_loss: 0.0077\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0112\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0251 - val_loss: 0.0318\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0333 - val_loss: 0.0327\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0360 - val_loss: 0.0457\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 0.0416 - val_loss: 0.0403\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 123us/step - loss: 0.0367 - val_loss: 0.0489\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0373 - val_loss: 0.0406\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0308 - val_loss: 0.0457\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0308 - val_loss: 0.0357\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0260 - val_loss: 0.0369\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0258 - val_loss: 0.0266\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0224 - val_loss: 0.0280\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0231 - val_loss: 0.0200\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0271 - val_loss: 0.0227\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0320 - val_loss: 0.0168\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.0185\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0288 - val_loss: 0.0110\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0220 - val_loss: 0.0106\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0163 - val_loss: 0.0059\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.0380\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0365 - val_loss: 0.0689\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0719 - val_loss: 0.1073\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0991 - val_loss: 0.0748\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0710 - val_loss: 0.0613\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0605 - val_loss: 0.0269\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.0177\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0266 - val_loss: 0.0086\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0182 - val_loss: 0.0074\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0162 - val_loss: 0.0052\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.0058\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.0051\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0142 - val_loss: 0.0068\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0159 - val_loss: 0.0070\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0222 - val_loss: 0.0140\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0272 - val_loss: 0.0262\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0385 - val_loss: 0.0308\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0454 - val_loss: 0.0457\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0547 - val_loss: 0.0367\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0448 - val_loss: 0.0399\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0403 - val_loss: 0.0273\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0278 - val_loss: 0.0298\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0243 - val_loss: 0.0249\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0199 - val_loss: 0.0325\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0324\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0234 - val_loss: 0.0401\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0281 - val_loss: 0.0323\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0274 - val_loss: 0.0337\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0287 - val_loss: 0.0233\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0227 - val_loss: 0.0203\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0232 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0223 - val_loss: 0.0185\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0241 - val_loss: 0.0174\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0227 - val_loss: 0.0144\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0205 - val_loss: 0.0100\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0165 - val_loss: 0.0223\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0224 - val_loss: 0.0335\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 93us/step - loss: 0.0364 - val_loss: 0.0681\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0639 - val_loss: 0.0753\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0739 - val_loss: 0.0857\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 95us/step - loss: 0.0806 - val_loss: 0.0483\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0533 - val_loss: 0.0338\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0415 - val_loss: 0.0146\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0241 - val_loss: 0.0108\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0187 - val_loss: 0.0060\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0138 - val_loss: 0.0061\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0129 - val_loss: 0.0047\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0122 - val_loss: 0.0060\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.0058\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0229 - val_loss: 0.0181\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0313 - val_loss: 0.0218\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0377 - val_loss: 0.0357\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0489 - val_loss: 0.0336\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0466 - val_loss: 0.0405\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0466 - val_loss: 0.0287\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0337 - val_loss: 0.0304\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0292 - val_loss: 0.0229\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0280\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0212 - val_loss: 0.0280\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0208 - val_loss: 0.0392\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0261 - val_loss: 0.0377\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0284 - val_loss: 0.0411\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0314 - val_loss: 0.0292\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0268 - val_loss: 0.0197\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0225 - val_loss: 0.0214\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0218 - val_loss: 0.0148\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0195 - val_loss: 0.0181\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0204 - val_loss: 0.0135\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0206 - val_loss: 0.0181\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0235 - val_loss: 0.0146\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0253 - val_loss: 0.0186\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0269 - val_loss: 0.0135\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 156us/step - loss: 0.0247 - val_loss: 0.0145\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0212 - val_loss: 0.0097\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 155us/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0205 - val_loss: 0.0339\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 0.0363 - val_loss: 0.0722\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0682 - val_loss: 0.0803\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0790 - val_loss: 0.0860\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0820 - val_loss: 0.0436\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0488 - val_loss: 0.0289\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0358 - val_loss: 0.0125\n",
      "0.026933351531624794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.71458894, -0.24896567, -0.1649349 ,  0.14206788,  0.34564862],\n",
       "        [ 0.32734793,  0.03354254, -0.43399936, -0.24522617, -0.0046199 ],\n",
       "        [-0.37366173,  0.08916539,  0.40448037, -0.34349647, -1.1836096 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.12872593, -0.4126139 , -0.21995746,  0.47616103, -0.2330058 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.08445498, -0.00715817,  0.20756647, -0.20227155, -0.21300034,\n",
       "          0.8139194 , -0.25034007,  0.19535618,  0.5497829 ,  0.19385365],\n",
       "        [ 0.33245674,  0.03375164,  0.29085335,  0.15033722,  0.350774  ,\n",
       "         -0.395077  , -0.01142964, -0.36585945, -0.2643435 , -0.59149694],\n",
       "        [ 0.14696895,  0.03544979,  0.47984785, -0.29932562, -0.27350557,\n",
       "         -0.05684932, -0.17854682, -0.50577176,  0.4026775 , -0.42308894],\n",
       "        [-0.8405634 , -0.66435444, -0.05299184,  0.29900095,  0.13477863,\n",
       "          0.44797152, -0.76723933,  0.10772793,  0.4661794 , -0.25249785],\n",
       "        [ 0.73105717,  0.79097736, -0.2864933 , -0.01704671, -0.10028996,\n",
       "         -0.53872895,  0.45026323, -0.2356144 ,  0.06167027,  0.25489157]],\n",
       "       dtype=float32),\n",
       " array([-0.47760227, -0.48037034, -0.46852913,  0.475621  , -0.44949806,\n",
       "         0.48671943, -0.48270392,  0.48011023,  0.4760885 ,  0.47262463],\n",
       "       dtype=float32),\n",
       " array([[-0.89787805],\n",
       "        [-0.7407538 ],\n",
       "        [-0.716872  ],\n",
       "        [ 0.40968597],\n",
       "        [-0.39961138],\n",
       "        [ 0.60102475],\n",
       "        [-0.9415163 ],\n",
       "        [ 0.9462012 ],\n",
       "        [ 0.4582981 ],\n",
       "        [ 0.80258906]], dtype=float32),\n",
       " array([0.5004554], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, RMSprop, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_rmsprop_2nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
