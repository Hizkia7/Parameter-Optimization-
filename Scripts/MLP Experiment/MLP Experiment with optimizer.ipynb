{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Dataset\n",
    "#Airfoil Self-Noise\n",
    "df_airfoil=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Airfoil_self_noise.csv')\n",
    "\n",
    "#Automobile\n",
    "df_automobile=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Automobile_data.txt')\n",
    "\n",
    "#Autompg\n",
    "df_autompg=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Auto-mpg.csv')\n",
    "\n",
    "#ChallengerUSA\n",
    "df_challenger=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Challenger USA Space Shuttle O-Ring.csv')\n",
    "\n",
    "#Combine Cycle Power\n",
    "df_combine=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Combine Cycle Power Plant.csv')\n",
    "\n",
    "#Computer Hardware\n",
    "df_computer=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Computer Hardware.csv')\n",
    "\n",
    "#Concrete Compressive Strength\n",
    "df_concrete_compressive_strength=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Compressive Strength.csv')\n",
    "\n",
    "#Concrete Slump Test\n",
    "df_concrete1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "df_concrete3=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Concrete Slump Test.csv')\n",
    "\n",
    "#Energy Efficiency\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "\n",
    "#Fertility Diagnosis\n",
    "df_fertility=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\fertility_Diagnosis.csv')\n",
    "\n",
    "#Forest Fires\n",
    "df_forest=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\forestfires.csv')\n",
    "\n",
    "#Housing\n",
    "df_housing=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Housing.csv')\n",
    "\n",
    "#Istanbul Stock Exchange\n",
    "df_istanbul=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Istanbul Stock Exchange.csv')\n",
    "\n",
    "#WDBC\n",
    "df_wdbc=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\wdbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#remove Nan columns of df_energy1\n",
    "df_energy1=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy1.drop(df_energy1.columns[11],inplace=True, axis = 1)\n",
    "df_energy1.drop(df_energy1.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove Nan columns of df_energy2\n",
    "df_energy2=pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\Datasets\\\\Energy Efficiency.csv')\n",
    "df_energy2.drop(df_energy2.columns[11],inplace=True, axis = 1)\n",
    "df_energy2.drop(df_energy2.columns[10],inplace=True, axis = 1)\n",
    "\n",
    "#remove question marks\n",
    "#df_automobile\n",
    "imp= Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "df_automobile=df_automobile.replace(\"?\", np.NaN)\n",
    "df_automobile['num-of-doors'] = df_automobile['num-of-doors'].fillna(\"four\")\n",
    "for i in df_automobile.columns:\n",
    "    if df_automobile[i].isnull().sum()>0:\n",
    "        df_automobile[i]=imp.fit_transform(df_automobile[[i]])\n",
    "#df_automobile = df_automobile[(df_automobile.astype(str) != '?').all(axis=1)]\n",
    "#df_automobile.reset_index(drop=True, inplace=True)\n",
    "df_automobile = df_automobile.drop(['engine-location'], axis=1)\n",
    "#df_autompg\n",
    "df_autompg = df_autompg[(df_autompg.astype(str) != '?').all(axis=1)]\n",
    "df_autompg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#convert string to number\n",
    "le=LabelEncoder()\n",
    "#df_automobile\n",
    "string_automobile=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=string_automobile.apply(le.fit_transform)\n",
    "encoder=df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']].astype(np.int64)\n",
    "df_automobile[['make','fuel-type','aspiration','num-of-doors', 'body-style', 'drive-wheels', 'engine-type', 'num-of-cylinders', 'fuel-system']]=encoder\n",
    "a=df_automobile[['normalized-losses','horsepower','price']].astype(np.int64)\n",
    "b=df_automobile[['bore','stroke','peak-rpm']].astype(float)\n",
    "df_automobile[['normalized-losses','horsepower','price']]=a\n",
    "df_automobile[['bore','stroke','peak-rpm']]=b\n",
    "#df_computer\n",
    "string_computer=df_computer[['Vendor','Model']]\n",
    "df_computer[['Vendor','Model']]=string_computer.apply(le.fit_transform)\n",
    "df_computer[['Vendor','Model']]=df_computer[['Vendor','Model']].astype(np.int64)\n",
    "\n",
    "#dropna spesific column & special preprocessing\n",
    "#df_forest\n",
    "df_forest=df_forest[(df_forest['area'].astype(int) != 0)] \n",
    "df_forest.reset_index(drop=True, inplace=True)\n",
    "num_features=10\n",
    "dimension=(num_features+1)*9+10\n",
    "population_size=(2*dimension+1)*2\n",
    "df_forest=df_forest[:population_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data1(df,num_features):\n",
    "    dimension=(num_features+1)*9+10\n",
    "    population_size=(2*dimension+1)*2\n",
    "    df=df.dropna()\n",
    "    df=df[:population_size]\n",
    "    df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df):\n",
    "    cor=df.corr()\n",
    "    plt.figure(figsize=(100,50))\n",
    "    sns.set(font_scale=3)\n",
    "    sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split1(x, y):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data2(df):\n",
    "    train_size = 0.85*len(df)\n",
    "    train_size = int(train_size)\n",
    "    df_train = df[:train_size]\n",
    "    df_test = df[train_size:]\n",
    "    print(len(df_test))\n",
    "    print(len(df_train))\n",
    "    validation_size=len(df_test)/len(df_train)\n",
    "    print(validation_size)\n",
    "    return df_train, df_test, validation_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#df_airfoil=preprocessing_data1(df_airfoil,5)\n",
    "#df_automobile=preprocessing_data1(df_automobile,22)\n",
    "#df_autompg=preprocessing_data1(df_autompg,7)\n",
    "#df_challenger=preprocessing_data1(df_challenger,3)\n",
    "#df_combine=preprocessing_data1(df_combine,4)\n",
    "#df_computer=preprocessing_data1(df_computer,9)\n",
    "#df_concrete_compressive_strength=preprocessing_data1(df_concrete_compressive_strength,8)\n",
    "#df_concrete1=preprocessing_data1(df_concrete1,7)\n",
    "#df_concrete2=preprocessing_data1(df_concrete2,7)\n",
    "#df_concrete3=preprocessing_data1(df_concrete3,7)\n",
    "#df_energy1=preprocessing_data1(df_energy1,8)\n",
    "#df_energy2=preprocessing_data1(df_energy2,8)\n",
    "\n",
    "#df_fertility=preprocessing_data1(df_fertility,9)\n",
    "for i in df_fertility:\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'N'] = 1\n",
    "    df_fertility.Diagnosis[df_fertility.Diagnosis == 'O'] = 2\n",
    "df_fertility['Diagnosis']=df_fertility['Diagnosis'].astype(np.int64)\n",
    "\n",
    "#df_forest=preprocessing_data1(df_forest,10)\n",
    "#df_housing=preprocessing_data1(df_housing,13)\n",
    "\n",
    "#df_istanbul=preprocessing_data1(df_istanbul,7)\n",
    "new_header = df_istanbul.iloc[0]\n",
    "df_istanbul = df_istanbul[1:]\n",
    "df_istanbul.columns = new_header\n",
    "df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']]=df_istanbul[['ISE1','ISE2','SP','DAX','FTSE','NIKKEI','BOVESPA','EU','EM']].astype(np.float64)\n",
    "\n",
    "\n",
    "#df_wdbc=preprocessing_data1(df_wdbc,10)\n",
    "df_wdbc.drop(df_wdbc.columns[0], axis=1, inplace = True)\n",
    "df_wdbc.columns=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "for i in df_wdbc:\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'M'] = 1\n",
    "    df_wdbc.diagnosis[df_wdbc.diagnosis == 'B'] = 2\n",
    "df_wdbc['diagnosis']=df_wdbc['diagnosis'].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency  Angle of Attack  Chord length  Free-stream velocity  \\\n",
      "0        800              0.0        0.3048                  71.3   \n",
      "1       1000              0.0        0.3048                  71.3   \n",
      "2       1250              0.0        0.3048                  71.3   \n",
      "3       1600              0.0        0.3048                  71.3   \n",
      "4       2000              0.0        0.3048                  71.3   \n",
      "\n",
      "   Suction side displacement thickness  Scaled sound pressure level  \n",
      "0                             0.002663                      126.201  \n",
      "1                             0.002663                      125.201  \n",
      "2                             0.002663                      125.951  \n",
      "3                             0.002663                      127.591  \n",
      "4                             0.002663                      127.461  \n",
      "    Mpg  Cylinders  Displacement Horsepower  Weight  Acceleration  Model Year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   Origin                   Car Name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "   symboling  normalized-losses  make  fuel-type  aspiration  num-of-doors  \\\n",
      "0          3                122     0          1           0             1   \n",
      "1          3                122     0          1           0             1   \n",
      "2          1                122     0          1           0             1   \n",
      "3          2                164     1          1           0             0   \n",
      "4          2                164     1          1           0             0   \n",
      "\n",
      "   body-style  drive-wheels  wheel-base  length  ...  engine-size  \\\n",
      "0           0             2        88.6   168.8  ...          130   \n",
      "1           0             2        88.6   168.8  ...          130   \n",
      "2           2             2        94.5   171.2  ...          152   \n",
      "3           3             1        99.8   176.6  ...          109   \n",
      "4           3             0        99.4   176.6  ...          136   \n",
      "\n",
      "   fuel-system  bore  stroke  compression-ratio  horsepower  peak-rpm  \\\n",
      "0            5  3.47    2.68                9.0         111    5000.0   \n",
      "1            5  3.47    2.68                9.0         111    5000.0   \n",
      "2            5  2.68    3.47                9.0         154    5000.0   \n",
      "3            5  3.19    3.40               10.0         102    5500.0   \n",
      "4            5  3.19    3.40                8.0         115    5500.0   \n",
      "\n",
      "   city-mpg  highway-mpg  price  \n",
      "0        21           27  13495  \n",
      "1        21           27  16500  \n",
      "2        19           26  16500  \n",
      "3        24           30  13950  \n",
      "4        18           22  17450  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Number of O-rings  Thermal Distress  Launch Temperature  \\\n",
      "0                  6                 0                  66   \n",
      "1                  6                 1                  70   \n",
      "2                  6                 0                  69   \n",
      "3                  6                 0                  68   \n",
      "4                  6                 0                  67   \n",
      "\n",
      "   Leak-Check Pressure  Temporal Order of Flight  \n",
      "0                   50                         1  \n",
      "1                   50                         2  \n",
      "2                   50                         3  \n",
      "3                   50                         4  \n",
      "4                   50                         5  \n"
     ]
    }
   ],
   "source": [
    "print(df_airfoil.head())\n",
    "print(df_autompg.head())\n",
    "print(df_automobile.head())\n",
    "print(df_challenger.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Train and Test 17 datasets\n",
    "#Airfoil\n",
    "x_airfoil = df_airfoil.drop(['Scaled sound pressure level'], axis = 1)\n",
    "y_airfoil = df_airfoil['Scaled sound pressure level']\n",
    "#Wdbc\n",
    "x_wdbc = df_wdbc[['radius_mean','perimeter_mean','area_mean','concavity_mean','concave points_mean','radius_worst','perimeter_worst','area_worst','concave points_worst']]\n",
    "y_wdbc = df_wdbc['diagnosis']\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_wdbc = labelencoder_Y.fit_transform(y_wdbc)\n",
    "#Automobile\n",
    "x_automobile = df_automobile.drop(['price','make','body-style'], axis = 1)\n",
    "y_automobile = df_automobile['price']\n",
    "y_automobile = np.reshape(y_automobile.values, (-1,1))\n",
    "#Autompg\n",
    "x_autompg = df_autompg.drop(['Mpg','Car Name'], axis = 1)\n",
    "y_autompg = df_autompg['Mpg']\n",
    "#Challenger\n",
    "x_challenger = df_challenger.drop(['Number of O-rings','Temporal Order of Flight'], axis = 1)\n",
    "y_challenger = df_challenger['Number of O-rings']\n",
    "#Combine\n",
    "x_combine = df_combine.drop(['PE'], axis = 1)\n",
    "y_combine = df_combine['PE']\n",
    "y_combine = np.reshape(y_combine.values, (-1,1))\n",
    "#Computer\n",
    "x_computer = df_computer.drop(['ERP'], axis = 1)\n",
    "y_computer = df_computer['ERP']\n",
    "y_computer = np.reshape(y_computer.values, (-1,1))\n",
    "#Concrete_compressive_strength\n",
    "x_concrete_compressive_strength = df_concrete_compressive_strength.drop(['CCS'], axis = 1)\n",
    "y_concrete_compressive_strength = df_concrete_compressive_strength['CCS']\n",
    "y_concrete_compressive_strength = np.reshape(y_concrete_compressive_strength.values, (-1,1))\n",
    "#Concrete1\n",
    "x_concrete1 = df_concrete1.drop(['No','Compressive Strength (28-day)(Mpa)'], axis = 1)\n",
    "y_concrete1 = df_concrete1['Compressive Strength (28-day)(Mpa)']\n",
    "#Concrete2\n",
    "x_concrete2 = df_concrete2.drop(['No','SLUMP(cm)'], axis = 1)\n",
    "y_concrete2 = df_concrete2['SLUMP(cm)']\n",
    "y_concrete2 = np.reshape(y_concrete2.values, (-1,1))\n",
    "#Concrete3\n",
    "x_concrete3 = df_concrete3.drop(['No','FLOW(cm)'], axis = 1)\n",
    "y_concrete3 = df_concrete3['FLOW(cm)']\n",
    "y_concrete3 = np.reshape(y_concrete3.values, (-1,1))\n",
    "#Energy1\n",
    "x_energy1 = df_energy1.drop(['Y1'], axis = 1)\n",
    "y_energy1 = df_energy1['Y1']\n",
    "#Energy2\n",
    "x_energy2 = df_energy2.drop(['Y2'], axis = 1)\n",
    "y_energy2 = df_energy2['Y2']\n",
    "#Fertility\n",
    "x_fertility = df_fertility.drop(['Diagnosis'], axis = 1)\n",
    "y_fertility = df_fertility['Diagnosis']\n",
    "#Forest\n",
    "x_forest = df_forest.drop(['month','day','area'], axis = 1)\n",
    "y_forest = df_forest['area']\n",
    "y_forest = np.reshape(y_forest.values, (-1,1))\n",
    "#Housing\n",
    "x_housing = df_housing.drop(['MEDV'], axis = 1)\n",
    "y_housing = df_housing['MEDV']\n",
    "#Istanbul\n",
    "x_istanbul = df_istanbul.drop(['date','ISE1','ISE2'], axis = 1)\n",
    "y_istanbul = df_istanbul[['ISE1','ISE2']]\n",
    "y_istanbul['mean'] = y_istanbul.mean(axis=1)\n",
    "y_istanbul = y_istanbul['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_airfoil, x_test_airfoil, y_train_airfoil, y_test_airfoil = train_test_split1(x_airfoil, y_airfoil)\n",
    "x_train_automobile, x_test_automobile, y_train_automobile, y_test_automobile = train_test_split1(x_automobile, y_automobile)\n",
    "x_train_autompg, x_test_autompg, y_train_autompg, y_test_autompg = train_test_split1(x_autompg, y_autompg)\n",
    "x_train_challenger, x_test_challenger, y_train_challenger, y_test_challenger = train_test_split1(x_challenger, y_challenger)\n",
    "x_train_combine, x_test_combine, y_train_combine, y_test_combine = train_test_split1(x_combine, y_combine)\n",
    "x_train_computer, x_test_computer, y_train_computer, y_test_computer = train_test_split1(x_computer, y_computer)\n",
    "x_train_concrete_compressive_strength, x_test_concrete_compressive_strength, y_train_concrete_compressive_strength, y_test_concrete_compressive_strength = train_test_split1(x_concrete_compressive_strength, y_concrete_compressive_strength)\n",
    "x_train_concrete1, x_test_concrete1, y_train_concrete1, y_test_concrete1 = train_test_split1(x_concrete1, y_concrete1)\n",
    "x_train_concrete2, x_test_concrete2, y_train_concrete2, y_test_concrete2 = train_test_split1(x_concrete2, y_concrete2)\n",
    "x_train_concrete3, x_test_concrete3, y_train_concrete3, y_test_concrete3 = train_test_split1(x_concrete3, y_concrete3)\n",
    "x_train_energy1, x_test_energy1, y_train_energy1, y_test_energy1 = train_test_split1(x_energy1, y_energy1)\n",
    "x_train_energy2, x_test_energy2, y_train_energy2, y_test_energy2 = train_test_split1(x_energy2, y_energy2)\n",
    "x_train_fertility, x_test_fertility, y_train_fertility, y_test_fertility = train_test_split1(x_fertility, y_fertility)\n",
    "x_train_forest, x_test_forest, y_train_forest, y_test_forest = train_test_split1(x_forest, y_forest)\n",
    "x_train_housing, x_test_housing, y_train_housing, y_test_housing = train_test_split1(x_housing, y_housing)\n",
    "x_train_istanbul, x_test_istanbul, y_train_istanbul, y_test_istanbul = train_test_split1(x_istanbul, y_istanbul)\n",
    "x_train_wdbc, x_test_wdbc, y_train_wdbc, y_test_wdbc = train_test_split1(x_wdbc, y_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(x_train, y_train):\n",
    "    X_train, X_val, Y_train, Y_val= train_test_split(x_train, y_train, test_size=0.176, random_state=42)\n",
    "    return X_train, X_val, Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X_train, X_val, x_test):\n",
    "    sc=StandardScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=sc.fit(X_train)\n",
    "    #X_scale_val=sc.fit(X_val)\n",
    "    #x_scale_test=sc.fit(x_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    return X_train, X_val, x_test, X_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler_automobile(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    minmax_x=MinMaxScaler()\n",
    "    minmax_y=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=minmax_x.fit(X_train)\n",
    "    #X_scale_val=min_max.fit(X_val)\n",
    "    #x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=minmax_y.fit(Y_train)\n",
    "    #Y_scale_val=min_max.fit(Y_val)\n",
    "    #y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_train.transform(X_val)\n",
    "    x_test=X_scale_train.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=Y_scale_train.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, X_scale_train, Y_scale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    min_max=MinMaxScaler()\n",
    "    X_train=X_train.values\n",
    "    X_val=X_val.values\n",
    "    x_test=x_test.values\n",
    "    X_scale_train=min_max.fit(X_train)\n",
    "    X_scale_val=min_max.fit(X_val)\n",
    "    x_scale_test=min_max.fit(x_test)\n",
    "    Y_scale_train=min_max.fit(Y_train)\n",
    "    Y_scale_val=min_max.fit(Y_val)\n",
    "    y_scale_test=min_max.fit(y_test)\n",
    "    X_train=X_scale_train.transform(X_train)\n",
    "    X_val=X_scale_val.transform(X_val)\n",
    "    x_test=x_scale_test.transform(x_test)\n",
    "    Y_train=Y_scale_train.transform(Y_train)\n",
    "    Y_val=Y_scale_train.transform(Y_val)\n",
    "    y_test=y_scale_test.transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test, min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train, X_val, x_test, Y_train, Y_val, y_test):\n",
    "    normalizer=Normalizer()\n",
    "    X_train=normalizer.fit_transform(X_train)\n",
    "    X_val=normalizer.fit_transform(X_val)\n",
    "    x_test=normalizer.fit_transform(x_test)\n",
    "    Y_train=normalizer.fit_transform(Y_train)\n",
    "    Y_val=normalizer.fit_transform(Y_val)\n",
    "    y_test=normalizer.fit_transform(y_test)\n",
    "    return X_train, X_val, x_test, Y_train, Y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer list\n",
    "adam0 = optimizers.Adam(lr=0.1)\n",
    "adam1 = optimizers.Adam(lr=0.001)\n",
    "adam2 = optimizers.Adam(lr=0.01)\n",
    "adam3 = optimizers.Adam(lr=0.0001)\n",
    "adam4 = optimizers.Adam(lr=0.00001)\n",
    "sgd = optimizers.SGD(lr=0.00001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "RMSprop= optimizers.RMSprop(lr=0.01,rho=0.9)\n",
    "adagrad = optimizers.Adagrad(lr=0.01)\n",
    "adadelta = optimizers.Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model_structure_regression(X_train, X_val, Y_train, Y_val, adam, size, epochs, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 5, input_dim = (X_train.shape[1])))\n",
    "    model.add(Activation('tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = adam , loss = 'mse')\n",
    "    model.summary()\n",
    "    history=model.fit(X_train,Y_train, batch_size=size,epochs=epochs, validation_data=(X_val, Y_val), shuffle=True)\n",
    "    evaluate = model.evaluate(x_test, y_test, verbose=2, batch_size=size)\n",
    "    print(evaluate)\n",
    "    return model, history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil = train_val_split(x_train_airfoil, y_train_airfoil)\n",
    "X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile = train_val_split(x_train_automobile, y_train_automobile)\n",
    "X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg = train_val_split(x_train_autompg, y_train_autompg)\n",
    "X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger = train_val_split(x_train_challenger, y_train_challenger)\n",
    "X_train_combine, X_val_combine, Y_train_combine, Y_val_combine = train_val_split(x_train_combine, y_train_combine)\n",
    "X_train_computer, X_val_computer, Y_train_computer, Y_val_computer = train_val_split(x_train_computer, y_train_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength = train_val_split(x_train_concrete_compressive_strength, y_train_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, Y_train_concrete1, Y_val_concrete1 = train_val_split(x_train_concrete1, y_train_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, Y_train_concrete2, Y_val_concrete2 = train_val_split(x_train_concrete2, y_train_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, Y_train_concrete3, Y_val_concrete3 = train_val_split(x_train_concrete3, y_train_concrete3)\n",
    "X_train_energy1, X_val_energy1, Y_train_energy1, Y_val_energy1 = train_val_split(x_train_energy1, y_train_energy1)\n",
    "X_train_energy2, X_val_energy2, Y_train_energy2, Y_val_energy2 = train_val_split(x_train_energy2, y_train_energy2)\n",
    "X_train_fertility, X_val_fertility, Y_train_fertility, Y_val_fertility = train_val_split(x_train_fertility, y_train_fertility)\n",
    "X_train_forest, X_val_forest, Y_train_forest, Y_val_forest = train_val_split(x_train_forest, y_train_forest)\n",
    "X_train_housing, X_val_housing, Y_train_housing, Y_val_housing = train_val_split(x_train_housing, y_train_housing)\n",
    "X_train_istanbul, X_val_istanbul, Y_train_istanbul, Y_val_istanbul = train_val_split(x_train_istanbul, y_train_istanbul)\n",
    "X_train_wdbc, X_val_wdbc, Y_train_wdbc, Y_val_wdbc = train_val_split(x_train_wdbc, y_train_wdbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_airfoil, X_val_airfoil, x_test_airfoil, X_scale_train_airfoil=standard_scaler(X_train_airfoil, X_val_airfoil, x_test_airfoil)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile=standard_scaler(X_train_automobile, X_val_automobile, x_test_automobile)\n",
    "#X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile = normalization(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile, X_scale_train_automobile, Y_scale_train_automobile=min_max_scaler_automobile(X_train_automobile, X_val_automobile, x_test_automobile, Y_train_automobile, Y_val_automobile, y_test_automobile)\n",
    "X_train_autompg, X_val_autompg, x_test_autompg, X_scale_train_autompg=standard_scaler(X_train_autompg, X_val_autompg, x_test_autompg)\n",
    "X_train_challenger, X_val_challenger, x_test_challenger, X_scale_train_challenger=standard_scaler(X_train_challenger, X_val_challenger, x_test_challenger)\n",
    "X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine, min_max_combine=min_max_scaler(X_train_combine, X_val_combine, x_test_combine, Y_train_combine, Y_val_combine, y_test_combine)\n",
    "X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer, min_max_computer=min_max_scaler(X_train_computer, X_val_computer, x_test_computer, Y_train_computer, Y_val_computer, y_test_computer)\n",
    "X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength, min_max_concrete_compressive_strength=min_max_scaler(X_train_concrete_compressive_strength, X_val_concrete_compressive_strength, x_test_concrete_compressive_strength, Y_train_concrete_compressive_strength, Y_val_concrete_compressive_strength, y_test_concrete_compressive_strength)\n",
    "X_train_concrete1, X_val_concrete1, x_test_concrete1, X_scale_train_concrete1=standard_scaler(X_train_concrete1, X_val_concrete1, x_test_concrete1)\n",
    "X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2, min_max_concrete2=min_max_scaler(X_train_concrete2, X_val_concrete2, x_test_concrete2, Y_train_concrete2, Y_val_concrete2, y_test_concrete2)\n",
    "X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3, min_max_concrete3=min_max_scaler(X_train_concrete3, X_val_concrete3, x_test_concrete3, Y_train_concrete3, Y_val_concrete3, y_test_concrete3)\n",
    "X_train_energy1, X_val_energy1, x_test_energy1, X_scale_train_energy1=standard_scaler(X_train_energy1, X_val_energy1, x_test_energy1)\n",
    "X_train_energy2, X_val_energy2, x_test_energy2, X_scale_train_energy2=standard_scaler(X_train_energy2, X_val_energy2, x_test_energy2)\n",
    "X_train_fertility, X_val_fertility, x_test_fertility, X_scale_train_fertility=standard_scaler(X_train_fertility, X_val_fertility, x_test_fertility)\n",
    "X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest, min_max_forest=min_max_scaler(X_train_forest, X_val_forest, x_test_forest, Y_train_forest, Y_val_forest, y_test_forest)\n",
    "X_train_housing, X_val_housing, x_test_housing, X_scale_train_housing=standard_scaler(X_train_housing, X_val_housing, x_test_housing)\n",
    "X_train_istanbul, X_val_istanbul, x_test_istanbul, X_scale_train_istanbul=standard_scaler(X_train_istanbul, X_val_istanbul, x_test_istanbul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 403us/step - loss: 15282.0949 - val_loss: 14668.9620\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 12495.1824 - val_loss: 8892.6694\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 4537.9594 - val_loss: 861.3208\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 179.4921 - val_loss: 45.2984\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 32.9359 - val_loss: 26.5034\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 24.1140 - val_loss: 25.9085\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.8487 - val_loss: 25.8731\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.3857 - val_loss: 26.1756\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1321 - val_loss: 26.2760\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.0949 - val_loss: 26.6455\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.1436 - val_loss: 26.4088\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1183 - val_loss: 26.1237\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1414 - val_loss: 26.8868\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9683 - val_loss: 26.4061\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9559 - val_loss: 26.6032\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.9177 - val_loss: 26.2737\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.8672 - val_loss: 26.2189\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9621 - val_loss: 26.8734\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.0685 - val_loss: 26.0450\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8474 - val_loss: 26.4599\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 21.8758 - val_loss: 25.9933\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0421 - val_loss: 25.8401\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9461 - val_loss: 26.4321\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.6853 - val_loss: 26.3486\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.5201 - val_loss: 27.3516\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 21.7784 - val_loss: 26.2183\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.7874 - val_loss: 25.9970\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.6947 - val_loss: 25.8328\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9210 - val_loss: 26.2630\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9454 - val_loss: 26.0462\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.5736 - val_loss: 25.8033\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.6195 - val_loss: 26.6139\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6784 - val_loss: 25.9208\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6179 - val_loss: 25.7115\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7833 - val_loss: 26.1275\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8258 - val_loss: 25.7353\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0430 - val_loss: 25.4946\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 21.36 - 0s 87us/step - loss: 21.9399 - val_loss: 26.0581\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.7370 - val_loss: 26.3536\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8475 - val_loss: 25.5276\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8110 - val_loss: 25.9884\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 21.7801 - val_loss: 26.8218\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0702 - val_loss: 27.7204\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7288 - val_loss: 25.8894\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.5554 - val_loss: 25.4315\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.0016 - val_loss: 26.5833\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3024 - val_loss: 25.8970\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.3537 - val_loss: 26.5213\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.8931 - val_loss: 26.8754\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6639 - val_loss: 25.7014\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.1231 - val_loss: 26.7520\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.4557 - val_loss: 25.8794\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.9996 - val_loss: 25.4451\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7944 - val_loss: 25.8140\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.9332 - val_loss: 27.6041\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8088 - val_loss: 26.9580\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0761 - val_loss: 25.9263\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5909 - val_loss: 25.6721\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8977 - val_loss: 25.4738\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.0129 - val_loss: 26.4216\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7832 - val_loss: 25.5328\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1187 - val_loss: 25.4030\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6358 - val_loss: 26.4243\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.3132 - val_loss: 26.1282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 22.2638 - val_loss: 26.8399\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.5665 - val_loss: 25.2136\n",
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.8354 - val_loss: 26.5113\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.5556 - val_loss: 25.5833\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8314 - val_loss: 26.8919\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6991 - val_loss: 25.5913\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8823 - val_loss: 25.7007\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7511 - val_loss: 26.1961\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8480 - val_loss: 25.4613\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.8842 - val_loss: 26.1350\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.8577 - val_loss: 27.0992\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.4338 - val_loss: 25.4607\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.0715 - val_loss: 27.1172\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 22.1829 - val_loss: 25.9801\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8615 - val_loss: 25.6567\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0653 - val_loss: 27.1223\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.1608 - val_loss: 26.3157\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1727 - val_loss: 25.2338\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.7648 - val_loss: 25.8760\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8012 - val_loss: 26.1206\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.3383 - val_loss: 26.9432\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0991 - val_loss: 25.7459\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.3040 - val_loss: 25.7538\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.7188 - val_loss: 26.5588\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.9293 - val_loss: 25.1990\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6948 - val_loss: 25.6099\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 22.0731 - val_loss: 26.7860\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.5165 - val_loss: 25.7748\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 22.0294 - val_loss: 26.7694\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 22.4599 - val_loss: 27.3109\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0330 - val_loss: 26.9702\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.9757 - val_loss: 25.8410\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.8935 - val_loss: 27.0036\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 24.0351 - val_loss: 28.1653\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6394 - val_loss: 27.1840\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.2082 - val_loss: 25.7315\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.1540 - val_loss: 27.0424\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.6072 - val_loss: 25.2957\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.0520 - val_loss: 25.4897\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 22.5685 - val_loss: 27.3829\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.8049 - val_loss: 26.0992\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.0179 - val_loss: 25.7596\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 22.7264 - val_loss: 26.9110\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.6187 - val_loss: 26.3892\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.2563 - val_loss: 25.6162\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.6036 - val_loss: 25.4097\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6448 - val_loss: 25.7200\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.2486 - val_loss: 26.0257\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.5645 - val_loss: 27.6493\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.4096 - val_loss: 25.1816\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6831 - val_loss: 25.5842\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.1181 - val_loss: 26.3277\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 21.6379 - val_loss: 25.6514\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.1133 - val_loss: 25.9025\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9818 - val_loss: 26.0974\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.8872 - val_loss: 25.3173\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5882 - val_loss: 25.3149\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 22.4451 - val_loss: 27.6219\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.6999 - val_loss: 26.2626\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.5692 - val_loss: 25.6742\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.9488 - val_loss: 25.1491\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6824 - val_loss: 25.9336\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 21.8076 - val_loss: 25.3956\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 21.8253 - val_loss: 25.5949\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 21.7839 - val_loss: 25.9427\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 21.8955 - val_loss: 26.3041\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 22.5013 - val_loss: 26.5792\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 22.8037 - val_loss: 27.1282\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 22.0331 - val_loss: 25.8124\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 21.9595 - val_loss: 25.4275\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 22.4869 - val_loss: 25.0242\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.1076 - val_loss: 25.1964\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.6683 - val_loss: 27.2185\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 22.0467 - val_loss: 28.6804\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 22.7477 - val_loss: 27.3824\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 21.6081 - val_loss: 25.0833\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 21.1935 - val_loss: 25.3275\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 23.0800 - val_loss: 30.2739\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 22.5418 - val_loss: 25.9273\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.7971 - val_loss: 27.7588\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.7746 - val_loss: 24.8882\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.2599 - val_loss: 25.6750\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.5458 - val_loss: 25.5031\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.3402 - val_loss: 26.0182\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.6422 - val_loss: 25.1323\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 21.3701 - val_loss: 24.8578\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.1730 - val_loss: 25.1098\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 21.2726 - val_loss: 24.4398\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 21.5313 - val_loss: 28.3708\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.2700 - val_loss: 24.4949\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 21.1741 - val_loss: 25.3913\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 20.6773 - val_loss: 25.4189\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.6346 - val_loss: 23.9719\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 20.3673 - val_loss: 24.0976\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.7105 - val_loss: 26.8182\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 20.2631 - val_loss: 23.7679\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 20.3133 - val_loss: 24.1384\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 19.9734 - val_loss: 23.9719\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.7194 - val_loss: 24.4264\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.6404 - val_loss: 23.6470\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 20.2130 - val_loss: 26.5632\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 19.7016 - val_loss: 24.0813\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 19.6310 - val_loss: 24.4420\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 19.3799 - val_loss: 22.4849\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 19.0000 - val_loss: 23.8267\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 19.1871 - val_loss: 23.5589\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.7095 - val_loss: 21.9442\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.2234 - val_loss: 24.0932\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 18.5884 - val_loss: 22.0562\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.1593 - val_loss: 22.4331\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 18.5835 - val_loss: 21.7680\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.9694 - val_loss: 21.4912\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 18.0090 - val_loss: 20.6867\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 18.2895 - val_loss: 20.8394\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.6554 - val_loss: 21.1815\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.5339 - val_loss: 21.6603\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 17.6025 - val_loss: 23.9577\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 18.5303 - val_loss: 20.7792\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.9083 - val_loss: 21.6009\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 17.3879 - val_loss: 20.0249\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.2376 - val_loss: 19.2344\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6399 - val_loss: 21.0109\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 17.1669 - val_loss: 20.7778\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.5548 - val_loss: 19.6256\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.6607 - val_loss: 20.0159\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.8463 - val_loss: 18.8098\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.7074 - val_loss: 19.9313\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.4216 - val_loss: 21.5066\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 17.2808 - val_loss: 18.8909\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.6018 - val_loss: 19.8224\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.2522 - val_loss: 19.8449\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 16.4758 - val_loss: 19.6320\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.3005 - val_loss: 19.1114\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1149 - val_loss: 20.2765\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 16.5635 - val_loss: 18.7788\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.5749 - val_loss: 19.2141\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1117 - val_loss: 18.8374\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.1236 - val_loss: 18.0254\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 17.0440 - val_loss: 18.8054\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.9400 - val_loss: 18.1528\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 16.4710 - val_loss: 18.0554\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.3803 - val_loss: 18.9958\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.8745 - val_loss: 18.6003\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.6824 - val_loss: 18.9341\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 16.1438 - val_loss: 17.5715\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4928 - val_loss: 19.2142\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 16.3881 - val_loss: 18.7956\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 15.3603 - val_loss: 18.9874\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.4903 - val_loss: 17.9216\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.6025 - val_loss: 18.7863\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 91us/step - loss: 16.1573 - val_loss: 18.7234\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4456 - val_loss: 18.3364\n",
      "Epoch 217/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8639 - val_loss: 18.5325\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.1995 - val_loss: 17.2437\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.8773 - val_loss: 17.9720\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 14.9519 - val_loss: 17.2121\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.2752 - val_loss: 17.9957\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.5759 - val_loss: 16.8675\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5442 - val_loss: 18.0699\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.1031 - val_loss: 23.1391\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 17.7914 - val_loss: 17.6386\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.8502 - val_loss: 18.6086\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.9387 - val_loss: 19.2063\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.3766 - val_loss: 17.6017\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 15.2597 - val_loss: 19.5523\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.8504 - val_loss: 19.5106\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4636 - val_loss: 17.2377\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.7302 - val_loss: 17.7780\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 14.3112 - val_loss: 17.6205\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.1380 - val_loss: 18.1192\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0767 - val_loss: 18.7741\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 15.4535 - val_loss: 18.4937\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.5065 - val_loss: 16.3860\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 13.9117 - val_loss: 16.8034\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 15.4186 - val_loss: 23.7431\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.1509 - val_loss: 17.0264\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.0784 - val_loss: 17.0968\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.4600 - val_loss: 16.6199\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.5586 - val_loss: 19.1544\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.7673 - val_loss: 16.8574\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.9752 - val_loss: 18.2986\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.9717 - val_loss: 17.5632\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1893 - val_loss: 16.8001\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 13.3144 - val_loss: 16.3366\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.4106 - val_loss: 18.1819\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.2370 - val_loss: 15.6806\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.5517 - val_loss: 16.2319\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 13.0953 - val_loss: 16.7652\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 12.7713 - val_loss: 15.2611\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 12.7072 - val_loss: 15.3386\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 12.8222 - val_loss: 16.0801\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.0780 - val_loss: 16.4995\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 12.8251 - val_loss: 17.4471\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.1964 - val_loss: 15.3655\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8971 - val_loss: 18.5176\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.9766 - val_loss: 15.2175\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.3462 - val_loss: 16.6471\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 12.4647 - val_loss: 14.6126\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 13.2234 - val_loss: 16.5510\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 11.6179 - val_loss: 14.8280\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.7463 - val_loss: 16.3215\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.8385 - val_loss: 14.1819\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 12.5911 - val_loss: 17.3775\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.5998 - val_loss: 15.4855\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.7756 - val_loss: 14.0171\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4887 - val_loss: 13.9509\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.7739 - val_loss: 14.2836\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4857 - val_loss: 14.8218\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.6824 - val_loss: 15.7339\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.1218 - val_loss: 15.2741\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.2630 - val_loss: 14.3456\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.8513 - val_loss: 15.0594\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 11.1989 - val_loss: 18.5607\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.6823 - val_loss: 13.6513\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 11.4835 - val_loss: 13.0794\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.8557 - val_loss: 13.8998\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0783 - val_loss: 14.1927\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1991 - val_loss: 15.3197\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 11.3579 - val_loss: 15.6233\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.3444 - val_loss: 12.8775\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 11.4562 - val_loss: 13.9183\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 11.0486 - val_loss: 14.5941\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 11.0667 - val_loss: 14.5370\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.1003 - val_loss: 16.3865\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 11.3678 - val_loss: 14.6174\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.2343 - val_loss: 13.7001\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 11.1532 - val_loss: 12.5143\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 10.5778 - val_loss: 12.8155\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 11.4691 - val_loss: 14.3012\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 10.9692 - val_loss: 13.4983\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 10.3754 - val_loss: 13.2417\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 11.0828 - val_loss: 14.2993\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 12.1031 - val_loss: 13.8477\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.5062 - val_loss: 13.2941\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.6962 - val_loss: 12.7163\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4221 - val_loss: 13.4372\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.4267 - val_loss: 13.0031\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.1389 - val_loss: 13.1642\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.3270 - val_loss: 12.4763\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.2784 - val_loss: 12.7509\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.6667 - val_loss: 12.6092\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9842 - val_loss: 12.5947\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8917 - val_loss: 12.3134\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1256 - val_loss: 12.1269\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 11.0718 - val_loss: 16.5978\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.1492 - val_loss: 13.0908\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0851 - val_loss: 12.3125\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0549 - val_loss: 13.6551\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.2031 - val_loss: 12.6975\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.4238 - val_loss: 12.3257\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.2864 - val_loss: 12.9105\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0799 - val_loss: 12.5117\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7019 - val_loss: 12.1355\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5626 - val_loss: 12.1423\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 10.6646 - val_loss: 12.5190\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5669 - val_loss: 12.8554\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9089 - val_loss: 13.0956\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3299 - val_loss: 11.9112\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5460 - val_loss: 12.9957\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1733 - val_loss: 12.5261\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4949 - val_loss: 11.8231\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0040 - val_loss: 12.0456\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 10.0331 - val_loss: 11.8196\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.8804 - val_loss: 11.7946\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0934 - val_loss: 11.4880\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7097 - val_loss: 12.2812\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7331 - val_loss: 12.1260\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5133 - val_loss: 11.4140\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4914 - val_loss: 11.5170\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4198 - val_loss: 13.1527\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6123 - val_loss: 11.9427\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6213 - val_loss: 13.3261\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6416 - val_loss: 11.5933\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7774 - val_loss: 11.2159\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5371 - val_loss: 11.7010\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.1083 - val_loss: 12.6046\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.5518 - val_loss: 11.5280\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.7897 - val_loss: 12.8714\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5456 - val_loss: 11.7429\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.3878 - val_loss: 11.3032\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6878 - val_loss: 12.1097\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4278 - val_loss: 11.5816\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4952 - val_loss: 11.3353\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8197 - val_loss: 11.1393\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4159 - val_loss: 12.5003\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.8637 - val_loss: 11.3899\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2855 - val_loss: 12.1424\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4897 - val_loss: 11.5461\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 10.2148 - val_loss: 11.3585\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.7087 - val_loss: 12.1117\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3565 - val_loss: 11.7720\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8578 - val_loss: 11.1550\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.8148 - val_loss: 12.0706\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2538 - val_loss: 11.6295\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2342 - val_loss: 11.6382\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8136 - val_loss: 11.4370\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1845 - val_loss: 11.8398\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5739 - val_loss: 11.4456\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3246 - val_loss: 12.5145\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7842 - val_loss: 12.6372\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8389 - val_loss: 12.1882\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9376 - val_loss: 11.3456\n",
      "Epoch 367/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2065 - val_loss: 11.6979\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.8895 - val_loss: 12.2514\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.4659 - val_loss: 12.4376\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4025 - val_loss: 11.3865\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5601 - val_loss: 11.0904\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4992 - val_loss: 12.0453\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5952 - val_loss: 11.9128\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.7833 - val_loss: 12.6986\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.4881 - val_loss: 13.5848\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2408 - val_loss: 11.3065\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4353 - val_loss: 10.9458\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2358 - val_loss: 11.1868\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2126 - val_loss: 11.4207\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3326 - val_loss: 12.0390\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0034 - val_loss: 11.0588\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4349 - val_loss: 10.9123\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4496 - val_loss: 11.4341\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2208 - val_loss: 11.2920\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5136 - val_loss: 12.7335\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8854 - val_loss: 11.8046\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3299 - val_loss: 11.3869\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7933 - val_loss: 12.5417\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8162 - val_loss: 11.0368\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5329 - val_loss: 11.4544\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.2521 - val_loss: 11.5066\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1956 - val_loss: 11.8980\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4512 - val_loss: 13.1505\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 10.3555 - val_loss: 11.3258\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0323 - val_loss: 11.1101\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.8943 - val_loss: 12.3500\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6564 - val_loss: 11.3088\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1777 - val_loss: 11.4283\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2965 - val_loss: 12.4397\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3374 - val_loss: 11.4157\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2862 - val_loss: 15.5658\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0024 - val_loss: 11.7050\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3177 - val_loss: 11.3547\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2566 - val_loss: 12.5767\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 10.0991 - val_loss: 10.9882\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2546 - val_loss: 10.7566\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1864 - val_loss: 10.9872\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.8108 - val_loss: 12.1712\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6103 - val_loss: 11.1683\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1280 - val_loss: 11.4715\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2238 - val_loss: 10.8885\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3935 - val_loss: 12.2386\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9979 - val_loss: 12.3517\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 10.3804 - val_loss: 11.7705\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3133 - val_loss: 11.3377\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.4989 - val_loss: 11.1857\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8496 - val_loss: 11.2056\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0037 - val_loss: 14.1087\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.0027 - val_loss: 13.3796\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6286 - val_loss: 11.6595\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3520 - val_loss: 10.8831\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4513 - val_loss: 12.4827\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4682 - val_loss: 10.9312\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1731 - val_loss: 11.0857\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4676 - val_loss: 10.9635\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3197 - val_loss: 13.6607\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6194 - val_loss: 11.1623\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8971 - val_loss: 11.9429\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4940 - val_loss: 10.6559\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4493 - val_loss: 11.1008\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0268 - val_loss: 11.5763\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2095 - val_loss: 11.7167\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.9936 - val_loss: 12.4154\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5738 - val_loss: 13.1289\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2125 - val_loss: 11.0413\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.6060 - val_loss: 11.4433\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9963 - val_loss: 11.0573\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3177 - val_loss: 11.4398\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0236 - val_loss: 11.3140\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4357 - val_loss: 10.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1124 - val_loss: 11.9510\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5899 - val_loss: 10.5185\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2638 - val_loss: 12.4839\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5738 - val_loss: 11.0009\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2836 - val_loss: 11.9007\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1942 - val_loss: 12.5540\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 10.0482 - val_loss: 11.8322\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5136 - val_loss: 11.0587\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1388 - val_loss: 10.7833\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3734 - val_loss: 10.7480\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1094 - val_loss: 11.0670\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2345 - val_loss: 11.3283\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6527 - val_loss: 11.2019\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6583 - val_loss: 11.3430\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8899 - val_loss: 14.5835\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5157 - val_loss: 11.1045\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4472 - val_loss: 12.6172\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2395 - val_loss: 10.9110\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9203 - val_loss: 10.9530\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2682 - val_loss: 11.8903\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.1673 - val_loss: 12.3337\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.7887 - val_loss: 16.2719\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 10.0413 - val_loss: 10.7059\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7415 - val_loss: 11.3673\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9439 - val_loss: 10.7920\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2389 - val_loss: 11.5694\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.6742 - val_loss: 10.8437\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.2950 - val_loss: 12.6075\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3879 - val_loss: 11.2598\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8806 - val_loss: 11.4783\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1237 - val_loss: 11.4095\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2786 - val_loss: 11.9904\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3734 - val_loss: 11.6235\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.5163 - val_loss: 13.5757\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6201 - val_loss: 10.8520\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1931 - val_loss: 10.8005\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0698 - val_loss: 11.1313\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6053 - val_loss: 11.0939\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9999 - val_loss: 11.4417\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1383 - val_loss: 11.4229\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1126 - val_loss: 12.0310\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2971 - val_loss: 12.5988\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1262 - val_loss: 11.0795\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0676 - val_loss: 12.2182\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2763 - val_loss: 10.9159\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0559 - val_loss: 11.4225\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2120 - val_loss: 12.1368\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0968 - val_loss: 12.3156\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0516 - val_loss: 10.9387\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6970 - val_loss: 12.5888\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.4381 - val_loss: 12.5752\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1523 - val_loss: 11.5716\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9502 - val_loss: 11.6531\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6068 - val_loss: 12.8282\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.2262 - val_loss: 10.7227\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3092 - val_loss: 10.7200\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8747 - val_loss: 11.4623\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1168 - val_loss: 10.7610\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6123 - val_loss: 11.2894\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5723 - val_loss: 12.2593\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6952 - val_loss: 11.6919\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5135 - val_loss: 12.5131\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1992 - val_loss: 11.0988\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1001 - val_loss: 10.6018\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8629 - val_loss: 12.3726\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2453 - val_loss: 11.0375\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9790 - val_loss: 10.5917\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5316 - val_loss: 12.4185\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2495 - val_loss: 11.3575\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2479 - val_loss: 10.6992\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4474 - val_loss: 11.7482\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9717 - val_loss: 11.2531\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0187 - val_loss: 10.7980\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.6994 - val_loss: 10.6960\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1322 - val_loss: 11.0539\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9941 - val_loss: 10.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0133 - val_loss: 10.5961\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8168 - val_loss: 11.1927\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9485 - val_loss: 13.9284\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3347 - val_loss: 11.2106\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1396 - val_loss: 10.6805\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2829 - val_loss: 10.6848\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4697 - val_loss: 10.9942\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2999 - val_loss: 11.4060\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1665 - val_loss: 10.5648\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1039 - val_loss: 12.1229\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3014 - val_loss: 10.6267\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9959 - val_loss: 11.5892\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1872 - val_loss: 11.4363\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2650 - val_loss: 12.0134\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0431 - val_loss: 13.1188\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1966 - val_loss: 12.0704\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1439 - val_loss: 10.4854\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3911 - val_loss: 11.3850\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3456 - val_loss: 11.1401\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8784 - val_loss: 11.6312\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1579 - val_loss: 11.6410\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9078 - val_loss: 10.7235\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2769 - val_loss: 10.8150\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2617 - val_loss: 11.0129\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0821 - val_loss: 11.4694\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1504 - val_loss: 10.9333\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7986 - val_loss: 11.0961\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5506 - val_loss: 11.2262\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2064 - val_loss: 11.3137\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7899 - val_loss: 10.8256\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6113 - val_loss: 10.9519\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1069 - val_loss: 11.4620\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5126 - val_loss: 10.5880\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3645 - val_loss: 11.7097\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1874 - val_loss: 11.6901\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1889 - val_loss: 11.4920\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2079 - val_loss: 10.6995\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0843 - val_loss: 10.7663\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8597 - val_loss: 10.4927\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4025 - val_loss: 11.2512\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5316 - val_loss: 11.4731\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0547 - val_loss: 11.4828\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0112 - val_loss: 10.7002\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3455 - val_loss: 10.8615\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.8742 - 0s 88us/step - loss: 9.2277 - val_loss: 10.6942\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2310 - val_loss: 10.8316\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1862 - val_loss: 10.9601\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0162 - val_loss: 11.0315\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3472 - val_loss: 10.6835\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0505 - val_loss: 11.7193\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0090 - val_loss: 11.1299\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1186 - val_loss: 14.1601\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9226 - val_loss: 12.5248\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0182 - val_loss: 11.7094\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0678 - val_loss: 10.8658\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8628 - val_loss: 10.5126\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8988 - val_loss: 11.3189\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7068 - val_loss: 10.7831\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6949 - val_loss: 10.6865\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1772 - val_loss: 10.6704\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3049 - val_loss: 10.5611\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0296 - val_loss: 10.5393\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1020 - val_loss: 10.2915\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0665 - val_loss: 11.2612\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1187 - val_loss: 10.8389\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6006 - val_loss: 11.3200\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4426 - val_loss: 10.6138\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5314 - val_loss: 11.0888\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3390 - val_loss: 11.3104\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8823 - val_loss: 10.6678\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4884 - val_loss: 10.5243\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1123 - val_loss: 12.5460\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3150 - val_loss: 11.5351\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1312 - val_loss: 10.4234\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9216 - val_loss: 10.6996\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3636 - val_loss: 10.7903\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.6401 - val_loss: 11.1616\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0758 - val_loss: 12.8280\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5368 - val_loss: 12.1863\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.5399 - val_loss: 10.5716\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 8.6858 - val_loss: 11.0730\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2561 - val_loss: 12.4736\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 116us/step - loss: 9.4640 - val_loss: 10.6142\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 113us/step - loss: 9.3141 - val_loss: 11.3090\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 9.7204 - val_loss: 12.1041\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 9.0495 - val_loss: 11.4694\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 136us/step - loss: 9.0462 - val_loss: 10.8115\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 104us/step - loss: 9.3571 - val_loss: 10.4448\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0224 - val_loss: 10.5083\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1358 - val_loss: 11.3990\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9475 - val_loss: 10.6769\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.2079 - val_loss: 10.7594\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.2156 - val_loss: 11.2755\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.0176 - val_loss: 10.7602\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0955 - val_loss: 11.4287\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7106 - val_loss: 10.8945\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0967 - val_loss: 11.1094\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.7397 - val_loss: 11.4511\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2417 - val_loss: 10.4764\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0250 - val_loss: 10.7379\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7905 - val_loss: 10.7285\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9487 - val_loss: 12.0104\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0491 - val_loss: 10.5766\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9450 - val_loss: 11.1374\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2447 - val_loss: 11.3941\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1547 - val_loss: 10.5438\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9819 - val_loss: 11.0236\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9736 - val_loss: 11.6985\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1088 - val_loss: 10.7248\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.7328 - val_loss: 11.8962\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 107us/step - loss: 8.9021 - val_loss: 11.2186\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9419 - val_loss: 10.7989\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 101us/step - loss: 9.2845 - val_loss: 10.3716\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0112 - val_loss: 10.3622\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.7681 - val_loss: 10.3548\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 8.9228 - val_loss: 11.8502\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.9013 - val_loss: 10.7825\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3616 - val_loss: 14.5878\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2562 - val_loss: 10.6715\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9722 - val_loss: 11.1237\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0425 - val_loss: 10.5738\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2042 - val_loss: 11.1231\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2021 - val_loss: 10.3871\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2322 - val_loss: 10.4431\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0666 - val_loss: 10.4565\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0002 - val_loss: 12.4314\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2627 - val_loss: 10.5755\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4565 - val_loss: 11.8410\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0349 - val_loss: 10.9104\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9665 - val_loss: 10.5217\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3914 - val_loss: 11.9320\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0675 - val_loss: 13.3287\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.6701 - val_loss: 10.6585\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1119 - val_loss: 10.9256\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 9.0529 - val_loss: 11.2336\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.3472 - val_loss: 10.3558\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.4929 - val_loss: 12.8913\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8838 - val_loss: 10.3687\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1980 - val_loss: 10.9950\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1509 - val_loss: 10.9256\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1648 - val_loss: 10.6270\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7955 - val_loss: 11.0188\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8160 - val_loss: 10.6829\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3389 - val_loss: 10.6010\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8992 - val_loss: 13.2074\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.2586 - val_loss: 10.5906\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 111us/step - loss: 8.9468 - val_loss: 11.0816\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0572 - val_loss: 12.7092\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0028 - val_loss: 11.8762\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4504 - val_loss: 10.5383\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7872 - val_loss: 11.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8969 - val_loss: 11.0667\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1273 - val_loss: 10.2462\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5325 - val_loss: 11.9572\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3607 - val_loss: 11.2514\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8103 - val_loss: 11.7199\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7920 - val_loss: 10.3492\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9712 - val_loss: 10.9080\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1896 - val_loss: 10.6347\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6571 - val_loss: 10.7211\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2447 - val_loss: 12.3940\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6555 - val_loss: 10.3537\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8945 - val_loss: 10.4707\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2649 - val_loss: 11.4395\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2644 - val_loss: 12.0028\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7794 - val_loss: 10.6594\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8443 - val_loss: 10.5039\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3647 - val_loss: 11.4980\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2343 - val_loss: 11.2433\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6697 - val_loss: 11.9616\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6707 - val_loss: 10.8663\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1204 - val_loss: 10.4810\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0421 - val_loss: 11.9298\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3282 - val_loss: 13.9390\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2808 - val_loss: 10.3819\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1074 - val_loss: 11.3543\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1933 - val_loss: 11.1006\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.9239 - val_loss: 10.5743\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4802 - val_loss: 11.4454\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9167 - val_loss: 12.2642\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9732 - val_loss: 11.0956\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.0285 - val_loss: 11.0061\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7361 - val_loss: 10.9219\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0005 - val_loss: 11.0050\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3467 - val_loss: 10.5439\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.5778 - val_loss: 12.3685\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2920 - val_loss: 10.6008\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9032 - val_loss: 10.6864\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2763 - val_loss: 10.4089\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0424 - val_loss: 11.5576\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0347 - val_loss: 11.5178\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8989 - val_loss: 10.8390\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9984 - val_loss: 12.4549\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.7893 - val_loss: 12.4461\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4467 - val_loss: 11.0625\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9158 - val_loss: 11.3460\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4295 - val_loss: 11.0056\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9149 - val_loss: 12.1985\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.1884 - val_loss: 13.1200\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4285 - val_loss: 10.4906\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8551 - val_loss: 10.8142\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0441 - val_loss: 10.6673\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8762 - val_loss: 15.5426\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.9601 - val_loss: 10.4301\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9387 - val_loss: 11.2558\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9386 - val_loss: 10.7724\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8796 - val_loss: 10.7440\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0752 - val_loss: 11.7826\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.9645 - val_loss: 11.4872\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.1998 - val_loss: 11.7193\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3550 - val_loss: 11.3814\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8715 - val_loss: 10.8865\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.6689 - val_loss: 10.4796\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8120 - val_loss: 10.7860\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3557 - val_loss: 11.8368\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1825 - val_loss: 10.6787\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1469 - val_loss: 11.6977\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0275 - val_loss: 11.8908\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6936 - val_loss: 10.9829\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2952 - val_loss: 10.5412\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7631 - val_loss: 10.6402\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9136 - val_loss: 10.4681\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0657 - val_loss: 10.6023\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8318 - val_loss: 11.0531\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3109 - val_loss: 10.9499\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2384 - val_loss: 10.8910\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2134 - val_loss: 10.6928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2820 - val_loss: 10.3062\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9815 - val_loss: 11.7752\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1438 - val_loss: 10.8278\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7024 - val_loss: 11.7364\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8894 - val_loss: 10.7746\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8635 - val_loss: 10.4289\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9491 - val_loss: 11.0045\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8361 - val_loss: 10.9276\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9683 - val_loss: 10.9278\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8187 - val_loss: 11.3291\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3112 - val_loss: 11.9434\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.5415 - val_loss: 10.3150\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8166 - val_loss: 10.6858\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3042 - val_loss: 15.1820\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.5983 - val_loss: 11.6489\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0351 - val_loss: 10.9054\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7120 - val_loss: 10.3570\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1448 - val_loss: 12.9168\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1100 - val_loss: 10.8229\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1431 - val_loss: 11.4808\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1765 - val_loss: 11.2649\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0604 - val_loss: 11.4695\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0563 - val_loss: 11.7343\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4211 - val_loss: 11.7253\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7401 - val_loss: 11.7205\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.3324 - val_loss: 10.6343\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.3054 - val_loss: 10.5403\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.1073 - val_loss: 10.4824\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7682 - val_loss: 10.8988\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7385 - val_loss: 10.4128\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3145 - val_loss: 11.0614\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7171 - val_loss: 11.1509\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9118 - val_loss: 10.5856\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.3842 - val_loss: 11.3149\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5485 - val_loss: 10.7621\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8775 - val_loss: 11.2082\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5172 - val_loss: 10.3124\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7707 - val_loss: 10.5736\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1306 - val_loss: 11.6704\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3949 - val_loss: 11.8150\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 10.0392 - val_loss: 10.9964\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6621 - val_loss: 14.8360\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8468 - val_loss: 10.6048\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0818 - val_loss: 13.5716\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6075 - val_loss: 10.5122\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.8653 - val_loss: 10.4872\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8495 - val_loss: 11.3511\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.7538 - val_loss: 10.7945\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.3861 - val_loss: 10.2001\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.6616 - val_loss: 11.6912\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9833 - val_loss: 10.4023\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 8.6998 - val_loss: 11.3427\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.1757 - val_loss: 11.3884\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2444 - val_loss: 11.8881\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 8.7947 - val_loss: 10.4393\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 9.4618 - val_loss: 10.5747\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.9153 - val_loss: 10.4194\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7362 - val_loss: 11.1439\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 8.8750 - val_loss: 12.0702\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2282 - val_loss: 11.7171\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9331 - val_loss: 12.2193\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1639 - val_loss: 11.3994\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 9.0138 - val_loss: 11.3561\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8298 - val_loss: 10.8530\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2507 - val_loss: 12.3710\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6649 - val_loss: 10.8219\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8905 - val_loss: 10.8389\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.5356 - val_loss: 11.3018\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8642 - val_loss: 10.9063\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2428 - val_loss: 10.3548\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8421 - val_loss: 10.5821\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.6999 - val_loss: 11.5007\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8430 - val_loss: 10.9604\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.8521 - val_loss: 10.9220\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9642 - val_loss: 11.6201\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8580 - val_loss: 10.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1090 - val_loss: 11.3274\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.7375 - val_loss: 13.5114\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.3223 - val_loss: 10.5708\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9976 - val_loss: 10.8281\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1400 - val_loss: 11.3068\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8457 - val_loss: 10.7445\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.9033 - val_loss: 10.4456\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1884 - val_loss: 10.7492\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4624 - val_loss: 11.0390\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6888 - val_loss: 12.7788\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2401 - val_loss: 10.8158\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 10.1613 - val_loss: 10.2514\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.1464 - val_loss: 13.3003\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4557 - val_loss: 10.8463\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1536 - val_loss: 10.3579\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.7989 - val_loss: 10.8061\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8775 - val_loss: 10.2385\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9144 - val_loss: 10.3867\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.4919 - val_loss: 10.5718\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8618 - val_loss: 10.5524\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2716 - val_loss: 10.3767\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4749 - val_loss: 11.4305\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1175 - val_loss: 11.4958\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9159 - val_loss: 10.7445\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9142 - val_loss: 11.0785\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5410 - val_loss: 11.0997\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8276 - val_loss: 11.3016\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8880 - val_loss: 10.6064\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8294 - val_loss: 10.7837\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.5656 - val_loss: 12.7967\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1106 - val_loss: 11.6884\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.7592 - val_loss: 11.8974\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8936 - val_loss: 10.4225\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8067 - val_loss: 11.9331\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.8439 - val_loss: 10.2513\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.3884 - val_loss: 11.3242\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9177 - val_loss: 10.3423\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8700 - val_loss: 10.4878\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9874 - val_loss: 11.0529\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1125 - val_loss: 10.1690\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0295 - val_loss: 12.8237\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8486 - val_loss: 11.0833\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2442 - val_loss: 10.9573\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2445 - val_loss: 11.9453\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6519 - val_loss: 12.8360\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.6461 - val_loss: 10.6397\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8027 - val_loss: 11.8404\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8119 - val_loss: 10.6159\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9681 - val_loss: 11.2896\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.4173 - val_loss: 10.9710\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.3810 - val_loss: 10.6057\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.4738 - val_loss: 10.3715\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6047 - val_loss: 11.1867\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0658 - val_loss: 10.9014\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.0994 - val_loss: 11.3936\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0897 - val_loss: 10.5299\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0455 - val_loss: 11.3998\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7388 - val_loss: 10.4439\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1482 - val_loss: 12.7206\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1596 - val_loss: 10.9828\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7808 - val_loss: 11.1030\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.7235 - val_loss: 10.7014\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2088 - val_loss: 11.9993\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 8.7103 - val_loss: 10.8230\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6689 - val_loss: 10.2260\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.3517 - val_loss: 12.2926\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8193 - val_loss: 11.0816\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0463 - val_loss: 11.1098\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.2382 - val_loss: 10.5043\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.5792 - val_loss: 11.2486\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.8453 - val_loss: 11.8640\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4141 - val_loss: 10.4275\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8522 - val_loss: 10.4191\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5887 - val_loss: 10.2893\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7120 - val_loss: 10.5172\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4479 - val_loss: 10.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7401 - val_loss: 10.4755\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.1625 - val_loss: 11.5431\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9314 - val_loss: 10.7372\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.2621 - val_loss: 11.2741\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.8853 - val_loss: 11.2288\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4526 - val_loss: 10.7029\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.6435 - val_loss: 10.5789\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0842 - val_loss: 10.2400\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7557 - val_loss: 11.5126\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0548 - val_loss: 10.6877\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.4090 - val_loss: 10.5597\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0441 - val_loss: 11.4466\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9235 - val_loss: 11.0149\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7643 - val_loss: 11.5224\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8288 - val_loss: 10.7727\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4765 - val_loss: 10.5333\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.5407 - val_loss: 11.3374\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.4864 - val_loss: 10.3574\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8600 - val_loss: 11.0224\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9996 - val_loss: 10.3911\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7523 - val_loss: 10.5314\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8580 - val_loss: 12.3016\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8430 - val_loss: 10.6865\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0078 - val_loss: 10.5423\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8648 - val_loss: 10.7509\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.0031 - val_loss: 11.7565\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.5738 - val_loss: 11.8072\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1023 - val_loss: 10.5545\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6234 - val_loss: 11.7472\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8352 - val_loss: 11.8311\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9754 - val_loss: 10.4064\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.0307 - val_loss: 10.1378\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1926 - val_loss: 10.8817\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8864 - val_loss: 11.0200\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1867 - val_loss: 11.8816\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9868 - val_loss: 11.0897\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.1091 - val_loss: 10.6994\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7340 - val_loss: 10.8825\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7356 - val_loss: 11.5774\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.8292 - val_loss: 12.3817\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0768 - val_loss: 11.6261\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6183 - val_loss: 10.6549\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.6186 - val_loss: 10.6343\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7743 - val_loss: 10.9247\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.8724 - val_loss: 10.4240\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2833 - val_loss: 10.6541\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8383 - val_loss: 10.2177\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8941 - val_loss: 11.1373\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.2031 - val_loss: 10.7241\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0794 - val_loss: 10.6655\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.4990 - val_loss: 11.3035\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7638 - val_loss: 10.6695\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7621 - val_loss: 11.3842\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 95us/step - loss: 8.9479 - val_loss: 10.3377\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 9.1529 - val_loss: 11.2725\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.9346 - val_loss: 11.2500\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1023 - val_loss: 10.3686\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1593 - val_loss: 11.7699\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.7025 - val_loss: 10.4425\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.6085 - val_loss: 10.9037\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7445 - val_loss: 10.9211\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2137 - val_loss: 11.1269\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.7044 - val_loss: 10.2730\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 9.3022 - val_loss: 11.2874\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7340 - val_loss: 10.4212\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.9398 - val_loss: 10.8980\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 109us/step - loss: 8.9097 - val_loss: 11.1234\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9904 - val_loss: 10.4303\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.8687 - val_loss: 11.2590\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.9195 - val_loss: 10.8995\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 8.9534 - val_loss: 10.7340\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8669 - val_loss: 11.5842\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 96us/step - loss: 9.5238 - val_loss: 11.6794\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 97us/step - loss: 8.8833 - val_loss: 10.2467\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7566 - val_loss: 10.5466\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0208 - val_loss: 10.0628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7704 - val_loss: 10.2628\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.5909 - val_loss: 10.4916\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.9081 - val_loss: 12.0301\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8690 - val_loss: 10.6649\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.0677 - val_loss: 10.3749\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.6019 - val_loss: 11.2440\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 94us/step - loss: 8.8812 - val_loss: 10.4728\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 8.8673 - val_loss: 10.4074\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2826 - val_loss: 12.0836\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0443 - val_loss: 11.0921\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7494 - val_loss: 10.4182\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.5276 - val_loss: 10.5479\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.7533 - val_loss: 12.7487\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0878 - val_loss: 10.4646\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.7768 - val_loss: 10.5695\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6072 - val_loss: 11.1288\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.7530 - val_loss: 10.7362\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.0624 - val_loss: 10.9988\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.6308 - val_loss: 10.5226\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.5925 - val_loss: 10.6001\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.9288 - val_loss: 10.8465\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.0346 - val_loss: 12.6045\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 8.9915 - val_loss: 11.7149\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.2127 - val_loss: 11.3028\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 8.8710 - val_loss: 10.6478\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 8.8530 - val_loss: 10.7250\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.9864 - val_loss: 11.1079\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8386 - val_loss: 10.7401\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1490 - val_loss: 10.2670\n",
      "9.089374521664814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.9559397 , -0.21596177,  2.366864  , -3.831444  , -3.3035686 ],\n",
       "        [ 0.34534797, -0.25029755, -0.1838482 ,  0.30868968, -0.03377806],\n",
       "        [ 0.2943394 , -0.37147492, -0.03003568, -0.6304434 , -0.02251988],\n",
       "        [ 0.05219527,  0.09726054, -0.1832903 ,  0.16818589, -0.16364615],\n",
       "        [-0.20100169, -0.18387212,  2.9241974 , -0.43552953, -0.44549966]],\n",
       "       dtype=float32),\n",
       " array([-1.3525501 , -0.09846009,  4.4292083 , -4.7381516 , -4.2068844 ],\n",
       "       dtype=float32),\n",
       " array([[-0.6809769 ,  0.4206214 ,  0.39323035,  0.28940502, -0.5959601 ,\n",
       "         -1.227106  ,  0.8751311 , -0.8745659 ,  0.7348782 , -0.69360673],\n",
       "        [-0.808588  ,  1.5924869 ,  0.50369525,  0.6683649 , -1.4414929 ,\n",
       "         -0.34412235,  0.9877406 , -0.99909794,  0.8753164 , -0.8959788 ],\n",
       "        [-0.9182221 ,  2.082325  ,  1.4653559 ,  1.5441968 , -1.5932399 ,\n",
       "         -2.00697   ,  1.1069134 , -2.0278935 ,  2.0587192 , -2.103446  ],\n",
       "        [ 1.5777928 , -1.7653612 , -1.5855818 , -2.0514302 ,  2.2792563 ,\n",
       "          1.8742207 , -1.9557337 ,  2.2252908 , -1.2567703 ,  1.2502769 ],\n",
       "        [ 2.166677  , -1.1942916 , -2.0262134 , -2.4010253 ,  1.6230129 ,\n",
       "          1.7038981 , -1.7959465 ,  2.1326263 , -1.4968514 ,  1.9609536 ]],\n",
       "       dtype=float32),\n",
       " array([-1.9147819,  1.8591672,  1.9383512,  2.042607 , -1.799344 ,\n",
       "        -1.843682 ,  1.813618 , -1.8112109,  1.972631 , -1.8866298],\n",
       "       dtype=float32),\n",
       " array([[-1.6951199],\n",
       "        [ 1.7811358],\n",
       "        [ 1.7596482],\n",
       "        [ 1.603367 ],\n",
       "        [-2.243553 ],\n",
       "        [-1.8983986],\n",
       "        [ 2.0682933],\n",
       "        [-2.1657124],\n",
       "        [ 1.5942794],\n",
       "        [-1.80947  ]], dtype=float32),\n",
       " array([1.7780287], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, adam2, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 166us/step - loss: 15366.6379 - val_loss: 15008.2172\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14174.9512 - val_loss: 12676.0804\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 8611.3751 - val_loss: 2287.1786\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 411.7792 - val_loss: 86.5355\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 41.2786 - val_loss: 33.4929\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 30.9395 - val_loss: 30.8242\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 29.2691 - val_loss: 29.5328\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 27.9686 - val_loss: 28.7535\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 27.0926 - val_loss: 28.2154\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 26.4117 - val_loss: 27.7756\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 25.9144 - val_loss: 27.5818\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 25.5431 - val_loss: 27.3074\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 25.1985 - val_loss: 27.1546\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.9256 - val_loss: 26.9460\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 24.7520 - val_loss: 26.8489\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 24.4929 - val_loss: 26.6789\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 24.2795 - val_loss: 26.6007\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 24.1311 - val_loss: 26.3785\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 23.9031 - val_loss: 26.3065\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 23.7385 - val_loss: 26.2107\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 23.6053 - val_loss: 26.1926\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4210 - val_loss: 26.0068\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 23.2682 - val_loss: 25.9634\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.1132 - val_loss: 25.8620\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.0189 - val_loss: 25.8113\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 22.8636 - val_loss: 25.7468\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 22.7145 - val_loss: 25.6701\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.6165 - val_loss: 25.6102\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.4785 - val_loss: 25.6516\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 22.3874 - val_loss: 25.4962\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 22.2430 - val_loss: 25.4513\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.1258 - val_loss: 25.3941\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.9904 - val_loss: 25.3807\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 21.8647 - val_loss: 25.3042\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.7332 - val_loss: 25.2379\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.6528 - val_loss: 25.2213\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 21.5277 - val_loss: 25.1608\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.3748 - val_loss: 25.2239\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.3090 - val_loss: 25.1421\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 21.2091 - val_loss: 25.1221\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 21.0652 - val_loss: 24.9834\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 20.9685 - val_loss: 25.0015\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 20.8411 - val_loss: 24.8878\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 20.7493 - val_loss: 24.8852\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.6609 - val_loss: 24.8631\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.5330 - val_loss: 24.8455\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.4416 - val_loss: 24.7614\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.3793 - val_loss: 24.8382\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 20.2562 - val_loss: 24.6931\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 20.1788 - val_loss: 24.6538\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 20.1114 - val_loss: 24.6429\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 20.0279 - val_loss: 24.5952\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.9593 - val_loss: 24.5157\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.8889 - val_loss: 24.4672\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.8155 - val_loss: 24.4739\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 19.7814 - val_loss: 24.4734\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 19.7234 - val_loss: 24.3984\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 19.6090 - val_loss: 24.3636\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.5530 - val_loss: 24.3586\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.5065 - val_loss: 24.3281\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 19.4991 - val_loss: 24.3178\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 19.4557 - val_loss: 24.2360\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.3795 - val_loss: 24.1861\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.3629 - val_loss: 24.1193\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 19.2822 - val_loss: 24.1209\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.2486 - val_loss: 24.1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 19.1987 - val_loss: 24.0649\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 19.1617 - val_loss: 24.1002\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 19.1851 - val_loss: 24.1726\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 19.1213 - val_loss: 24.0298\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 19.0466 - val_loss: 24.0426\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 19.0484 - val_loss: 23.9414\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.9992 - val_loss: 23.9798\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.9880 - val_loss: 23.9695\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.9609 - val_loss: 23.9599\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.9073 - val_loss: 23.8635\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.8952 - val_loss: 23.9142\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.8893 - val_loss: 23.8944\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8461 - val_loss: 23.8504\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8393 - val_loss: 23.8427\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.8319 - val_loss: 23.8733\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.7922 - val_loss: 23.7974\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.7866 - val_loss: 23.7553\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.7449 - val_loss: 23.7664\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 62us/step - loss: 18.7430 - val_loss: 23.7663\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.7054 - val_loss: 23.7412\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6870 - val_loss: 23.7018\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6790 - val_loss: 23.7177\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.6958 - val_loss: 23.6794\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.6543 - val_loss: 23.7137\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.6523 - val_loss: 23.6723\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.6048 - val_loss: 23.6826\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.6061 - val_loss: 23.6286\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.5875 - val_loss: 23.6089\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.5936 - val_loss: 23.5794\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.5828 - val_loss: 23.5926\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.5265 - val_loss: 23.6050\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.5142 - val_loss: 23.5682\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.5058 - val_loss: 23.5695\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.4921 - val_loss: 23.5396\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.4796 - val_loss: 23.4942\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.4586 - val_loss: 23.5049\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.4436 - val_loss: 23.4666\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.4439 - val_loss: 23.4714\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.4217 - val_loss: 23.4438\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 18.4371 - val_loss: 23.4312\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.4130 - val_loss: 23.4009\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3927 - val_loss: 23.4415\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 18.3744 - val_loss: 23.3874\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3611 - val_loss: 23.3838\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.3415 - val_loss: 23.3955\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.3294 - val_loss: 23.3843\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.3329 - val_loss: 23.3648\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.3476 - val_loss: 23.3252\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.3085 - val_loss: 23.3227\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 18.2880 - val_loss: 23.3103\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 18.2920 - val_loss: 23.2953\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2643 - val_loss: 23.2563\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.2613 - val_loss: 23.2462\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2669 - val_loss: 23.2901\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 18.2368 - val_loss: 23.2693\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.2129 - val_loss: 23.2219\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 18.2024 - val_loss: 23.2426\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1938 - val_loss: 23.2317\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.1987 - val_loss: 23.2057\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 18.1616 - val_loss: 23.1874\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.1615 - val_loss: 23.1549\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.1735 - val_loss: 23.1300\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1691 - val_loss: 23.1014\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1426 - val_loss: 23.1379\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.1144 - val_loss: 23.1399\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 18.1050 - val_loss: 23.0794\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0848 - val_loss: 23.1025\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.0784 - val_loss: 23.0362\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 18.0721 - val_loss: 23.0284\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 18.0573 - val_loss: 23.0257\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0391 - val_loss: 23.0495\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 18.0370 - val_loss: 23.0134\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 18.0362 - val_loss: 23.0009\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 18.0045 - val_loss: 22.9749\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 18.0112 - val_loss: 22.9908\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 17.9937 - val_loss: 22.9613\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9782 - val_loss: 22.9296\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9737 - val_loss: 22.9042\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.9565 - val_loss: 22.8840\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9473 - val_loss: 22.8836\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.9370 - val_loss: 22.8401\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.9361 - val_loss: 22.8213\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.9229 - val_loss: 22.8150\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.8953 - val_loss: 22.8177\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 17.77 - 0s 77us/step - loss: 17.8903 - val_loss: 22.7854\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.8814 - val_loss: 22.8253\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8738 - val_loss: 22.7712\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8647 - val_loss: 22.7722\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.8525 - val_loss: 22.7270\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8650 - val_loss: 22.7170\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 17.8395 - val_loss: 22.6607\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.8088 - val_loss: 22.7123\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.7808 - val_loss: 22.6593\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 17.8008 - val_loss: 22.6095\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.7738 - val_loss: 22.6603\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.7558 - val_loss: 22.6060\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.7509 - val_loss: 22.5675\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.7596 - val_loss: 22.6244\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.7670 - val_loss: 22.5442\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.7265 - val_loss: 22.5590\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.7068 - val_loss: 22.5022\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.6864 - val_loss: 22.4834\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.6672 - val_loss: 22.5098\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.6791 - val_loss: 22.4975\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.6620 - val_loss: 22.4449\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.6984 - val_loss: 22.4662\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.6224 - val_loss: 22.4003\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 17.6374 - val_loss: 22.3594\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.5898 - val_loss: 22.4169\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.5930 - val_loss: 22.3598\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.5796 - val_loss: 22.2973\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5998 - val_loss: 22.3227\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.5575 - val_loss: 22.2676\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5295 - val_loss: 22.2787\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.5403 - val_loss: 22.3163\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.5185 - val_loss: 22.2294\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.5026 - val_loss: 22.2051\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.4993 - val_loss: 22.1822\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.4797 - val_loss: 22.1716\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.4586 - val_loss: 22.1659\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.4497 - val_loss: 22.1249\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.4440 - val_loss: 22.0679\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.4357 - val_loss: 22.1059\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.4287 - val_loss: 22.0700\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.3966 - val_loss: 22.0364\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 17.3989 - val_loss: 22.0607\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.3780 - val_loss: 22.0155\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.3702 - val_loss: 21.9820\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.3671 - val_loss: 21.9876\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.3347 - val_loss: 21.9715\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.3471 - val_loss: 21.9079\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.3115 - val_loss: 21.8920\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 17.2997 - val_loss: 21.8948\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.3135 - val_loss: 21.8963\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.2734 - val_loss: 21.8637\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 17.2642 - val_loss: 21.7797\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.2919 - val_loss: 21.7360\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2664 - val_loss: 21.7096\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.2469 - val_loss: 21.8083\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.2181 - val_loss: 21.7385\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.2157 - val_loss: 21.7048\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 17.1881 - val_loss: 21.6848\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 17.1801 - val_loss: 21.6435\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.1688 - val_loss: 21.6623\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.1577 - val_loss: 21.5818\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.1348 - val_loss: 21.5821\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.1447 - val_loss: 21.5833\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.1135 - val_loss: 21.5048\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.1123 - val_loss: 21.5443\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0987 - val_loss: 21.4951\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0829 - val_loss: 21.4694\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0771 - val_loss: 21.4166\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 17.0707 - val_loss: 21.4018\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.0451 - val_loss: 21.4061\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.0284 - val_loss: 21.3750\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 17.0177 - val_loss: 21.3756\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 17.0191 - val_loss: 21.3213\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0277 - val_loss: 21.3582\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 17.0208 - val_loss: 21.3335\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.9890 - val_loss: 21.3106\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.9746 - val_loss: 21.2711\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.9825 - val_loss: 21.2276\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.9743 - val_loss: 21.2165\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.9314 - val_loss: 21.1912\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.9210 - val_loss: 21.1936\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.9110 - val_loss: 21.1628\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9142 - val_loss: 21.1109\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.9066 - val_loss: 21.0771\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.8774 - val_loss: 21.0992\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8988 - val_loss: 21.1277\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 16.8822 - val_loss: 21.0569\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.8710 - val_loss: 21.0172\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.8567 - val_loss: 21.0383\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.8410 - val_loss: 20.9876\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.8428 - val_loss: 20.9915\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.8272 - val_loss: 20.9118\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.8148 - val_loss: 20.9885\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.8129 - val_loss: 20.8936\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.7959 - val_loss: 20.9131\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.7826 - val_loss: 20.8528\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.7657 - val_loss: 20.8156\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7573 - val_loss: 20.8286\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.7452 - val_loss: 20.7688\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.7392 - val_loss: 20.7832\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7314 - val_loss: 20.8121\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.7325 - val_loss: 20.7176\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.7278 - val_loss: 20.7550\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7119 - val_loss: 20.7126\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.7293 - val_loss: 20.7219\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.7022 - val_loss: 20.6881\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6922 - val_loss: 20.6476\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6683 - val_loss: 20.6498\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.6620 - val_loss: 20.6416\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.6619 - val_loss: 20.6379\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.6309 - val_loss: 20.5802\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 16.6459 - val_loss: 20.5089\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.6515 - val_loss: 20.5232\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6527 - val_loss: 20.5927\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.6034 - val_loss: 20.5289\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.6175 - val_loss: 20.4729\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.6071 - val_loss: 20.5071\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.6065 - val_loss: 20.4724\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5854 - val_loss: 20.5432\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.5739 - val_loss: 20.4612\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.5587 - val_loss: 20.4250\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.5442 - val_loss: 20.3906\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.5365 - val_loss: 20.3814\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.5305 - val_loss: 20.3741\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5513 - val_loss: 20.3396\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5152 - val_loss: 20.4053\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5244 - val_loss: 20.3163\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.5137 - val_loss: 20.3442\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.5022 - val_loss: 20.3179\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4843 - val_loss: 20.2778\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.5121 - val_loss: 20.3081\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.4955 - val_loss: 20.3421\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.4798 - val_loss: 20.2316\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4738 - val_loss: 20.2508\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.4798 - val_loss: 20.1939\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4569 - val_loss: 20.1607\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.4543 - val_loss: 20.1929\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.4356 - val_loss: 20.2186\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4261 - val_loss: 20.1529\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.4264 - val_loss: 20.1342\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.4083 - val_loss: 20.1183\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4101 - val_loss: 20.1738\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.4070 - val_loss: 20.1448\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.3956 - val_loss: 20.0850\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3852 - val_loss: 20.0998\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.3962 - val_loss: 20.0871\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.3885 - val_loss: 20.0554\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.4123 - val_loss: 20.0334\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.3517 - val_loss: 20.0397\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.3513 - val_loss: 20.0665\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3678 - val_loss: 19.9743\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3300 - val_loss: 20.0036\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.3242 - val_loss: 19.9768\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.3287 - val_loss: 20.0273\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.3127 - val_loss: 19.9720\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.3093 - val_loss: 19.9612\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3027 - val_loss: 19.9551\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.3052 - val_loss: 19.8833\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2865 - val_loss: 19.9369\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2843 - val_loss: 19.9022\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2987 - val_loss: 19.8894\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.2802 - val_loss: 19.9454\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.2916 - val_loss: 19.9047\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2586 - val_loss: 19.8524\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 16.2769 - val_loss: 19.8702\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2453 - val_loss: 19.8335\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.2898 - val_loss: 19.8718\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2378 - val_loss: 19.7906\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.2311 - val_loss: 19.7657\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.2374 - val_loss: 19.8059\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2335 - val_loss: 19.7765\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.2153 - val_loss: 19.7780\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.2324 - val_loss: 19.7776\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.2104 - val_loss: 19.7818\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.1985 - val_loss: 19.7838\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1963 - val_loss: 19.7305\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.2182 - val_loss: 19.7033\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1817 - val_loss: 19.7212\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 16.1872 - val_loss: 19.6680\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1632 - val_loss: 19.6967\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1708 - val_loss: 19.6849\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1631 - val_loss: 19.6843\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1670 - val_loss: 19.6961\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.1820 - val_loss: 19.7061\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1490 - val_loss: 19.6572\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.1596 - val_loss: 19.6534\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 16.1456 - val_loss: 19.6017\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.1270 - val_loss: 19.6206\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1415 - val_loss: 19.6022\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.1140 - val_loss: 19.6324\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1345 - val_loss: 19.6461\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.0991 - val_loss: 19.5681\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1141 - val_loss: 19.5749\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.0998 - val_loss: 19.5741\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.1223 - val_loss: 19.5974\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0900 - val_loss: 19.5317\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0949 - val_loss: 19.5469\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0764 - val_loss: 19.5463\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0679 - val_loss: 19.5449\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.0735 - val_loss: 19.5031\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0746 - val_loss: 19.5339\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 16.0495 - val_loss: 19.4709\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0508 - val_loss: 19.4964\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 16.0475 - val_loss: 19.4933\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0307 - val_loss: 19.5122\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 16.0380 - val_loss: 19.4720\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 16.0318 - val_loss: 19.4968\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 16.0342 - val_loss: 19.4484\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 16.0200 - val_loss: 19.4290\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.0193 - val_loss: 19.4590\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.0206 - val_loss: 19.4525\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.0119 - val_loss: 19.4156\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 16.0144 - val_loss: 19.4209\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9938 - val_loss: 19.3944\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 16.0031 - val_loss: 19.4355\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9855 - val_loss: 19.4242\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.9815 - val_loss: 19.3472\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.9829 - val_loss: 19.4005\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.9890 - val_loss: 19.3722\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9630 - val_loss: 19.4015\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.9595 - val_loss: 19.3827\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.9615 - val_loss: 19.3627\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9496 - val_loss: 19.3416\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9747 - val_loss: 19.3212\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9436 - val_loss: 19.3489\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.9469 - val_loss: 19.3623\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9326 - val_loss: 19.3165\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.9395 - val_loss: 19.2880\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.9360 - val_loss: 19.3486\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.9571 - val_loss: 19.4128\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.9044 - val_loss: 19.2461\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.9158 - val_loss: 19.2619\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.9247 - val_loss: 19.2527\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.9104 - val_loss: 19.3399\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8870 - val_loss: 19.2474\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.9021 - val_loss: 19.2746\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.9075 - val_loss: 19.3191\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.9047 - val_loss: 19.2194\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.8885 - val_loss: 19.2939\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.8781 - val_loss: 19.2479\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.8926 - val_loss: 19.2495\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8897 - val_loss: 19.2862\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8708 - val_loss: 19.2133\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8779 - val_loss: 19.1921\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8840 - val_loss: 19.2401\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8529 - val_loss: 19.1757\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8622 - val_loss: 19.1911\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.8479 - val_loss: 19.2029\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8432 - val_loss: 19.1501\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.8388 - val_loss: 19.1813\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8356 - val_loss: 19.1803\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8498 - val_loss: 19.1284\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.8284 - val_loss: 19.1866\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8524 - val_loss: 19.1671\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.8056 - val_loss: 19.2046\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.8299 - val_loss: 19.1762\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.8186 - val_loss: 19.1344\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8076 - val_loss: 19.1595\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.8021 - val_loss: 19.1359\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.8051 - val_loss: 19.1393\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.8121 - val_loss: 19.1122\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.7868 - val_loss: 19.1094\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7840 - val_loss: 19.1622\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.7958 - val_loss: 19.0799\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7803 - val_loss: 19.1013\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7799 - val_loss: 19.0963\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7777 - val_loss: 19.1696\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7711 - val_loss: 19.0980\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7659 - val_loss: 19.1364\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.7655 - val_loss: 19.1058\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.7579 - val_loss: 19.1071\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7645 - val_loss: 19.1026\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7343 - val_loss: 19.0553\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7549 - val_loss: 19.0243\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.7441 - val_loss: 19.0441\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7393 - val_loss: 19.0184\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.7274 - val_loss: 19.0512\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.7259 - val_loss: 19.0349\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.7407 - val_loss: 18.9903\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.7192 - val_loss: 19.0973\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.7213 - val_loss: 19.0269\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.7225 - val_loss: 19.0069\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7149 - val_loss: 18.9887\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.6979 - val_loss: 19.0310\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.7016 - val_loss: 19.0317\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.7082 - val_loss: 19.0078\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6935 - val_loss: 19.0270\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.7108 - val_loss: 18.9680\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6966 - val_loss: 18.9854\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6820 - val_loss: 19.0414\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6875 - val_loss: 19.0001\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6861 - val_loss: 19.0043\n",
      "Epoch 443/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.6751 - val_loss: 19.0046\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6785 - val_loss: 18.9852\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6679 - val_loss: 18.9413\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6677 - val_loss: 18.9537\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6669 - val_loss: 18.9322\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.6567 - val_loss: 18.9941\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6443 - val_loss: 18.9457\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.6401 - val_loss: 18.9471\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6512 - val_loss: 18.9342\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6417 - val_loss: 18.9611\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6370 - val_loss: 18.9346\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.6418 - val_loss: 18.9310\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.6406 - val_loss: 18.9233\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6407 - val_loss: 18.9158\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.6293 - val_loss: 18.8971\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.6291 - val_loss: 18.9319\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6150 - val_loss: 18.9076\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.6102 - val_loss: 18.8692\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.6254 - val_loss: 18.8823\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 56us/step - loss: 15.6111 - val_loss: 18.9505\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.6107 - val_loss: 18.9077\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5971 - val_loss: 18.8702\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5971 - val_loss: 18.8604\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5967 - val_loss: 18.8666\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.6019 - val_loss: 18.9203\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5893 - val_loss: 18.8430\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5810 - val_loss: 18.8843\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5897 - val_loss: 18.8660\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5764 - val_loss: 18.8796\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5634 - val_loss: 18.8183\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5725 - val_loss: 18.8443\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5932 - val_loss: 18.8467\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5622 - val_loss: 18.8077\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5720 - val_loss: 18.8670\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5671 - val_loss: 18.8442\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5566 - val_loss: 18.8222\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5567 - val_loss: 18.8166\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5614 - val_loss: 18.8161\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.5456 - val_loss: 18.8594\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5422 - val_loss: 18.8122\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5486 - val_loss: 18.7542\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5424 - val_loss: 18.8633\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.5304 - val_loss: 18.7602\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5335 - val_loss: 18.8373\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.5224 - val_loss: 18.8047\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5214 - val_loss: 18.7803\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5273 - val_loss: 18.8157\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.5446 - val_loss: 18.7642\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.5059 - val_loss: 18.7550\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5259 - val_loss: 18.8022\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5073 - val_loss: 18.7734\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.5273 - val_loss: 18.7750\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.5056 - val_loss: 18.7473\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4936 - val_loss: 18.7696\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.5126 - val_loss: 18.8031\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.5028 - val_loss: 18.7614\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4830 - val_loss: 18.8021\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4936 - val_loss: 18.7803\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4774 - val_loss: 18.7320\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4885 - val_loss: 18.7626\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.4864 - val_loss: 18.7766\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4839 - val_loss: 18.7477\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.4735 - val_loss: 18.7364\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4741 - val_loss: 18.7332\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4687 - val_loss: 18.7241\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4735 - val_loss: 18.7165\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4529 - val_loss: 18.7424\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4769 - val_loss: 18.7278\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4492 - val_loss: 18.7302\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.4513 - val_loss: 18.7169\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4631 - val_loss: 18.7032\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4426 - val_loss: 18.7500\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4564 - val_loss: 18.6918\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4361 - val_loss: 18.7328\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4383 - val_loss: 18.7374\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.4279 - val_loss: 18.6796\n",
      "Epoch 519/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.4407 - val_loss: 18.6863\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.4280 - val_loss: 18.7064\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.4659 - val_loss: 18.7418\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4271 - val_loss: 18.6630\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.4376 - val_loss: 18.7030\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4168 - val_loss: 18.6639\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.4185 - val_loss: 18.6714\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4126 - val_loss: 18.6862\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.4360 - val_loss: 18.7077\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.4081 - val_loss: 18.6434\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.4046 - val_loss: 18.6423\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.4053 - val_loss: 18.7027\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.4156 - val_loss: 18.6948\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.4156 - val_loss: 18.6368\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3897 - val_loss: 18.6752\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3881 - val_loss: 18.6605\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3867 - val_loss: 18.6443\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3876 - val_loss: 18.6301\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3798 - val_loss: 18.6280\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3814 - val_loss: 18.6620\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3773 - val_loss: 18.6451\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 15.44 - 0s 71us/step - loss: 15.3668 - val_loss: 18.6329\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.3704 - val_loss: 18.6533\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3971 - val_loss: 18.6638\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.3820 - val_loss: 18.5819\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3798 - val_loss: 18.6331\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3554 - val_loss: 18.6268\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3804 - val_loss: 18.6223\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3516 - val_loss: 18.6642\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.3569 - val_loss: 18.6105\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3472 - val_loss: 18.5908\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.3614 - val_loss: 18.5875\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3585 - val_loss: 18.6330\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.3557 - val_loss: 18.5709\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3499 - val_loss: 18.6248\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3654 - val_loss: 18.6078\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.3323 - val_loss: 18.6215\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3287 - val_loss: 18.6104\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.3494 - val_loss: 18.6095\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.3385 - val_loss: 18.6321\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3116 - val_loss: 18.5611\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3187 - val_loss: 18.5600\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.3299 - val_loss: 18.6111\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.3076 - val_loss: 18.5600\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.3209 - val_loss: 18.5652\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.3052 - val_loss: 18.5674\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.3119 - val_loss: 18.6299\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 15.3000 - val_loss: 18.5372\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.3039 - val_loss: 18.5750\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.2996 - val_loss: 18.5891\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.2945 - val_loss: 18.5977\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2858 - val_loss: 18.5832\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.3050 - val_loss: 18.5024\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.2847 - val_loss: 18.5740\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 15.2825 - val_loss: 18.5760\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 15.2790 - val_loss: 18.5753\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2766 - val_loss: 18.5430\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2724 - val_loss: 18.5237\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.2733 - val_loss: 18.5401\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.2661 - val_loss: 18.5592\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2727 - val_loss: 18.5432\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2658 - val_loss: 18.5478\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2640 - val_loss: 18.5676\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.2624 - val_loss: 18.5227\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.2618 - val_loss: 18.4944\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.2652 - val_loss: 18.5202\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.2606 - val_loss: 18.5808\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.2696 - val_loss: 18.5056\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 15.2560 - val_loss: 18.5507\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2483 - val_loss: 18.5311\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2448 - val_loss: 18.4930\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2456 - val_loss: 18.4711\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.2436 - val_loss: 18.5375\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2320 - val_loss: 18.4836\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.2400 - val_loss: 18.5265\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2288 - val_loss: 18.4897\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.2263 - val_loss: 18.4869\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2179 - val_loss: 18.5115\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.2305 - val_loss: 18.4748\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2279 - val_loss: 18.4923\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.2215 - val_loss: 18.5472\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.2317 - val_loss: 18.4630\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.2124 - val_loss: 18.4805\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2128 - val_loss: 18.4452\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2136 - val_loss: 18.5319\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2214 - val_loss: 18.4818\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.2110 - val_loss: 18.4663\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.2110 - val_loss: 18.4858\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 15.1975 - val_loss: 18.4678\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.1958 - val_loss: 18.4921\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1884 - val_loss: 18.4431\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.1940 - val_loss: 18.4693\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.2065 - val_loss: 18.4804\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1824 - val_loss: 18.4433\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1789 - val_loss: 18.4361\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.1842 - val_loss: 18.4612\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1822 - val_loss: 18.4810\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1805 - val_loss: 18.4431\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1713 - val_loss: 18.4399\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1721 - val_loss: 18.4685\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1651 - val_loss: 18.4559\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 15.1799 - val_loss: 18.4189\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1707 - val_loss: 18.4702\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1635 - val_loss: 18.4323\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.1622 - val_loss: 18.4223\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1586 - val_loss: 18.4325\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1589 - val_loss: 18.4394\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.1479 - val_loss: 18.4585\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1566 - val_loss: 18.4431\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1469 - val_loss: 18.4445\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1531 - val_loss: 18.4145\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 15.1506 - val_loss: 18.4536\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1328 - val_loss: 18.4017\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1403 - val_loss: 18.4302\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1408 - val_loss: 18.3761\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.1410 - val_loss: 18.3975\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.1364 - val_loss: 18.4543\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1335 - val_loss: 18.4426\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1389 - val_loss: 18.4242\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1306 - val_loss: 18.4304\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1275 - val_loss: 18.3976\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1281 - val_loss: 18.4645\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1076 - val_loss: 18.3762\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1149 - val_loss: 18.4009\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.1227 - val_loss: 18.4494\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.1125 - val_loss: 18.3753\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.1025 - val_loss: 18.3928\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1035 - val_loss: 18.4120\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.1080 - val_loss: 18.4317\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.1037 - val_loss: 18.4049\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.1064 - val_loss: 18.4061\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0937 - val_loss: 18.4215\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.1031 - val_loss: 18.3844\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0896 - val_loss: 18.4131\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0877 - val_loss: 18.4056\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0930 - val_loss: 18.4118\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0847 - val_loss: 18.3469\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0859 - val_loss: 18.3679\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0790 - val_loss: 18.3758\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0935 - val_loss: 18.4219\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 15.0736 - val_loss: 18.3481\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0821 - val_loss: 18.3692\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0653 - val_loss: 18.3428\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0772 - val_loss: 18.3829\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0592 - val_loss: 18.3885\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 63us/step - loss: 15.0716 - val_loss: 18.3411\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0570 - val_loss: 18.3989\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0740 - val_loss: 18.3522\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0706 - val_loss: 18.2979\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0549 - val_loss: 18.3926\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0583 - val_loss: 18.3801\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0571 - val_loss: 18.3482\n",
      "Epoch 671/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0552 - val_loss: 18.3548\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0574 - val_loss: 18.3945\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0570 - val_loss: 18.3587\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0404 - val_loss: 18.3726\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0503 - val_loss: 18.4087\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0508 - val_loss: 18.3322\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0360 - val_loss: 18.3438\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0367 - val_loss: 18.3362\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.0311 - val_loss: 18.3360\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.0301 - val_loss: 18.3388\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0291 - val_loss: 18.3231\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0347 - val_loss: 18.3130\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0209 - val_loss: 18.3471\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0184 - val_loss: 18.3238\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0192 - val_loss: 18.3225\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0145 - val_loss: 18.3258\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0288 - val_loss: 18.2997\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0373 - val_loss: 18.3605\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 15.0139 - val_loss: 18.3068\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 15.0048 - val_loss: 18.2986\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 15.0057 - val_loss: 18.3066\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0023 - val_loss: 18.3236\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 15.0028 - val_loss: 18.2690\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 15.0053 - val_loss: 18.3211\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0003 - val_loss: 18.3244\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 15.0052 - val_loss: 18.3411\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9874 - val_loss: 18.2649\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 15.0021 - val_loss: 18.3136\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9960 - val_loss: 18.2605\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9912 - val_loss: 18.2695\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9806 - val_loss: 18.2978\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.9775 - val_loss: 18.3169\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9764 - val_loss: 18.2986\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9762 - val_loss: 18.2913\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9844 - val_loss: 18.3172\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9720 - val_loss: 18.2560\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9709 - val_loss: 18.2605\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9664 - val_loss: 18.2763\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9748 - val_loss: 18.2586\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9629 - val_loss: 18.3111\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9996 - val_loss: 18.2549\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9841 - val_loss: 18.3489\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.9441 - val_loss: 18.2520\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9628 - val_loss: 18.2859\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9509 - val_loss: 18.2696\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9503 - val_loss: 18.2562\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9492 - val_loss: 18.2472\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.9414 - val_loss: 18.2767\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9702 - val_loss: 18.3026\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.9437 - val_loss: 18.2593\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.9399 - val_loss: 18.2893\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9451 - val_loss: 18.2798\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9313 - val_loss: 18.2827\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9425 - val_loss: 18.2721\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9365 - val_loss: 18.2734\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.9287 - val_loss: 18.3045\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9291 - val_loss: 18.2885\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.9272 - val_loss: 18.2336\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9360 - val_loss: 18.2195\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9361 - val_loss: 18.2552\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9153 - val_loss: 18.2798\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.9132 - val_loss: 18.2619\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9126 - val_loss: 18.2490\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9138 - val_loss: 18.2221\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9097 - val_loss: 18.2465\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.9079 - val_loss: 18.2538\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.9169 - val_loss: 18.2730\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8999 - val_loss: 18.2288\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.9100 - val_loss: 18.1937\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8985 - val_loss: 18.2750\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8962 - val_loss: 18.2236\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.9020 - val_loss: 18.2209\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.9094 - val_loss: 18.2219\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.9422 - val_loss: 18.2627\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8903 - val_loss: 18.2074\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.8916 - val_loss: 18.1661\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8950 - val_loss: 18.2370\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8795 - val_loss: 18.2190\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.8878 - val_loss: 18.1951\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8745 - val_loss: 18.2190\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.8907 - val_loss: 18.2601\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8758 - val_loss: 18.1768\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.8782 - val_loss: 18.2088\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.8798 - val_loss: 18.2263\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8613 - val_loss: 18.2142\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8726 - val_loss: 18.2550\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8583 - val_loss: 18.2457\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8660 - val_loss: 18.2121\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8827 - val_loss: 18.2481\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.8459 - val_loss: 18.1782\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8522 - val_loss: 18.2025\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8576 - val_loss: 18.1747\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8524 - val_loss: 18.2128\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.8508 - val_loss: 18.1627\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8551 - val_loss: 18.2004\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.8468 - val_loss: 18.1788\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8369 - val_loss: 18.1731\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8432 - val_loss: 18.2123\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8493 - val_loss: 18.1359\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8337 - val_loss: 18.2617\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8330 - val_loss: 18.1910\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8360 - val_loss: 18.1702\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.8341 - val_loss: 18.2250\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.8295 - val_loss: 18.1687\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.8242 - val_loss: 18.1584\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.8229 - val_loss: 18.1845\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.8272 - val_loss: 18.1614\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.8248 - val_loss: 18.2157\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8208 - val_loss: 18.1980\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.8190 - val_loss: 18.1883\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.8148 - val_loss: 18.1635\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.8121 - val_loss: 18.1758\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.8076 - val_loss: 18.1379\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.8033 - val_loss: 18.1791\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.8185 - val_loss: 18.2046\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8041 - val_loss: 18.1933\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.8056 - val_loss: 18.1361\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.8020 - val_loss: 18.1740\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.8140 - val_loss: 18.1482\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.7954 - val_loss: 18.1349\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.7872 - val_loss: 18.1657\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 61us/step - loss: 14.8090 - val_loss: 18.2179\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7906 - val_loss: 18.1515\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7971 - val_loss: 18.1779\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.8009 - val_loss: 18.2396\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7851 - val_loss: 18.1292\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7865 - val_loss: 18.1260\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7733 - val_loss: 18.1486\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7744 - val_loss: 18.2028\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.7759 - val_loss: 18.1804\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.7820 - val_loss: 18.1452\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.7736 - val_loss: 18.1727\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.7671 - val_loss: 18.1557\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7624 - val_loss: 18.1588\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.7738 - val_loss: 18.1411\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 62us/step - loss: 14.7746 - val_loss: 18.1468\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7704 - val_loss: 18.1562\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.7688 - val_loss: 18.1373\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7583 - val_loss: 18.1519\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.7629 - val_loss: 18.1502\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.7532 - val_loss: 18.1545\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.7519 - val_loss: 18.1881\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7405 - val_loss: 18.1101\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7411 - val_loss: 18.1393\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.7514 - val_loss: 18.1064\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7408 - val_loss: 18.1907\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.7364 - val_loss: 18.1488\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7379 - val_loss: 18.1557\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7275 - val_loss: 18.1376\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7285 - val_loss: 18.1090\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7484 - val_loss: 18.1659\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7259 - val_loss: 18.0919\n",
      "Epoch 823/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7275 - val_loss: 18.0981\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7315 - val_loss: 18.1687\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7234 - val_loss: 18.1286\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.7310 - val_loss: 18.0890\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7313 - val_loss: 18.0914\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7143 - val_loss: 18.1217\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7185 - val_loss: 18.1323\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7221 - val_loss: 18.0968\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7313 - val_loss: 18.1612\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7179 - val_loss: 18.0705\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.7145 - val_loss: 18.1086\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.7138 - val_loss: 18.0984\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7047 - val_loss: 18.0692\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7078 - val_loss: 18.1065\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.6978 - val_loss: 18.0826\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.7032 - val_loss: 18.1028\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.7047 - val_loss: 18.1385\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.7084 - val_loss: 18.0533\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6941 - val_loss: 18.0979\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.7195 - val_loss: 18.0834\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6996 - val_loss: 18.1039\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6843 - val_loss: 18.1187\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6906 - val_loss: 18.1050\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.6832 - val_loss: 18.1055\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 61us/step - loss: 14.6952 - val_loss: 18.1360\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.6743 - val_loss: 18.0807\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.6761 - val_loss: 18.0919\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6811 - val_loss: 18.0537\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6813 - val_loss: 18.0948\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6724 - val_loss: 18.1126\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6730 - val_loss: 18.1241\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6709 - val_loss: 18.0934\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.6597 - val_loss: 18.1249\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6652 - val_loss: 18.1270\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6687 - val_loss: 18.0494\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6628 - val_loss: 18.1137\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.6802 - val_loss: 18.0545\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6542 - val_loss: 18.1040\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6564 - val_loss: 18.1082\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6515 - val_loss: 18.1324\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6470 - val_loss: 18.0613\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6525 - val_loss: 18.0775\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6452 - val_loss: 18.0505\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6418 - val_loss: 18.1061\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6413 - val_loss: 18.1172\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.6521 - val_loss: 18.0643\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6349 - val_loss: 18.0832\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6378 - val_loss: 18.0909\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.6400 - val_loss: 18.0968\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6330 - val_loss: 18.0905\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6371 - val_loss: 18.0702\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6216 - val_loss: 18.1315\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6361 - val_loss: 18.0606\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6285 - val_loss: 18.0602\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.6150 - val_loss: 18.0552\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6262 - val_loss: 18.0507\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6171 - val_loss: 18.0502\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.6098 - val_loss: 18.1009\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.6110 - val_loss: 18.0703\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6129 - val_loss: 18.0414\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6051 - val_loss: 18.0360\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.6239 - val_loss: 18.0408\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.6035 - val_loss: 18.0601\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.6080 - val_loss: 18.1047\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.6091 - val_loss: 18.0436\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6209 - val_loss: 18.0769\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.6036 - val_loss: 18.0296\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.6022 - val_loss: 18.0726\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5995 - val_loss: 18.0806\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.5958 - val_loss: 18.0234\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.6108 - val_loss: 18.0789\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.5872 - val_loss: 18.0277\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5880 - val_loss: 18.0465\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5800 - val_loss: 18.0352\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 14.5871 - val_loss: 18.0000\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.5947 - val_loss: 18.0674\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.5889 - val_loss: 18.0088\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5671 - val_loss: 18.0374\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5686 - val_loss: 18.0767\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5727 - val_loss: 18.0408\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5739 - val_loss: 18.0450\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5672 - val_loss: 18.0620\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5619 - val_loss: 18.0387\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5602 - val_loss: 18.0205\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5697 - val_loss: 18.0293\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5585 - val_loss: 18.0339\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 14.5642 - val_loss: 18.0448\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5597 - val_loss: 18.0028\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5544 - val_loss: 18.0239\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5588 - val_loss: 18.0231\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.5542 - val_loss: 18.0406\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5527 - val_loss: 18.0507\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5404 - val_loss: 18.0092\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5486 - val_loss: 18.0342\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5615 - val_loss: 18.0663\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5426 - val_loss: 18.0428\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5367 - val_loss: 18.0077\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5356 - val_loss: 17.9908\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5389 - val_loss: 18.0308\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5396 - val_loss: 18.0184\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.5349 - val_loss: 18.0005\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5285 - val_loss: 18.0183\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.5373 - val_loss: 18.0207\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5441 - val_loss: 18.0500\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.5255 - val_loss: 17.9965\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5163 - val_loss: 18.0420\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5309 - val_loss: 18.0145\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5157 - val_loss: 17.9832\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5165 - val_loss: 18.0166\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 69us/step - loss: 14.5126 - val_loss: 18.0195\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.5194 - val_loss: 18.0313\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.5188 - val_loss: 18.0221\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.5040 - val_loss: 17.9991\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.4968 - val_loss: 18.0362\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4984 - val_loss: 18.0172\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.5018 - val_loss: 18.0302\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.5008 - val_loss: 18.0188\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.5019 - val_loss: 17.9587\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4905 - val_loss: 18.0039\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.4953 - val_loss: 17.9932\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 66us/step - loss: 14.4919 - val_loss: 18.0665\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4911 - val_loss: 18.0093\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4868 - val_loss: 17.9987\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4936 - val_loss: 18.0077\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 68us/step - loss: 14.4853 - val_loss: 18.0048\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4785 - val_loss: 18.0196\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4860 - val_loss: 17.9924\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4800 - val_loss: 18.0315\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4717 - val_loss: 17.9685\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4755 - val_loss: 17.9915\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4754 - val_loss: 17.9911\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.4852 - val_loss: 18.0169\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.4817 - val_loss: 18.0018\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4740 - val_loss: 18.0209\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4647 - val_loss: 17.9874\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4602 - val_loss: 17.9865\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4596 - val_loss: 17.9843\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4678 - val_loss: 18.0297\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4598 - val_loss: 17.9624\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.4604 - val_loss: 17.9719\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4647 - val_loss: 17.9340\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.4614 - val_loss: 18.0133\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4479 - val_loss: 17.9411\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4589 - val_loss: 18.0286\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 14.4475 - val_loss: 17.9331\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.4511 - val_loss: 17.9543\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4468 - val_loss: 18.0001\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 70us/step - loss: 14.4475 - val_loss: 17.9983\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4420 - val_loss: 17.9526\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4450 - val_loss: 17.9910\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4487 - val_loss: 17.9443\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.4365 - val_loss: 18.0132\n",
      "Epoch 975/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.4288 - val_loss: 17.9578\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4383 - val_loss: 17.9582\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4290 - val_loss: 17.9514\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.4327 - val_loss: 17.9744\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 14.4266 - val_loss: 18.0126\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4248 - val_loss: 17.9778\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 64us/step - loss: 14.4261 - val_loss: 17.9391\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.4098 - val_loss: 17.9417\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4172 - val_loss: 17.9712\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4138 - val_loss: 17.9583\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4147 - val_loss: 17.9757\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.4153 - val_loss: 17.9426\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.4041 - val_loss: 17.9533\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4134 - val_loss: 17.9710\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 14.4000 - val_loss: 17.9543\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.4171 - val_loss: 17.9614\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 14.4035 - val_loss: 17.9611\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.4053 - val_loss: 17.9063\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.4071 - val_loss: 17.9678\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.3991 - val_loss: 17.9414\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.3988 - val_loss: 17.9469\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.4081 - val_loss: 17.9549\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 14.3926 - val_loss: 17.9676\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 14.3919 - val_loss: 17.9262\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3814 - val_loss: 17.9756\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 14.3991 - val_loss: 17.9394\n",
      "14.640229435093636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.13033597,  0.00303281,  1.7227659 , -1.0531831 , -0.17828006],\n",
       "        [-0.18282004, -0.07353149,  0.19935131, -0.00593473, -0.29323864],\n",
       "        [-0.2028655 ,  0.13727102,  0.56147593, -0.31900823, -0.27328742],\n",
       "        [ 0.18218863, -0.17772901, -0.11527186,  0.04287469, -0.03190209],\n",
       "        [-0.11026367,  0.10199023,  0.28287208, -0.36970282, -0.10065217]],\n",
       "       dtype=float32),\n",
       " array([ 1.3502218 , -1.8546903 ,  0.16378397, -1.6417633 ,  1.236223  ],\n",
       "       dtype=float32),\n",
       " array([[ 0.2135845 , -0.6219347 ,  1.1291891 ,  0.6353949 , -0.443345  ,\n",
       "          1.1553172 ,  1.635895  ,  1.5232306 , -0.18809892, -0.66794246],\n",
       "        [ 0.3326957 ,  0.53798354, -1.0827736 , -0.7132953 ,  1.5540054 ,\n",
       "         -1.242647  , -1.556107  , -0.94100356, -0.94831026,  0.08904866],\n",
       "        [-0.23788857, -0.21416181, -0.6978882 , -0.30026183,  0.00361623,\n",
       "         -0.5643646 , -0.76579994, -0.3459301 , -0.31992802,  0.30696556],\n",
       "        [ 0.36328542,  1.1176475 , -0.3797254 , -0.8697098 ,  0.8166162 ,\n",
       "         -0.9503264 , -1.3452784 , -1.7615135 , -0.40499616,  0.3465326 ],\n",
       "        [-0.76113325, -0.86438364,  1.08708   ,  0.9904912 , -0.5316376 ,\n",
       "          0.75988835,  0.75276434,  1.0111274 ,  0.75612444, -0.77973974]],\n",
       "       dtype=float32),\n",
       " array([-1.1076711 , -1.4127687 ,  1.4832228 ,  1.4743837 , -2.2907772 ,\n",
       "         1.8395884 ,  2.5801654 ,  2.780227  ,  0.7374531 , -0.84688455],\n",
       "       dtype=float32),\n",
       " array([[-1.1684825],\n",
       "        [-2.0679593],\n",
       "        [ 2.380206 ],\n",
       "        [ 2.1829908],\n",
       "        [-2.7756827],\n",
       "        [ 2.7914572],\n",
       "        [ 3.7583957],\n",
       "        [ 3.8385816],\n",
       "        [ 1.210266 ],\n",
       "        [-1.2743094]], dtype=float32),\n",
       " array([2.2370775], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, sgd, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1052 samples, validate on 225 samples\n",
      "Epoch 1/1000\n",
      "1052/1052 [==============================] - 0s 178us/step - loss: 14243.2198 - val_loss: 11980.1308\n",
      "Epoch 2/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9249.0470 - val_loss: 5550.1818\n",
      "Epoch 3/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 3016.7945 - val_loss: 767.2792\n",
      "Epoch 4/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 211.2341 - val_loss: 34.3181\n",
      "Epoch 5/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 27.6042 - val_loss: 29.0779\n",
      "Epoch 6/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 25.6317 - val_loss: 27.3592\n",
      "Epoch 7/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.9724 - val_loss: 28.8244\n",
      "Epoch 8/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.5524 - val_loss: 26.9156\n",
      "Epoch 9/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.5827 - val_loss: 27.1293\n",
      "Epoch 10/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4387 - val_loss: 30.6134\n",
      "Epoch 11/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.0404 - val_loss: 27.0660\n",
      "Epoch 12/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.7242 - val_loss: 28.4037\n",
      "Epoch 13/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.7112 - val_loss: 26.4319\n",
      "Epoch 14/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.3914 - val_loss: 29.6242\n",
      "Epoch 15/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.8513 - val_loss: 26.2299\n",
      "Epoch 16/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.9636 - val_loss: 26.9509\n",
      "Epoch 17/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 23.3337 - val_loss: 27.3842\n",
      "Epoch 18/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.7818 - val_loss: 27.8567\n",
      "Epoch 19/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 24.0853 - val_loss: 28.4471\n",
      "Epoch 20/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6443 - val_loss: 27.0521\n",
      "Epoch 21/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.5352 - val_loss: 28.9612\n",
      "Epoch 22/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.1053 - val_loss: 27.7735\n",
      "Epoch 23/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.1511 - val_loss: 29.7363\n",
      "Epoch 24/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.4343 - val_loss: 27.1509\n",
      "Epoch 25/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.9546 - val_loss: 27.1962\n",
      "Epoch 26/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3503 - val_loss: 31.2588\n",
      "Epoch 27/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.6856 - val_loss: 27.4867\n",
      "Epoch 28/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.8450 - val_loss: 26.0930\n",
      "Epoch 29/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.7821 - val_loss: 25.5543\n",
      "Epoch 30/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.0456 - val_loss: 26.1486\n",
      "Epoch 31/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.8547 - val_loss: 30.1437\n",
      "Epoch 32/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6353 - val_loss: 28.5523\n",
      "Epoch 33/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.0665 - val_loss: 26.8066\n",
      "Epoch 34/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.2257 - val_loss: 25.3355\n",
      "Epoch 35/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.1052 - val_loss: 26.3959\n",
      "Epoch 36/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 24.1971 - val_loss: 26.0246\n",
      "Epoch 37/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.4164 - val_loss: 27.7379\n",
      "Epoch 38/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 23.6077 - val_loss: 25.8477\n",
      "Epoch 39/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.1829 - val_loss: 29.7709\n",
      "Epoch 40/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 23.7543 - val_loss: 28.4720\n",
      "Epoch 41/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6083 - val_loss: 25.0981\n",
      "Epoch 42/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 24.3975 - val_loss: 26.1438\n",
      "Epoch 43/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4346 - val_loss: 28.3257\n",
      "Epoch 44/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.4353 - val_loss: 26.4886\n",
      "Epoch 45/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 23.2441 - val_loss: 27.7379\n",
      "Epoch 46/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.3713 - val_loss: 27.6086\n",
      "Epoch 47/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.2341 - val_loss: 25.7447\n",
      "Epoch 48/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6529 - val_loss: 26.2320\n",
      "Epoch 49/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.2159 - val_loss: 27.8686\n",
      "Epoch 50/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.8310 - val_loss: 25.8993\n",
      "Epoch 51/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.9792 - val_loss: 26.5473\n",
      "Epoch 52/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 23.4623 - val_loss: 26.3317\n",
      "Epoch 53/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0709 - val_loss: 28.8255\n",
      "Epoch 54/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6148 - val_loss: 26.6667\n",
      "Epoch 55/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.6860 - val_loss: 29.9022\n",
      "Epoch 56/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.3710 - val_loss: 28.8563\n",
      "Epoch 57/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.8025 - val_loss: 25.0801\n",
      "Epoch 58/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.7595 - val_loss: 27.1492\n",
      "Epoch 59/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.7237 - val_loss: 26.2279\n",
      "Epoch 60/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.2308 - val_loss: 25.0860\n",
      "Epoch 61/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 24.1072 - val_loss: 26.2917\n",
      "Epoch 62/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6480 - val_loss: 31.8609\n",
      "Epoch 63/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.1849 - val_loss: 27.0469\n",
      "Epoch 64/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.5113 - val_loss: 31.8444\n",
      "Epoch 65/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.3835 - val_loss: 29.3973\n",
      "Epoch 66/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 23.6305 - val_loss: 27.7479\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 22.5814 - val_loss: 25.4380\n",
      "Epoch 68/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.8582 - val_loss: 25.9379\n",
      "Epoch 69/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 23.2364 - val_loss: 25.1508\n",
      "Epoch 70/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.1497 - val_loss: 29.2185\n",
      "Epoch 71/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.4130 - val_loss: 29.0687\n",
      "Epoch 72/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.4235 - val_loss: 26.1855\n",
      "Epoch 73/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 24.1645 - val_loss: 26.9188\n",
      "Epoch 74/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0503 - val_loss: 25.7331\n",
      "Epoch 75/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 23.2031 - val_loss: 29.1827\n",
      "Epoch 76/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.1504 - val_loss: 26.4278\n",
      "Epoch 77/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 23.0778 - val_loss: 30.3284\n",
      "Epoch 78/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.8539 - val_loss: 33.0295\n",
      "Epoch 79/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.2483 - val_loss: 28.9949\n",
      "Epoch 80/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 23.1448 - val_loss: 25.7700\n",
      "Epoch 81/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 23.5584 - val_loss: 25.1208\n",
      "Epoch 82/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.9813 - val_loss: 25.2831\n",
      "Epoch 83/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.9627 - val_loss: 25.5774\n",
      "Epoch 84/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.9761 - val_loss: 26.7258\n",
      "Epoch 85/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 22.2424 - val_loss: 27.8256\n",
      "Epoch 86/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 22.8362 - val_loss: 25.8571\n",
      "Epoch 87/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 22.6581 - val_loss: 28.6658\n",
      "Epoch 88/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.4915 - val_loss: 26.0590\n",
      "Epoch 89/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.4501 - val_loss: 25.5650\n",
      "Epoch 90/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 22.2633 - val_loss: 25.9835\n",
      "Epoch 91/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 22.2402 - val_loss: 25.1219\n",
      "Epoch 92/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 22.0745 - val_loss: 25.5530\n",
      "Epoch 93/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 21.8064 - val_loss: 30.3863\n",
      "Epoch 94/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.3782 - val_loss: 24.5362\n",
      "Epoch 95/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 21.7676 - val_loss: 28.7972\n",
      "Epoch 96/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 21.1348 - val_loss: 24.1046\n",
      "Epoch 97/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 21.3068 - val_loss: 27.4634\n",
      "Epoch 98/1000\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 20.3239 - val_loss: 24.8414\n",
      "Epoch 99/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 21.3471 - val_loss: 24.9711\n",
      "Epoch 100/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 20.4500 - val_loss: 25.0799\n",
      "Epoch 101/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 20.6873 - val_loss: 23.6770\n",
      "Epoch 102/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 20.1628 - val_loss: 25.4518\n",
      "Epoch 103/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.9066 - val_loss: 25.1684\n",
      "Epoch 104/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 19.7573 - val_loss: 23.6024\n",
      "Epoch 105/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 19.2599 - val_loss: 26.7340\n",
      "Epoch 106/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 19.2515 - val_loss: 21.9578\n",
      "Epoch 107/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.8680 - val_loss: 21.8626\n",
      "Epoch 108/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 18.5703 - val_loss: 21.8047\n",
      "Epoch 109/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.0779 - val_loss: 23.1940\n",
      "Epoch 110/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 18.4252 - val_loss: 21.1413\n",
      "Epoch 111/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.3891 - val_loss: 21.4936\n",
      "Epoch 112/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 18.0554 - val_loss: 20.8191\n",
      "Epoch 113/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 18.2676 - val_loss: 24.1337\n",
      "Epoch 114/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.3960 - val_loss: 22.6238\n",
      "Epoch 115/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.5861 - val_loss: 21.2718\n",
      "Epoch 116/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 18.3880 - val_loss: 22.6688\n",
      "Epoch 117/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 17.6894 - val_loss: 20.6160\n",
      "Epoch 118/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 17.6823 - val_loss: 19.2999\n",
      "Epoch 119/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.6877 - val_loss: 19.0202\n",
      "Epoch 120/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 17.3375 - val_loss: 21.5237\n",
      "Epoch 121/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.0935 - val_loss: 19.2421\n",
      "Epoch 122/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.9923 - val_loss: 18.4956\n",
      "Epoch 123/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.0171 - val_loss: 18.7498\n",
      "Epoch 124/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 17.3366 - val_loss: 21.6837\n",
      "Epoch 125/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.6564 - val_loss: 18.7468\n",
      "Epoch 126/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 17.0729 - val_loss: 18.3429\n",
      "Epoch 127/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 16.7497 - val_loss: 18.3012\n",
      "Epoch 128/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.9285 - val_loss: 19.1772\n",
      "Epoch 129/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 17.6104 - val_loss: 17.3639\n",
      "Epoch 130/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.2090 - val_loss: 19.0036\n",
      "Epoch 131/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.5954 - val_loss: 21.2326\n",
      "Epoch 132/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 16.2986 - val_loss: 17.8418\n",
      "Epoch 133/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 16.9442 - val_loss: 17.4523\n",
      "Epoch 134/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.4222 - val_loss: 17.6145\n",
      "Epoch 135/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.3879 - val_loss: 17.7351\n",
      "Epoch 136/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 16.0335 - val_loss: 18.3305\n",
      "Epoch 137/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 16.1594 - val_loss: 17.8116\n",
      "Epoch 138/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1635 - val_loss: 17.8160\n",
      "Epoch 139/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.8569 - val_loss: 20.0583\n",
      "Epoch 140/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 16.1970 - val_loss: 17.8795\n",
      "Epoch 141/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 16.0174 - val_loss: 22.4557\n",
      "Epoch 142/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 16.3453 - val_loss: 17.7309\n",
      "Epoch 143/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.7412 - val_loss: 18.9342\n",
      "Epoch 144/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.9427 - val_loss: 16.9293\n",
      "Epoch 145/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.8726 - val_loss: 18.2411\n",
      "Epoch 146/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.6626 - val_loss: 18.4317\n",
      "Epoch 147/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.9432 - val_loss: 17.9339\n",
      "Epoch 148/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 15.5691 - val_loss: 16.6905\n",
      "Epoch 149/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.7433 - val_loss: 17.0838\n",
      "Epoch 150/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 15.4498 - val_loss: 18.1325\n",
      "Epoch 151/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 15.0410 - val_loss: 20.3839\n",
      "Epoch 152/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.1802 - val_loss: 18.4453\n",
      "Epoch 153/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.0837 - val_loss: 25.4806\n",
      "Epoch 154/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 15.6547 - val_loss: 17.5351\n",
      "Epoch 155/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 15.5498 - val_loss: 17.5814\n",
      "Epoch 156/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 15.2303 - val_loss: 17.5301\n",
      "Epoch 157/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 15.5018 - val_loss: 20.1400\n",
      "Epoch 158/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.9931 - val_loss: 17.4671\n",
      "Epoch 159/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.8890 - val_loss: 17.6208\n",
      "Epoch 160/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 15.2822 - val_loss: 17.1644\n",
      "Epoch 161/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.7064 - val_loss: 21.9181\n",
      "Epoch 162/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 14.6469 - val_loss: 19.5775\n",
      "Epoch 163/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 14.6357 - val_loss: 17.7244\n",
      "Epoch 164/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 14.9473 - val_loss: 18.4780\n",
      "Epoch 165/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 14.5809 - val_loss: 16.9309\n",
      "Epoch 166/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.9908 - val_loss: 19.9273\n",
      "Epoch 167/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 14.7372 - val_loss: 24.5223\n",
      "Epoch 168/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 14.7125 - val_loss: 24.8311\n",
      "Epoch 169/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.7097 - val_loss: 16.9925\n",
      "Epoch 170/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 14.5438 - val_loss: 17.5858\n",
      "Epoch 171/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 14.3413 - val_loss: 16.2296\n",
      "Epoch 172/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 14.8993 - val_loss: 16.7010\n",
      "Epoch 173/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 14.4967 - val_loss: 16.2420\n",
      "Epoch 174/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 13.8468 - val_loss: 17.0683\n",
      "Epoch 175/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.1299 - val_loss: 16.9494\n",
      "Epoch 176/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.4134 - val_loss: 15.8754\n",
      "Epoch 177/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 14.3147 - val_loss: 20.5817\n",
      "Epoch 178/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 14.6018 - val_loss: 16.9086\n",
      "Epoch 179/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.6547 - val_loss: 16.4545\n",
      "Epoch 180/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.9744 - val_loss: 17.4098\n",
      "Epoch 181/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 14.0775 - val_loss: 16.8691\n",
      "Epoch 182/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.2015 - val_loss: 16.5252\n",
      "Epoch 183/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.5872 - val_loss: 16.4950\n",
      "Epoch 184/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.3274 - val_loss: 16.2260\n",
      "Epoch 185/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 14.0988 - val_loss: 16.0604\n",
      "Epoch 186/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.8838 - val_loss: 16.2458\n",
      "Epoch 187/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.4626 - val_loss: 19.2977\n",
      "Epoch 188/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.2826 - val_loss: 17.6712\n",
      "Epoch 189/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.9029 - val_loss: 15.1967\n",
      "Epoch 190/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.4247 - val_loss: 15.8212\n",
      "Epoch 191/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.8009 - val_loss: 17.7423\n",
      "Epoch 192/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.5178 - val_loss: 18.5129\n",
      "Epoch 193/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.1282 - val_loss: 18.5565\n",
      "Epoch 194/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.3556 - val_loss: 16.1022\n",
      "Epoch 195/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 13.4933 - val_loss: 17.9753\n",
      "Epoch 196/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 13.3933 - val_loss: 15.3979\n",
      "Epoch 197/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 13.1547 - val_loss: 15.8166\n",
      "Epoch 198/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.1815 - val_loss: 16.2835\n",
      "Epoch 199/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 13.1839 - val_loss: 15.2591\n",
      "Epoch 200/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 13.2121 - val_loss: 15.8093\n",
      "Epoch 201/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.0792 - val_loss: 18.8197\n",
      "Epoch 202/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.6139 - val_loss: 15.3870\n",
      "Epoch 203/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 13.7851 - val_loss: 14.5765\n",
      "Epoch 204/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.5841 - val_loss: 16.1847\n",
      "Epoch 205/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.6719 - val_loss: 16.6077\n",
      "Epoch 206/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 13.0330 - val_loss: 14.4538\n",
      "Epoch 207/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.8555 - val_loss: 15.1330\n",
      "Epoch 208/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 12.9924 - val_loss: 14.5499\n",
      "Epoch 209/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.7177 - val_loss: 14.1206\n",
      "Epoch 210/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 13.1887 - val_loss: 13.9585\n",
      "Epoch 211/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.6266 - val_loss: 15.4964\n",
      "Epoch 212/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.1096 - val_loss: 15.4219\n",
      "Epoch 213/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 12.2157 - val_loss: 14.7196\n",
      "Epoch 214/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 12.2045 - val_loss: 17.6394\n",
      "Epoch 215/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.5265 - val_loss: 15.2454\n",
      "Epoch 216/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.6814 - val_loss: 19.4588\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.7100 - val_loss: 18.7153\n",
      "Epoch 218/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9562 - val_loss: 15.7216\n",
      "Epoch 219/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.1065 - val_loss: 14.3248\n",
      "Epoch 220/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 12.1020 - val_loss: 15.1884\n",
      "Epoch 221/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.9717 - val_loss: 17.3455\n",
      "Epoch 222/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 12.3575 - val_loss: 17.2771\n",
      "Epoch 223/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8749 - val_loss: 13.1186\n",
      "Epoch 224/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.2094 - val_loss: 14.2753\n",
      "Epoch 225/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 12.5602 - val_loss: 15.2283\n",
      "Epoch 226/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.6116 - val_loss: 14.0954\n",
      "Epoch 227/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.9322 - val_loss: 13.9907\n",
      "Epoch 228/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 12.2965 - val_loss: 15.2643\n",
      "Epoch 229/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.8901 - val_loss: 24.3606\n",
      "Epoch 230/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 12.3183 - val_loss: 13.8674\n",
      "Epoch 231/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.6724 - val_loss: 12.7567\n",
      "Epoch 232/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4637 - val_loss: 13.2486\n",
      "Epoch 233/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.6598 - val_loss: 13.5166\n",
      "Epoch 234/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7659 - val_loss: 13.2228\n",
      "Epoch 235/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.7368 - val_loss: 17.4156\n",
      "Epoch 236/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.4579 - val_loss: 15.3681\n",
      "Epoch 237/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.8529 - val_loss: 12.8778\n",
      "Epoch 238/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 11.8831 - val_loss: 14.8798\n",
      "Epoch 239/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 11.8054 - val_loss: 13.1250\n",
      "Epoch 240/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.4704 - val_loss: 13.4043\n",
      "Epoch 241/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.2692 - val_loss: 13.5050\n",
      "Epoch 242/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 11.5249 - val_loss: 22.4361\n",
      "Epoch 243/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3568 - val_loss: 12.9160\n",
      "Epoch 244/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.0398 - val_loss: 12.9455\n",
      "Epoch 245/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3848 - val_loss: 14.3736\n",
      "Epoch 246/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 11.4963 - val_loss: 13.0309\n",
      "Epoch 247/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0807 - val_loss: 16.4628\n",
      "Epoch 248/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.9620 - val_loss: 12.4402\n",
      "Epoch 249/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 11.4169 - val_loss: 14.1857\n",
      "Epoch 250/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6095 - val_loss: 17.3574\n",
      "Epoch 251/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.9653 - val_loss: 13.9255\n",
      "Epoch 252/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 11.1442 - val_loss: 15.5206\n",
      "Epoch 253/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.9468 - val_loss: 15.3153\n",
      "Epoch 254/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.3880 - val_loss: 12.3238\n",
      "Epoch 255/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0108 - val_loss: 13.2997\n",
      "Epoch 256/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.4274 - val_loss: 12.1964\n",
      "Epoch 257/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9991 - val_loss: 18.9829\n",
      "Epoch 258/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 11.6044 - val_loss: 12.4596\n",
      "Epoch 259/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.9282 - val_loss: 14.2368\n",
      "Epoch 260/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.5293 - val_loss: 13.7123\n",
      "Epoch 261/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.3469 - val_loss: 12.3726\n",
      "Epoch 262/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.4019 - val_loss: 12.3563\n",
      "Epoch 263/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.7929 - val_loss: 14.8879\n",
      "Epoch 264/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.8530 - val_loss: 14.5477\n",
      "Epoch 265/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8489 - val_loss: 14.4200\n",
      "Epoch 266/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 11.0847 - val_loss: 12.6707\n",
      "Epoch 267/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8319 - val_loss: 12.5667\n",
      "Epoch 268/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.5385 - val_loss: 15.1031\n",
      "Epoch 269/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.8990 - val_loss: 12.5991\n",
      "Epoch 270/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 10.3039 - val_loss: 15.3565\n",
      "Epoch 271/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.7566 - val_loss: 13.4132\n",
      "Epoch 272/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 10.4180 - val_loss: 15.1228\n",
      "Epoch 273/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.8149 - val_loss: 13.2092\n",
      "Epoch 274/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 11.1498 - val_loss: 12.0439\n",
      "Epoch 275/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.4749 - val_loss: 12.8632\n",
      "Epoch 276/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 11.0649 - val_loss: 11.9664\n",
      "Epoch 277/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.3551 - val_loss: 11.7812\n",
      "Epoch 278/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.6882 - val_loss: 11.7370\n",
      "Epoch 279/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.8966 - val_loss: 11.7727\n",
      "Epoch 280/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1287 - val_loss: 13.4851\n",
      "Epoch 281/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1947 - val_loss: 12.3763\n",
      "Epoch 282/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.5825 - val_loss: 13.7136\n",
      "Epoch 283/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.5343 - val_loss: 12.4618\n",
      "Epoch 284/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.0229 - val_loss: 11.7961\n",
      "Epoch 285/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9318 - val_loss: 15.9273\n",
      "Epoch 286/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.5713 - val_loss: 12.7792\n",
      "Epoch 287/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 10.3478 - val_loss: 11.7790\n",
      "Epoch 288/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.1991 - val_loss: 11.6096\n",
      "Epoch 289/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.5793 - val_loss: 12.2005\n",
      "Epoch 290/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.6016 - val_loss: 11.2030\n",
      "Epoch 291/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.4176 - val_loss: 12.7438\n",
      "Epoch 292/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.3715 - val_loss: 13.2825\n",
      "Epoch 293/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9866 - val_loss: 11.9640\n",
      "Epoch 294/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8979 - val_loss: 14.0236\n",
      "Epoch 295/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9986 - val_loss: 11.2490\n",
      "Epoch 296/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 10.2497 - val_loss: 12.2926\n",
      "Epoch 297/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0748 - val_loss: 11.6428\n",
      "Epoch 298/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8617 - val_loss: 10.7937\n",
      "Epoch 299/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9848 - val_loss: 14.3442\n",
      "Epoch 300/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.4173 - val_loss: 12.1187\n",
      "Epoch 301/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.2127 - val_loss: 11.7312\n",
      "Epoch 302/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8598 - val_loss: 12.5216\n",
      "Epoch 303/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9562 - val_loss: 11.2059\n",
      "Epoch 304/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 10.2926 - val_loss: 11.0023\n",
      "Epoch 305/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8307 - val_loss: 11.3788\n",
      "Epoch 306/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.0474 - val_loss: 11.9491\n",
      "Epoch 307/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7621 - val_loss: 15.2410\n",
      "Epoch 308/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8255 - val_loss: 11.8614\n",
      "Epoch 309/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9180 - val_loss: 12.6114\n",
      "Epoch 310/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0004 - val_loss: 11.6660\n",
      "Epoch 311/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.1400 - val_loss: 11.9335\n",
      "Epoch 312/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5661 - val_loss: 11.7836\n",
      "Epoch 313/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5009 - val_loss: 11.8225\n",
      "Epoch 314/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.3476 - val_loss: 11.7913\n",
      "Epoch 315/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1183 - val_loss: 10.4764\n",
      "Epoch 316/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0192 - val_loss: 10.9272\n",
      "Epoch 317/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5829 - val_loss: 11.2811\n",
      "Epoch 318/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7462 - val_loss: 11.0149\n",
      "Epoch 319/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9711 - val_loss: 10.5385\n",
      "Epoch 320/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8039 - val_loss: 13.2922\n",
      "Epoch 321/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7243 - val_loss: 10.7605\n",
      "Epoch 322/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 10.1757 - val_loss: 10.9018\n",
      "Epoch 323/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7751 - val_loss: 10.6486\n",
      "Epoch 324/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 10.0897 - val_loss: 10.8115\n",
      "Epoch 325/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6543 - val_loss: 10.5300\n",
      "Epoch 326/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.7143 - val_loss: 12.9934\n",
      "Epoch 327/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.9598 - val_loss: 10.3677\n",
      "Epoch 328/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5655 - val_loss: 10.4309\n",
      "Epoch 329/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.9740 - val_loss: 10.8393\n",
      "Epoch 330/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 10.1086 - val_loss: 11.3435\n",
      "Epoch 331/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7028 - val_loss: 11.5402\n",
      "Epoch 332/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5439 - val_loss: 20.0720\n",
      "Epoch 333/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6221 - val_loss: 11.2405\n",
      "Epoch 334/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5553 - val_loss: 10.6989\n",
      "Epoch 335/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6732 - val_loss: 15.8174\n",
      "Epoch 336/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6078 - val_loss: 11.4810\n",
      "Epoch 337/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 10.0264 - val_loss: 12.3983\n",
      "Epoch 338/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3761 - val_loss: 10.9052\n",
      "Epoch 339/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5633 - val_loss: 10.9625\n",
      "Epoch 340/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6754 - val_loss: 18.7172\n",
      "Epoch 341/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7452 - val_loss: 10.8235\n",
      "Epoch 342/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 10.0565 - val_loss: 18.1586\n",
      "Epoch 343/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7054 - val_loss: 13.2448\n",
      "Epoch 344/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8025 - val_loss: 10.8750\n",
      "Epoch 345/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3217 - val_loss: 10.1460\n",
      "Epoch 346/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8056 - val_loss: 10.5706\n",
      "Epoch 347/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6320 - val_loss: 10.1730\n",
      "Epoch 348/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6568 - val_loss: 11.7570\n",
      "Epoch 349/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6873 - val_loss: 11.3179\n",
      "Epoch 350/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8071 - val_loss: 10.5145\n",
      "Epoch 351/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.5213 - val_loss: 10.8949\n",
      "Epoch 352/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 9.5621 - val_loss: 12.4747\n",
      "Epoch 353/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.4506 - val_loss: 11.6795\n",
      "Epoch 354/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.6570 - val_loss: 11.8065\n",
      "Epoch 355/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.6384 - val_loss: 10.9632\n",
      "Epoch 356/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.9169 - val_loss: 10.4332\n",
      "Epoch 357/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.6245 - val_loss: 10.3782\n",
      "Epoch 358/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.7123 - val_loss: 11.0646\n",
      "Epoch 359/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2268 - val_loss: 10.8867\n",
      "Epoch 360/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 10.0066 - val_loss: 12.6863\n",
      "Epoch 361/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.8334 - val_loss: 11.0029\n",
      "Epoch 362/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.8006 - val_loss: 11.6199\n",
      "Epoch 363/1000\n",
      "1052/1052 [==============================] - ETA: 0s - loss: 9.868 - 0s 80us/step - loss: 9.5672 - val_loss: 12.3120\n",
      "Epoch 364/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7965 - val_loss: 10.2116\n",
      "Epoch 365/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7983 - val_loss: 10.6127\n",
      "Epoch 366/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.9410 - val_loss: 11.2552\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5668 - val_loss: 15.3282\n",
      "Epoch 368/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9079 - val_loss: 10.1731\n",
      "Epoch 369/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6590 - val_loss: 10.3643\n",
      "Epoch 370/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6231 - val_loss: 11.6582\n",
      "Epoch 371/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6320 - val_loss: 12.1280\n",
      "Epoch 372/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4178 - val_loss: 11.2604\n",
      "Epoch 373/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5555 - val_loss: 10.3800\n",
      "Epoch 374/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5275 - val_loss: 10.3614\n",
      "Epoch 375/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9578 - val_loss: 13.3340\n",
      "Epoch 376/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7146 - val_loss: 10.7726\n",
      "Epoch 377/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3328 - val_loss: 11.2639\n",
      "Epoch 378/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4603 - val_loss: 10.8364\n",
      "Epoch 379/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4305 - val_loss: 11.4736\n",
      "Epoch 380/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.7248 - val_loss: 11.9374\n",
      "Epoch 381/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7458 - val_loss: 13.1009\n",
      "Epoch 382/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5368 - val_loss: 10.4926\n",
      "Epoch 383/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6151 - val_loss: 14.8893\n",
      "Epoch 384/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7458 - val_loss: 11.1053\n",
      "Epoch 385/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6446 - val_loss: 11.4450\n",
      "Epoch 386/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7303 - val_loss: 11.0040\n",
      "Epoch 387/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6036 - val_loss: 10.3138\n",
      "Epoch 388/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6217 - val_loss: 11.5027\n",
      "Epoch 389/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4465 - val_loss: 10.1969\n",
      "Epoch 390/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6213 - val_loss: 11.6235\n",
      "Epoch 391/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4245 - val_loss: 12.9714\n",
      "Epoch 392/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6851 - val_loss: 12.8255\n",
      "Epoch 393/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3174 - val_loss: 10.9450\n",
      "Epoch 394/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5557 - val_loss: 12.9800\n",
      "Epoch 395/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6585 - val_loss: 14.4087\n",
      "Epoch 396/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2123 - val_loss: 12.8257\n",
      "Epoch 397/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3239 - val_loss: 10.9179\n",
      "Epoch 398/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7001 - val_loss: 10.5082\n",
      "Epoch 399/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6719 - val_loss: 12.1428\n",
      "Epoch 400/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1391 - val_loss: 11.0370\n",
      "Epoch 401/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5254 - val_loss: 12.8086\n",
      "Epoch 402/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5337 - val_loss: 10.9844\n",
      "Epoch 403/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7289 - val_loss: 12.3497\n",
      "Epoch 404/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7581 - val_loss: 12.3308\n",
      "Epoch 405/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4334 - val_loss: 10.3608\n",
      "Epoch 406/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3329 - val_loss: 9.9053\n",
      "Epoch 407/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3126 - val_loss: 11.7719\n",
      "Epoch 408/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3155 - val_loss: 12.2321\n",
      "Epoch 409/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.1999 - val_loss: 10.1163\n",
      "Epoch 410/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2064 - val_loss: 10.9418\n",
      "Epoch 411/1000\n",
      "1052/1052 [==============================] - 0s 71us/step - loss: 9.5820 - val_loss: 15.6191\n",
      "Epoch 412/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.8587 - val_loss: 11.1401\n",
      "Epoch 413/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4643 - val_loss: 10.1002\n",
      "Epoch 414/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2327 - val_loss: 9.7734\n",
      "Epoch 415/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5457 - val_loss: 12.6243\n",
      "Epoch 416/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3850 - val_loss: 10.4136\n",
      "Epoch 417/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6096 - val_loss: 9.7756\n",
      "Epoch 418/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5064 - val_loss: 10.2095\n",
      "Epoch 419/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.5266 - val_loss: 13.1910\n",
      "Epoch 420/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0363 - val_loss: 10.4959\n",
      "Epoch 421/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3764 - val_loss: 11.4391\n",
      "Epoch 422/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5620 - val_loss: 13.0471\n",
      "Epoch 423/1000\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 9.1393 - val_loss: 15.5861\n",
      "Epoch 424/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6746 - val_loss: 10.1205\n",
      "Epoch 425/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6053 - val_loss: 15.6131\n",
      "Epoch 426/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7902 - val_loss: 10.4189\n",
      "Epoch 427/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0351 - val_loss: 10.5697\n",
      "Epoch 428/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8084 - val_loss: 10.0501\n",
      "Epoch 429/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2888 - val_loss: 10.3647\n",
      "Epoch 430/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3949 - val_loss: 10.3698\n",
      "Epoch 431/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5130 - val_loss: 10.1897\n",
      "Epoch 432/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3367 - val_loss: 10.3897\n",
      "Epoch 433/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4999 - val_loss: 12.8465\n",
      "Epoch 434/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.7054 - val_loss: 11.4919\n",
      "Epoch 435/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0389 - val_loss: 15.3565\n",
      "Epoch 436/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.7298 - val_loss: 10.5910\n",
      "Epoch 437/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4677 - val_loss: 13.0809\n",
      "Epoch 438/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2049 - val_loss: 10.6736\n",
      "Epoch 439/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6131 - val_loss: 10.9690\n",
      "Epoch 440/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.9414 - val_loss: 9.8053\n",
      "Epoch 441/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3514 - val_loss: 10.4933\n",
      "Epoch 442/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2618 - val_loss: 11.5406\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4541 - val_loss: 13.7589\n",
      "Epoch 444/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.8396 - val_loss: 11.3595\n",
      "Epoch 445/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.7795 - val_loss: 11.6462\n",
      "Epoch 446/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8474 - val_loss: 10.4240\n",
      "Epoch 447/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2970 - val_loss: 12.0565\n",
      "Epoch 448/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1627 - val_loss: 9.9575\n",
      "Epoch 449/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0054 - val_loss: 13.9717\n",
      "Epoch 450/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2877 - val_loss: 11.5575\n",
      "Epoch 451/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8214 - val_loss: 10.4048\n",
      "Epoch 452/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8543 - val_loss: 10.5952\n",
      "Epoch 453/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5088 - val_loss: 16.6943\n",
      "Epoch 454/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.7510 - val_loss: 11.1663\n",
      "Epoch 455/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4825 - val_loss: 10.0836\n",
      "Epoch 456/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9574 - val_loss: 11.4536\n",
      "Epoch 457/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8095 - val_loss: 10.2549\n",
      "Epoch 458/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4018 - val_loss: 11.5653\n",
      "Epoch 459/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 10.0338 - val_loss: 10.3878\n",
      "Epoch 460/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1542 - val_loss: 14.1923\n",
      "Epoch 461/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1216 - val_loss: 11.0452\n",
      "Epoch 462/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8366 - val_loss: 10.5233\n",
      "Epoch 463/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0306 - val_loss: 14.4342\n",
      "Epoch 464/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2340 - val_loss: 11.6716\n",
      "Epoch 465/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5308 - val_loss: 11.0012\n",
      "Epoch 466/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6632 - val_loss: 11.7134\n",
      "Epoch 467/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2954 - val_loss: 10.8162\n",
      "Epoch 468/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1955 - val_loss: 12.3402\n",
      "Epoch 469/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4910 - val_loss: 12.4642\n",
      "Epoch 470/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6666 - val_loss: 10.1352\n",
      "Epoch 471/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2432 - val_loss: 10.2077\n",
      "Epoch 472/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4803 - val_loss: 10.6361\n",
      "Epoch 473/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3805 - val_loss: 10.2366\n",
      "Epoch 474/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1428 - val_loss: 10.4422\n",
      "Epoch 475/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3083 - val_loss: 9.8154\n",
      "Epoch 476/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1332 - val_loss: 13.8042\n",
      "Epoch 477/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5290 - val_loss: 12.7795\n",
      "Epoch 478/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5052 - val_loss: 10.6750\n",
      "Epoch 479/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2827 - val_loss: 9.9159\n",
      "Epoch 480/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0386 - val_loss: 11.5373\n",
      "Epoch 481/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5663 - val_loss: 10.1361\n",
      "Epoch 482/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.6896 - val_loss: 10.0970\n",
      "Epoch 483/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5677 - val_loss: 12.9022\n",
      "Epoch 484/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6523 - val_loss: 10.5015\n",
      "Epoch 485/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2237 - val_loss: 11.9851\n",
      "Epoch 486/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3843 - val_loss: 11.9346\n",
      "Epoch 487/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3380 - val_loss: 10.6039\n",
      "Epoch 488/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4942 - val_loss: 10.2538\n",
      "Epoch 489/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5827 - val_loss: 10.4818\n",
      "Epoch 490/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4224 - val_loss: 12.1121\n",
      "Epoch 491/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4371 - val_loss: 10.8511\n",
      "Epoch 492/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4917 - val_loss: 9.8858\n",
      "Epoch 493/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3093 - val_loss: 10.8707\n",
      "Epoch 494/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4394 - val_loss: 10.3970\n",
      "Epoch 495/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4331 - val_loss: 16.3396\n",
      "Epoch 496/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8497 - val_loss: 12.9407\n",
      "Epoch 497/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4874 - val_loss: 10.0783\n",
      "Epoch 498/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2001 - val_loss: 11.5565\n",
      "Epoch 499/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5866 - val_loss: 10.3278\n",
      "Epoch 500/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1341 - val_loss: 9.9721\n",
      "Epoch 501/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5089 - val_loss: 16.3270\n",
      "Epoch 502/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.5512 - val_loss: 10.1232\n",
      "Epoch 503/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2704 - val_loss: 10.6567\n",
      "Epoch 504/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5526 - val_loss: 9.9014\n",
      "Epoch 505/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2767 - val_loss: 10.9544\n",
      "Epoch 506/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3607 - val_loss: 9.9575\n",
      "Epoch 507/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5938 - val_loss: 10.2757\n",
      "Epoch 508/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1840 - val_loss: 10.8955\n",
      "Epoch 509/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4421 - val_loss: 11.9417\n",
      "Epoch 510/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2700 - val_loss: 11.9552\n",
      "Epoch 511/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4690 - val_loss: 10.0540\n",
      "Epoch 512/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2715 - val_loss: 12.3568\n",
      "Epoch 513/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3540 - val_loss: 18.2403\n",
      "Epoch 514/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4482 - val_loss: 12.5756\n",
      "Epoch 515/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1886 - val_loss: 17.9144\n",
      "Epoch 516/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.8300 - val_loss: 11.4925\n",
      "Epoch 517/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0645 - val_loss: 10.5130\n",
      "Epoch 518/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5928 - val_loss: 10.2253\n",
      "Epoch 519/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.8892 - val_loss: 11.1135\n",
      "Epoch 520/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6676 - val_loss: 12.2904\n",
      "Epoch 521/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4235 - val_loss: 10.8504\n",
      "Epoch 522/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0757 - val_loss: 13.3075\n",
      "Epoch 523/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5606 - val_loss: 10.0502\n",
      "Epoch 524/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.5200 - val_loss: 10.3897\n",
      "Epoch 525/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2699 - val_loss: 11.2341\n",
      "Epoch 526/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3571 - val_loss: 10.6253\n",
      "Epoch 527/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9989 - val_loss: 14.6826\n",
      "Epoch 528/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2784 - val_loss: 12.4319\n",
      "Epoch 529/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.6065 - val_loss: 9.5867\n",
      "Epoch 530/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8957 - val_loss: 11.7714\n",
      "Epoch 531/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3164 - val_loss: 11.6339\n",
      "Epoch 532/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.9343 - val_loss: 10.2731\n",
      "Epoch 533/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1247 - val_loss: 10.5434\n",
      "Epoch 534/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2964 - val_loss: 10.2489\n",
      "Epoch 535/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8721 - val_loss: 11.1690\n",
      "Epoch 536/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0612 - val_loss: 9.8580\n",
      "Epoch 537/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2728 - val_loss: 9.7799\n",
      "Epoch 538/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4415 - val_loss: 10.4994\n",
      "Epoch 539/1000\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 9.2958 - val_loss: 10.2046\n",
      "Epoch 540/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9769 - val_loss: 13.4128\n",
      "Epoch 541/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4430 - val_loss: 10.4142\n",
      "Epoch 542/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0744 - val_loss: 10.0065\n",
      "Epoch 543/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.4481 - val_loss: 9.9520\n",
      "Epoch 544/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.0027 - val_loss: 15.2938\n",
      "Epoch 545/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.4003 - val_loss: 11.3783\n",
      "Epoch 546/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.1473 - val_loss: 10.1525\n",
      "Epoch 547/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.3075 - val_loss: 10.6748\n",
      "Epoch 548/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1156 - val_loss: 9.6291\n",
      "Epoch 549/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7011 - val_loss: 9.5282\n",
      "Epoch 550/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2499 - val_loss: 10.2775\n",
      "Epoch 551/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3654 - val_loss: 13.1256\n",
      "Epoch 552/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4782 - val_loss: 10.1499\n",
      "Epoch 553/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2233 - val_loss: 11.1104\n",
      "Epoch 554/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6988 - val_loss: 10.4954\n",
      "Epoch 555/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2283 - val_loss: 9.8318\n",
      "Epoch 556/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9451 - val_loss: 13.0403\n",
      "Epoch 557/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4550 - val_loss: 10.4613\n",
      "Epoch 558/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9708 - val_loss: 11.7219\n",
      "Epoch 559/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8687 - val_loss: 10.8546\n",
      "Epoch 560/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4439 - val_loss: 10.8322\n",
      "Epoch 561/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0620 - val_loss: 9.8729\n",
      "Epoch 562/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4425 - val_loss: 11.7330\n",
      "Epoch 563/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3437 - val_loss: 10.7895\n",
      "Epoch 564/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0828 - val_loss: 10.0107\n",
      "Epoch 565/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3303 - val_loss: 9.9694\n",
      "Epoch 566/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0711 - val_loss: 10.3631\n",
      "Epoch 567/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1570 - val_loss: 9.7770\n",
      "Epoch 568/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2256 - val_loss: 13.4557\n",
      "Epoch 569/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.8270 - val_loss: 9.7283\n",
      "Epoch 570/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0945 - val_loss: 15.8140\n",
      "Epoch 571/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3167 - val_loss: 10.2709\n",
      "Epoch 572/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1121 - val_loss: 16.1417\n",
      "Epoch 573/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3019 - val_loss: 11.4856\n",
      "Epoch 574/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5219 - val_loss: 11.7933\n",
      "Epoch 575/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3598 - val_loss: 10.0784\n",
      "Epoch 576/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5619 - val_loss: 13.3005\n",
      "Epoch 577/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4185 - val_loss: 12.3543\n",
      "Epoch 578/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3346 - val_loss: 9.8926\n",
      "Epoch 579/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.6270 - val_loss: 11.6981\n",
      "Epoch 580/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2218 - val_loss: 9.7310\n",
      "Epoch 581/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0829 - val_loss: 10.4825\n",
      "Epoch 582/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1663 - val_loss: 11.5634\n",
      "Epoch 583/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3657 - val_loss: 9.8481\n",
      "Epoch 584/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9197 - val_loss: 9.8409\n",
      "Epoch 585/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1148 - val_loss: 11.8459\n",
      "Epoch 586/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3018 - val_loss: 10.3564\n",
      "Epoch 587/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3893 - val_loss: 9.9407\n",
      "Epoch 588/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4476 - val_loss: 10.3500\n",
      "Epoch 589/1000\n",
      "1052/1052 [==============================] - 0s 72us/step - loss: 8.8525 - val_loss: 10.7833\n",
      "Epoch 590/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2766 - val_loss: 10.1469\n",
      "Epoch 591/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2896 - val_loss: 10.8179\n",
      "Epoch 592/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.7555 - val_loss: 10.3558\n",
      "Epoch 593/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3978 - val_loss: 12.0063\n",
      "Epoch 594/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.7050 - val_loss: 10.4225\n",
      "Epoch 595/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5795 - val_loss: 12.1064\n",
      "Epoch 596/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.6693 - val_loss: 9.5184\n",
      "Epoch 597/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3360 - val_loss: 10.8996\n",
      "Epoch 598/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 8.7547 - val_loss: 11.3680\n",
      "Epoch 599/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4629 - val_loss: 9.7562\n",
      "Epoch 600/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.7376 - val_loss: 9.4349\n",
      "Epoch 601/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4792 - val_loss: 10.1646\n",
      "Epoch 602/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5679 - val_loss: 10.9516\n",
      "Epoch 603/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1001 - val_loss: 14.2621\n",
      "Epoch 604/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4060 - val_loss: 10.1554\n",
      "Epoch 605/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2090 - val_loss: 10.9618\n",
      "Epoch 606/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3296 - val_loss: 9.8340\n",
      "Epoch 607/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3835 - val_loss: 9.7136\n",
      "Epoch 608/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3450 - val_loss: 9.8242\n",
      "Epoch 609/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1507 - val_loss: 13.1995\n",
      "Epoch 610/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3634 - val_loss: 10.9984\n",
      "Epoch 611/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3140 - val_loss: 11.8464\n",
      "Epoch 612/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9621 - val_loss: 10.1997\n",
      "Epoch 613/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2434 - val_loss: 12.4180\n",
      "Epoch 614/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2611 - val_loss: 11.6675\n",
      "Epoch 615/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.6626 - val_loss: 9.6174\n",
      "Epoch 616/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2923 - val_loss: 10.7765\n",
      "Epoch 617/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1905 - val_loss: 10.5223\n",
      "Epoch 618/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6419 - val_loss: 9.7721\n",
      "Epoch 619/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0548 - val_loss: 11.7538\n",
      "Epoch 620/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1792 - val_loss: 9.9198\n",
      "Epoch 621/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.6971 - val_loss: 10.0983\n",
      "Epoch 622/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3076 - val_loss: 10.4214\n",
      "Epoch 623/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2218 - val_loss: 9.8839\n",
      "Epoch 624/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0073 - val_loss: 10.5302\n",
      "Epoch 625/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.3694 - val_loss: 10.6743\n",
      "Epoch 626/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0423 - val_loss: 9.7026\n",
      "Epoch 627/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2462 - val_loss: 11.2040\n",
      "Epoch 628/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8702 - val_loss: 10.6338\n",
      "Epoch 629/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.9615 - val_loss: 9.4997\n",
      "Epoch 630/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8112 - val_loss: 10.2169\n",
      "Epoch 631/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6432 - val_loss: 9.6864\n",
      "Epoch 632/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0376 - val_loss: 10.0578\n",
      "Epoch 633/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1017 - val_loss: 15.2361\n",
      "Epoch 634/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.0818 - val_loss: 10.4239\n",
      "Epoch 635/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2048 - val_loss: 11.4647\n",
      "Epoch 636/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3769 - val_loss: 12.9934\n",
      "Epoch 637/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8761 - val_loss: 10.8603\n",
      "Epoch 638/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2174 - val_loss: 10.7307\n",
      "Epoch 639/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3380 - val_loss: 10.4885\n",
      "Epoch 640/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2567 - val_loss: 10.5861\n",
      "Epoch 641/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9554 - val_loss: 10.0378\n",
      "Epoch 642/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0962 - val_loss: 10.2048\n",
      "Epoch 643/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1188 - val_loss: 13.4090\n",
      "Epoch 644/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1059 - val_loss: 15.5258\n",
      "Epoch 645/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4532 - val_loss: 11.0453\n",
      "Epoch 646/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9073 - val_loss: 11.5575\n",
      "Epoch 647/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1187 - val_loss: 18.8412\n",
      "Epoch 648/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5206 - val_loss: 11.4556\n",
      "Epoch 649/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4597 - val_loss: 11.5237\n",
      "Epoch 650/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0478 - val_loss: 9.9392\n",
      "Epoch 651/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.2239 - val_loss: 12.0984\n",
      "Epoch 652/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.6229 - val_loss: 10.1851\n",
      "Epoch 653/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4380 - val_loss: 9.7685\n",
      "Epoch 654/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3647 - val_loss: 9.6759\n",
      "Epoch 655/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2978 - val_loss: 10.4641\n",
      "Epoch 656/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4071 - val_loss: 9.7413\n",
      "Epoch 657/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2843 - val_loss: 13.0536\n",
      "Epoch 658/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4942 - val_loss: 9.4402\n",
      "Epoch 659/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8252 - val_loss: 9.7058\n",
      "Epoch 660/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1679 - val_loss: 11.4232\n",
      "Epoch 661/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1346 - val_loss: 12.1523\n",
      "Epoch 662/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3831 - val_loss: 10.8818\n",
      "Epoch 663/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3804 - val_loss: 9.9163\n",
      "Epoch 664/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1131 - val_loss: 9.7563\n",
      "Epoch 665/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2004 - val_loss: 9.8824\n",
      "Epoch 666/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3524 - val_loss: 12.7446\n",
      "Epoch 667/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2958 - val_loss: 10.1218\n",
      "Epoch 668/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2430 - val_loss: 12.3968\n",
      "Epoch 669/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1955 - val_loss: 12.1195\n",
      "Epoch 670/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1781 - val_loss: 10.6240\n",
      "Epoch 671/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4439 - val_loss: 9.7589\n",
      "Epoch 672/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.2224 - val_loss: 10.7086\n",
      "Epoch 673/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4353 - val_loss: 10.1495\n",
      "Epoch 674/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3870 - val_loss: 9.6937\n",
      "Epoch 675/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0922 - val_loss: 10.0849\n",
      "Epoch 676/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3733 - val_loss: 13.3896\n",
      "Epoch 677/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4696 - val_loss: 11.5546\n",
      "Epoch 678/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0990 - val_loss: 10.8745\n",
      "Epoch 679/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9947 - val_loss: 9.8591\n",
      "Epoch 680/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3764 - val_loss: 12.2097\n",
      "Epoch 681/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0354 - val_loss: 11.2355\n",
      "Epoch 682/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 8.8024 - val_loss: 11.8710\n",
      "Epoch 683/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3046 - val_loss: 16.3865\n",
      "Epoch 684/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2257 - val_loss: 15.1181\n",
      "Epoch 685/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.5425 - val_loss: 10.6606\n",
      "Epoch 686/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1041 - val_loss: 12.8420\n",
      "Epoch 687/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0650 - val_loss: 9.5840\n",
      "Epoch 688/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3926 - val_loss: 9.7532\n",
      "Epoch 689/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9985 - val_loss: 10.3115\n",
      "Epoch 690/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2220 - val_loss: 11.5987\n",
      "Epoch 691/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2115 - val_loss: 10.5768\n",
      "Epoch 692/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0833 - val_loss: 9.6425\n",
      "Epoch 693/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1215 - val_loss: 13.7028\n",
      "Epoch 694/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7618 - val_loss: 11.8208\n",
      "Epoch 695/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6451 - val_loss: 9.5784\n",
      "Epoch 696/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1217 - val_loss: 13.2213\n",
      "Epoch 697/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3638 - val_loss: 11.8408\n",
      "Epoch 698/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0488 - val_loss: 9.9080\n",
      "Epoch 699/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1363 - val_loss: 10.6825\n",
      "Epoch 700/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0733 - val_loss: 12.9638\n",
      "Epoch 701/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3604 - val_loss: 9.6873\n",
      "Epoch 702/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2286 - val_loss: 10.3237\n",
      "Epoch 703/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3077 - val_loss: 12.9133\n",
      "Epoch 704/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1622 - val_loss: 10.0208\n",
      "Epoch 705/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5562 - val_loss: 10.8027\n",
      "Epoch 706/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1325 - val_loss: 13.1982\n",
      "Epoch 707/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3960 - val_loss: 12.5002\n",
      "Epoch 708/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0759 - val_loss: 14.2522\n",
      "Epoch 709/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2097 - val_loss: 10.5095\n",
      "Epoch 710/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0847 - val_loss: 9.9265\n",
      "Epoch 711/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2803 - val_loss: 12.2293\n",
      "Epoch 712/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3644 - val_loss: 9.4189\n",
      "Epoch 713/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2108 - val_loss: 12.6938\n",
      "Epoch 714/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8249 - val_loss: 11.7448\n",
      "Epoch 715/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2578 - val_loss: 12.9757\n",
      "Epoch 716/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4196 - val_loss: 10.5891\n",
      "Epoch 717/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9104 - val_loss: 9.6305\n",
      "Epoch 718/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9416 - val_loss: 10.4055\n",
      "Epoch 719/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3516 - val_loss: 10.6407\n",
      "Epoch 720/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0560 - val_loss: 11.7443\n",
      "Epoch 721/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4954 - val_loss: 14.0003\n",
      "Epoch 722/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9857 - val_loss: 10.0558\n",
      "Epoch 723/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4136 - val_loss: 12.1888\n",
      "Epoch 724/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1415 - val_loss: 10.3894\n",
      "Epoch 725/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.1255 - val_loss: 9.9642\n",
      "Epoch 726/1000\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 8.9901 - val_loss: 11.3139\n",
      "Epoch 727/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.5734 - val_loss: 10.4173\n",
      "Epoch 728/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8194 - val_loss: 14.9385\n",
      "Epoch 729/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4945 - val_loss: 10.4427\n",
      "Epoch 730/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9970 - val_loss: 17.4981\n",
      "Epoch 731/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.1618 - val_loss: 16.6647\n",
      "Epoch 732/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4498 - val_loss: 9.6346\n",
      "Epoch 733/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 8.8955 - val_loss: 9.7241\n",
      "Epoch 734/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2898 - val_loss: 9.6863\n",
      "Epoch 735/1000\n",
      "1052/1052 [==============================] - 0s 74us/step - loss: 9.3821 - val_loss: 10.1125\n",
      "Epoch 736/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2350 - val_loss: 10.3040\n",
      "Epoch 737/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2161 - val_loss: 10.3092\n",
      "Epoch 738/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2022 - val_loss: 9.7108\n",
      "Epoch 739/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1932 - val_loss: 12.1123\n",
      "Epoch 740/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4668 - val_loss: 9.7707\n",
      "Epoch 741/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.6994 - val_loss: 9.5105\n",
      "Epoch 742/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.8982 - val_loss: 11.9395\n",
      "Epoch 743/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9988 - val_loss: 14.4150\n",
      "Epoch 744/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9495 - val_loss: 9.6587\n",
      "Epoch 745/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1546 - val_loss: 12.2690\n",
      "Epoch 746/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3885 - val_loss: 9.6445\n",
      "Epoch 747/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8451 - val_loss: 9.4752\n",
      "Epoch 748/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4292 - val_loss: 10.0086\n",
      "Epoch 749/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3051 - val_loss: 9.6659\n",
      "Epoch 750/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1827 - val_loss: 10.0557\n",
      "Epoch 751/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.6111 - val_loss: 9.6364\n",
      "Epoch 752/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0204 - val_loss: 9.9835\n",
      "Epoch 753/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2823 - val_loss: 10.6701\n",
      "Epoch 754/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0151 - val_loss: 9.8502\n",
      "Epoch 755/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.4859 - val_loss: 13.6392\n",
      "Epoch 756/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2129 - val_loss: 10.3276\n",
      "Epoch 757/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.1910 - val_loss: 9.7251\n",
      "Epoch 758/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.8936 - val_loss: 10.5227\n",
      "Epoch 759/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2355 - val_loss: 12.8521\n",
      "Epoch 760/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2958 - val_loss: 14.7443\n",
      "Epoch 761/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2910 - val_loss: 16.2493\n",
      "Epoch 762/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1342 - val_loss: 10.2458\n",
      "Epoch 763/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4045 - val_loss: 9.4738\n",
      "Epoch 764/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9394 - val_loss: 9.6922\n",
      "Epoch 765/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2548 - val_loss: 13.3236\n",
      "Epoch 766/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1759 - val_loss: 11.4582\n",
      "Epoch 767/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2279 - val_loss: 10.5553\n",
      "Epoch 768/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.3408 - val_loss: 10.2402\n",
      "Epoch 769/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4106 - val_loss: 9.5783\n",
      "Epoch 770/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1711 - val_loss: 10.8733\n",
      "Epoch 771/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1394 - val_loss: 10.2991\n",
      "Epoch 772/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0079 - val_loss: 13.2267\n",
      "Epoch 773/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4202 - val_loss: 10.1390\n",
      "Epoch 774/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0344 - val_loss: 11.2048\n",
      "Epoch 775/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1231 - val_loss: 9.7843\n",
      "Epoch 776/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.8693 - val_loss: 14.6624\n",
      "Epoch 777/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.0318 - val_loss: 10.1932\n",
      "Epoch 778/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.6988 - val_loss: 9.6808\n",
      "Epoch 779/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0696 - val_loss: 10.3719\n",
      "Epoch 780/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1016 - val_loss: 9.6228\n",
      "Epoch 781/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2921 - val_loss: 10.0296\n",
      "Epoch 782/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.3450 - val_loss: 9.6157\n",
      "Epoch 783/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1246 - val_loss: 9.8932\n",
      "Epoch 784/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3120 - val_loss: 11.5714\n",
      "Epoch 785/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1173 - val_loss: 9.8746\n",
      "Epoch 786/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.5978 - val_loss: 9.6028\n",
      "Epoch 787/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.5174 - val_loss: 14.1535\n",
      "Epoch 788/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.5528 - val_loss: 10.9947\n",
      "Epoch 789/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2052 - val_loss: 9.8625\n",
      "Epoch 790/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4057 - val_loss: 10.0363\n",
      "Epoch 791/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8031 - val_loss: 10.3796\n",
      "Epoch 792/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7794 - val_loss: 12.7536\n",
      "Epoch 793/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1076 - val_loss: 13.0854\n",
      "Epoch 794/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9465 - val_loss: 9.4863\n",
      "Epoch 795/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2863 - val_loss: 10.0321\n",
      "Epoch 796/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2041 - val_loss: 9.4184\n",
      "Epoch 797/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0012 - val_loss: 12.1540\n",
      "Epoch 798/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3920 - val_loss: 14.0209\n",
      "Epoch 799/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0334 - val_loss: 10.3697\n",
      "Epoch 800/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.0473 - val_loss: 11.2564\n",
      "Epoch 801/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1360 - val_loss: 9.6782\n",
      "Epoch 802/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4921 - val_loss: 10.5293\n",
      "Epoch 803/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2645 - val_loss: 10.7083\n",
      "Epoch 804/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2435 - val_loss: 10.0199\n",
      "Epoch 805/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0015 - val_loss: 9.4616\n",
      "Epoch 806/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4188 - val_loss: 9.7559\n",
      "Epoch 807/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0642 - val_loss: 9.2336\n",
      "Epoch 808/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.5575 - val_loss: 10.4417\n",
      "Epoch 809/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.7671 - val_loss: 10.3102\n",
      "Epoch 810/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3914 - val_loss: 11.5347\n",
      "Epoch 811/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0015 - val_loss: 10.0815\n",
      "Epoch 812/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3291 - val_loss: 9.7134\n",
      "Epoch 813/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9432 - val_loss: 10.8983\n",
      "Epoch 814/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4030 - val_loss: 10.1364\n",
      "Epoch 815/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8578 - val_loss: 10.4782\n",
      "Epoch 816/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1641 - val_loss: 9.3194\n",
      "Epoch 817/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1501 - val_loss: 12.6003\n",
      "Epoch 818/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3309 - val_loss: 10.5113\n",
      "Epoch 819/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.5921 - val_loss: 13.2026\n",
      "Epoch 820/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1283 - val_loss: 9.7325\n",
      "Epoch 821/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2376 - val_loss: 9.8931\n",
      "Epoch 822/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1051 - val_loss: 9.8345\n",
      "Epoch 823/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8875 - val_loss: 11.9768\n",
      "Epoch 824/1000\n",
      "1052/1052 [==============================] - 0s 90us/step - loss: 9.2874 - val_loss: 9.8136\n",
      "Epoch 825/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2799 - val_loss: 9.5913\n",
      "Epoch 826/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0596 - val_loss: 9.6589\n",
      "Epoch 827/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.2857 - val_loss: 10.3445\n",
      "Epoch 828/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0509 - val_loss: 10.3620\n",
      "Epoch 829/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1552 - val_loss: 11.0458\n",
      "Epoch 830/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1378 - val_loss: 10.9479\n",
      "Epoch 831/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1000 - val_loss: 9.8757\n",
      "Epoch 832/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4595 - val_loss: 10.2470\n",
      "Epoch 833/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2288 - val_loss: 9.6255\n",
      "Epoch 834/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9820 - val_loss: 10.9943\n",
      "Epoch 835/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4626 - val_loss: 9.9659\n",
      "Epoch 836/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9259 - val_loss: 9.5666\n",
      "Epoch 837/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0969 - val_loss: 12.2199\n",
      "Epoch 838/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0208 - val_loss: 10.6790\n",
      "Epoch 839/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2026 - val_loss: 11.8997\n",
      "Epoch 840/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3393 - val_loss: 11.0917\n",
      "Epoch 841/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9206 - val_loss: 11.6528\n",
      "Epoch 842/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0907 - val_loss: 11.3901\n",
      "Epoch 843/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2873 - val_loss: 11.9767\n",
      "Epoch 844/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0285 - val_loss: 10.4169\n",
      "Epoch 845/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.2074 - val_loss: 11.1041\n",
      "Epoch 846/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1582 - val_loss: 11.6047\n",
      "Epoch 847/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1714 - val_loss: 10.7427\n",
      "Epoch 848/1000\n",
      "1052/1052 [==============================] - 0s 87us/step - loss: 9.2356 - val_loss: 11.5554\n",
      "Epoch 849/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.6703 - val_loss: 11.0384\n",
      "Epoch 850/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5357 - val_loss: 12.6162\n",
      "Epoch 851/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0227 - val_loss: 9.5383\n",
      "Epoch 852/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7553 - val_loss: 12.2407\n",
      "Epoch 853/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3767 - val_loss: 9.4426\n",
      "Epoch 854/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1346 - val_loss: 13.5505\n",
      "Epoch 855/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4872 - val_loss: 10.0463\n",
      "Epoch 856/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.6274 - val_loss: 9.5208\n",
      "Epoch 857/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4856 - val_loss: 9.6000\n",
      "Epoch 858/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.9069 - val_loss: 9.4971\n",
      "Epoch 859/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1132 - val_loss: 11.4205\n",
      "Epoch 860/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2142 - val_loss: 10.0353\n",
      "Epoch 861/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7243 - val_loss: 9.5878\n",
      "Epoch 862/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2601 - val_loss: 10.0556\n",
      "Epoch 863/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.4500 - val_loss: 15.5452\n",
      "Epoch 864/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9923 - val_loss: 11.4526\n",
      "Epoch 865/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.4095 - val_loss: 10.3935\n",
      "Epoch 866/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.7933 - val_loss: 13.1528\n",
      "Epoch 867/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.8344 - val_loss: 10.1068\n",
      "Epoch 868/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0686 - val_loss: 12.5933\n",
      "Epoch 869/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8061 - val_loss: 10.0138\n",
      "Epoch 870/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1944 - val_loss: 11.5928\n",
      "Epoch 871/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1260 - val_loss: 10.0657\n",
      "Epoch 872/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1773 - val_loss: 12.1563\n",
      "Epoch 873/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0710 - val_loss: 9.2243\n",
      "Epoch 874/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0761 - val_loss: 9.5972\n",
      "Epoch 875/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1736 - val_loss: 9.7611\n",
      "Epoch 876/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1972 - val_loss: 9.6124\n",
      "Epoch 877/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1909 - val_loss: 9.5436\n",
      "Epoch 878/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.8153 - val_loss: 10.4971\n",
      "Epoch 879/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.3335 - val_loss: 9.8595\n",
      "Epoch 880/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0677 - val_loss: 15.7549\n",
      "Epoch 881/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1031 - val_loss: 13.7407\n",
      "Epoch 882/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 8.9361 - val_loss: 16.9331\n",
      "Epoch 883/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9001 - val_loss: 12.4731\n",
      "Epoch 884/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3492 - val_loss: 10.3504\n",
      "Epoch 885/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.7760 - val_loss: 11.4113\n",
      "Epoch 886/1000\n",
      "1052/1052 [==============================] - 0s 73us/step - loss: 9.4744 - val_loss: 10.1939\n",
      "Epoch 887/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2168 - val_loss: 9.7336\n",
      "Epoch 888/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.8322 - val_loss: 9.6234\n",
      "Epoch 889/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.6132 - val_loss: 9.8554\n",
      "Epoch 890/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3536 - val_loss: 9.3610\n",
      "Epoch 891/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8851 - val_loss: 12.0878\n",
      "Epoch 892/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0343 - val_loss: 10.7527\n",
      "Epoch 893/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4972 - val_loss: 11.0738\n",
      "Epoch 894/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.9287 - val_loss: 10.5184\n",
      "Epoch 895/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.3489 - val_loss: 9.6115\n",
      "Epoch 896/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3529 - val_loss: 9.6974\n",
      "Epoch 897/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0716 - val_loss: 10.2935\n",
      "Epoch 898/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2141 - val_loss: 10.0056\n",
      "Epoch 899/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1055 - val_loss: 9.8625\n",
      "Epoch 900/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2758 - val_loss: 9.8879\n",
      "Epoch 901/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3619 - val_loss: 11.7187\n",
      "Epoch 902/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2595 - val_loss: 9.3398\n",
      "Epoch 903/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 8.9784 - val_loss: 11.6372\n",
      "Epoch 904/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.5108 - val_loss: 12.6885\n",
      "Epoch 905/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 8.7398 - val_loss: 9.6111\n",
      "Epoch 906/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.1471 - val_loss: 18.9839\n",
      "Epoch 907/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.2840 - val_loss: 11.0295\n",
      "Epoch 908/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.7393 - val_loss: 9.7264\n",
      "Epoch 909/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9977 - val_loss: 9.4262\n",
      "Epoch 910/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1571 - val_loss: 11.7022\n",
      "Epoch 911/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.2023 - val_loss: 10.7756\n",
      "Epoch 912/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 9.2929 - val_loss: 9.7136\n",
      "Epoch 913/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7774 - val_loss: 10.5972\n",
      "Epoch 914/1000\n",
      "1052/1052 [==============================] - 0s 89us/step - loss: 9.4783 - val_loss: 10.0855\n",
      "Epoch 915/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.1207 - val_loss: 11.0239\n",
      "Epoch 916/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2795 - val_loss: 11.1520\n",
      "Epoch 917/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7038 - val_loss: 10.1480\n",
      "Epoch 918/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0270 - val_loss: 10.1526\n",
      "Epoch 919/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.2786 - val_loss: 10.1125\n",
      "Epoch 920/1000\n",
      "1052/1052 [==============================] - 0s 91us/step - loss: 8.8180 - val_loss: 9.8064\n",
      "Epoch 921/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2380 - val_loss: 10.7598\n",
      "Epoch 922/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8843 - val_loss: 11.3215\n",
      "Epoch 923/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3157 - val_loss: 9.2495\n",
      "Epoch 924/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1353 - val_loss: 10.2620\n",
      "Epoch 925/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5283 - val_loss: 9.7511\n",
      "Epoch 926/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.0150 - val_loss: 12.8338\n",
      "Epoch 927/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.4312 - val_loss: 10.9586\n",
      "Epoch 928/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0306 - val_loss: 11.2095\n",
      "Epoch 929/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.2859 - val_loss: 11.2194\n",
      "Epoch 930/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1362 - val_loss: 11.8921\n",
      "Epoch 931/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.5605 - val_loss: 10.1108\n",
      "Epoch 932/1000\n",
      "1052/1052 [==============================] - 0s 86us/step - loss: 9.0078 - val_loss: 17.1067\n",
      "Epoch 933/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7978 - val_loss: 13.0558\n",
      "Epoch 934/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 8.9265 - val_loss: 14.5331\n",
      "Epoch 935/1000\n",
      "1052/1052 [==============================] - 0s 75us/step - loss: 9.1522 - val_loss: 9.6533\n",
      "Epoch 936/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.0939 - val_loss: 9.8860\n",
      "Epoch 937/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4114 - val_loss: 9.9347\n",
      "Epoch 938/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0005 - val_loss: 10.7782\n",
      "Epoch 939/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1170 - val_loss: 15.1006\n",
      "Epoch 940/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3749 - val_loss: 9.7798\n",
      "Epoch 941/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.1613 - val_loss: 9.9526\n",
      "Epoch 942/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.0766 - val_loss: 10.9459\n",
      "Epoch 943/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 8.7571 - val_loss: 17.5709\n",
      "Epoch 944/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1746 - val_loss: 9.9670\n",
      "Epoch 945/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3462 - val_loss: 10.1718\n",
      "Epoch 946/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.0647 - val_loss: 12.9638\n",
      "Epoch 947/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.7782 - val_loss: 9.8379\n",
      "Epoch 948/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2334 - val_loss: 9.8104\n",
      "Epoch 949/1000\n",
      "1052/1052 [==============================] - 0s 85us/step - loss: 9.4363 - val_loss: 12.0093\n",
      "Epoch 950/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.3297 - val_loss: 13.9684\n",
      "Epoch 951/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1536 - val_loss: 9.4949\n",
      "Epoch 952/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 8.7556 - val_loss: 12.4906\n",
      "Epoch 953/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.3371 - val_loss: 11.0488\n",
      "Epoch 954/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1221 - val_loss: 14.4396\n",
      "Epoch 955/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.0599 - val_loss: 15.4285\n",
      "Epoch 956/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3772 - val_loss: 12.0590\n",
      "Epoch 957/1000\n",
      "1052/1052 [==============================] - 0s 76us/step - loss: 9.4171 - val_loss: 9.8968\n",
      "Epoch 958/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.1598 - val_loss: 11.7921\n",
      "Epoch 959/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.0476 - val_loss: 9.5822\n",
      "Epoch 960/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1686 - val_loss: 13.0278\n",
      "Epoch 961/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 8.9215 - val_loss: 9.8173\n",
      "Epoch 962/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2726 - val_loss: 10.3814\n",
      "Epoch 963/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.1313 - val_loss: 10.3256\n",
      "Epoch 964/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2102 - val_loss: 9.5744\n",
      "Epoch 965/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.4179 - val_loss: 9.5299\n",
      "Epoch 966/1000\n",
      "1052/1052 [==============================] - 0s 84us/step - loss: 9.1706 - val_loss: 9.7131\n",
      "Epoch 967/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5113 - val_loss: 9.5697\n",
      "Epoch 968/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1784 - val_loss: 9.8314\n",
      "Epoch 969/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2627 - val_loss: 9.9234\n",
      "Epoch 970/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.4908 - val_loss: 9.4537\n",
      "Epoch 971/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1558 - val_loss: 15.5919\n",
      "Epoch 972/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1593 - val_loss: 13.6460\n",
      "Epoch 973/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 9.0832 - val_loss: 10.3190\n",
      "Epoch 974/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8055 - val_loss: 10.8325\n",
      "Epoch 975/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1482 - val_loss: 10.5584\n",
      "Epoch 976/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2704 - val_loss: 9.3596\n",
      "Epoch 977/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 9.2949 - val_loss: 9.4754\n",
      "Epoch 978/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3136 - val_loss: 10.2756\n",
      "Epoch 979/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3032 - val_loss: 11.7979\n",
      "Epoch 980/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1763 - val_loss: 9.6323\n",
      "Epoch 981/1000\n",
      "1052/1052 [==============================] - 0s 78us/step - loss: 8.9183 - val_loss: 11.8745\n",
      "Epoch 982/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3701 - val_loss: 11.3295\n",
      "Epoch 983/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.2483 - val_loss: 15.8180\n",
      "Epoch 984/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9584 - val_loss: 10.8105\n",
      "Epoch 985/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.3208 - val_loss: 10.4518\n",
      "Epoch 986/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.1913 - val_loss: 15.7202\n",
      "Epoch 987/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9036 - val_loss: 9.8613\n",
      "Epoch 988/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.2028 - val_loss: 12.0736\n",
      "Epoch 989/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 9.1922 - val_loss: 9.5913\n",
      "Epoch 990/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3756 - val_loss: 9.9965\n",
      "Epoch 991/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.4054 - val_loss: 10.1748\n",
      "Epoch 992/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.9516 - val_loss: 9.4474\n",
      "Epoch 993/1000\n",
      "1052/1052 [==============================] - 0s 77us/step - loss: 9.0312 - val_loss: 11.0159\n",
      "Epoch 994/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.2165 - val_loss: 9.6189\n",
      "Epoch 995/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.5907 - val_loss: 9.8488\n",
      "Epoch 996/1000\n",
      "1052/1052 [==============================] - 0s 83us/step - loss: 8.8715 - val_loss: 10.5991\n",
      "Epoch 997/1000\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 9.1161 - val_loss: 9.4321\n",
      "Epoch 998/1000\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 9.3738 - val_loss: 9.6013\n",
      "Epoch 999/1000\n",
      "1052/1052 [==============================] - 0s 79us/step - loss: 9.3679 - val_loss: 10.1752\n",
      "Epoch 1000/1000\n",
      "1052/1052 [==============================] - 0s 82us/step - loss: 8.8232 - val_loss: 13.4564\n",
      "10.035002396170016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.23980168, -3.0775476 ,  1.9238695 ,  4.074303  , -0.52805436],\n",
       "        [ 0.26333433,  0.03217886, -0.42205986, -0.2658044 , -0.92313665],\n",
       "        [ 0.39308098, -0.01686005, -0.3811762 ,  0.75786495, -1.1825671 ],\n",
       "        [-0.20145257,  0.07780248, -0.08081143, -0.14767772,  0.21002544],\n",
       "        [ 0.21653584, -2.5301168 ,  0.285228  ,  0.37229577, -0.02353309]],\n",
       "       dtype=float32),\n",
       " array([-1.9731987, -4.580515 ,  1.2496729,  4.903427 , -0.6276174],\n",
       "       dtype=float32),\n",
       " array([[-1.700869  , -2.147959  , -2.216699  , -2.0911913 , -1.9612491 ,\n",
       "         -1.5509742 ,  2.0992248 , -2.1024323 ,  1.4332374 , -1.112386  ],\n",
       "        [-1.0053661 , -1.7048118 , -1.6520998 , -1.6725256 , -2.0499234 ,\n",
       "         -0.74319756,  1.5714961 , -1.7908423 ,  0.7960452 , -1.581173  ],\n",
       "        [-1.0406294 , -0.7054909 , -0.18988483, -0.9183626 ,  0.12353275,\n",
       "         -0.64403975, -0.06064613, -0.88460356,  0.82952344, -0.4889287 ],\n",
       "        [ 2.1049173 ,  1.156369  ,  1.6272953 ,  1.5907923 ,  1.3284103 ,\n",
       "          2.2337277 , -1.8486824 ,  2.1412861 , -1.6490252 ,  1.7044252 ],\n",
       "        [ 0.36633748,  0.80258965,  0.7478303 ,  0.02185939,  0.10574987,\n",
       "         -0.1311177 , -0.72554886,  0.6083767 ,  0.00924218,  0.6846914 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.9471437,  2.0311568,  2.0876083,  1.9538239,  2.0442479,\n",
       "         1.9695822, -2.0626388,  2.0733685, -2.0117984,  1.9531993],\n",
       "       dtype=float32),\n",
       " array([[ 1.6165497],\n",
       "        [ 1.9419814],\n",
       "        [ 2.196298 ],\n",
       "        [ 1.5263293],\n",
       "        [ 2.0315208],\n",
       "        [ 1.7174422],\n",
       "        [-2.0557978],\n",
       "        [ 2.1773708],\n",
       "        [-1.8235317],\n",
       "        [ 1.5959669]], dtype=float32),\n",
       " array([2.5900733], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_airfoil, history_airfoil, evaluate_airfoil=NN_model_structure_regression(X_train_airfoil, X_val_airfoil, Y_train_airfoil, Y_val_airfoil, RMSprop, 32, 1000, x_test_airfoil, y_test_airfoil)\n",
    "model_airfoil.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_airfoil.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_airfoil_rmsprop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 581us/step - loss: 526.9467 - val_loss: 285.9184\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 134.3754 - val_loss: 81.8906\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 54.1494 - val_loss: 34.6338\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 24.4476 - val_loss: 24.7437\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 17.4458 - val_loss: 21.7336\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 16.2238 - val_loss: 20.4876\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 14.9127 - val_loss: 19.7547\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.8768 - val_loss: 19.5030\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 12.7883 - val_loss: 18.9649\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 11.8289 - val_loss: 17.9986\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 11.3856 - val_loss: 17.3048\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 10.5421 - val_loss: 16.8281\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 10.2732 - val_loss: 15.8684\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.7470 - val_loss: 15.5475\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 9.6209 - val_loss: 14.6203\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.5493 - val_loss: 14.3440\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.9829 - val_loss: 13.7865\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 9.2408 - val_loss: 13.2952\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7539 - val_loss: 12.9115\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.6637 - val_loss: 12.3546\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 8.7001 - val_loss: 12.4782\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2994 - val_loss: 12.4502\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4050 - val_loss: 12.2994\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.2452 - val_loss: 11.5861\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3167 - val_loss: 11.5743\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.1172 - val_loss: 11.3919\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.0293 - val_loss: 11.3011\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9330 - val_loss: 11.2651\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8473 - val_loss: 11.1458\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8706 - val_loss: 10.8116\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.7410 - val_loss: 11.2243\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7164 - val_loss: 11.2599\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7661 - val_loss: 10.7826\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.298 - 0s 102us/step - loss: 7.6911 - val_loss: 11.1953\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5437 - val_loss: 10.8274\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4599 - val_loss: 11.0653\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6078 - val_loss: 10.7654\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5796 - val_loss: 10.7823\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.6635 - val_loss: 10.8603\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3890 - val_loss: 10.9764\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.4299 - val_loss: 10.7704\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4848 - val_loss: 10.5082\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2030 - val_loss: 10.5332\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2437 - val_loss: 11.0093\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.2491 - val_loss: 10.7990\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.2634 - val_loss: 10.4627\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.1538 - val_loss: 10.4382\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.0969 - val_loss: 10.5081\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0533 - val_loss: 10.3380\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0925 - val_loss: 10.4086\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.0775 - val_loss: 10.2522\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.0844 - val_loss: 10.5025\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.2430 - val_loss: 10.5313\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.2573 - val_loss: 9.8020\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.9882 - val_loss: 10.1274\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.0005 - val_loss: 10.0354\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9758 - val_loss: 10.3285\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7830 - val_loss: 10.0698\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.8090 - val_loss: 9.9789\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.1045 - val_loss: 9.9796\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.9177 - val_loss: 10.2804\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8097 - val_loss: 9.9691\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7476 - val_loss: 10.0736\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.7491 - val_loss: 9.6953\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6794 - val_loss: 9.7050\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.9059 - val_loss: 9.9363\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5936 - val_loss: 9.9033\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6868 - val_loss: 9.9481\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7061 - val_loss: 9.6875\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.7963 - val_loss: 9.7474\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6545 - val_loss: 9.9548\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.7034 - val_loss: 10.1575\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.6517 - val_loss: 9.5094\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6332 - val_loss: 10.0779\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5706 - val_loss: 9.6470\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6420 - val_loss: 9.5245\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5861 - val_loss: 9.6305\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5272 - val_loss: 10.0150\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5359 - val_loss: 9.5614\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5528 - val_loss: 9.5926\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5708 - val_loss: 9.3256\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5581 - val_loss: 9.8107\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 6.6843 - val_loss: 9.5564\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4846 - val_loss: 9.8460\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.6671 - val_loss: 10.1997\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.8890 - val_loss: 11.2047\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.5297 - val_loss: 10.6842\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.6978 - val_loss: 9.8271\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.6065 - val_loss: 9.3976\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.4323 - val_loss: 10.2265\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.5899 - val_loss: 9.8646\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4818 - val_loss: 9.8616\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.3788 - val_loss: 9.9303\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5581 - val_loss: 9.9396\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.2509 - val_loss: 10.2122\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.6700 - val_loss: 9.8024\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 6.2741 - val_loss: 9.5464\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.4812 - val_loss: 9.6494\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.3631 - val_loss: 9.4722\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.2792 - val_loss: 9.4552\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2311 - val_loss: 9.2429\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2589 - val_loss: 9.4210\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 6.3641 - val_loss: 9.6677\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.5231 - val_loss: 9.5804\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3538 - val_loss: 9.7832\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 6.1614 - val_loss: 9.5407\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1367 - val_loss: 9.5861\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3237 - val_loss: 9.8576\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3904 - val_loss: 9.8691\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3867 - val_loss: 9.6343\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3285 - val_loss: 9.8725\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2763 - val_loss: 9.3946\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.1962 - val_loss: 9.6390\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1959 - val_loss: 9.8642\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.3790 - val_loss: 9.5996\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1159 - val_loss: 9.5432\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.1884 - val_loss: 9.6598\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0622 - val_loss: 9.6083\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2852 - val_loss: 9.7199\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.5667 - val_loss: 9.4550\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1399 - val_loss: 9.5381\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 6.4548 - val_loss: 9.7429\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.6737 - val_loss: 9.9949\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.1753 - val_loss: 9.8271\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2223 - val_loss: 10.0057\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 6.0533 - val_loss: 9.7649\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.2790 - val_loss: 9.6268\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.3953 - val_loss: 9.2652\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 6.3707 - val_loss: 9.3788\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4617 - val_loss: 9.5214\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2113 - val_loss: 9.6895\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.2451 - val_loss: 9.6881\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1469 - val_loss: 9.5225\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1542 - val_loss: 9.6405\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.0637 - val_loss: 9.8183\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9748 - val_loss: 9.7293\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1678 - val_loss: 9.6756\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.7661 - val_loss: 10.7262\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.3322 - val_loss: 10.0793\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8123 - val_loss: 10.4534\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.3191 - val_loss: 9.6175\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1875 - val_loss: 9.5094\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1355 - val_loss: 9.8419\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5862 - val_loss: 10.5778\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 6.2970 - val_loss: 10.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9285 - val_loss: 9.7464\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0453 - val_loss: 9.9717\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9808 - val_loss: 9.6072\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9368 - val_loss: 9.7358\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8901 - val_loss: 9.6389\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9054 - val_loss: 9.8585\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.9235 - val_loss: 9.6057\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.8880 - val_loss: 9.7094\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8921 - val_loss: 9.8724\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8490 - val_loss: 9.6626\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8291 - val_loss: 9.5238\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8379 - val_loss: 9.6184\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9501 - val_loss: 9.9113\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.8715 - val_loss: 10.1084\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8560 - val_loss: 9.9336\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.2126 - val_loss: 9.5432\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.1291 - val_loss: 10.2040\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1382 - val_loss: 9.8641\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 5.9328 - val_loss: 9.6374\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.4255 - val_loss: 9.9304\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 6.6629 - val_loss: 10.1827\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 7.0192 - val_loss: 10.9753\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0417 - val_loss: 10.0511\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8903 - val_loss: 10.0078\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9691 - val_loss: 9.7020\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 6.0264 - val_loss: 10.1423\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0565 - val_loss: 10.1160\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9417 - val_loss: 10.1672\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9362 - val_loss: 10.2112\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9107 - val_loss: 10.1997\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9040 - val_loss: 10.1387\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8735 - val_loss: 10.0789\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7840 - val_loss: 9.8752\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.7129 - val_loss: 9.7831\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6915 - val_loss: 10.1276\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8546 - val_loss: 9.9649\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.9348 - val_loss: 9.9226\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.7363 - val_loss: 10.3585\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7585 - val_loss: 10.1852\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9939 - val_loss: 10.0811\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6800 - val_loss: 10.1664\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8033 - val_loss: 9.8108\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8063 - val_loss: 10.1183\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8733 - val_loss: 10.1261\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8621 - val_loss: 9.6654\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8357 - val_loss: 10.0420\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7200 - val_loss: 9.7733\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7770 - val_loss: 9.8772\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.8122 - val_loss: 10.5287\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7221 - val_loss: 10.2201\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6899 - val_loss: 10.1690\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8633 - val_loss: 10.0509\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6879 - val_loss: 10.7097\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7632 - val_loss: 10.1512\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.8138 - val_loss: 10.1216\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7871 - val_loss: 10.2740\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.0632 - val_loss: 10.3167\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9756 - val_loss: 10.0754\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.6720 - val_loss: 10.0735\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6752 - val_loss: 10.1143\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7541 - val_loss: 10.8153\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.2267 - val_loss: 10.2876\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9430 - val_loss: 10.3611\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6306 - val_loss: 10.1735\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.9357 - val_loss: 10.9701\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6146 - val_loss: 10.5014\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8477 - val_loss: 10.2743\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.8352 - val_loss: 9.9154\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6637 - val_loss: 10.3509\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8705 - val_loss: 10.8924\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6748 - val_loss: 10.6391\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7164 - val_loss: 10.3341\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6834 - val_loss: 10.3575\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7956 - val_loss: 10.2121\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.8262 - val_loss: 10.0217\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6290 - val_loss: 10.5070\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.7236 - val_loss: 10.6136\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 99us/step - loss: 5.7460 - val_loss: 10.5867\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9961 - val_loss: 10.5360\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7454 - val_loss: 10.2242\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7197 - val_loss: 10.0623\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6296 - val_loss: 10.6349\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6657 - val_loss: 10.5903\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6886 - val_loss: 10.0545\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6594 - val_loss: 10.3533\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5175 - val_loss: 10.3204\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5446 - val_loss: 10.5881\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7509 - val_loss: 10.2693\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.5561 - val_loss: 10.2922\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6103 - val_loss: 10.5734\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6739 - val_loss: 10.3873\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.1640 - val_loss: 10.4764\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 6.2015 - val_loss: 10.8622\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7981 - val_loss: 10.8481\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7895 - val_loss: 10.2598\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8849 - val_loss: 10.2547\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7456 - val_loss: 10.4827\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7610 - val_loss: 10.4847\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5765 - val_loss: 10.5559\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5653 - val_loss: 10.8070\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8625 - val_loss: 10.6431\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4123 - val_loss: 11.0432\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7171 - val_loss: 10.3669\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.9319 - val_loss: 11.1996\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7851 - val_loss: 10.8613\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.9269 - val_loss: 10.3434\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5302 - val_loss: 10.6857\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6281 - val_loss: 10.6203\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7005 - val_loss: 10.4873\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9482 - val_loss: 11.0960\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5727 - val_loss: 10.9911\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5920 - val_loss: 10.5592\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5792 - val_loss: 10.0297\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6053 - val_loss: 10.7420\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5436 - val_loss: 10.9669\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5815 - val_loss: 10.9402\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6429 - val_loss: 10.6395\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7292 - val_loss: 10.8026\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7189 - val_loss: 11.0000\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.5521 - val_loss: 10.9537\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8181 - val_loss: 11.0223\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 7.129 - 0s 131us/step - loss: 5.7909 - val_loss: 10.5303\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.7021 - val_loss: 10.4935\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5304 - val_loss: 10.1355\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5797 - val_loss: 10.4732\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7327 - val_loss: 10.8157\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8430 - val_loss: 11.2816\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.1198 - val_loss: 10.6294\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8798 - val_loss: 10.3384\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5498 - val_loss: 10.6085\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6360 - val_loss: 10.5522\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9158 - val_loss: 10.5289\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5781 - val_loss: 10.5301\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6307 - val_loss: 10.8268\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5018 - val_loss: 11.2343\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5090 - val_loss: 10.7305\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4913 - val_loss: 10.3798\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5612 - val_loss: 10.9046\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5036 - val_loss: 10.4250\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5851 - val_loss: 10.6700\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6867 - val_loss: 10.9969\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7178 - val_loss: 10.7217\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.6385 - val_loss: 10.6494\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7378 - val_loss: 10.3823\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5172 - val_loss: 10.8984\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5733 - val_loss: 10.7474\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.5141 - val_loss: 10.8150\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6247 - val_loss: 10.5442\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5469 - val_loss: 10.8021\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4836 - val_loss: 10.6302\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4751 - val_loss: 10.8968\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5791 - val_loss: 10.4486\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4973 - val_loss: 10.7897\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4893 - val_loss: 11.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4829 - val_loss: 10.6586\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4242 - val_loss: 10.3881\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6511 - val_loss: 10.6812\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6555 - val_loss: 10.8177\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4889 - val_loss: 10.9554\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5073 - val_loss: 11.0437\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4992 - val_loss: 10.7730\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4845 - val_loss: 10.3521\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5970 - val_loss: 10.5264\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5746 - val_loss: 10.8720\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5457 - val_loss: 10.9826\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7822 - val_loss: 11.3179\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.6770 - val_loss: 11.2127\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5175 - val_loss: 10.8011\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.6776 - val_loss: 10.9433\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5375 - val_loss: 10.7041\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9824 - val_loss: 11.3580\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6954 - val_loss: 11.0241\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6906 - val_loss: 11.1073\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5468 - val_loss: 11.0290\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4723 - val_loss: 11.3160\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5838 - val_loss: 10.5660\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5174 - val_loss: 10.8513\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4926 - val_loss: 10.9313\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4501 - val_loss: 10.6479\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5145 - val_loss: 11.0938\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3729 - val_loss: 10.9571\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7691 - val_loss: 11.2121\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7146 - val_loss: 10.8634\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5423 - val_loss: 11.0125\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6331 - val_loss: 10.6707\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7162 - val_loss: 11.7029\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.4743 - val_loss: 11.0876\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.0484 - val_loss: 12.2457\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9427 - val_loss: 11.2764\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.6013 - val_loss: 10.9797\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7743 - val_loss: 11.0358\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.0474 - val_loss: 11.4246\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5818 - val_loss: 10.8214\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4610 - val_loss: 11.0329\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.5450 - val_loss: 10.8574\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4674 - val_loss: 11.7275\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6845 - val_loss: 10.9178\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 4.483 - 0s 102us/step - loss: 5.5566 - val_loss: 11.0446\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7937 - val_loss: 11.1390\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4381 - val_loss: 10.6201\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3444 - val_loss: 11.1860\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3664 - val_loss: 11.2546\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4311 - val_loss: 10.6379\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4343 - val_loss: 11.1917\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.9071 - val_loss: 11.2539\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6104 - val_loss: 11.6737\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6918 - val_loss: 10.5359\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4104 - val_loss: 10.6316\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3865 - val_loss: 11.0183\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.5143 - val_loss: 11.4463\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3438 - val_loss: 10.5834\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4049 - val_loss: 10.6055\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6213 - val_loss: 10.7174\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4435 - val_loss: 11.0292\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4157 - val_loss: 11.0315\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3932 - val_loss: 10.7078\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4731 - val_loss: 11.0499\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4065 - val_loss: 10.8244\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4476 - val_loss: 11.1293\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5076 - val_loss: 11.0551\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3514 - val_loss: 10.8278\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3670 - val_loss: 11.4830\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5593 - val_loss: 10.9423\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3467 - val_loss: 10.7970\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5289 - val_loss: 10.9006\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4531 - val_loss: 10.8771\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5156 - val_loss: 11.2085\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4601 - val_loss: 10.9423\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.4002 - val_loss: 11.5179\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4205 - val_loss: 10.9265\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7295 - val_loss: 11.3799\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6143 - val_loss: 11.2412\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5342 - val_loss: 11.1183\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4468 - val_loss: 10.6188\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4026 - val_loss: 10.8895\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.4667 - val_loss: 10.4852\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5958 - val_loss: 10.8812\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4404 - val_loss: 11.0481\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3651 - val_loss: 11.5057\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3915 - val_loss: 10.9944\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3767 - val_loss: 11.0169\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3650 - val_loss: 11.0579\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3815 - val_loss: 10.9872\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4381 - val_loss: 11.3512\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5720 - val_loss: 10.8571\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4409 - val_loss: 11.0099\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.3502 - val_loss: 10.9197\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5231 - val_loss: 10.8538\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 6.5978 - val_loss: 12.0150\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8376 - val_loss: 10.9686\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5923 - val_loss: 11.2941\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 6.0063 - val_loss: 11.4096\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6386 - val_loss: 11.6113\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4287 - val_loss: 10.9489\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4082 - val_loss: 10.4726\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4352 - val_loss: 10.8375\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2589 - val_loss: 11.3213\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4423 - val_loss: 11.8992\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7478 - val_loss: 11.1049\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6159 - val_loss: 10.7635\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7490 - val_loss: 11.4676\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4217 - val_loss: 11.8253\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5224 - val_loss: 11.1555\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3811 - val_loss: 11.1000\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3826 - val_loss: 10.9450\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3607 - val_loss: 10.9053\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3596 - val_loss: 11.2744\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2825 - val_loss: 10.8149\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3145 - val_loss: 11.1807\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3703 - val_loss: 11.0858\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3994 - val_loss: 11.1699\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4100 - val_loss: 11.1777\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4147 - val_loss: 10.6506\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3402 - val_loss: 10.9497\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4371 - val_loss: 11.3680\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3699 - val_loss: 11.5418\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4028 - val_loss: 11.2342\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3994 - val_loss: 11.3726\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4682 - val_loss: 10.9619\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.6529 - val_loss: 11.2566\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4196 - val_loss: 11.0106\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.5478 - val_loss: 10.9986\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4832 - val_loss: 11.0409\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3238 - val_loss: 11.3546\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3590 - val_loss: 11.3019\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2924 - val_loss: 10.6675\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3159 - val_loss: 11.0984\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2987 - val_loss: 11.2441\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.5199 - val_loss: 11.4085\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4493 - val_loss: 11.3471\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3195 - val_loss: 11.6685\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5238 - val_loss: 11.4745\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4844 - val_loss: 10.7614\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2794 - val_loss: 11.7220\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3245 - val_loss: 11.4858\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3609 - val_loss: 11.4581\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.9067 - val_loss: 11.3386\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6731 - val_loss: 11.6008\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6003 - val_loss: 11.1357\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5618 - val_loss: 11.0797\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3473 - val_loss: 11.0752\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4320 - val_loss: 10.7834\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2913 - val_loss: 11.3075\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3997 - val_loss: 11.5574\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4264 - val_loss: 11.2509\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8643 - val_loss: 12.0512\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4655 - val_loss: 11.2460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3845 - val_loss: 12.0232\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 5.7061 - val_loss: 11.0984\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9067 - val_loss: 11.5055\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7650 - val_loss: 11.5303\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8158 - val_loss: 10.8990\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5119 - val_loss: 11.2075\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3691 - val_loss: 11.3164\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3226 - val_loss: 11.3673\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4815 - val_loss: 10.8674\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4122 - val_loss: 11.0981\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2836 - val_loss: 11.1380\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2971 - val_loss: 11.6864\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3623 - val_loss: 11.1701\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2729 - val_loss: 11.5181\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2607 - val_loss: 11.1021\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3773 - val_loss: 10.7781\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3752 - val_loss: 11.0145\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4784 - val_loss: 10.8771\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3244 - val_loss: 11.2739\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4272 - val_loss: 11.4371\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3181 - val_loss: 10.9420\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3388 - val_loss: 11.1790\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3375 - val_loss: 10.9999\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3667 - val_loss: 11.3235\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3240 - val_loss: 11.1097\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5575 - val_loss: 11.1819\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2165 - val_loss: 11.5831\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4207 - val_loss: 11.3192\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4022 - val_loss: 11.2318\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4372 - val_loss: 11.5516\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2797 - val_loss: 11.2352\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.5006 - val_loss: 11.0985\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3793 - val_loss: 11.3873\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5207 - val_loss: 11.3009\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6838 - val_loss: 11.3693\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4144 - val_loss: 10.6815\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5445 - val_loss: 10.8067\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3132 - val_loss: 11.2527\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3921 - val_loss: 11.5371\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7313 - val_loss: 11.5884\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.7792 - val_loss: 11.6563\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5208 - val_loss: 11.4661\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.0419 - val_loss: 11.4438\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7850 - val_loss: 11.4805\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4081 - val_loss: 11.2117\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4528 - val_loss: 11.9223\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.8082 - val_loss: 11.7114\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5865 - val_loss: 10.9267\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3452 - val_loss: 11.3224\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3312 - val_loss: 11.4564\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3823 - val_loss: 11.0384\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3710 - val_loss: 11.1791\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2701 - val_loss: 11.4333\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.4736 - val_loss: 11.2543\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.5010 - val_loss: 11.7277\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.2908 - val_loss: 11.4503\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3168 - val_loss: 10.7148\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3150 - val_loss: 10.8709\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4081 - val_loss: 11.3659\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4411 - val_loss: 11.6050\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2355 - val_loss: 11.4336\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3490 - val_loss: 11.1144\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3655 - val_loss: 11.0762\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5743 - val_loss: 11.3073\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1734 - val_loss: 11.2353\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2912 - val_loss: 11.6175\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4890 - val_loss: 11.5874\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5687 - val_loss: 12.8276\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.8672 - val_loss: 12.3009\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.7545 - val_loss: 11.9334\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2476 - val_loss: 11.0344\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4139 - val_loss: 11.5527\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5984 - val_loss: 11.6412\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3070 - val_loss: 12.2632\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4857 - val_loss: 11.4457\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.703 - 0s 95us/step - loss: 5.3625 - val_loss: 11.4416\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2114 - val_loss: 11.2940\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3345 - val_loss: 11.8096\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2869 - val_loss: 11.6580\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3170 - val_loss: 11.2142\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3117 - val_loss: 11.0479\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3605 - val_loss: 11.1872\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3020 - val_loss: 11.6725\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3617 - val_loss: 12.0056\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.6950 - val_loss: 10.6307\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4189 - val_loss: 11.2795\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5280 - val_loss: 11.9154\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3427 - val_loss: 12.2662\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6287 - val_loss: 11.2357\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2427 - val_loss: 11.5557\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3549 - val_loss: 11.5894\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5978 - val_loss: 12.6506\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9763 - val_loss: 11.7405\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4735 - val_loss: 11.9822\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5549 - val_loss: 11.1144\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5110 - val_loss: 11.5457\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.5143 - val_loss: 11.4176\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7242 - val_loss: 11.0757\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.8494 - val_loss: 12.0312\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8608 - val_loss: 11.5718\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.4801 - val_loss: 11.6940\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3266 - val_loss: 11.5362\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5372 - val_loss: 11.2867\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4067 - val_loss: 11.1761\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4209 - val_loss: 11.9320\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6483 - val_loss: 11.9100\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5236 - val_loss: 10.9563\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4026 - val_loss: 11.6050\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4766 - val_loss: 11.6164\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2902 - val_loss: 11.8765\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2786 - val_loss: 11.0404\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2756 - val_loss: 11.9425\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2875 - val_loss: 11.5025\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3177 - val_loss: 11.4437\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3947 - val_loss: 11.6190\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3354 - val_loss: 11.6805\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2783 - val_loss: 11.5271\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3891 - val_loss: 11.4566\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.3108 - val_loss: 11.5314\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5226 - val_loss: 11.2304\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3588 - val_loss: 11.5816\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3646 - val_loss: 11.2765\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3149 - val_loss: 11.2986\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2688 - val_loss: 11.7337\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2116 - val_loss: 11.0837\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2244 - val_loss: 11.4307\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3510 - val_loss: 12.4328\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4756 - val_loss: 11.4957\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4130 - val_loss: 11.4254\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2854 - val_loss: 11.6685\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3664 - val_loss: 11.4078\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5362 - val_loss: 11.9119\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3261 - val_loss: 11.3821\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3193 - val_loss: 11.7123\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2819 - val_loss: 11.8835\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.3014 - val_loss: 11.3503\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2540 - val_loss: 11.4097\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3139 - val_loss: 11.4692\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2852 - val_loss: 11.5819\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3910 - val_loss: 11.7214\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4168 - val_loss: 11.2385\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3627 - val_loss: 11.5385\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.7623 - val_loss: 11.4854\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6706 - val_loss: 11.6178\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2467 - val_loss: 11.5750\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4060 - val_loss: 11.1798\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.7405 - val_loss: 11.0674\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4171 - val_loss: 11.8489\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3947 - val_loss: 11.5768\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3818 - val_loss: 11.4888\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1889 - val_loss: 11.3188\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4199 - val_loss: 11.5046\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1866 - val_loss: 11.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3021 - val_loss: 11.2970\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3289 - val_loss: 11.0949\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2544 - val_loss: 11.2289\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3162 - val_loss: 11.4466\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4462 - val_loss: 11.5903\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3182 - val_loss: 11.5094\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.5416 - val_loss: 11.3954\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2146 - val_loss: 11.7572\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2184 - val_loss: 11.4323\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5802 - val_loss: 11.9995\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.4148 - val_loss: 11.7527\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5082 - val_loss: 12.3864\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6810 - val_loss: 11.3006\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2752 - val_loss: 11.5288\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3143 - val_loss: 11.1960\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3563 - val_loss: 11.3780\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3000 - val_loss: 11.3603\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3260 - val_loss: 11.3323\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1866 - val_loss: 11.6858\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5110 - val_loss: 12.0485\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6311 - val_loss: 11.4134\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 6.4211 - val_loss: 12.3276\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 7.0836 - val_loss: 11.6605\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8931 - val_loss: 12.3898\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7855 - val_loss: 11.7303\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5194 - val_loss: 11.9949\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4083 - val_loss: 11.2971\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2779 - val_loss: 11.6077\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6727 - val_loss: 11.2840\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3952 - val_loss: 11.6051\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2955 - val_loss: 11.7313\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2669 - val_loss: 11.9164\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2952 - val_loss: 11.2577\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2821 - val_loss: 11.6867\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4311 - val_loss: 11.5080\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3737 - val_loss: 11.4236\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3002 - val_loss: 11.3074\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3432 - val_loss: 11.3615\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3114 - val_loss: 11.2210\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2131 - val_loss: 11.9315\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2283 - val_loss: 11.3735\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5014 - val_loss: 11.6282\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.1990 - val_loss: 11.3236\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2351 - val_loss: 11.5293\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3086 - val_loss: 11.5583\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2866 - val_loss: 11.7906\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3460 - val_loss: 11.6593\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4089 - val_loss: 11.3859\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5061 - val_loss: 11.9248\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3383 - val_loss: 11.5016\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2485 - val_loss: 11.6427\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2961 - val_loss: 11.3957\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1825 - val_loss: 11.6823\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.2814 - val_loss: 11.4732\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3606 - val_loss: 11.3847\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4330 - val_loss: 11.1048\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2494 - val_loss: 11.2195\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2861 - val_loss: 11.5506\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7640 - val_loss: 12.0457\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6369 - val_loss: 11.3797\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2274 - val_loss: 11.8468\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4906 - val_loss: 11.3412\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2412 - val_loss: 11.5676\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2358 - val_loss: 11.3368\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2586 - val_loss: 11.4844\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.6426 - val_loss: 12.4833\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2022 - val_loss: 11.6475\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3285 - val_loss: 11.7513\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3144 - val_loss: 11.3039\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.9868 - val_loss: 12.0658\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4862 - val_loss: 11.6650\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.5008 - val_loss: 12.1109\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1738 - val_loss: 11.6806\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2535 - val_loss: 11.8811\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2195 - val_loss: 12.0470\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2540 - val_loss: 11.5176\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3437 - val_loss: 11.3931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2590 - val_loss: 11.2391\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3168 - val_loss: 11.5805\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7600 - val_loss: 12.1036\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6303 - val_loss: 11.4726\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4407 - val_loss: 11.7608\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4179 - val_loss: 11.1475\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3141 - val_loss: 11.4378\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3907 - val_loss: 11.9656\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3233 - val_loss: 11.7114\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3217 - val_loss: 11.6922\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2560 - val_loss: 11.5767\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3610 - val_loss: 11.8014\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5257 - val_loss: 11.7845\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2600 - val_loss: 11.6765\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1572 - val_loss: 11.4076\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.3095 - val_loss: 11.4047\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3897 - val_loss: 11.3435\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2351 - val_loss: 11.1793\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2887 - val_loss: 11.8593\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3050 - val_loss: 12.0679\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2238 - val_loss: 11.6213\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1557 - val_loss: 11.7303\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2513 - val_loss: 11.9646\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1986 - val_loss: 11.4257\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2838 - val_loss: 11.9338\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4625 - val_loss: 11.6707\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1450 - val_loss: 11.6078\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2235 - val_loss: 11.8829\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2781 - val_loss: 11.4897\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.3546 - val_loss: 12.0228\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4237 - val_loss: 12.4006\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3736 - val_loss: 11.3168\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4267 - val_loss: 11.2643\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3031 - val_loss: 11.7710\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2959 - val_loss: 11.2159\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2902 - val_loss: 11.6524\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3863 - val_loss: 11.8616\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.8215 - val_loss: 12.1022\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4917 - val_loss: 12.0691\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3764 - val_loss: 12.4419\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3955 - val_loss: 11.8490\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2325 - val_loss: 12.1994\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2257 - val_loss: 11.6257\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2572 - val_loss: 11.8771\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2007 - val_loss: 11.5066\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3285 - val_loss: 11.4290\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3497 - val_loss: 11.5809\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2518 - val_loss: 12.0687\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3170 - val_loss: 11.6029\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5131 - val_loss: 11.8573\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5989 - val_loss: 11.5913\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3601 - val_loss: 11.8053\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3324 - val_loss: 11.5673\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2125 - val_loss: 11.4301\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3838 - val_loss: 11.6653\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3984 - val_loss: 11.7719\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2647 - val_loss: 11.6904\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2645 - val_loss: 11.5823\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2489 - val_loss: 11.8523\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1926 - val_loss: 11.7547\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1698 - val_loss: 11.8527\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2143 - val_loss: 11.5998\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2426 - val_loss: 11.5573\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1879 - val_loss: 11.5210\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1790 - val_loss: 11.7381\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4297 - val_loss: 11.5415\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3240 - val_loss: 11.6668\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3400 - val_loss: 12.2064\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2634 - val_loss: 11.7477\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1539 - val_loss: 12.0058\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2451 - val_loss: 11.4274\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2150 - val_loss: 11.8973\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2364 - val_loss: 12.3493\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4624 - val_loss: 12.0305\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2938 - val_loss: 11.6143\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1408 - val_loss: 11.8051\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3335 - val_loss: 11.6859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2949 - val_loss: 11.8282\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1600 - val_loss: 12.0374\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.2624 - val_loss: 12.0132\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 124us/step - loss: 5.1694 - val_loss: 11.6709\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2282 - val_loss: 11.6640\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2857 - val_loss: 11.7629\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5098 - val_loss: 12.1379\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3596 - val_loss: 11.7012\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2821 - val_loss: 11.6081\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3964 - val_loss: 11.5166\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2050 - val_loss: 11.7563\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3221 - val_loss: 12.1381\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5546 - val_loss: 11.7482\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1795 - val_loss: 11.4144\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1955 - val_loss: 11.5813\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2695 - val_loss: 11.6295\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2377 - val_loss: 11.2308\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5288 - val_loss: 11.8829\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4324 - val_loss: 11.8094\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3833 - val_loss: 12.4055\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.5215 - val_loss: 11.9369\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1798 - val_loss: 11.6121\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3009 - val_loss: 11.2605\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2138 - val_loss: 12.0663\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2889 - val_loss: 12.2678\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4865 - val_loss: 12.4740\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3461 - val_loss: 11.5969\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1888 - val_loss: 11.5285\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3516 - val_loss: 11.7292\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2660 - val_loss: 12.1292\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3134 - val_loss: 11.5462\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.1929 - val_loss: 11.5284\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2396 - val_loss: 11.6563\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3130 - val_loss: 11.7740\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.1758 - val_loss: 12.0120\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2686 - val_loss: 11.6583\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1449 - val_loss: 11.5567\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5308 - val_loss: 11.6724\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 5.3169 - val_loss: 11.7948\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2980 - val_loss: 12.0578\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.8500 - val_loss: 11.7442\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2745 - val_loss: 11.6830\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2954 - val_loss: 12.0005\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2011 - val_loss: 11.6496\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2323 - val_loss: 11.7471\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.2623 - val_loss: 11.3002\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.3692 - val_loss: 11.5709\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2049 - val_loss: 12.2164\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.3169 - val_loss: 11.9104\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1887 - val_loss: 12.2462\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3401 - val_loss: 11.4071\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3219 - val_loss: 11.4866\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2241 - val_loss: 11.9559\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2925 - val_loss: 11.6638\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.2807 - val_loss: 11.5650\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1848 - val_loss: 11.8529\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2679 - val_loss: 11.7090\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.2541 - val_loss: 11.8795\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2867 - val_loss: 12.5001\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4008 - val_loss: 12.0306\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2799 - val_loss: 11.7487\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3238 - val_loss: 11.9644\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5014 - val_loss: 12.3720\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5466 - val_loss: 11.6247\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2800 - val_loss: 12.2593\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.4405 - val_loss: 12.0279\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.1679 - val_loss: 11.8458\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3599 - val_loss: 11.8292\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.1811 - val_loss: 11.7012\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4686 - val_loss: 12.9151\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.4855 - val_loss: 11.8607\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3428 - val_loss: 12.2613\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4096 - val_loss: 11.5591\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3330 - val_loss: 11.7282\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1738 - val_loss: 12.0000\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3520 - val_loss: 11.6427\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2037 - val_loss: 12.3034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1509 - val_loss: 12.3988\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3916 - val_loss: 12.3196\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2459 - val_loss: 11.8300\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1556 - val_loss: 12.0909\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3211 - val_loss: 11.5260\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2707 - val_loss: 11.6257\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.5328 - val_loss: 12.2813\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.7643 - val_loss: 13.2464\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.3908 - val_loss: 12.3223\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1995 - val_loss: 12.8731\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6176 - val_loss: 11.4816\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.4525 - val_loss: 12.3698\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4090 - val_loss: 12.3742\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4345 - val_loss: 11.9401\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.4834 - val_loss: 11.4478\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 127us/step - loss: 5.4004 - val_loss: 11.9178\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 5.2886 - val_loss: 11.5242\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2141 - val_loss: 11.9773\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.1815 - val_loss: 11.9450\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2562 - val_loss: 11.7046\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2447 - val_loss: 12.1102\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3026 - val_loss: 12.1436\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.4005 - val_loss: 12.1367\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1735 - val_loss: 12.0007\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2377 - val_loss: 11.8538\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3071 - val_loss: 12.0401\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1738 - val_loss: 12.1695\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2450 - val_loss: 12.0813\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.1288 - val_loss: 11.5790\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2417 - val_loss: 11.9558\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.1109 - val_loss: 11.8412\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1573 - val_loss: 12.2659\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 5.5569 - val_loss: 11.8203\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 116us/step - loss: 5.3370 - val_loss: 12.5151\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3918 - val_loss: 11.9706\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2005 - val_loss: 12.1216\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5093 - val_loss: 12.1171\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1903 - val_loss: 11.5406\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2366 - val_loss: 11.8522\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3433 - val_loss: 12.6776\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2127 - val_loss: 11.7692\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3544 - val_loss: 12.3226\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5550 - val_loss: 12.0688\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5264 - val_loss: 11.9187\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3239 - val_loss: 11.2454\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.3746 - val_loss: 11.6250\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2653 - val_loss: 12.4816\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.2373 - val_loss: 12.2178\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1951 - val_loss: 11.9086\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1804 - val_loss: 11.8414\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.1933 - val_loss: 11.7001\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2883 - val_loss: 11.7687\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2389 - val_loss: 12.3841\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2612 - val_loss: 11.4444\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.4751 - val_loss: 11.6296\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2532 - val_loss: 12.5597\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6477 - val_loss: 11.8831\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.6146 - val_loss: 12.4426\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.6323 - val_loss: 12.0202\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3090 - val_loss: 12.2723\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2283 - val_loss: 12.0063\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2197 - val_loss: 12.0161\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1171 - val_loss: 11.6524\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1905 - val_loss: 12.2214\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1982 - val_loss: 12.1336\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2499 - val_loss: 11.4970\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 5.2034 - val_loss: 11.9555\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2789 - val_loss: 11.9912\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3209 - val_loss: 12.1563\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 5.5317 - val_loss: 12.7061\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.7211 - val_loss: 12.1894\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2918 - val_loss: 11.4620\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2267 - val_loss: 12.2495\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3754 - val_loss: 12.1796\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2072 - val_loss: 11.9632\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2298 - val_loss: 11.7834\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4060 - val_loss: 12.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.5550 - val_loss: 11.8459\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3163 - val_loss: 11.9548\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1699 - val_loss: 11.8072\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2136 - val_loss: 11.9626\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 99us/step - loss: 5.2633 - val_loss: 12.4002\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1932 - val_loss: 12.2517\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.5100 - val_loss: 12.0903\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 101us/step - loss: 5.7015 - val_loss: 12.0285\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.4763 - val_loss: 12.3103\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.7497 - val_loss: 12.2153\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3510 - val_loss: 12.4863\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1696 - val_loss: 11.8561\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4096 - val_loss: 12.4019\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2946 - val_loss: 12.2178\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3172 - val_loss: 12.4058\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2268 - val_loss: 11.6812\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4043 - val_loss: 11.4839\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.5400 - val_loss: 12.2801\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.4643 - val_loss: 12.3565\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.5053 - val_loss: 12.7372\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4687 - val_loss: 11.8299\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3612 - val_loss: 11.5277\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1241 - val_loss: 11.9957\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2671 - val_loss: 11.9541\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4575 - val_loss: 11.9411\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3281 - val_loss: 11.8100\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.2229 - val_loss: 12.1358\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2511 - val_loss: 12.7030\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.1960 - val_loss: 11.8322\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1126 - val_loss: 12.1725\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1878 - val_loss: 11.9811\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1842 - val_loss: 11.8598\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1935 - val_loss: 11.8963\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2827 - val_loss: 12.1045\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2441 - val_loss: 12.3387\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.1397 - val_loss: 12.0313\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2441 - val_loss: 11.7486\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3290 - val_loss: 12.0263\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.2542 - val_loss: 12.2798\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3671 - val_loss: 12.0676\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3204 - val_loss: 12.4689\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1435 - val_loss: 11.8181\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.3062 - val_loss: 11.6197\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2836 - val_loss: 12.7252\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2597 - val_loss: 12.0592\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.4811 - val_loss: 12.2443\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 103us/step - loss: 5.2333 - val_loss: 11.9289\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.3609 - val_loss: 12.3730\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 5.2639 - val_loss: 12.0597\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 5.1789 - val_loss: 11.6931\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.2045 - val_loss: 11.9453\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2301 - val_loss: 12.3972\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.2278 - val_loss: 11.8173\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 5.1386 - val_loss: 11.9658\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3073 - val_loss: 12.2980\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3252 - val_loss: 11.8535\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1997 - val_loss: 12.0416\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.6906 - val_loss: 11.9608\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.8545 - val_loss: 12.6871\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3355 - val_loss: 11.8182\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2369 - val_loss: 12.1311\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1984 - val_loss: 11.8619\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2309 - val_loss: 11.9661\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 5.4819 - val_loss: 12.2227\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 5.2396 - val_loss: 11.9847\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.3095 - val_loss: 12.6490\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2612 - val_loss: 12.1858\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.2710 - val_loss: 11.8976\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2718 - val_loss: 11.9123\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.1336 - val_loss: 12.1787\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3375 - val_loss: 12.3552\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.5241 - val_loss: 12.6375\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 5.4006 - val_loss: 12.0653\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 5.3657 - val_loss: 11.8814\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 5.3786 - val_loss: 12.4319\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 5.1811 - val_loss: 12.1593\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2311 - val_loss: 12.2303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.2057 - val_loss: 11.8983\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1482 - val_loss: 12.4020\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3537 - val_loss: 12.0096\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.6310 - val_loss: 12.5196\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.3094 - val_loss: 11.7051\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.5693 - val_loss: 12.5327\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 5.3736 - val_loss: 12.4900\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 5.1659 - val_loss: 12.5420\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1646 - val_loss: 12.0669\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 5.1627 - val_loss: 12.3434\n",
      "6.589242611901235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.394878  , -1.4884644 ,  1.703876  ,  0.4099867 , -5.5041075 ],\n",
       "        [-0.30577022, -0.26036423, -0.50021327, -0.74712986,  2.554801  ],\n",
       "        [ 0.06273019,  1.8117826 ,  0.5501748 ,  0.2434969 , -2.0181887 ],\n",
       "        [-0.6284594 , -0.25257117,  0.5892034 ,  0.478446  , -1.4118404 ],\n",
       "        [ 0.2047307 ,  1.1138835 , -0.01824114, -0.14766394,  0.00887501],\n",
       "        [-0.3404026 ,  0.2607666 , -0.45395944, -1.1378863 ,  1.9377538 ],\n",
       "        [-0.19011907, -1.5919288 , -0.420459  , -0.019365  ,  1.8430926 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.8397186 , -2.3327327 , -0.01653498,  0.91879916,  0.93806285],\n",
       "       dtype=float32),\n",
       " array([[-0.34428728,  0.071261  , -0.9571967 ,  0.37676704, -0.14425221,\n",
       "          0.7226811 ,  0.7470566 ,  0.83972204, -0.8070323 ,  0.31378728],\n",
       "        [ 0.07172816, -0.27309045,  0.06666806, -0.2625405 , -0.42119864,\n",
       "         -0.46323612, -0.3162143 , -0.93956566,  0.17364994, -0.25602219],\n",
       "        [ 1.5484027 , -0.71763873,  1.6585562 , -1.8473309 , -0.86004466,\n",
       "         -1.4416953 , -1.6125208 , -0.99397844,  1.7173345 , -0.9053445 ],\n",
       "        [ 0.42595848, -0.4516972 ,  0.22233155, -0.11770816, -1.1220233 ,\n",
       "         -0.9624783 , -0.8923839 , -0.8715168 ,  0.32950768, -0.7730536 ],\n",
       "        [ 0.51091313, -0.620065  ,  0.4211166 , -1.3636316 , -0.79480547,\n",
       "         -0.5891134 , -1.1665471 , -0.7087444 ,  0.54187536, -1.4849951 ]],\n",
       "       dtype=float32),\n",
       " array([-1.3928585,  1.2668529, -1.3658432,  1.3903587,  1.2234093,\n",
       "         1.3780018,  1.3855377,  1.3506362, -1.3917727,  1.0998727],\n",
       "       dtype=float32),\n",
       " array([[-1.54648   ],\n",
       "        [ 0.7041226 ],\n",
       "        [-1.2093726 ],\n",
       "        [ 1.551886  ],\n",
       "        [ 0.82440567],\n",
       "        [ 1.5578561 ],\n",
       "        [ 1.5876316 ],\n",
       "        [ 1.342005  ],\n",
       "        [-1.6180915 ],\n",
       "        [ 0.80047786]], dtype=float32),\n",
       " array([1.4395899], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, adam2, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 510us/step - loss: 601.3979 - val_loss: 641.8258\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 600.5788 - val_loss: 640.7073\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 599.4444 - val_loss: 639.4053\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 598.1900 - val_loss: 638.0436\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 596.9026 - val_loss: 636.6534\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 595.5956 - val_loss: 635.2419\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 594.2715 - val_loss: 633.8321\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 592.9487 - val_loss: 632.4174\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 591.6273 - val_loss: 630.9927\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 590.2862 - val_loss: 629.5693\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 588.9405 - val_loss: 628.1569\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 587.6165 - val_loss: 626.7354\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 586.2832 - val_loss: 625.3090\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 584.9447 - val_loss: 623.8736\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 583.6094 - val_loss: 622.4225\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 582.2405 - val_loss: 620.9937\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 580.8916 - val_loss: 619.5291\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 579.5263 - val_loss: 618.0556\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 578.1234 - val_loss: 616.6045\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 576.7597 - val_loss: 615.1179\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 575.3640 - val_loss: 613.6222\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 573.9698 - val_loss: 612.1163\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 572.5716 - val_loss: 610.5984\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 571.1512 - val_loss: 609.0736\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 569.7169 - val_loss: 607.5433\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 568.2783 - val_loss: 606.0047\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 566.8231 - val_loss: 604.4552\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 565.3990 - val_loss: 602.8497\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 563.9060 - val_loss: 601.2587\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 562.4093 - val_loss: 599.6799\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 560.9155 - val_loss: 598.1038\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 559.4406 - val_loss: 596.4719\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 557.8989 - val_loss: 594.8579\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 556.4011 - val_loss: 593.1789\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 554.8416 - val_loss: 591.5167\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 553.3063 - val_loss: 589.8291\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 551.7340 - val_loss: 588.1458\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 550.1540 - val_loss: 586.4576\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 548.5523 - val_loss: 584.7524\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 546.9478 - val_loss: 583.0073\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 545.3341 - val_loss: 581.2198\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 543.7076 - val_loss: 579.4118\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 542.0155 - val_loss: 577.6273\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 540.3186 - val_loss: 575.8411\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 538.6476 - val_loss: 574.0198\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 536.9653 - val_loss: 572.1422\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 535.2000 - val_loss: 570.2668\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 533.4543 - val_loss: 568.3474\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 531.6767 - val_loss: 566.4059\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 529.8558 - val_loss: 564.4827\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 528.0410 - val_loss: 562.5406\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 526.2361 - val_loss: 560.5288\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 524.3461 - val_loss: 558.5150\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 522.4768 - val_loss: 556.4728\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 520.5828 - val_loss: 554.3891\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 518.6461 - val_loss: 552.2849\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 516.6685 - val_loss: 550.1828\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 514.7184 - val_loss: 548.0055\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 512.7126 - val_loss: 545.8078\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 510.6635 - val_loss: 543.6155\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 508.6214 - val_loss: 541.4011\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 506.5452 - val_loss: 539.1261\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 504.4292 - val_loss: 536.8129\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 502.2775 - val_loss: 534.4937\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 500.1159 - val_loss: 532.1407\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 497.9485 - val_loss: 529.7241\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 495.6830 - val_loss: 527.3045\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 493.4198 - val_loss: 524.8450\n",
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 491.1649 - val_loss: 522.3382\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 488.8346 - val_loss: 519.8114\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 486.4749 - val_loss: 517.2475\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 484.0855 - val_loss: 514.6602\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 481.6847 - val_loss: 512.0302\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 479.2227 - val_loss: 509.3471\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 476.7249 - val_loss: 506.6142\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 474.2543 - val_loss: 503.8218\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 471.6225 - val_loss: 501.0701\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 469.0555 - val_loss: 498.2714\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 466.4564 - val_loss: 495.3968\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 463.7728 - val_loss: 492.5201\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 461.0729 - val_loss: 489.5907\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 458.3775 - val_loss: 486.5734\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 455.5651 - val_loss: 483.5423\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 452.7811 - val_loss: 480.4290\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 449.9425 - val_loss: 477.2929\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 447.0350 - val_loss: 474.1793\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 444.1646 - val_loss: 470.9897\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 441.1591 - val_loss: 467.8572\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 438.2900 - val_loss: 464.5780\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 435.2299 - val_loss: 461.3210\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 432.1941 - val_loss: 457.9888\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 429.1309 - val_loss: 454.6100\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 425.9891 - val_loss: 451.2043\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 422.8346 - val_loss: 447.7535\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 419.6363 - val_loss: 444.2582\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 416.4368 - val_loss: 440.6725\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 413.0500 - val_loss: 437.1663\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 409.8047 - val_loss: 433.5081\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 406.4396 - val_loss: 429.8096\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 403.0085 - val_loss: 426.1270\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 399.5391 - val_loss: 422.4548\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 396.2321 - val_loss: 418.5740\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 392.6326 - val_loss: 414.7910\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 389.1029 - val_loss: 410.9893\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 385.5766 - val_loss: 407.1384\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 382.0068 - val_loss: 403.2219\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 378.4112 - val_loss: 399.2029\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 374.7121 - val_loss: 395.1976\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 370.9915 - val_loss: 391.1817\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 367.2756 - val_loss: 387.1506\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 363.5554 - val_loss: 383.0360\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 359.7248 - val_loss: 378.9245\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 355.9133 - val_loss: 374.7414\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 352.0464 - val_loss: 370.5045\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 348.1228 - val_loss: 366.2909\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 344.2754 - val_loss: 362.0084\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 340.2406 - val_loss: 357.7942\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 336.3439 - val_loss: 353.4796\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 332.3725 - val_loss: 349.1090\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 328.3803 - val_loss: 344.6804\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 324.2169 - val_loss: 340.3766\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 320.1999 - val_loss: 335.9427\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 316.1677 - val_loss: 331.4228\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 311.9772 - val_loss: 326.9526\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 307.7886 - val_loss: 322.5438\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 303.7062 - val_loss: 317.9890\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 299.5192 - val_loss: 313.4438\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 295.2810 - val_loss: 308.9739\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 291.1409 - val_loss: 304.4424\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 286.9545 - val_loss: 299.8767\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 282.7484 - val_loss: 295.3166\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 278.4618 - val_loss: 290.8078\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 274.2218 - val_loss: 286.2151\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 269.9968 - val_loss: 281.5533\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 265.7276 - val_loss: 276.8996\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 261.3684 - val_loss: 272.3760\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 257.1554 - val_loss: 267.7732\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 252.8717 - val_loss: 263.1966\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 248.6399 - val_loss: 258.6024\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 244.3448 - val_loss: 254.0792\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 240.0676 - val_loss: 249.5114\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 235.8278 - val_loss: 244.9023\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 231.5743 - val_loss: 240.2877\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 227.2866 - val_loss: 235.7844\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 223.0368 - val_loss: 231.3022\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 218.8471 - val_loss: 226.7630\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 214.6314 - val_loss: 222.2301\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 210.3676 - val_loss: 217.7991\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 206.1957 - val_loss: 213.3619\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 185.038 - 0s 84us/step - loss: 202.0422 - val_loss: 208.9099\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 197.8883 - val_loss: 204.4986\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 193.7642 - val_loss: 200.0951\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 189.6500 - val_loss: 195.7474\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 185.5207 - val_loss: 191.4684\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 181.4758 - val_loss: 187.2041\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 177.4576 - val_loss: 182.9603\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 173.4282 - val_loss: 178.7777\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 169.4982 - val_loss: 174.5926\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 165.5000 - val_loss: 170.4814\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 161.6152 - val_loss: 166.3483\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 157.6899 - val_loss: 162.2540\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 153.8088 - val_loss: 158.2547\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 150.0394 - val_loss: 154.2835\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 146.2827 - val_loss: 150.3813\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 142.6095 - val_loss: 146.5125\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 138.9362 - val_loss: 142.6948\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 135.3134 - val_loss: 138.9615\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 131.7594 - val_loss: 135.2997\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 128.2384 - val_loss: 131.7225\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 124.8514 - val_loss: 128.1671\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 121.4813 - val_loss: 124.6510\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 118.1356 - val_loss: 121.2376\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 114.8791 - val_loss: 117.8753\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 111.6750 - val_loss: 114.5811\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 108.5601 - val_loss: 111.3246\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 105.4460 - val_loss: 108.1814\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 102.4589 - val_loss: 105.1105\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 99.5545 - val_loss: 102.0673\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 96.6417 - val_loss: 99.1132\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 93.8564 - val_loss: 96.2248\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 91.1221 - val_loss: 93.3947\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 88.4137 - val_loss: 90.6727\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 85.8723 - val_loss: 87.9677\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 83.2949 - val_loss: 85.3815\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 80.8295 - val_loss: 82.8779\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 78.4544 - val_loss: 80.3942\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 76.1425 - val_loss: 77.9639\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 73.8354 - val_loss: 75.6780\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 71.6870 - val_loss: 73.4206\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 69.5509 - val_loss: 71.2899\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 67.5101 - val_loss: 69.2053\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 65.5500 - val_loss: 67.1875\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 63.6556 - val_loss: 65.2125\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 61.7713 - val_loss: 63.3303\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 60.0096 - val_loss: 61.4815\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 58.2841 - val_loss: 59.7208\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 56.6102 - val_loss: 58.0318\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 54.9956 - val_loss: 56.3974\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 53.4547 - val_loss: 54.8112\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 51.9590 - val_loss: 53.2847\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 50.5113 - val_loss: 51.8161\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 49.1190 - val_loss: 50.4172\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 47.8147 - val_loss: 49.0700\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 46.5292 - val_loss: 47.7924\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 45.3091 - val_loss: 46.5764\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 44.1423 - val_loss: 45.4212\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 43.0256 - val_loss: 44.3054\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 41.9391 - val_loss: 43.2321\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 40.9344 - val_loss: 42.2084\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 39.9664 - val_loss: 41.2064\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 39.0180 - val_loss: 40.2718\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 38.1140 - val_loss: 39.4042\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 37.2692 - val_loss: 38.5972\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 36.4713 - val_loss: 37.7972\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 35.7027 - val_loss: 37.0257\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 34.9460 - val_loss: 36.3128\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 34.2477 - val_loss: 35.5950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 33.5688 - val_loss: 34.9321\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 32.8974 - val_loss: 34.3345\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 32.3067 - val_loss: 33.7411\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 31.7274 - val_loss: 33.1714\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 31.1606 - val_loss: 32.6408\n",
      "Epoch 223/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 30.6396 - val_loss: 32.1238\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 30.1435 - val_loss: 31.6179\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 29.6457 - val_loss: 31.1593\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 29.1845 - val_loss: 30.7156\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 28.7474 - val_loss: 30.3063\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 28.3286 - val_loss: 29.9103\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 27.9387 - val_loss: 29.5251\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 70us/step - loss: 27.5639 - val_loss: 29.1701\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 27.1974 - val_loss: 28.8195\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 26.8464 - val_loss: 28.4856\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 26.5377 - val_loss: 28.1610\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 26.2128 - val_loss: 27.8863\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 25.9222 - val_loss: 27.6124\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 25.6469 - val_loss: 27.3335\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 25.3854 - val_loss: 27.0733\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 25.1239 - val_loss: 26.8405\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.8848 - val_loss: 26.6086\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 24.6608 - val_loss: 26.3757\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 24.4202 - val_loss: 26.1701\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 24.2037 - val_loss: 25.9616\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 24.0013 - val_loss: 25.7678\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.8013 - val_loss: 25.5821\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 23.6218 - val_loss: 25.3996\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.4331 - val_loss: 25.2319\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 23.2706 - val_loss: 25.0612\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 23.0989 - val_loss: 24.9190\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 22.9490 - val_loss: 24.7684\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.7982 - val_loss: 24.6180\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.6583 - val_loss: 24.4766\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 22.5150 - val_loss: 24.3494\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.3855 - val_loss: 24.2207\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 113us/step - loss: 22.2576 - val_loss: 24.0920\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 22.1426 - val_loss: 23.9726\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 22.0196 - val_loss: 23.8624\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.9005 - val_loss: 23.7593\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.7985 - val_loss: 23.6644\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.6897 - val_loss: 23.5705\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 21.6019 - val_loss: 23.4648\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.4947 - val_loss: 23.3614\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.4020 - val_loss: 23.2714\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.3075 - val_loss: 23.1842\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 21.2196 - val_loss: 23.1031\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 21.1337 - val_loss: 23.0134\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 21.0507 - val_loss: 22.9332\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.9690 - val_loss: 22.8594\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.8989 - val_loss: 22.7744\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.8148 - val_loss: 22.7017\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 20.7386 - val_loss: 22.6215\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 20.6644 - val_loss: 22.5450\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 20.5913 - val_loss: 22.4709\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 20.5229 - val_loss: 22.4104\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.4540 - val_loss: 22.3397\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 20.3907 - val_loss: 22.2759\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 20.3294 - val_loss: 22.1996\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.2605 - val_loss: 22.1386\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.2000 - val_loss: 22.0792\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 20.1336 - val_loss: 22.0235\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 26.16 - 0s 84us/step - loss: 20.0771 - val_loss: 21.9653\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 20.0215 - val_loss: 21.8994\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.9606 - val_loss: 21.8431\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.9045 - val_loss: 21.7800\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 19.8479 - val_loss: 21.7264\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.8011 - val_loss: 21.6653\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.7440 - val_loss: 21.6138\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.6940 - val_loss: 21.5644\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.6399 - val_loss: 21.5162\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.5905 - val_loss: 21.4699\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.5458 - val_loss: 21.4121\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 19.4928 - val_loss: 21.3692\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.4499 - val_loss: 21.3139\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.4016 - val_loss: 21.2657\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.3507 - val_loss: 21.2226\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.3058 - val_loss: 21.1749\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 19.2607 - val_loss: 21.1255\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 19.2169 - val_loss: 21.0744\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 19.1691 - val_loss: 21.0330\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.1250 - val_loss: 20.9859\n",
      "Epoch 300/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 19.0850 - val_loss: 20.9408\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 19.0462 - val_loss: 20.8866\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.9991 - val_loss: 20.8474\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.9611 - val_loss: 20.8017\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.9162 - val_loss: 20.7567\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.8783 - val_loss: 20.7137\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 18.8359 - val_loss: 20.6649\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.7996 - val_loss: 20.6235\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.7584 - val_loss: 20.5749\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.7183 - val_loss: 20.5327\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.6835 - val_loss: 20.4970\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.6420 - val_loss: 20.4556\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.6067 - val_loss: 20.4181\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.5700 - val_loss: 20.3802\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.5325 - val_loss: 20.3436\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.4985 - val_loss: 20.3029\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4671 - val_loss: 20.2625\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.4287 - val_loss: 20.2308\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 18.3948 - val_loss: 20.1958\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 18.3591 - val_loss: 20.1584\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 18.3267 - val_loss: 20.1195\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2930 - val_loss: 20.0860\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.2607 - val_loss: 20.0456\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 18.2260 - val_loss: 20.0119\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 18.1966 - val_loss: 19.9759\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 18.1638 - val_loss: 19.9417\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.1320 - val_loss: 19.9120\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 18.1005 - val_loss: 19.8771\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0680 - val_loss: 19.8440\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 18.0366 - val_loss: 19.8075\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 18.0080 - val_loss: 19.7700\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 17.9755 - val_loss: 19.7389\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.9481 - val_loss: 19.7059\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.9149 - val_loss: 19.6743\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.8850 - val_loss: 19.6440\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.8582 - val_loss: 19.6140\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.8288 - val_loss: 19.5868\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7980 - val_loss: 19.5557\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7713 - val_loss: 19.5323\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7428 - val_loss: 19.4989\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.7152 - val_loss: 19.4667\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.6864 - val_loss: 19.4371\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.6605 - val_loss: 19.4086\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.6327 - val_loss: 19.3769\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.6037 - val_loss: 19.3520\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.5794 - val_loss: 19.3238\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 17.5542 - val_loss: 19.2891\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.5245 - val_loss: 19.2605\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 17.4975 - val_loss: 19.2313\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.4734 - val_loss: 19.2086\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 17.4472 - val_loss: 19.1787\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.4206 - val_loss: 19.1501\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3956 - val_loss: 19.1243\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.3714 - val_loss: 19.0989\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.3468 - val_loss: 19.0725\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.3215 - val_loss: 19.0424\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.2968 - val_loss: 19.0159\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.2717 - val_loss: 18.9911\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.2479 - val_loss: 18.9659\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.2242 - val_loss: 18.9360\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 17.2005 - val_loss: 18.9122\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1762 - val_loss: 18.8861\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1542 - val_loss: 18.8598\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1306 - val_loss: 18.8356\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.1061 - val_loss: 18.8158\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0843 - val_loss: 18.7921\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 17.0608 - val_loss: 18.7639\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 17.0412 - val_loss: 18.7433\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 17.0165 - val_loss: 18.7198\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.9968 - val_loss: 18.7000\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 76us/step - loss: 16.9741 - val_loss: 18.6774\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.9556 - val_loss: 18.6533\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9301 - val_loss: 18.6355\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.9093 - val_loss: 18.6107\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.8883 - val_loss: 18.5888\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.8650 - val_loss: 18.5653\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 16.8448 - val_loss: 18.5421\n",
      "Epoch 377/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.8241 - val_loss: 18.5127\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.8026 - val_loss: 18.4902\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7818 - val_loss: 18.4703\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.7597 - val_loss: 18.4478\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7411 - val_loss: 18.4240\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.7203 - val_loss: 18.4039\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 16.7007 - val_loss: 18.3869\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.6798 - val_loss: 18.3644\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.6620 - val_loss: 18.3440\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.6395 - val_loss: 18.3203\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 16.6205 - val_loss: 18.2932\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.6016 - val_loss: 18.2695\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5803 - val_loss: 18.2477\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5610 - val_loss: 18.2277\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5428 - val_loss: 18.2083\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.5234 - val_loss: 18.1867\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.5040 - val_loss: 18.1658\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4843 - val_loss: 18.1467\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4658 - val_loss: 18.1248\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.4469 - val_loss: 18.1037\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.4289 - val_loss: 18.0865\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.4086 - val_loss: 18.0631\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 16.3928 - val_loss: 18.0350\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3721 - val_loss: 18.0161\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.3541 - val_loss: 17.9957\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.3368 - val_loss: 17.9776\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 16.3178 - val_loss: 17.9596\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.3008 - val_loss: 17.9404\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 16.2823 - val_loss: 17.9216\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2658 - val_loss: 17.9023\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2466 - val_loss: 17.8882\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.2308 - val_loss: 17.8707\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.2115 - val_loss: 17.8545\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 16.1949 - val_loss: 17.8339\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.1779 - val_loss: 17.8141\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1613 - val_loss: 17.7925\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.1417 - val_loss: 17.7749\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1257 - val_loss: 17.7547\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 16.1102 - val_loss: 17.7301\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0928 - val_loss: 17.7177\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0742 - val_loss: 17.6992\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.0579 - val_loss: 17.6792\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 16.0428 - val_loss: 17.6615\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0246 - val_loss: 17.6457\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 16.0088 - val_loss: 17.6248\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.9927 - val_loss: 17.6056\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9771 - val_loss: 17.5871\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9614 - val_loss: 17.5718\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9440 - val_loss: 17.5560\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.9301 - val_loss: 17.5359\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.9127 - val_loss: 17.5203\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8967 - val_loss: 17.5091\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8815 - val_loss: 17.4959\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.8661 - val_loss: 17.4819\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.8515 - val_loss: 17.4701\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8360 - val_loss: 17.4531\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.8211 - val_loss: 17.4363\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.8042 - val_loss: 17.4183\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 15.7897 - val_loss: 17.4000\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7745 - val_loss: 17.3829\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.7591 - val_loss: 17.3680\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.7439 - val_loss: 17.3543\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.7283 - val_loss: 17.3378\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.7148 - val_loss: 17.3204\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.7017 - val_loss: 17.3053\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.6872 - val_loss: 17.2847\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.6705 - val_loss: 17.2699\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6594 - val_loss: 17.2603\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.6413 - val_loss: 17.2430\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.6289 - val_loss: 17.2240\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 105us/step - loss: 15.6128 - val_loss: 17.2115\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.5970 - val_loss: 17.1938\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5845 - val_loss: 17.1745\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.5702 - val_loss: 17.1595\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.5566 - val_loss: 17.1479\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.5420 - val_loss: 17.1329\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5274 - val_loss: 17.1210\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.5135 - val_loss: 17.1029\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.5010 - val_loss: 17.0846\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.4856 - val_loss: 17.0693\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.4733 - val_loss: 17.0536\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4588 - val_loss: 17.0374\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4453 - val_loss: 17.0229\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4302 - val_loss: 17.0109\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4166 - val_loss: 16.9978\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.4032 - val_loss: 16.9832\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3907 - val_loss: 16.9668\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.3774 - val_loss: 16.9521\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3635 - val_loss: 16.9404\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3501 - val_loss: 16.9287\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.3366 - val_loss: 16.9159\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3250 - val_loss: 16.8987\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.3111 - val_loss: 16.8892\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.2965 - val_loss: 16.8751\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2840 - val_loss: 16.8613\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2713 - val_loss: 16.8492\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.2595 - val_loss: 16.8313\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 15.2478 - val_loss: 16.8224\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 15.2329 - val_loss: 16.8049\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.2212 - val_loss: 16.7888\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.2076 - val_loss: 16.7776\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1958 - val_loss: 16.7649\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 15.1826 - val_loss: 16.7558\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 15.1709 - val_loss: 16.7447\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.1587 - val_loss: 16.7326\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.1462 - val_loss: 16.7200\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.1339 - val_loss: 16.7077\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.1213 - val_loss: 16.6956\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 15.1084 - val_loss: 16.6817\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0969 - val_loss: 16.6707\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 15.0834 - val_loss: 16.6592\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.0716 - val_loss: 16.6471\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.0591 - val_loss: 16.6334\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 15.0468 - val_loss: 16.6209\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.0351 - val_loss: 16.6096\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 15.0236 - val_loss: 16.5996\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 15.0105 - val_loss: 16.5909\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.9998 - val_loss: 16.5797\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 14.9870 - val_loss: 16.5685\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9755 - val_loss: 16.5587\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.9633 - val_loss: 16.5498\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 14.9518 - val_loss: 16.5416\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9402 - val_loss: 16.5256\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 14.9282 - val_loss: 16.5123\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9167 - val_loss: 16.5042\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.9051 - val_loss: 16.4925\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8929 - val_loss: 16.4789\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8822 - val_loss: 16.4652\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.8708 - val_loss: 16.4547\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8596 - val_loss: 16.4430\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8476 - val_loss: 16.4334\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8366 - val_loss: 16.4230\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.8250 - val_loss: 16.4137\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 14.8145 - val_loss: 16.3979\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.8011 - val_loss: 16.3850\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.7898 - val_loss: 16.3697\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7785 - val_loss: 16.3579\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7669 - val_loss: 16.3463\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7549 - val_loss: 16.3361\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7436 - val_loss: 16.3243\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 14.7328 - val_loss: 16.3131\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.7224 - val_loss: 16.2987\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.7110 - val_loss: 16.2889\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.7008 - val_loss: 16.2806\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6896 - val_loss: 16.2706\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 14.6794 - val_loss: 16.2577\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.6668 - val_loss: 16.2484\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 14.6564 - val_loss: 16.2356\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.6457 - val_loss: 16.2263\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6346 - val_loss: 16.2122\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.6247 - val_loss: 16.1997\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6125 - val_loss: 16.1900\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.6032 - val_loss: 16.1811\n",
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 14.5909 - val_loss: 16.1723\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5809 - val_loss: 16.1642\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5703 - val_loss: 16.1549\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5608 - val_loss: 16.1421\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.5501 - val_loss: 16.1336\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 14.5382 - val_loss: 16.1191\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5284 - val_loss: 16.1092\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.5180 - val_loss: 16.1007\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.5062 - val_loss: 16.0881\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4963 - val_loss: 16.0748\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4868 - val_loss: 16.0584\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4750 - val_loss: 16.0500\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.4649 - val_loss: 16.0396\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4543 - val_loss: 16.0279\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.4451 - val_loss: 16.0202\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4350 - val_loss: 16.0093\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4240 - val_loss: 16.0034\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4142 - val_loss: 15.9945\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.4047 - val_loss: 15.9854\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3936 - val_loss: 15.9695\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 14.3832 - val_loss: 15.9591\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3728 - val_loss: 15.9486\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3633 - val_loss: 15.9380\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3534 - val_loss: 15.9294\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 14.3426 - val_loss: 15.9201\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.3331 - val_loss: 15.9109\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3228 - val_loss: 15.9032\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.3126 - val_loss: 15.8926\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.3030 - val_loss: 15.8810\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 14.2940 - val_loss: 15.8712\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2840 - val_loss: 15.8626\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2735 - val_loss: 15.8536\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2637 - val_loss: 15.8444\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.2544 - val_loss: 15.8369\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2442 - val_loss: 15.8268\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.2344 - val_loss: 15.8156\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2252 - val_loss: 15.8082\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.2147 - val_loss: 15.8012\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.2051 - val_loss: 15.7913\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1970 - val_loss: 15.7784\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1869 - val_loss: 15.7691\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.1778 - val_loss: 15.7612\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.1675 - val_loss: 15.7486\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 14.1576 - val_loss: 15.7414\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1491 - val_loss: 15.7301\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.1380 - val_loss: 15.7208\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1292 - val_loss: 15.7113\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 14.1193 - val_loss: 15.7028\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1098 - val_loss: 15.6987\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.1010 - val_loss: 15.6869\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.0903 - val_loss: 15.6786\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.0831 - val_loss: 15.6675\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0729 - val_loss: 15.6613\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 14.0628 - val_loss: 15.6546\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 14.0540 - val_loss: 15.6456\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 69us/step - loss: 14.0462 - val_loss: 15.6344\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0359 - val_loss: 15.6320\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 14.0274 - val_loss: 15.6215\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 14.0170 - val_loss: 15.6132\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 14.0081 - val_loss: 15.6027\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9983 - val_loss: 15.5918\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9883 - val_loss: 15.5814\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9802 - val_loss: 15.5721\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9713 - val_loss: 15.5626\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9615 - val_loss: 15.5528\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.9528 - val_loss: 15.5465\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9444 - val_loss: 15.5405\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9347 - val_loss: 15.5295\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.9243 - val_loss: 15.5188\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.9156 - val_loss: 15.5105\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.9068 - val_loss: 15.5024\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8979 - val_loss: 15.4987\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8889 - val_loss: 15.4852\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8801 - val_loss: 15.4721\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8701 - val_loss: 15.4655\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.8610 - val_loss: 15.4582\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8542 - val_loss: 15.4542\n",
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8434 - val_loss: 15.4419\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.8345 - val_loss: 15.4328\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8256 - val_loss: 15.4216\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8171 - val_loss: 15.4132\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.8076 - val_loss: 15.4047\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.8000 - val_loss: 15.3982\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7907 - val_loss: 15.3886\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7818 - val_loss: 15.3810\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7729 - val_loss: 15.3761\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.7637 - val_loss: 15.3671\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7551 - val_loss: 15.3578\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.7472 - val_loss: 15.3507\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7377 - val_loss: 15.3402\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.7299 - val_loss: 15.3319\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7200 - val_loss: 15.3241\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.7125 - val_loss: 15.3165\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.7032 - val_loss: 15.3099\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.6949 - val_loss: 15.3025\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.6862 - val_loss: 15.2994\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.6782 - val_loss: 15.2939\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.6687 - val_loss: 15.2870\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6607 - val_loss: 15.2796\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 13.6527 - val_loss: 15.2732\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6431 - val_loss: 15.2634\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.6360 - val_loss: 15.2546\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.6268 - val_loss: 15.2491\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 13.6184 - val_loss: 15.2410\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.6102 - val_loss: 15.2355\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.6027 - val_loss: 15.2291\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5933 - val_loss: 15.2236\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.5856 - val_loss: 15.2186\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5782 - val_loss: 15.2099\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.5684 - val_loss: 15.2055\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 13.5602 - val_loss: 15.1993\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5526 - val_loss: 15.1912\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5436 - val_loss: 15.1857\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5351 - val_loss: 15.1799\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.5297 - val_loss: 15.1705\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5193 - val_loss: 15.1671\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.5113 - val_loss: 15.1626\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.5029 - val_loss: 15.1551\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4944 - val_loss: 15.1492\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4873 - val_loss: 15.1437\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4778 - val_loss: 15.1337\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.4692 - val_loss: 15.1255\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4615 - val_loss: 15.1138\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.4538 - val_loss: 15.1023\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 13.4456 - val_loss: 15.0983\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4373 - val_loss: 15.0909\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4290 - val_loss: 15.0828\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.4215 - val_loss: 15.0705\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.4125 - val_loss: 15.0630\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.4042 - val_loss: 15.0533\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3955 - val_loss: 15.0460\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 13.3883 - val_loss: 15.0402\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 13.3813 - val_loss: 15.0295\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.3719 - val_loss: 15.0246\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3644 - val_loss: 15.0200\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3567 - val_loss: 15.0116\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.3485 - val_loss: 15.0065\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3411 - val_loss: 14.9996\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.3330 - val_loss: 14.9941\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.3260 - val_loss: 14.9826\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3173 - val_loss: 14.9763\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3098 - val_loss: 14.9688\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.3019 - val_loss: 14.9608\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2942 - val_loss: 14.9528\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 13.2861 - val_loss: 14.9470\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.2779 - val_loss: 14.9367\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2698 - val_loss: 14.9284\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2630 - val_loss: 14.9228\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2553 - val_loss: 14.9092\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2475 - val_loss: 14.9008\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 13.2380 - val_loss: 14.8963\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2306 - val_loss: 14.8918\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2233 - val_loss: 14.8879\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.2160 - val_loss: 14.8810\n",
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2079 - val_loss: 14.8742\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.2002 - val_loss: 14.8677\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1942 - val_loss: 14.8581\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1856 - val_loss: 14.8547\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 13.1782 - val_loss: 14.8487\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1702 - val_loss: 14.8411\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1624 - val_loss: 14.8327\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1562 - val_loss: 14.8298\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.1477 - val_loss: 14.8226\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1398 - val_loss: 14.8157\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1325 - val_loss: 14.8095\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.1250 - val_loss: 14.8022\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.1171 - val_loss: 14.7951\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 13.1104 - val_loss: 14.7870\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 13.1021 - val_loss: 14.7823\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0945 - val_loss: 14.7763\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 13.0865 - val_loss: 14.7704\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0793 - val_loss: 14.7613\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0718 - val_loss: 14.7544\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0662 - val_loss: 14.7452\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 13.0565 - val_loss: 14.7407\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 13.0487 - val_loss: 14.7318\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0416 - val_loss: 14.7253\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0345 - val_loss: 14.7182\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 13.0269 - val_loss: 14.7144\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.0190 - val_loss: 14.7055\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 13.0116 - val_loss: 14.6991\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 13.0045 - val_loss: 14.6937\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9981 - val_loss: 14.6857\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 12.9894 - val_loss: 14.6792\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9820 - val_loss: 14.6717\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9742 - val_loss: 14.6632\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.9679 - val_loss: 14.6555\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9595 - val_loss: 14.6499\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9525 - val_loss: 14.6391\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9449 - val_loss: 14.6307\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.9390 - val_loss: 14.6190\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.9297 - val_loss: 14.6106\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.9216 - val_loss: 14.6039\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.9143 - val_loss: 14.5978\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.9076 - val_loss: 14.5928\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.9005 - val_loss: 14.5820\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8932 - val_loss: 14.5787\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8854 - val_loss: 14.5710\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8773 - val_loss: 14.5647\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8707 - val_loss: 14.5571\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 12.8626 - val_loss: 14.5503\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.8563 - val_loss: 14.5434\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8506 - val_loss: 14.5345\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8408 - val_loss: 14.5295\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.8345 - val_loss: 14.5197\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8265 - val_loss: 14.5135\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8195 - val_loss: 14.5106\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.8128 - val_loss: 14.4996\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.8045 - val_loss: 14.4955\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7970 - val_loss: 14.4904\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7899 - val_loss: 14.4842\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.7821 - val_loss: 14.4807\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7762 - val_loss: 14.4776\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7686 - val_loss: 14.4721\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7623 - val_loss: 14.4659\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7551 - val_loss: 14.4631\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7478 - val_loss: 14.4572\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7404 - val_loss: 14.4521\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.7347 - val_loss: 14.4454\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.7266 - val_loss: 14.4402\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.7197 - val_loss: 14.4365\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7151 - val_loss: 14.4271\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.7061 - val_loss: 14.4226\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6999 - val_loss: 14.4193\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 12.6917 - val_loss: 14.4131\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6860 - val_loss: 14.4044\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.6784 - val_loss: 14.4009\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6712 - val_loss: 14.3930\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6646 - val_loss: 14.3862\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.6571 - val_loss: 14.3811\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6505 - val_loss: 14.3767\n",
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.6439 - val_loss: 14.3680\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6365 - val_loss: 14.3591\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 12.6294 - val_loss: 14.3506\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6223 - val_loss: 14.3442\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6155 - val_loss: 14.3398\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.6081 - val_loss: 14.3341\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.6017 - val_loss: 14.3273\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5943 - val_loss: 14.3205\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.5887 - val_loss: 14.3190\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5820 - val_loss: 14.3145\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5738 - val_loss: 14.3078\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5670 - val_loss: 14.3015\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.5602 - val_loss: 14.2936\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5540 - val_loss: 14.2831\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5480 - val_loss: 14.2765\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5402 - val_loss: 14.2741\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5328 - val_loss: 14.2688\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.5250 - val_loss: 14.2605\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5192 - val_loss: 14.2525\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.5123 - val_loss: 14.2448\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.5050 - val_loss: 14.2401\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4989 - val_loss: 14.2331\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4914 - val_loss: 14.2285\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4846 - val_loss: 14.2246\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.4800 - val_loss: 14.2220\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4720 - val_loss: 14.2165\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4646 - val_loss: 14.2100\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.4585 - val_loss: 14.2006\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4517 - val_loss: 14.1936\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.4451 - val_loss: 14.1882\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4421 - val_loss: 14.1767\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 12.4310 - val_loss: 14.1714\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4245 - val_loss: 14.1655\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.4186 - val_loss: 14.1589\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4109 - val_loss: 14.1534\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.4057 - val_loss: 14.1477\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3974 - val_loss: 14.1399\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.3923 - val_loss: 14.1287\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.3854 - val_loss: 14.1194\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3777 - val_loss: 14.1155\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3716 - val_loss: 14.1109\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3643 - val_loss: 14.1054\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3577 - val_loss: 14.0972\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 12.3508 - val_loss: 14.0944\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3440 - val_loss: 14.0868\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.3370 - val_loss: 14.0819\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3314 - val_loss: 14.0778\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.3234 - val_loss: 14.0740\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 12.3179 - val_loss: 14.0689\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3105 - val_loss: 14.0671\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.3042 - val_loss: 14.0625\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2973 - val_loss: 14.0573\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2907 - val_loss: 14.0510\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 44us/step - loss: 12.2844 - val_loss: 14.0461\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 130us/step - loss: 12.2774 - val_loss: 14.0418\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.2704 - val_loss: 14.0395\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.2643 - val_loss: 14.0353\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.036 - 0s 87us/step - loss: 12.2577 - val_loss: 14.0313\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.2514 - val_loss: 14.0281\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2450 - val_loss: 14.0209\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 12.2392 - val_loss: 14.0168\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 75us/step - loss: 12.2322 - val_loss: 14.0075\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.2257 - val_loss: 14.0011\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 12.2194 - val_loss: 13.9974\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2131 - val_loss: 13.9955\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 84us/step - loss: 12.2062 - val_loss: 13.9926\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.2011 - val_loss: 13.9897\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 12.1950 - val_loss: 13.9814\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1871 - val_loss: 13.9749\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.1805 - val_loss: 13.9708\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1740 - val_loss: 13.9684\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.1687 - val_loss: 13.9624\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1641 - val_loss: 13.9589\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1547 - val_loss: 13.9491\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1490 - val_loss: 13.9416\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1422 - val_loss: 13.9339\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.1363 - val_loss: 13.9309\n",
      "Epoch 838/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1316 - val_loss: 13.9237\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.1239 - val_loss: 13.9193\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 12.1167 - val_loss: 13.9144\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.1112 - val_loss: 13.9115\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 12.1049 - val_loss: 13.9067\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0993 - val_loss: 13.8982\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0923 - val_loss: 13.8897\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 12.0856 - val_loss: 13.8859\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0799 - val_loss: 13.8794\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0730 - val_loss: 13.8742\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 12.0669 - val_loss: 13.8705\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 12.0609 - val_loss: 13.8687\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0544 - val_loss: 13.8635\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 12.0485 - val_loss: 13.8594\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0426 - val_loss: 13.8540\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0353 - val_loss: 13.8461\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0306 - val_loss: 13.8391\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 12.0231 - val_loss: 13.8338\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 12.0168 - val_loss: 13.8258\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 12.0117 - val_loss: 13.8209\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 12.0041 - val_loss: 13.8171\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.9979 - val_loss: 13.8120\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9918 - val_loss: 13.8066\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9858 - val_loss: 13.8021\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9794 - val_loss: 13.7969\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.9735 - val_loss: 13.7884\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 11.9665 - val_loss: 13.7851\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9610 - val_loss: 13.7792\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9557 - val_loss: 13.7730\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.9486 - val_loss: 13.7701\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9432 - val_loss: 13.7670\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.9365 - val_loss: 13.7579\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9308 - val_loss: 13.7503\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9249 - val_loss: 13.7441\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9189 - val_loss: 13.7358\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 17.56 - 0s 80us/step - loss: 11.9118 - val_loss: 13.7342\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.9061 - val_loss: 13.7307\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.9007 - val_loss: 13.7290\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.8938 - val_loss: 13.7260\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 11.8884 - val_loss: 13.7206\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8820 - val_loss: 13.7179\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8760 - val_loss: 13.7132\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8704 - val_loss: 13.7069\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.8640 - val_loss: 13.7036\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 11.8576 - val_loss: 13.7004\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.8521 - val_loss: 13.6946\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.8470 - val_loss: 13.6857\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8402 - val_loss: 13.6823\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 11.8345 - val_loss: 13.6781\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8289 - val_loss: 13.6758\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8229 - val_loss: 13.6705\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8173 - val_loss: 13.6690\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.8103 - val_loss: 13.6624\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.8052 - val_loss: 13.6559\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7991 - val_loss: 13.6547\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.7934 - val_loss: 13.6475\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7861 - val_loss: 13.6436\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7808 - val_loss: 13.6389\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.7749 - val_loss: 13.6345\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7688 - val_loss: 13.6284\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7634 - val_loss: 13.6236\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7567 - val_loss: 13.6199\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7513 - val_loss: 13.6160\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7451 - val_loss: 13.6151\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7401 - val_loss: 13.6105\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.7333 - val_loss: 13.6071\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7277 - val_loss: 13.6029\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7215 - val_loss: 13.5994\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7172 - val_loss: 13.5951\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.7099 - val_loss: 13.5869\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.7046 - val_loss: 13.5786\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.6979 - val_loss: 13.5741\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.6930 - val_loss: 13.5707\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.6872 - val_loss: 13.5609\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.6811 - val_loss: 13.5584\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.6748 - val_loss: 13.5540\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.6694 - val_loss: 13.5503\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6636 - val_loss: 13.5413\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6572 - val_loss: 13.5366\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.6522 - val_loss: 13.5306\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6459 - val_loss: 13.5260\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.6409 - val_loss: 13.5194\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6350 - val_loss: 13.5147\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6300 - val_loss: 13.5093\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6233 - val_loss: 13.5061\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6172 - val_loss: 13.5048\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6119 - val_loss: 13.5003\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.6067 - val_loss: 13.4931\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 73us/step - loss: 11.6011 - val_loss: 13.4892\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5950 - val_loss: 13.4870\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5892 - val_loss: 13.4846\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5834 - val_loss: 13.4762\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 11.5782 - val_loss: 13.4687\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5727 - val_loss: 13.4622\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.5660 - val_loss: 13.4590\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 11.5602 - val_loss: 13.4572\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 11.5550 - val_loss: 13.4535\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 11.5497 - val_loss: 13.4497\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.5434 - val_loss: 13.4433\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5385 - val_loss: 13.4354\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5321 - val_loss: 13.4312\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.5259 - val_loss: 13.4236\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.5206 - val_loss: 13.4207\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5149 - val_loss: 13.4182\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.5094 - val_loss: 13.4140\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.5035 - val_loss: 13.4106\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4989 - val_loss: 13.4043\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.4928 - val_loss: 13.4025\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.4867 - val_loss: 13.3986\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4817 - val_loss: 13.3957\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4762 - val_loss: 13.3890\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.4702 - val_loss: 13.3839\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.4654 - val_loss: 13.3790\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.4587 - val_loss: 13.3723\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 11.4536 - val_loss: 13.3693\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4483 - val_loss: 13.3646\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4433 - val_loss: 13.3596\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 11.4370 - val_loss: 13.3554\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4317 - val_loss: 13.3488\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4273 - val_loss: 13.3469\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4206 - val_loss: 13.3440\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4156 - val_loss: 13.3418\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.4098 - val_loss: 13.3381\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.4053 - val_loss: 13.3347\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3989 - val_loss: 13.3290\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 11.3939 - val_loss: 13.3234\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3886 - val_loss: 13.3160\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.3828 - val_loss: 13.3103\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3773 - val_loss: 13.3081\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3738 - val_loss: 13.3014\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3668 - val_loss: 13.2990\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3614 - val_loss: 13.2964\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.3559 - val_loss: 13.2912\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3511 - val_loss: 13.2847\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3452 - val_loss: 13.2773\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3400 - val_loss: 13.2737\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3351 - val_loss: 13.2701\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3293 - val_loss: 13.2650\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.3243 - val_loss: 13.2586\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3183 - val_loss: 13.2554\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 83us/step - loss: 11.3129 - val_loss: 13.2507\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.3076 - val_loss: 13.2473\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.3024 - val_loss: 13.2434\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2969 - val_loss: 13.2387\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 76us/step - loss: 11.2921 - val_loss: 13.2363\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2858 - val_loss: 13.2335\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.2816 - val_loss: 13.2315\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2770 - val_loss: 13.2293\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 11.2706 - val_loss: 13.2240\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2664 - val_loss: 13.2206\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2609 - val_loss: 13.2184\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2561 - val_loss: 13.2097\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2496 - val_loss: 13.2047\n",
      "Epoch 991/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2446 - val_loss: 13.2013\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 11.2392 - val_loss: 13.1969\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2340 - val_loss: 13.1917\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2286 - val_loss: 13.1844\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2239 - val_loss: 13.1776\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.2182 - val_loss: 13.1746\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 11.2124 - val_loss: 13.1694\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 82us/step - loss: 11.2073 - val_loss: 13.1640\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 11.2027 - val_loss: 13.1540\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 11.2003 - val_loss: 13.1456\n",
      "12.625592029700845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.1589509 ,  0.288581  ,  0.02756506, -0.23423865,  0.08846465],\n",
       "        [-0.5468112 ,  0.41990665,  0.1826548 , -0.37435243, -0.08257213],\n",
       "        [ 0.30302823,  0.15068734, -0.07832705,  0.12217239, -0.5837464 ],\n",
       "        [ 0.21054249, -0.12464371, -0.37689134, -0.7408029 ,  0.5025258 ],\n",
       "        [ 0.01965409,  0.57485855,  0.5610765 ,  0.2516148 , -0.11407346],\n",
       "        [-0.20426354,  0.12939483,  0.62788767,  0.06891876,  0.69022894],\n",
       "        [-0.08856832, -0.337488  , -0.08539102,  0.37062246, -0.06784084]],\n",
       "       dtype=float32),\n",
       " array([-0.9901753 , -1.0133439 ,  0.18916191, -0.10418037,  0.21094565],\n",
       "       dtype=float32),\n",
       " array([[ 0.09275706,  1.1027613 , -0.44580683, -0.63820094, -1.198967  ,\n",
       "          0.4233238 , -0.04828922, -1.0488257 , -0.13137946, -0.21146952],\n",
       "        [ 0.18793471,  0.4564533 ,  0.23445234, -0.49052835, -1.0812689 ,\n",
       "          0.6953258 ,  0.21358359, -0.3958399 ,  0.12150183,  0.28841454],\n",
       "        [ 0.42533726,  0.12610047,  0.5879555 ,  0.08642611,  0.6856074 ,\n",
       "         -0.6537233 , -0.38731912, -0.19460492, -0.39757067, -0.31797028],\n",
       "        [-0.31312525, -0.40539327,  0.33012673, -0.38519368,  0.9205263 ,\n",
       "         -0.94781536, -0.01082134, -0.13101083, -0.43118662,  0.10204799],\n",
       "        [ 0.3258556 ,  0.5163737 , -0.09247423,  0.63599724,  0.37180883,\n",
       "         -0.07496666, -0.14287876,  0.11264412, -0.40103242,  0.18744457]],\n",
       "       dtype=float32),\n",
       " array([ 0.37623638, -1.2314541 ,  0.0224859 ,  0.14473373,  1.6003592 ,\n",
       "        -1.6013243 , -0.7771559 ,  1.085552  , -0.36771855,  0.5057798 ],\n",
       "       dtype=float32),\n",
       " array([[ 0.31457064],\n",
       "        [-1.6511238 ],\n",
       "        [ 0.23946592],\n",
       "        [ 0.36842346],\n",
       "        [ 2.4464753 ],\n",
       "        [-2.1534894 ],\n",
       "        [-0.8689495 ],\n",
       "        [ 1.3778907 ],\n",
       "        [-0.52675265],\n",
       "        [ 0.47613093]], dtype=float32),\n",
       " array([1.5017889], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, sgd, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 59 samples\n",
      "Epoch 1/1000\n",
      "274/274 [==============================] - 0s 619us/step - loss: 555.5962 - val_loss: 515.5889\n",
      "Epoch 2/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 449.1514 - val_loss: 390.7533\n",
      "Epoch 3/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 345.2032 - val_loss: 280.0039\n",
      "Epoch 4/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 238.5656 - val_loss: 162.9266\n",
      "Epoch 5/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 114.7872 - val_loss: 60.3864\n",
      "Epoch 6/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 39.4776 - val_loss: 29.6825\n",
      "Epoch 7/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 20.5563 - val_loss: 18.5583\n",
      "Epoch 8/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 17.1062 - val_loss: 20.3535\n",
      "Epoch 9/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 16.0225 - val_loss: 16.2643\n",
      "Epoch 10/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 15.4513 - val_loss: 16.8734\n",
      "Epoch 11/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 14.3847 - val_loss: 16.9543\n",
      "Epoch 12/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 13.3288 - val_loss: 21.1269\n",
      "Epoch 13/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 13.5815 - val_loss: 15.2513\n",
      "Epoch 14/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 12.3847 - val_loss: 13.3483\n",
      "Epoch 15/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 11.2397 - val_loss: 13.2355\n",
      "Epoch 16/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 11.4745 - val_loss: 12.2370\n",
      "Epoch 17/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 11.1067 - val_loss: 12.5647\n",
      "Epoch 18/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 10.4476 - val_loss: 11.5100\n",
      "Epoch 19/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.7272 - val_loss: 12.3084\n",
      "Epoch 20/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.9275 - val_loss: 15.3647\n",
      "Epoch 21/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.7438 - val_loss: 12.3220\n",
      "Epoch 22/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.6881 - val_loss: 11.7211\n",
      "Epoch 23/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.5254 - val_loss: 11.7953\n",
      "Epoch 24/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 9.5428 - val_loss: 10.6737\n",
      "Epoch 25/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.0846 - val_loss: 13.7568\n",
      "Epoch 26/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0988 - val_loss: 10.9942\n",
      "Epoch 27/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0232 - val_loss: 12.5561\n",
      "Epoch 28/1000\n",
      "274/274 [==============================] - 0s 90us/step - loss: 8.5859 - val_loss: 12.0207\n",
      "Epoch 29/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.8204 - val_loss: 10.7925\n",
      "Epoch 30/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.7640 - val_loss: 10.2443\n",
      "Epoch 31/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 9.3431 - val_loss: 11.8473\n",
      "Epoch 32/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 9.0347 - val_loss: 12.5916\n",
      "Epoch 33/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 9.4417 - val_loss: 11.4032\n",
      "Epoch 34/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9081 - val_loss: 11.0923\n",
      "Epoch 35/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.6272 - val_loss: 11.3306\n",
      "Epoch 36/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.8172 - val_loss: 12.2403\n",
      "Epoch 37/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.1093 - val_loss: 10.4953\n",
      "Epoch 38/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.3908 - val_loss: 10.4977\n",
      "Epoch 39/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.9264 - val_loss: 11.5272\n",
      "Epoch 40/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4296 - val_loss: 11.2289\n",
      "Epoch 41/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.8622 - val_loss: 10.6990\n",
      "Epoch 42/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2122 - val_loss: 11.6414\n",
      "Epoch 43/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5725 - val_loss: 11.0173\n",
      "Epoch 44/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.1572 - val_loss: 11.0048\n",
      "Epoch 45/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5968 - val_loss: 11.1294\n",
      "Epoch 46/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3157 - val_loss: 12.1640\n",
      "Epoch 47/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.8043 - val_loss: 10.5461\n",
      "Epoch 48/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.6577 - val_loss: 11.8827\n",
      "Epoch 49/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 9.0873 - val_loss: 12.3620\n",
      "Epoch 50/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.4466 - val_loss: 11.3208\n",
      "Epoch 51/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.4761 - val_loss: 11.5542\n",
      "Epoch 52/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.5625 - val_loss: 11.1405\n",
      "Epoch 53/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5256 - val_loss: 11.2788\n",
      "Epoch 54/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9594 - val_loss: 11.9726\n",
      "Epoch 55/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.5192 - val_loss: 10.9599\n",
      "Epoch 56/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 9.0137 - val_loss: 10.5083\n",
      "Epoch 57/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2676 - val_loss: 11.4602\n",
      "Epoch 58/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.3949 - val_loss: 14.3676\n",
      "Epoch 59/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.8962 - val_loss: 10.6508\n",
      "Epoch 60/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8686 - val_loss: 13.0317\n",
      "Epoch 61/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.8362 - val_loss: 11.1194\n",
      "Epoch 62/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.4230 - val_loss: 11.0299\n",
      "Epoch 63/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.5597 - val_loss: 12.1879\n",
      "Epoch 64/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0803 - val_loss: 12.0081\n",
      "Epoch 65/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.6596 - val_loss: 11.0336\n",
      "Epoch 66/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9169 - val_loss: 14.7858\n",
      "Epoch 67/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 9.4275 - val_loss: 11.0576\n",
      "Epoch 68/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.0853 - val_loss: 11.2699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.4753 - val_loss: 11.5714\n",
      "Epoch 70/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.5609 - val_loss: 13.3235\n",
      "Epoch 71/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.8597 - val_loss: 11.9162\n",
      "Epoch 72/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2388 - val_loss: 11.4134\n",
      "Epoch 73/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.2693 - val_loss: 11.1458\n",
      "Epoch 74/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.9107 - val_loss: 11.6571\n",
      "Epoch 75/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1438 - val_loss: 11.3947\n",
      "Epoch 76/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.1884 - val_loss: 12.7839\n",
      "Epoch 77/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 8.0554 - val_loss: 13.9641\n",
      "Epoch 78/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 8.0949 - val_loss: 11.2221\n",
      "Epoch 79/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2059 - val_loss: 10.8784\n",
      "Epoch 80/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 8.2802 - val_loss: 11.6366\n",
      "Epoch 81/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7241 - val_loss: 12.5361\n",
      "Epoch 82/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.8097 - val_loss: 12.2979\n",
      "Epoch 83/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.2444 - val_loss: 12.5629\n",
      "Epoch 84/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7812 - val_loss: 11.8660\n",
      "Epoch 85/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.4570 - val_loss: 11.0947\n",
      "Epoch 86/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7906 - val_loss: 11.6678\n",
      "Epoch 87/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 8.1630 - val_loss: 13.2230\n",
      "Epoch 88/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.0390 - val_loss: 14.5562\n",
      "Epoch 89/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.3077 - val_loss: 11.0125\n",
      "Epoch 90/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.2616 - val_loss: 16.4731\n",
      "Epoch 91/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.4711 - val_loss: 11.2631\n",
      "Epoch 92/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0616 - val_loss: 11.4191\n",
      "Epoch 93/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.8949 - val_loss: 14.1973\n",
      "Epoch 94/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 8.1723 - val_loss: 12.1153\n",
      "Epoch 95/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.5499 - val_loss: 12.0293\n",
      "Epoch 96/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6172 - val_loss: 13.6897\n",
      "Epoch 97/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9041 - val_loss: 12.0275\n",
      "Epoch 98/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.9320 - val_loss: 14.3352\n",
      "Epoch 99/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8593 - val_loss: 14.2310\n",
      "Epoch 100/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9926 - val_loss: 11.9162\n",
      "Epoch 101/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4416 - val_loss: 11.7928\n",
      "Epoch 102/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 8.0579 - val_loss: 11.4647\n",
      "Epoch 103/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6374 - val_loss: 12.2452\n",
      "Epoch 104/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3802 - val_loss: 11.8051\n",
      "Epoch 105/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9660 - val_loss: 13.1642\n",
      "Epoch 106/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.4866 - val_loss: 11.4715\n",
      "Epoch 107/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7016 - val_loss: 12.3961\n",
      "Epoch 108/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.3962 - val_loss: 11.2394\n",
      "Epoch 109/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5084 - val_loss: 11.7292\n",
      "Epoch 110/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7925 - val_loss: 12.8498\n",
      "Epoch 111/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.7110 - val_loss: 14.8849\n",
      "Epoch 112/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0036 - val_loss: 11.4487\n",
      "Epoch 113/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.4590 - val_loss: 12.6377\n",
      "Epoch 114/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5716 - val_loss: 12.3883\n",
      "Epoch 115/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.2831 - val_loss: 11.3874\n",
      "Epoch 116/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4902 - val_loss: 11.3706\n",
      "Epoch 117/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.8564 - val_loss: 13.0397\n",
      "Epoch 118/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.7098 - val_loss: 12.4266\n",
      "Epoch 119/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6923 - val_loss: 11.9846\n",
      "Epoch 120/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8036 - val_loss: 11.5311\n",
      "Epoch 121/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8867 - val_loss: 14.0326\n",
      "Epoch 122/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.3887 - val_loss: 11.3214\n",
      "Epoch 123/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.3331 - val_loss: 12.3186\n",
      "Epoch 124/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.9590 - val_loss: 14.8388\n",
      "Epoch 125/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.8659 - val_loss: 12.9431\n",
      "Epoch 126/1000\n",
      "274/274 [==============================] - 0s 83us/step - loss: 7.8025 - val_loss: 15.6723\n",
      "Epoch 127/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.7470 - val_loss: 13.6029\n",
      "Epoch 128/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.9279 - val_loss: 11.6179\n",
      "Epoch 129/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.5095 - val_loss: 13.8634\n",
      "Epoch 130/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.8213 - val_loss: 13.9879\n",
      "Epoch 131/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9087 - val_loss: 11.5762\n",
      "Epoch 132/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.9242 - val_loss: 12.6649\n",
      "Epoch 133/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2011 - val_loss: 11.5894\n",
      "Epoch 134/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5076 - val_loss: 15.3026\n",
      "Epoch 135/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 8.5655 - val_loss: 11.7022\n",
      "Epoch 136/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.8864 - val_loss: 11.7763\n",
      "Epoch 137/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3157 - val_loss: 13.7935\n",
      "Epoch 138/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0370 - val_loss: 11.4520\n",
      "Epoch 139/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5782 - val_loss: 12.9766\n",
      "Epoch 140/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5273 - val_loss: 11.8593\n",
      "Epoch 141/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9396 - val_loss: 12.4756\n",
      "Epoch 142/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.9628 - val_loss: 12.0581\n",
      "Epoch 143/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5466 - val_loss: 11.7105\n",
      "Epoch 144/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.4466 - val_loss: 12.3223\n",
      "Epoch 145/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 8.2610 - val_loss: 11.4579\n",
      "Epoch 146/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6172 - val_loss: 11.8328\n",
      "Epoch 147/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3183 - val_loss: 14.6410\n",
      "Epoch 148/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 8.1744 - val_loss: 11.8710\n",
      "Epoch 149/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0262 - val_loss: 13.1651\n",
      "Epoch 150/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.6285 - val_loss: 13.5350\n",
      "Epoch 151/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5714 - val_loss: 12.9990\n",
      "Epoch 152/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.1529 - val_loss: 12.8495\n",
      "Epoch 153/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.1515 - val_loss: 11.4459\n",
      "Epoch 154/1000\n",
      "274/274 [==============================] - 0s 80us/step - loss: 7.6577 - val_loss: 11.8947\n",
      "Epoch 155/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.9974 - val_loss: 11.6993\n",
      "Epoch 156/1000\n",
      "274/274 [==============================] - 0s 86us/step - loss: 7.3393 - val_loss: 11.5286\n",
      "Epoch 157/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.1608 - val_loss: 12.6781\n",
      "Epoch 158/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5281 - val_loss: 12.2151\n",
      "Epoch 159/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 8.4945 - val_loss: 12.8189\n",
      "Epoch 160/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.4525 - val_loss: 11.7313\n",
      "Epoch 161/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.5789 - val_loss: 11.8900\n",
      "Epoch 162/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 8.0013 - val_loss: 11.0930\n",
      "Epoch 163/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5398 - val_loss: 11.5323\n",
      "Epoch 164/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.2984 - val_loss: 11.4889\n",
      "Epoch 165/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 7.4268 - val_loss: 11.3894\n",
      "Epoch 166/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.5478 - val_loss: 11.7585\n",
      "Epoch 167/1000\n",
      "274/274 [==============================] - 0s 84us/step - loss: 7.5706 - val_loss: 12.9177\n",
      "Epoch 168/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.0995 - val_loss: 14.9400\n",
      "Epoch 169/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 8.2028 - val_loss: 11.7897\n",
      "Epoch 170/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 7.5172 - val_loss: 12.9620\n",
      "Epoch 171/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9495 - val_loss: 12.7693\n",
      "Epoch 172/1000\n",
      "274/274 [==============================] - 0s 92us/step - loss: 8.0717 - val_loss: 11.1745\n",
      "Epoch 173/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.6182 - val_loss: 12.1721\n",
      "Epoch 174/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.2838 - val_loss: 11.9387\n",
      "Epoch 175/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5859 - val_loss: 13.7237\n",
      "Epoch 176/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.4513 - val_loss: 12.1240\n",
      "Epoch 177/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.7455 - val_loss: 13.0925\n",
      "Epoch 178/1000\n",
      "274/274 [==============================] - 0s 95us/step - loss: 7.9298 - val_loss: 12.8968\n",
      "Epoch 179/1000\n",
      "274/274 [==============================] - 0s 94us/step - loss: 7.3471 - val_loss: 11.8549\n",
      "Epoch 180/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.3930 - val_loss: 11.7936\n",
      "Epoch 181/1000\n",
      "274/274 [==============================] - 0s 85us/step - loss: 8.0308 - val_loss: 12.4440\n",
      "Epoch 182/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.3411 - val_loss: 11.6262\n",
      "Epoch 183/1000\n",
      "274/274 [==============================] - 0s 91us/step - loss: 7.6369 - val_loss: 12.4407\n",
      "Epoch 184/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.5697 - val_loss: 12.5052\n",
      "Epoch 185/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 7.7889 - val_loss: 11.5328\n",
      "Epoch 186/1000\n",
      "274/274 [==============================] - 0s 89us/step - loss: 7.9990 - val_loss: 13.0566\n",
      "Epoch 187/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 7.5985 - val_loss: 11.2920\n",
      "Epoch 188/1000\n",
      "274/274 [==============================] - 0s 102us/step - loss: 7.5379 - val_loss: 11.3668\n",
      "Epoch 189/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 7.6556 - val_loss: 12.9628\n",
      "Epoch 190/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 8.0767 - val_loss: 12.1316\n",
      "Epoch 191/1000\n",
      "274/274 [==============================] - 0s 104us/step - loss: 7.6040 - val_loss: 13.9939\n",
      "Epoch 192/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 8.1024 - val_loss: 12.0472\n",
      "Epoch 193/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7399 - val_loss: 11.9357\n",
      "Epoch 194/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5658 - val_loss: 11.8604\n",
      "Epoch 195/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 8.1121 - val_loss: 12.3517\n",
      "Epoch 196/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6137 - val_loss: 11.6041\n",
      "Epoch 197/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3299 - val_loss: 11.1987\n",
      "Epoch 198/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2803 - val_loss: 12.1869\n",
      "Epoch 199/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.8600 - val_loss: 11.5614\n",
      "Epoch 200/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1396 - val_loss: 11.8570\n",
      "Epoch 201/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6898 - val_loss: 12.9965\n",
      "Epoch 202/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4557 - val_loss: 12.6302\n",
      "Epoch 203/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4735 - val_loss: 12.1139\n",
      "Epoch 204/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 8.0900 - val_loss: 12.6818\n",
      "Epoch 205/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.6293 - val_loss: 13.8980\n",
      "Epoch 206/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5040 - val_loss: 13.6040\n",
      "Epoch 207/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3704 - val_loss: 11.7508\n",
      "Epoch 208/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4500 - val_loss: 12.0915\n",
      "Epoch 209/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5959 - val_loss: 11.1931\n",
      "Epoch 210/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6482 - val_loss: 13.9412\n",
      "Epoch 211/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.7931 - val_loss: 11.5312\n",
      "Epoch 212/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6699 - val_loss: 12.0257\n",
      "Epoch 213/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2596 - val_loss: 11.8402\n",
      "Epoch 214/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 8.2609 - val_loss: 13.3396\n",
      "Epoch 215/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2850 - val_loss: 12.7892\n",
      "Epoch 216/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6508 - val_loss: 12.5565\n",
      "Epoch 217/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5853 - val_loss: 11.7727\n",
      "Epoch 218/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.6316 - val_loss: 12.2635\n",
      "Epoch 219/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4021 - val_loss: 12.4678\n",
      "Epoch 220/1000\n",
      "274/274 [==============================] - 0s 120us/step - loss: 7.6237 - val_loss: 11.8866\n",
      "Epoch 221/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4554 - val_loss: 12.6940\n",
      "Epoch 222/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.6183 - val_loss: 12.3108\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 57us/step - loss: 7.2748 - val_loss: 12.2731\n",
      "Epoch 224/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6683 - val_loss: 11.9225\n",
      "Epoch 225/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1493 - val_loss: 11.7583\n",
      "Epoch 226/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5349 - val_loss: 10.9051\n",
      "Epoch 227/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 8.0057 - val_loss: 11.4342\n",
      "Epoch 228/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4862 - val_loss: 11.6871\n",
      "Epoch 229/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3259 - val_loss: 12.3830\n",
      "Epoch 230/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3927 - val_loss: 12.5251\n",
      "Epoch 231/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.8161 - val_loss: 11.8548\n",
      "Epoch 232/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5839 - val_loss: 12.8869\n",
      "Epoch 233/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2882 - val_loss: 12.2099\n",
      "Epoch 234/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3932 - val_loss: 13.6299\n",
      "Epoch 235/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5295 - val_loss: 13.4458\n",
      "Epoch 236/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5919 - val_loss: 12.9311\n",
      "Epoch 237/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3669 - val_loss: 11.3135\n",
      "Epoch 238/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3342 - val_loss: 12.1002\n",
      "Epoch 239/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5444 - val_loss: 11.1150\n",
      "Epoch 240/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4049 - val_loss: 11.3751\n",
      "Epoch 241/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.8216 - val_loss: 12.5995\n",
      "Epoch 242/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5789 - val_loss: 14.2546\n",
      "Epoch 243/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5624 - val_loss: 11.6513\n",
      "Epoch 244/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4169 - val_loss: 13.3280\n",
      "Epoch 245/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2867 - val_loss: 14.0130\n",
      "Epoch 246/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2679 - val_loss: 13.1422\n",
      "Epoch 247/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7514 - val_loss: 12.2662\n",
      "Epoch 248/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1452 - val_loss: 13.7748\n",
      "Epoch 249/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3593 - val_loss: 12.3304\n",
      "Epoch 250/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.7265 - val_loss: 12.4145\n",
      "Epoch 251/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5292 - val_loss: 12.3642\n",
      "Epoch 252/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1474 - val_loss: 14.2771\n",
      "Epoch 253/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5467 - val_loss: 12.0964\n",
      "Epoch 254/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 8.0128 - val_loss: 14.6688\n",
      "Epoch 255/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.9554 - val_loss: 11.5830\n",
      "Epoch 256/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1386 - val_loss: 11.7791\n",
      "Epoch 257/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5935 - val_loss: 12.6269\n",
      "Epoch 258/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6365 - val_loss: 11.2671\n",
      "Epoch 259/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.6752 - val_loss: 11.9172\n",
      "Epoch 260/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4690 - val_loss: 11.1747\n",
      "Epoch 261/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4392 - val_loss: 13.5440\n",
      "Epoch 262/1000\n",
      "274/274 [==============================] - 0s 87us/step - loss: 7.5031 - val_loss: 11.7620\n",
      "Epoch 263/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4425 - val_loss: 12.5449\n",
      "Epoch 264/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.9902 - val_loss: 12.1908\n",
      "Epoch 265/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7646 - val_loss: 12.6181\n",
      "Epoch 266/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2114 - val_loss: 11.1287\n",
      "Epoch 267/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3731 - val_loss: 11.9923\n",
      "Epoch 268/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4535 - val_loss: 11.7336\n",
      "Epoch 269/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.9365 - val_loss: 11.9815\n",
      "Epoch 270/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5074 - val_loss: 11.7088\n",
      "Epoch 271/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2359 - val_loss: 11.7076\n",
      "Epoch 272/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6029 - val_loss: 13.0687\n",
      "Epoch 273/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5175 - val_loss: 12.2923\n",
      "Epoch 274/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.8123 - val_loss: 12.4957\n",
      "Epoch 275/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2487 - val_loss: 12.8496\n",
      "Epoch 276/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4693 - val_loss: 12.8656\n",
      "Epoch 277/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2920 - val_loss: 13.4250\n",
      "Epoch 278/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2880 - val_loss: 14.8904\n",
      "Epoch 279/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 8.1536 - val_loss: 12.3938\n",
      "Epoch 280/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1620 - val_loss: 14.3486\n",
      "Epoch 281/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3058 - val_loss: 15.3289\n",
      "Epoch 282/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6582 - val_loss: 11.3580\n",
      "Epoch 283/1000\n",
      "274/274 [==============================] - 0s 109us/step - loss: 7.3583 - val_loss: 12.8638\n",
      "Epoch 284/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.6244 - val_loss: 11.1506\n",
      "Epoch 285/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1566 - val_loss: 10.8479\n",
      "Epoch 286/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0801 - val_loss: 11.3406\n",
      "Epoch 287/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.6017 - val_loss: 11.4633\n",
      "Epoch 288/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9890 - val_loss: 12.1979\n",
      "Epoch 289/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5929 - val_loss: 11.0429\n",
      "Epoch 290/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4314 - val_loss: 11.3198\n",
      "Epoch 291/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.7250 - val_loss: 12.3733\n",
      "Epoch 292/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2387 - val_loss: 12.3890\n",
      "Epoch 293/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.9486 - val_loss: 11.2278\n",
      "Epoch 294/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7284 - val_loss: 10.9420\n",
      "Epoch 295/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8847 - val_loss: 13.8076\n",
      "Epoch 296/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1336 - val_loss: 11.1831\n",
      "Epoch 297/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3562 - val_loss: 11.5806\n",
      "Epoch 298/1000\n",
      "274/274 [==============================] - 0s 144us/step - loss: 7.4997 - val_loss: 11.1937\n",
      "Epoch 299/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 7.4299 - val_loss: 11.8717\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 139us/step - loss: 7.3350 - val_loss: 12.1118\n",
      "Epoch 301/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2129 - val_loss: 11.3489\n",
      "Epoch 302/1000\n",
      "274/274 [==============================] - 0s 88us/step - loss: 7.3799 - val_loss: 11.6308\n",
      "Epoch 303/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3608 - val_loss: 11.6068\n",
      "Epoch 304/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9014 - val_loss: 12.3747\n",
      "Epoch 305/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1971 - val_loss: 12.3374\n",
      "Epoch 306/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2835 - val_loss: 10.9748\n",
      "Epoch 307/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4962 - val_loss: 12.1434\n",
      "Epoch 308/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3840 - val_loss: 12.4218\n",
      "Epoch 309/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5307 - val_loss: 11.7460\n",
      "Epoch 310/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9990 - val_loss: 12.4469\n",
      "Epoch 311/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7947 - val_loss: 11.4780\n",
      "Epoch 312/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5330 - val_loss: 11.7009\n",
      "Epoch 313/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1404 - val_loss: 13.2346\n",
      "Epoch 314/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4354 - val_loss: 11.6519\n",
      "Epoch 315/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2265 - val_loss: 13.3360\n",
      "Epoch 316/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5124 - val_loss: 12.0056\n",
      "Epoch 317/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3763 - val_loss: 10.9840\n",
      "Epoch 318/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0444 - val_loss: 11.0778\n",
      "Epoch 319/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6216 - val_loss: 12.1481\n",
      "Epoch 320/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1481 - val_loss: 11.7708\n",
      "Epoch 321/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2641 - val_loss: 12.5895\n",
      "Epoch 322/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1562 - val_loss: 11.6081\n",
      "Epoch 323/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2788 - val_loss: 11.1787\n",
      "Epoch 324/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1290 - val_loss: 11.2116\n",
      "Epoch 325/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5191 - val_loss: 12.1316\n",
      "Epoch 326/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1512 - val_loss: 11.6447\n",
      "Epoch 327/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3027 - val_loss: 11.5284\n",
      "Epoch 328/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9739 - val_loss: 12.1394\n",
      "Epoch 329/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2810 - val_loss: 12.3604\n",
      "Epoch 330/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1973 - val_loss: 12.4559\n",
      "Epoch 331/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1411 - val_loss: 12.2096\n",
      "Epoch 332/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1507 - val_loss: 11.7312\n",
      "Epoch 333/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2165 - val_loss: 12.7885\n",
      "Epoch 334/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3410 - val_loss: 12.0784\n",
      "Epoch 335/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5286 - val_loss: 11.8425\n",
      "Epoch 336/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9897 - val_loss: 12.3421\n",
      "Epoch 337/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.6689 - val_loss: 12.1091\n",
      "Epoch 338/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8747 - val_loss: 11.5352\n",
      "Epoch 339/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4918 - val_loss: 11.7034\n",
      "Epoch 340/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9428 - val_loss: 11.8502\n",
      "Epoch 341/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9670 - val_loss: 11.5011\n",
      "Epoch 342/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8086 - val_loss: 11.6474\n",
      "Epoch 343/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2206 - val_loss: 12.1141\n",
      "Epoch 344/1000\n",
      "274/274 [==============================] - 0s 125us/step - loss: 7.1572 - val_loss: 11.3118\n",
      "Epoch 345/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 7.9385 - val_loss: 11.6698\n",
      "Epoch 346/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9784 - val_loss: 12.1075\n",
      "Epoch 347/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1505 - val_loss: 11.5312\n",
      "Epoch 348/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4923 - val_loss: 12.2084\n",
      "Epoch 349/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0763 - val_loss: 11.0297\n",
      "Epoch 350/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8802 - val_loss: 13.9425\n",
      "Epoch 351/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5006 - val_loss: 12.4409\n",
      "Epoch 352/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2831 - val_loss: 11.9086\n",
      "Epoch 353/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8203 - val_loss: 11.6006\n",
      "Epoch 354/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3096 - val_loss: 11.3672\n",
      "Epoch 355/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1906 - val_loss: 12.0311\n",
      "Epoch 356/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9798 - val_loss: 11.7863\n",
      "Epoch 357/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1092 - val_loss: 12.4513\n",
      "Epoch 358/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1297 - val_loss: 12.6442\n",
      "Epoch 359/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4327 - val_loss: 11.2869\n",
      "Epoch 360/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7586 - val_loss: 11.5503\n",
      "Epoch 361/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1289 - val_loss: 11.0074\n",
      "Epoch 362/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1760 - val_loss: 11.6462\n",
      "Epoch 363/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8503 - val_loss: 16.5771\n",
      "Epoch 364/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5298 - val_loss: 11.3930\n",
      "Epoch 365/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8716 - val_loss: 10.7435\n",
      "Epoch 366/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9008 - val_loss: 13.0579\n",
      "Epoch 367/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3946 - val_loss: 13.0951\n",
      "Epoch 368/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0283 - val_loss: 11.1302\n",
      "Epoch 369/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4142 - val_loss: 12.1284\n",
      "Epoch 370/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1959 - val_loss: 11.7223\n",
      "Epoch 371/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0763 - val_loss: 11.2974\n",
      "Epoch 372/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7761 - val_loss: 11.2874\n",
      "Epoch 373/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1124 - val_loss: 11.2549\n",
      "Epoch 374/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8204 - val_loss: 11.6060\n",
      "Epoch 375/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4572 - val_loss: 11.2241\n",
      "Epoch 376/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0401 - val_loss: 10.9643\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 114us/step - loss: 7.0440 - val_loss: 11.3737\n",
      "Epoch 378/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2470 - val_loss: 12.1223\n",
      "Epoch 379/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6963 - val_loss: 15.0638\n",
      "Epoch 380/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0510 - val_loss: 10.5599\n",
      "Epoch 381/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2944 - val_loss: 12.1963\n",
      "Epoch 382/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6463 - val_loss: 14.0671\n",
      "Epoch 383/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3205 - val_loss: 11.3994\n",
      "Epoch 384/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1374 - val_loss: 12.7164\n",
      "Epoch 385/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8123 - val_loss: 11.1717\n",
      "Epoch 386/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.5143 - val_loss: 11.8132\n",
      "Epoch 387/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9542 - val_loss: 11.1620\n",
      "Epoch 388/1000\n",
      "274/274 [==============================] - 0s 81us/step - loss: 6.6277 - val_loss: 11.6007\n",
      "Epoch 389/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3390 - val_loss: 12.7753\n",
      "Epoch 390/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9850 - val_loss: 11.2274\n",
      "Epoch 391/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7650 - val_loss: 12.1500\n",
      "Epoch 392/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9159 - val_loss: 12.1126\n",
      "Epoch 393/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9365 - val_loss: 12.3332\n",
      "Epoch 394/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0553 - val_loss: 11.3689\n",
      "Epoch 395/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8987 - val_loss: 11.2847\n",
      "Epoch 396/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8528 - val_loss: 11.3350\n",
      "Epoch 397/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7705 - val_loss: 11.4518\n",
      "Epoch 398/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8038 - val_loss: 11.5213\n",
      "Epoch 399/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6335 - val_loss: 11.7332\n",
      "Epoch 400/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8834 - val_loss: 12.4521\n",
      "Epoch 401/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9155 - val_loss: 14.8452\n",
      "Epoch 402/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2395 - val_loss: 11.2606\n",
      "Epoch 403/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7076 - val_loss: 11.1356\n",
      "Epoch 404/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0895 - val_loss: 11.8611\n",
      "Epoch 405/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7224 - val_loss: 11.0758\n",
      "Epoch 406/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1599 - val_loss: 11.1186\n",
      "Epoch 407/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 12.25 - 0s 114us/step - loss: 6.6424 - val_loss: 11.9978\n",
      "Epoch 408/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4351 - val_loss: 11.3456\n",
      "Epoch 409/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8066 - val_loss: 11.1950\n",
      "Epoch 410/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2327 - val_loss: 11.7189\n",
      "Epoch 411/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7917 - val_loss: 11.4777\n",
      "Epoch 412/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1037 - val_loss: 11.8752\n",
      "Epoch 413/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5164 - val_loss: 11.2034\n",
      "Epoch 414/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7687 - val_loss: 14.5706\n",
      "Epoch 415/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9340 - val_loss: 12.3940\n",
      "Epoch 416/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9222 - val_loss: 11.1980\n",
      "Epoch 417/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1394 - val_loss: 13.3069\n",
      "Epoch 418/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6933 - val_loss: 11.2844\n",
      "Epoch 419/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7410 - val_loss: 11.4866\n",
      "Epoch 420/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.7324 - val_loss: 12.0753\n",
      "Epoch 421/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8516 - val_loss: 11.0823\n",
      "Epoch 422/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9560 - val_loss: 14.3471\n",
      "Epoch 423/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9871 - val_loss: 10.8000\n",
      "Epoch 424/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0308 - val_loss: 13.4234\n",
      "Epoch 425/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0910 - val_loss: 11.0006\n",
      "Epoch 426/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8407 - val_loss: 13.3022\n",
      "Epoch 427/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 13.24 - 0s 57us/step - loss: 7.2471 - val_loss: 11.2762\n",
      "Epoch 428/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8948 - val_loss: 10.6115\n",
      "Epoch 429/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0392 - val_loss: 12.3555\n",
      "Epoch 430/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.8576 - val_loss: 10.7136\n",
      "Epoch 431/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8623 - val_loss: 11.1668\n",
      "Epoch 432/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4506 - val_loss: 11.0214\n",
      "Epoch 433/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8064 - val_loss: 12.1843\n",
      "Epoch 434/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0771 - val_loss: 12.1388\n",
      "Epoch 435/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3625 - val_loss: 12.2109\n",
      "Epoch 436/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0508 - val_loss: 11.0931\n",
      "Epoch 437/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8258 - val_loss: 10.9882\n",
      "Epoch 438/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9630 - val_loss: 11.2037\n",
      "Epoch 439/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7919 - val_loss: 11.5204\n",
      "Epoch 440/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1739 - val_loss: 11.1213\n",
      "Epoch 441/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4568 - val_loss: 11.6714\n",
      "Epoch 442/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2598 - val_loss: 12.2559\n",
      "Epoch 443/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6741 - val_loss: 10.9640\n",
      "Epoch 444/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8964 - val_loss: 11.5498\n",
      "Epoch 445/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1417 - val_loss: 11.6619\n",
      "Epoch 446/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1971 - val_loss: 11.0948\n",
      "Epoch 447/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7659 - val_loss: 11.3813\n",
      "Epoch 448/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9099 - val_loss: 11.2101\n",
      "Epoch 449/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8288 - val_loss: 12.7910\n",
      "Epoch 450/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7783 - val_loss: 11.9752\n",
      "Epoch 451/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9876 - val_loss: 11.4187\n",
      "Epoch 452/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0316 - val_loss: 11.2260\n",
      "Epoch 453/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9500 - val_loss: 11.2311\n",
      "Epoch 454/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1454 - val_loss: 11.5836\n",
      "Epoch 455/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 8.0401 - val_loss: 11.7829\n",
      "Epoch 456/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7073 - val_loss: 11.5949\n",
      "Epoch 457/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8896 - val_loss: 11.2295\n",
      "Epoch 458/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7299 - val_loss: 14.0413\n",
      "Epoch 459/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1812 - val_loss: 10.9684\n",
      "Epoch 460/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1363 - val_loss: 11.5226\n",
      "Epoch 461/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7713 - val_loss: 12.3318\n",
      "Epoch 462/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7686 - val_loss: 12.2034\n",
      "Epoch 463/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2378 - val_loss: 11.6793\n",
      "Epoch 464/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2602 - val_loss: 11.1836\n",
      "Epoch 465/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8193 - val_loss: 12.6359\n",
      "Epoch 466/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0737 - val_loss: 12.7850\n",
      "Epoch 467/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8502 - val_loss: 11.5765\n",
      "Epoch 468/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1902 - val_loss: 11.7705\n",
      "Epoch 469/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8223 - val_loss: 11.5579\n",
      "Epoch 470/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1170 - val_loss: 11.7759\n",
      "Epoch 471/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6324 - val_loss: 11.7720\n",
      "Epoch 472/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5857 - val_loss: 12.6105\n",
      "Epoch 473/1000\n",
      "274/274 [==============================] - 0s 108us/step - loss: 7.0743 - val_loss: 11.7915\n",
      "Epoch 474/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9564 - val_loss: 14.3652\n",
      "Epoch 475/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1182 - val_loss: 11.7875\n",
      "Epoch 476/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7148 - val_loss: 11.2827\n",
      "Epoch 477/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0702 - val_loss: 12.8431\n",
      "Epoch 478/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0468 - val_loss: 12.2375\n",
      "Epoch 479/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0040 - val_loss: 11.5457\n",
      "Epoch 480/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7674 - val_loss: 11.0181\n",
      "Epoch 481/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.5186 - val_loss: 11.6100\n",
      "Epoch 482/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9112 - val_loss: 12.2231\n",
      "Epoch 483/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8444 - val_loss: 11.1519\n",
      "Epoch 484/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0059 - val_loss: 11.0214\n",
      "Epoch 485/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2630 - val_loss: 12.2997\n",
      "Epoch 486/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0911 - val_loss: 11.6366\n",
      "Epoch 487/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6280 - val_loss: 12.2178\n",
      "Epoch 488/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 5.954 - 0s 114us/step - loss: 6.7735 - val_loss: 11.6388\n",
      "Epoch 489/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0674 - val_loss: 11.5417\n",
      "Epoch 490/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2254 - val_loss: 12.6040\n",
      "Epoch 491/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2222 - val_loss: 11.7292\n",
      "Epoch 492/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8009 - val_loss: 11.0582\n",
      "Epoch 493/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8379 - val_loss: 12.1411\n",
      "Epoch 494/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5563 - val_loss: 12.0311\n",
      "Epoch 495/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4724 - val_loss: 11.0137\n",
      "Epoch 496/1000\n",
      "274/274 [==============================] - 0s 150us/step - loss: 6.6770 - val_loss: 11.6895\n",
      "Epoch 497/1000\n",
      "274/274 [==============================] - 0s 77us/step - loss: 6.2901 - val_loss: 12.3247\n",
      "Epoch 498/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7295 - val_loss: 12.0237\n",
      "Epoch 499/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7107 - val_loss: 13.3753\n",
      "Epoch 500/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8738 - val_loss: 11.2599\n",
      "Epoch 501/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8287 - val_loss: 13.6637\n",
      "Epoch 502/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7965 - val_loss: 12.6089\n",
      "Epoch 503/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.4918 - val_loss: 11.3981\n",
      "Epoch 504/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6163 - val_loss: 12.1787\n",
      "Epoch 505/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6639 - val_loss: 11.7155\n",
      "Epoch 506/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7836 - val_loss: 12.2045\n",
      "Epoch 507/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8481 - val_loss: 12.9342\n",
      "Epoch 508/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6551 - val_loss: 14.8030\n",
      "Epoch 509/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.2663 - val_loss: 12.0480\n",
      "Epoch 510/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9341 - val_loss: 11.7309\n",
      "Epoch 511/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0973 - val_loss: 10.6867\n",
      "Epoch 512/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0221 - val_loss: 11.9170\n",
      "Epoch 513/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8594 - val_loss: 11.4296\n",
      "Epoch 514/1000\n",
      "274/274 [==============================] - 0s 93us/step - loss: 6.6208 - val_loss: 11.8878\n",
      "Epoch 515/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8242 - val_loss: 11.1556\n",
      "Epoch 516/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1653 - val_loss: 12.4429\n",
      "Epoch 517/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6845 - val_loss: 12.8258\n",
      "Epoch 518/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7885 - val_loss: 11.3020\n",
      "Epoch 519/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9274 - val_loss: 11.4151\n",
      "Epoch 520/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8016 - val_loss: 11.4593\n",
      "Epoch 521/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8964 - val_loss: 11.3168\n",
      "Epoch 522/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7573 - val_loss: 10.9944\n",
      "Epoch 523/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5555 - val_loss: 11.7861\n",
      "Epoch 524/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0422 - val_loss: 11.1793\n",
      "Epoch 525/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7610 - val_loss: 12.0808\n",
      "Epoch 526/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.1271 - val_loss: 11.9173\n",
      "Epoch 527/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6819 - val_loss: 10.9926\n",
      "Epoch 528/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8360 - val_loss: 11.7169\n",
      "Epoch 529/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6962 - val_loss: 11.4497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6685 - val_loss: 11.3772\n",
      "Epoch 531/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4505 - val_loss: 11.8137\n",
      "Epoch 532/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7417 - val_loss: 11.3112\n",
      "Epoch 533/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.4926 - val_loss: 11.9772\n",
      "Epoch 534/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8037 - val_loss: 11.5614\n",
      "Epoch 535/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6396 - val_loss: 11.6380\n",
      "Epoch 536/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8817 - val_loss: 11.3897\n",
      "Epoch 537/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7899 - val_loss: 12.1256\n",
      "Epoch 538/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5644 - val_loss: 11.6085\n",
      "Epoch 539/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3900 - val_loss: 11.3819\n",
      "Epoch 540/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0302 - val_loss: 13.3983\n",
      "Epoch 541/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0643 - val_loss: 11.1639\n",
      "Epoch 542/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8106 - val_loss: 12.0736\n",
      "Epoch 543/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7054 - val_loss: 12.7002\n",
      "Epoch 544/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5158 - val_loss: 10.9232\n",
      "Epoch 545/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6463 - val_loss: 11.8902\n",
      "Epoch 546/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6536 - val_loss: 13.6318\n",
      "Epoch 547/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.0464 - val_loss: 10.6418\n",
      "Epoch 548/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6074 - val_loss: 12.1508\n",
      "Epoch 549/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9515 - val_loss: 10.9993\n",
      "Epoch 550/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.3016 - val_loss: 11.0749\n",
      "Epoch 551/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7104 - val_loss: 11.1796\n",
      "Epoch 552/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8929 - val_loss: 11.8702\n",
      "Epoch 553/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8200 - val_loss: 12.1983\n",
      "Epoch 554/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4119 - val_loss: 11.6413\n",
      "Epoch 555/1000\n",
      "274/274 [==============================] - 0s 138us/step - loss: 6.5683 - val_loss: 12.0313\n",
      "Epoch 556/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 6.8350 - val_loss: 11.6713\n",
      "Epoch 557/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5016 - val_loss: 11.7653\n",
      "Epoch 558/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8494 - val_loss: 11.2673\n",
      "Epoch 559/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6561 - val_loss: 12.7958\n",
      "Epoch 560/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.9587 - val_loss: 11.4446\n",
      "Epoch 561/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5983 - val_loss: 11.1310\n",
      "Epoch 562/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5644 - val_loss: 10.8239\n",
      "Epoch 563/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.0004 - val_loss: 11.6054\n",
      "Epoch 564/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7003 - val_loss: 12.3007\n",
      "Epoch 565/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5426 - val_loss: 12.1553\n",
      "Epoch 566/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4511 - val_loss: 13.0085\n",
      "Epoch 567/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.2980 - val_loss: 11.2407\n",
      "Epoch 568/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5960 - val_loss: 12.2055\n",
      "Epoch 569/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6422 - val_loss: 10.8780\n",
      "Epoch 570/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5519 - val_loss: 11.2609\n",
      "Epoch 571/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4862 - val_loss: 12.1017\n",
      "Epoch 572/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7970 - val_loss: 11.0755\n",
      "Epoch 573/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7384 - val_loss: 12.0082\n",
      "Epoch 574/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 7.3567 - val_loss: 11.3476\n",
      "Epoch 575/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4036 - val_loss: 11.3268\n",
      "Epoch 576/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7396 - val_loss: 11.0808\n",
      "Epoch 577/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4211 - val_loss: 11.7757\n",
      "Epoch 578/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4875 - val_loss: 10.9520\n",
      "Epoch 579/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9316 - val_loss: 11.9753\n",
      "Epoch 580/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8443 - val_loss: 11.2499\n",
      "Epoch 581/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5390 - val_loss: 12.9803\n",
      "Epoch 582/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6493 - val_loss: 11.5433\n",
      "Epoch 583/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5581 - val_loss: 12.6915\n",
      "Epoch 584/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7649 - val_loss: 10.9969\n",
      "Epoch 585/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2692 - val_loss: 12.0823\n",
      "Epoch 586/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8695 - val_loss: 11.1628\n",
      "Epoch 587/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7578 - val_loss: 13.0825\n",
      "Epoch 588/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9553 - val_loss: 10.7401\n",
      "Epoch 589/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4158 - val_loss: 12.9409\n",
      "Epoch 590/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7694 - val_loss: 10.9904\n",
      "Epoch 591/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6807 - val_loss: 10.4779\n",
      "Epoch 592/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6086 - val_loss: 12.9556\n",
      "Epoch 593/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5660 - val_loss: 11.3528\n",
      "Epoch 594/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3533 - val_loss: 12.3216\n",
      "Epoch 595/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.6332 - val_loss: 10.6644\n",
      "Epoch 596/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7619 - val_loss: 12.0972\n",
      "Epoch 597/1000\n",
      "274/274 [==============================] - 0s 98us/step - loss: 6.7497 - val_loss: 12.0363\n",
      "Epoch 598/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3547 - val_loss: 16.6854\n",
      "Epoch 599/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 7.1917 - val_loss: 10.9644\n",
      "Epoch 600/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2608 - val_loss: 11.1615\n",
      "Epoch 601/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7588 - val_loss: 11.2195\n",
      "Epoch 602/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4885 - val_loss: 11.4646\n",
      "Epoch 603/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5393 - val_loss: 10.7133\n",
      "Epoch 604/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5485 - val_loss: 11.0054\n",
      "Epoch 605/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8475 - val_loss: 11.9082\n",
      "Epoch 606/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5602 - val_loss: 11.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8060 - val_loss: 11.5017\n",
      "Epoch 608/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9555 - val_loss: 13.7534\n",
      "Epoch 609/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2331 - val_loss: 10.7159\n",
      "Epoch 610/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5633 - val_loss: 12.5703\n",
      "Epoch 611/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8558 - val_loss: 11.3225\n",
      "Epoch 612/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4244 - val_loss: 13.6105\n",
      "Epoch 613/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7745 - val_loss: 10.9375\n",
      "Epoch 614/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.7208 - val_loss: 11.1956\n",
      "Epoch 615/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6835 - val_loss: 10.8151\n",
      "Epoch 616/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5162 - val_loss: 11.4364\n",
      "Epoch 617/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6723 - val_loss: 11.7393\n",
      "Epoch 618/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3698 - val_loss: 12.8448\n",
      "Epoch 619/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.8723 - val_loss: 11.5813\n",
      "Epoch 620/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2642 - val_loss: 12.1011\n",
      "Epoch 621/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6840 - val_loss: 11.0194\n",
      "Epoch 622/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2273 - val_loss: 11.2887\n",
      "Epoch 623/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4959 - val_loss: 11.5173\n",
      "Epoch 624/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3664 - val_loss: 11.3926\n",
      "Epoch 625/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4431 - val_loss: 12.7884\n",
      "Epoch 626/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6767 - val_loss: 12.9644\n",
      "Epoch 627/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4193 - val_loss: 11.1740\n",
      "Epoch 628/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1824 - val_loss: 12.0300\n",
      "Epoch 629/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5457 - val_loss: 11.3369\n",
      "Epoch 630/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7044 - val_loss: 11.1987\n",
      "Epoch 631/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5020 - val_loss: 11.6540\n",
      "Epoch 632/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4675 - val_loss: 11.6244\n",
      "Epoch 633/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2943 - val_loss: 10.9988\n",
      "Epoch 634/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3465 - val_loss: 11.1257\n",
      "Epoch 635/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1742 - val_loss: 10.7272\n",
      "Epoch 636/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6733 - val_loss: 10.6528\n",
      "Epoch 637/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3300 - val_loss: 11.3516\n",
      "Epoch 638/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7417 - val_loss: 11.1372\n",
      "Epoch 639/1000\n",
      "274/274 [==============================] - 0s 119us/step - loss: 6.3989 - val_loss: 11.8629\n",
      "Epoch 640/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4362 - val_loss: 11.5668\n",
      "Epoch 641/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2824 - val_loss: 10.6630\n",
      "Epoch 642/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2812 - val_loss: 12.5653\n",
      "Epoch 643/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2984 - val_loss: 10.5863\n",
      "Epoch 644/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.8280 - val_loss: 10.8912\n",
      "Epoch 645/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3525 - val_loss: 11.2118\n",
      "Epoch 646/1000\n",
      "274/274 [==============================] - 0s 110us/step - loss: 6.4041 - val_loss: 11.9849\n",
      "Epoch 647/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 6.7716 - val_loss: 10.8824\n",
      "Epoch 648/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0351 - val_loss: 11.8374\n",
      "Epoch 649/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2728 - val_loss: 11.7694\n",
      "Epoch 650/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2857 - val_loss: 11.5873\n",
      "Epoch 651/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6537 - val_loss: 10.8398\n",
      "Epoch 652/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4781 - val_loss: 11.7005\n",
      "Epoch 653/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3655 - val_loss: 12.1091\n",
      "Epoch 654/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.9316 - val_loss: 12.2170\n",
      "Epoch 655/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2315 - val_loss: 11.1518\n",
      "Epoch 656/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2839 - val_loss: 11.3146\n",
      "Epoch 657/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1194 - val_loss: 12.3219\n",
      "Epoch 658/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5967 - val_loss: 11.1135\n",
      "Epoch 659/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4205 - val_loss: 12.0983\n",
      "Epoch 660/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3672 - val_loss: 13.6776\n",
      "Epoch 661/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2400 - val_loss: 11.3943\n",
      "Epoch 662/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1681 - val_loss: 11.4403\n",
      "Epoch 663/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.6114 - val_loss: 11.0825\n",
      "Epoch 664/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0548 - val_loss: 11.3008\n",
      "Epoch 665/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0144 - val_loss: 14.1385\n",
      "Epoch 666/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3330 - val_loss: 11.0023\n",
      "Epoch 667/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3114 - val_loss: 11.7531\n",
      "Epoch 668/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2721 - val_loss: 11.9856\n",
      "Epoch 669/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.7440 - val_loss: 10.9050\n",
      "Epoch 670/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4166 - val_loss: 11.2211\n",
      "Epoch 671/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5195 - val_loss: 12.0624\n",
      "Epoch 672/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5040 - val_loss: 11.0889\n",
      "Epoch 673/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0753 - val_loss: 11.5419\n",
      "Epoch 674/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0371 - val_loss: 11.8386\n",
      "Epoch 675/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5589 - val_loss: 13.2402\n",
      "Epoch 676/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3935 - val_loss: 11.2209\n",
      "Epoch 677/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5087 - val_loss: 11.3561\n",
      "Epoch 678/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1182 - val_loss: 11.4160\n",
      "Epoch 679/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2720 - val_loss: 11.4294\n",
      "Epoch 680/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8836 - val_loss: 10.7689\n",
      "Epoch 681/1000\n",
      "274/274 [==============================] - 0s 106us/step - loss: 6.5962 - val_loss: 10.7770\n",
      "Epoch 682/1000\n",
      "274/274 [==============================] - 0s 78us/step - loss: 6.0588 - val_loss: 11.7769\n",
      "Epoch 683/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1710 - val_loss: 11.5504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3537 - val_loss: 10.9512\n",
      "Epoch 685/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1458 - val_loss: 10.6181\n",
      "Epoch 686/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3981 - val_loss: 11.6765\n",
      "Epoch 687/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9668 - val_loss: 11.4846\n",
      "Epoch 688/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1673 - val_loss: 11.0289\n",
      "Epoch 689/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0209 - val_loss: 12.7273\n",
      "Epoch 690/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4373 - val_loss: 11.9094\n",
      "Epoch 691/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2299 - val_loss: 10.7475\n",
      "Epoch 692/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0303 - val_loss: 11.3679\n",
      "Epoch 693/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1596 - val_loss: 10.9786\n",
      "Epoch 694/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.5392 - val_loss: 10.5234\n",
      "Epoch 695/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9230 - val_loss: 11.1297\n",
      "Epoch 696/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9249 - val_loss: 10.7527\n",
      "Epoch 697/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3013 - val_loss: 10.6408\n",
      "Epoch 698/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1432 - val_loss: 10.6077\n",
      "Epoch 699/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7654 - val_loss: 11.5182\n",
      "Epoch 700/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0359 - val_loss: 11.0874\n",
      "Epoch 701/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1840 - val_loss: 11.3581\n",
      "Epoch 702/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2567 - val_loss: 12.3309\n",
      "Epoch 703/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1990 - val_loss: 11.4253\n",
      "Epoch 704/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1341 - val_loss: 10.9983\n",
      "Epoch 705/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1004 - val_loss: 11.7531\n",
      "Epoch 706/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6613 - val_loss: 12.4754\n",
      "Epoch 707/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2111 - val_loss: 11.4435\n",
      "Epoch 708/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3154 - val_loss: 11.2318\n",
      "Epoch 709/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0133 - val_loss: 11.0463\n",
      "Epoch 710/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2163 - val_loss: 10.9670\n",
      "Epoch 711/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0654 - val_loss: 11.1582\n",
      "Epoch 712/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8952 - val_loss: 11.4034\n",
      "Epoch 713/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0287 - val_loss: 14.1894\n",
      "Epoch 714/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0179 - val_loss: 11.7092\n",
      "Epoch 715/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.5591 - val_loss: 11.6366\n",
      "Epoch 716/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4020 - val_loss: 13.6822\n",
      "Epoch 717/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3729 - val_loss: 10.9834\n",
      "Epoch 718/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9346 - val_loss: 13.1664\n",
      "Epoch 719/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4096 - val_loss: 11.2806\n",
      "Epoch 720/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0986 - val_loss: 11.0207\n",
      "Epoch 721/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1526 - val_loss: 11.2296\n",
      "Epoch 722/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3928 - val_loss: 12.3182\n",
      "Epoch 723/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1246 - val_loss: 11.5253\n",
      "Epoch 724/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9464 - val_loss: 10.5396\n",
      "Epoch 725/1000\n",
      "274/274 [==============================] - 0s 96us/step - loss: 6.1687 - val_loss: 12.6556\n",
      "Epoch 726/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8695 - val_loss: 10.8670\n",
      "Epoch 727/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9714 - val_loss: 11.2596\n",
      "Epoch 728/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9415 - val_loss: 13.1079\n",
      "Epoch 729/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2869 - val_loss: 13.1568\n",
      "Epoch 730/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2069 - val_loss: 11.1655\n",
      "Epoch 731/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0542 - val_loss: 10.8998\n",
      "Epoch 732/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9069 - val_loss: 10.7419\n",
      "Epoch 733/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9250 - val_loss: 11.5826\n",
      "Epoch 734/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0208 - val_loss: 11.3260\n",
      "Epoch 735/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1855 - val_loss: 10.7266\n",
      "Epoch 736/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7938 - val_loss: 11.3376\n",
      "Epoch 737/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1377 - val_loss: 10.9986\n",
      "Epoch 738/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4418 - val_loss: 11.6779\n",
      "Epoch 739/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8849 - val_loss: 10.9838\n",
      "Epoch 740/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2395 - val_loss: 11.4546\n",
      "Epoch 741/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1322 - val_loss: 10.7400\n",
      "Epoch 742/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8865 - val_loss: 10.6888\n",
      "Epoch 743/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1525 - val_loss: 11.0619\n",
      "Epoch 744/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3564 - val_loss: 11.0903\n",
      "Epoch 745/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3530 - val_loss: 10.5538\n",
      "Epoch 746/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8071 - val_loss: 12.7323\n",
      "Epoch 747/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9821 - val_loss: 10.9573\n",
      "Epoch 748/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1180 - val_loss: 11.3814\n",
      "Epoch 749/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8207 - val_loss: 12.1470\n",
      "Epoch 750/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0121 - val_loss: 10.6152\n",
      "Epoch 751/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2948 - val_loss: 10.9779\n",
      "Epoch 752/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8295 - val_loss: 11.4636\n",
      "Epoch 753/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0587 - val_loss: 11.4997\n",
      "Epoch 754/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8182 - val_loss: 11.0235\n",
      "Epoch 755/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7726 - val_loss: 10.5079\n",
      "Epoch 756/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3275 - val_loss: 11.1800\n",
      "Epoch 757/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7303 - val_loss: 11.1425\n",
      "Epoch 758/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1157 - val_loss: 11.0526\n",
      "Epoch 759/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1851 - val_loss: 11.1579\n",
      "Epoch 760/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0152 - val_loss: 10.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6431 - val_loss: 12.7390\n",
      "Epoch 762/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2416 - val_loss: 11.7602\n",
      "Epoch 763/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3325 - val_loss: 11.4936\n",
      "Epoch 764/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1124 - val_loss: 10.9814\n",
      "Epoch 765/1000\n",
      "274/274 [==============================] - 0s 142us/step - loss: 5.6907 - val_loss: 11.4795\n",
      "Epoch 766/1000\n",
      "274/274 [==============================] - 0s 66us/step - loss: 6.0762 - val_loss: 11.0601\n",
      "Epoch 767/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0098 - val_loss: 10.3093\n",
      "Epoch 768/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5897 - val_loss: 11.7634\n",
      "Epoch 769/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1063 - val_loss: 10.3914\n",
      "Epoch 770/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7696 - val_loss: 10.7692\n",
      "Epoch 771/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1214 - val_loss: 10.7108\n",
      "Epoch 772/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7621 - val_loss: 10.6501\n",
      "Epoch 773/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8460 - val_loss: 11.5338\n",
      "Epoch 774/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6969 - val_loss: 11.1581\n",
      "Epoch 775/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.3037 - val_loss: 10.9348\n",
      "Epoch 776/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9339 - val_loss: 10.4936\n",
      "Epoch 777/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0160 - val_loss: 11.0337\n",
      "Epoch 778/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2491 - val_loss: 11.6900\n",
      "Epoch 779/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1445 - val_loss: 11.7586\n",
      "Epoch 780/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7561 - val_loss: 10.7522\n",
      "Epoch 781/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5719 - val_loss: 12.0113\n",
      "Epoch 782/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7630 - val_loss: 11.1356\n",
      "Epoch 783/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6987 - val_loss: 11.5643\n",
      "Epoch 784/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7119 - val_loss: 10.3183\n",
      "Epoch 785/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9162 - val_loss: 10.3794\n",
      "Epoch 786/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.4737 - val_loss: 10.3939\n",
      "Epoch 787/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6305 - val_loss: 10.6947\n",
      "Epoch 788/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6872 - val_loss: 10.7909\n",
      "Epoch 789/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2735 - val_loss: 10.7030\n",
      "Epoch 790/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8029 - val_loss: 13.8366\n",
      "Epoch 791/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9099 - val_loss: 11.1655\n",
      "Epoch 792/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7756 - val_loss: 10.8707\n",
      "Epoch 793/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1265 - val_loss: 10.9267\n",
      "Epoch 794/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0192 - val_loss: 10.3611\n",
      "Epoch 795/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7722 - val_loss: 10.5478\n",
      "Epoch 796/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.1542 - val_loss: 11.9594\n",
      "Epoch 797/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9799 - val_loss: 11.6787\n",
      "Epoch 798/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9441 - val_loss: 10.8540\n",
      "Epoch 799/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6492 - val_loss: 12.3762\n",
      "Epoch 800/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9820 - val_loss: 9.9956\n",
      "Epoch 801/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8611 - val_loss: 11.3127\n",
      "Epoch 802/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7033 - val_loss: 10.2283\n",
      "Epoch 803/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8433 - val_loss: 10.6595\n",
      "Epoch 804/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9853 - val_loss: 10.4121\n",
      "Epoch 805/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9631 - val_loss: 11.3056\n",
      "Epoch 806/1000\n",
      "274/274 [==============================] - 0s 107us/step - loss: 5.9407 - val_loss: 10.8104\n",
      "Epoch 807/1000\n",
      "274/274 [==============================] - 0s 79us/step - loss: 5.3648 - val_loss: 12.9885\n",
      "Epoch 808/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1347 - val_loss: 10.7255\n",
      "Epoch 809/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9398 - val_loss: 10.7196\n",
      "Epoch 810/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9182 - val_loss: 11.9995\n",
      "Epoch 811/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1493 - val_loss: 10.6415\n",
      "Epoch 812/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6937 - val_loss: 10.4270\n",
      "Epoch 813/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6455 - val_loss: 10.9149\n",
      "Epoch 814/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9482 - val_loss: 10.6740\n",
      "Epoch 815/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0056 - val_loss: 10.4553\n",
      "Epoch 816/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7887 - val_loss: 10.4270\n",
      "Epoch 817/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5710 - val_loss: 11.2270\n",
      "Epoch 818/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6520 - val_loss: 10.5929\n",
      "Epoch 819/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2113 - val_loss: 10.5664\n",
      "Epoch 820/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7146 - val_loss: 11.6636\n",
      "Epoch 821/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6672 - val_loss: 11.4352\n",
      "Epoch 822/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8679 - val_loss: 11.3697\n",
      "Epoch 823/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6063 - val_loss: 11.9047\n",
      "Epoch 824/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6201 - val_loss: 10.9110\n",
      "Epoch 825/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8369 - val_loss: 10.5544\n",
      "Epoch 826/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3965 - val_loss: 13.2421\n",
      "Epoch 827/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.3059 - val_loss: 11.1592\n",
      "Epoch 828/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5425 - val_loss: 10.6310\n",
      "Epoch 829/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6331 - val_loss: 10.8098\n",
      "Epoch 830/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9761 - val_loss: 11.0315\n",
      "Epoch 831/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8368 - val_loss: 11.1863\n",
      "Epoch 832/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5401 - val_loss: 11.0944\n",
      "Epoch 833/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7545 - val_loss: 11.7520\n",
      "Epoch 834/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6493 - val_loss: 11.9500\n",
      "Epoch 835/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5997 - val_loss: 11.3109\n",
      "Epoch 836/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9308 - val_loss: 11.7021\n",
      "Epoch 837/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6573 - val_loss: 13.9561\n",
      "Epoch 838/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 114us/step - loss: 5.9987 - val_loss: 11.9360\n",
      "Epoch 839/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6732 - val_loss: 11.5611\n",
      "Epoch 840/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6476 - val_loss: 10.9355\n",
      "Epoch 841/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8753 - val_loss: 10.3356\n",
      "Epoch 842/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0759 - val_loss: 10.8213\n",
      "Epoch 843/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4161 - val_loss: 11.5302\n",
      "Epoch 844/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6748 - val_loss: 12.2719\n",
      "Epoch 845/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6125 - val_loss: 10.6945\n",
      "Epoch 846/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2262 - val_loss: 11.0961\n",
      "Epoch 847/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8109 - val_loss: 11.6953\n",
      "Epoch 848/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7715 - val_loss: 11.3101\n",
      "Epoch 849/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4747 - val_loss: 11.1952\n",
      "Epoch 850/1000\n",
      "274/274 [==============================] - 0s 97us/step - loss: 6.2198 - val_loss: 11.1094\n",
      "Epoch 851/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4970 - val_loss: 10.4129\n",
      "Epoch 852/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5336 - val_loss: 12.2943\n",
      "Epoch 853/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2589 - val_loss: 11.0873\n",
      "Epoch 854/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7073 - val_loss: 11.6691\n",
      "Epoch 855/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7865 - val_loss: 11.1012\n",
      "Epoch 856/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8072 - val_loss: 11.1004\n",
      "Epoch 857/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3267 - val_loss: 12.9108\n",
      "Epoch 858/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9830 - val_loss: 11.8583\n",
      "Epoch 859/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7455 - val_loss: 12.0683\n",
      "Epoch 860/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.4836 - val_loss: 11.5240\n",
      "Epoch 861/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6161 - val_loss: 10.7414\n",
      "Epoch 862/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4424 - val_loss: 10.6956\n",
      "Epoch 863/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4236 - val_loss: 10.5178\n",
      "Epoch 864/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7410 - val_loss: 10.2077\n",
      "Epoch 865/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7041 - val_loss: 10.8861\n",
      "Epoch 866/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7699 - val_loss: 12.7033\n",
      "Epoch 867/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0393 - val_loss: 10.6881\n",
      "Epoch 868/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4526 - val_loss: 10.1626\n",
      "Epoch 869/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4697 - val_loss: 11.1144\n",
      "Epoch 870/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5866 - val_loss: 11.6513\n",
      "Epoch 871/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9080 - val_loss: 11.3698\n",
      "Epoch 872/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.9640 - val_loss: 11.2404\n",
      "Epoch 873/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4138 - val_loss: 10.5682\n",
      "Epoch 874/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5499 - val_loss: 10.8900\n",
      "Epoch 875/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6452 - val_loss: 10.3802\n",
      "Epoch 876/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1921 - val_loss: 11.2471\n",
      "Epoch 877/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4611 - val_loss: 12.4404\n",
      "Epoch 878/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4406 - val_loss: 11.5235\n",
      "Epoch 879/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8834 - val_loss: 10.8310\n",
      "Epoch 880/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6177 - val_loss: 11.1001\n",
      "Epoch 881/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6894 - val_loss: 12.3653\n",
      "Epoch 882/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6001 - val_loss: 11.3045\n",
      "Epoch 883/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7897 - val_loss: 11.0868\n",
      "Epoch 884/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6050 - val_loss: 13.5184\n",
      "Epoch 885/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 13.18 - 0s 114us/step - loss: 5.8685 - val_loss: 10.9136\n",
      "Epoch 886/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8259 - val_loss: 11.8311\n",
      "Epoch 887/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7234 - val_loss: 11.8385\n",
      "Epoch 888/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 2.322 - 0s 57us/step - loss: 5.8985 - val_loss: 10.4896\n",
      "Epoch 889/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1320 - val_loss: 11.2251\n",
      "Epoch 890/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5027 - val_loss: 10.9196\n",
      "Epoch 891/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5854 - val_loss: 10.8451\n",
      "Epoch 892/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5154 - val_loss: 10.9633\n",
      "Epoch 893/1000\n",
      "274/274 [==============================] - 0s 111us/step - loss: 5.6663 - val_loss: 11.8705\n",
      "Epoch 894/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3539 - val_loss: 11.6431\n",
      "Epoch 895/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7744 - val_loss: 11.5889\n",
      "Epoch 896/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6404 - val_loss: 10.8809\n",
      "Epoch 897/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9157 - val_loss: 11.1509\n",
      "Epoch 898/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6783 - val_loss: 10.8865\n",
      "Epoch 899/1000\n",
      "274/274 [==============================] - ETA: 0s - loss: 6.698 - 0s 57us/step - loss: 5.3853 - val_loss: 10.9918\n",
      "Epoch 900/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.1972 - val_loss: 10.1633\n",
      "Epoch 901/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8909 - val_loss: 11.3031\n",
      "Epoch 902/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5931 - val_loss: 10.1453\n",
      "Epoch 903/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4392 - val_loss: 10.3607\n",
      "Epoch 904/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.8324 - val_loss: 10.7044\n",
      "Epoch 905/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7013 - val_loss: 10.2787\n",
      "Epoch 906/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6936 - val_loss: 10.5549\n",
      "Epoch 907/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8808 - val_loss: 10.8667\n",
      "Epoch 908/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3478 - val_loss: 9.9798\n",
      "Epoch 909/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4034 - val_loss: 11.7696\n",
      "Epoch 910/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7056 - val_loss: 10.8773\n",
      "Epoch 911/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.1986 - val_loss: 10.9596\n",
      "Epoch 912/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6927 - val_loss: 11.5755\n",
      "Epoch 913/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6717 - val_loss: 10.1969\n",
      "Epoch 914/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.2863 - val_loss: 11.5562\n",
      "Epoch 915/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.2196 - val_loss: 11.0598\n",
      "Epoch 916/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3258 - val_loss: 10.7169\n",
      "Epoch 917/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7879 - val_loss: 11.8266\n",
      "Epoch 918/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6509 - val_loss: 10.5540\n",
      "Epoch 919/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7724 - val_loss: 9.9230\n",
      "Epoch 920/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6590 - val_loss: 11.1028\n",
      "Epoch 921/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9563 - val_loss: 10.2784\n",
      "Epoch 922/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3870 - val_loss: 13.4992\n",
      "Epoch 923/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8542 - val_loss: 11.4563\n",
      "Epoch 924/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5648 - val_loss: 10.8708\n",
      "Epoch 925/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.2638 - val_loss: 13.1143\n",
      "Epoch 926/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4428 - val_loss: 10.7760\n",
      "Epoch 927/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5950 - val_loss: 10.4957\n",
      "Epoch 928/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5099 - val_loss: 10.8040\n",
      "Epoch 929/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5203 - val_loss: 10.7764\n",
      "Epoch 930/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7182 - val_loss: 10.4732\n",
      "Epoch 931/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.1945 - val_loss: 11.0237\n",
      "Epoch 932/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3503 - val_loss: 10.5773\n",
      "Epoch 933/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8068 - val_loss: 11.4898\n",
      "Epoch 934/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7590 - val_loss: 11.7240\n",
      "Epoch 935/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7221 - val_loss: 10.5931\n",
      "Epoch 936/1000\n",
      "274/274 [==============================] - 0s 100us/step - loss: 5.7657 - val_loss: 10.4034\n",
      "Epoch 937/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.2794 - val_loss: 11.7858\n",
      "Epoch 938/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7910 - val_loss: 10.2793\n",
      "Epoch 939/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4558 - val_loss: 10.7480\n",
      "Epoch 940/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8107 - val_loss: 12.7148\n",
      "Epoch 941/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5122 - val_loss: 10.4477\n",
      "Epoch 942/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5006 - val_loss: 10.6741\n",
      "Epoch 943/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5413 - val_loss: 10.4660\n",
      "Epoch 944/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5289 - val_loss: 10.8442\n",
      "Epoch 945/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3405 - val_loss: 10.9849\n",
      "Epoch 946/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7555 - val_loss: 10.6182\n",
      "Epoch 947/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6519 - val_loss: 11.0664\n",
      "Epoch 948/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6525 - val_loss: 12.3083\n",
      "Epoch 949/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6569 - val_loss: 12.8327\n",
      "Epoch 950/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7699 - val_loss: 11.0808\n",
      "Epoch 951/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 6.0799 - val_loss: 10.6154\n",
      "Epoch 952/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3630 - val_loss: 10.0097\n",
      "Epoch 953/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.2880 - val_loss: 10.9635\n",
      "Epoch 954/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6555 - val_loss: 10.3321\n",
      "Epoch 955/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5213 - val_loss: 11.9638\n",
      "Epoch 956/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8167 - val_loss: 11.3387\n",
      "Epoch 957/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5352 - val_loss: 11.1145\n",
      "Epoch 958/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3842 - val_loss: 10.7968\n",
      "Epoch 959/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.0601 - val_loss: 10.5774\n",
      "Epoch 960/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6888 - val_loss: 11.1103\n",
      "Epoch 961/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5295 - val_loss: 10.6461\n",
      "Epoch 962/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4939 - val_loss: 10.8139\n",
      "Epoch 963/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5218 - val_loss: 10.6868\n",
      "Epoch 964/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4763 - val_loss: 11.9175\n",
      "Epoch 965/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4181 - val_loss: 11.3414\n",
      "Epoch 966/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.9844 - val_loss: 10.2679\n",
      "Epoch 967/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5528 - val_loss: 11.0231\n",
      "Epoch 968/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8727 - val_loss: 10.9768\n",
      "Epoch 969/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5802 - val_loss: 10.7825\n",
      "Epoch 970/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7088 - val_loss: 9.9247\n",
      "Epoch 971/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4348 - val_loss: 10.1166\n",
      "Epoch 972/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3162 - val_loss: 12.0635\n",
      "Epoch 973/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6998 - val_loss: 10.9640\n",
      "Epoch 974/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4240 - val_loss: 13.1810\n",
      "Epoch 975/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6567 - val_loss: 10.8143\n",
      "Epoch 976/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8250 - val_loss: 10.2611\n",
      "Epoch 977/1000\n",
      "274/274 [==============================] - 0s 128us/step - loss: 5.6835 - val_loss: 10.2662\n",
      "Epoch 978/1000\n",
      "274/274 [==============================] - 0s 68us/step - loss: 5.7001 - val_loss: 10.5963\n",
      "Epoch 979/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6060 - val_loss: 10.8718\n",
      "Epoch 980/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7418 - val_loss: 11.6438\n",
      "Epoch 981/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.8021 - val_loss: 10.3374\n",
      "Epoch 982/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5983 - val_loss: 11.5409\n",
      "Epoch 983/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3915 - val_loss: 11.5076\n",
      "Epoch 984/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 6.2618 - val_loss: 11.1608\n",
      "Epoch 985/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.3395 - val_loss: 10.8953\n",
      "Epoch 986/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.2227 - val_loss: 11.1230\n",
      "Epoch 987/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.6071 - val_loss: 10.7809\n",
      "Epoch 988/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4278 - val_loss: 12.4382\n",
      "Epoch 989/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7624 - val_loss: 10.9188\n",
      "Epoch 990/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.3912 - val_loss: 10.7705\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 0s 57us/step - loss: 5.4415 - val_loss: 10.3482\n",
      "Epoch 992/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.7697 - val_loss: 11.2350\n",
      "Epoch 993/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6045 - val_loss: 10.0579\n",
      "Epoch 994/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5707 - val_loss: 10.8962\n",
      "Epoch 995/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.5207 - val_loss: 10.5212\n",
      "Epoch 996/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.5977 - val_loss: 11.6458\n",
      "Epoch 997/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.6905 - val_loss: 10.4350\n",
      "Epoch 998/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.7608 - val_loss: 11.0640\n",
      "Epoch 999/1000\n",
      "274/274 [==============================] - 0s 114us/step - loss: 5.4005 - val_loss: 10.2729\n",
      "Epoch 1000/1000\n",
      "274/274 [==============================] - 0s 57us/step - loss: 5.4997 - val_loss: 11.3819\n",
      "7.311341802952653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.1746191 ,  2.4293883 , -6.91856   ,  1.9678552 , -2.2026954 ],\n",
       "        [ 0.47316688, -3.016624  ,  3.4685297 ,  0.03263656,  0.16508159],\n",
       "        [ 0.11575423,  0.5445551 , -2.0351822 , -0.6714933 ,  0.2927511 ],\n",
       "        [ 0.46256348,  2.946144  , -2.714637  ,  0.3525459 ,  0.62859106],\n",
       "        [ 0.5747    , -1.9116157 , -0.37213433, -0.12003113, -0.2591557 ],\n",
       "        [-0.22660203, -0.89768785,  0.96917105,  1.1227708 ,  0.30428106],\n",
       "        [-1.2314231 , -0.64644545,  0.07762497, -0.16471599,  0.11163276]],\n",
       "       dtype=float32),\n",
       " array([-1.1737967, -2.9409952, -1.9340348,  1.4686694, -0.9354909],\n",
       "       dtype=float32),\n",
       " array([[ 0.0528037 , -0.3853231 , -0.08422575,  0.5677087 , -0.07431588,\n",
       "          0.574651  ,  1.010017  ,  0.6747852 , -0.65608954, -0.4426655 ],\n",
       "        [-0.03173079,  0.08912551, -0.26017058,  1.0346096 , -0.5392855 ,\n",
       "          0.90504646,  0.26732296,  0.25705466, -0.10923968, -0.7899628 ],\n",
       "        [-0.9667876 ,  1.2490555 ,  0.654677  , -1.235496  ,  0.55927676,\n",
       "         -0.4930984 , -1.118492  , -1.5420212 ,  0.8643246 ,  0.8649217 ],\n",
       "        [-0.62492853,  0.41209567,  0.97254324, -1.0414616 ,  0.8575806 ,\n",
       "         -0.23196009,  0.06047972, -0.6129647 ,  0.91003543,  0.8306116 ],\n",
       "        [ 0.8233734 , -0.47559997, -0.8989012 ,  0.52311563, -0.86588997,\n",
       "          0.8470263 ,  0.4920358 ,  0.42776588, -0.8810875 , -0.5376998 ]],\n",
       "       dtype=float32),\n",
       " array([-1.0641699,  1.0983225,  1.1179373, -1.1668757,  0.9215151,\n",
       "        -1.1135509, -1.0942183, -1.1778519,  1.0579562,  1.1282037],\n",
       "       dtype=float32),\n",
       " array([[-0.71552366],\n",
       "        [ 0.7464685 ],\n",
       "        [ 1.0652046 ],\n",
       "        [-1.4524205 ],\n",
       "        [ 0.56457406],\n",
       "        [-1.0447569 ],\n",
       "        [-0.8930419 ],\n",
       "        [-1.4346596 ],\n",
       "        [ 0.8014114 ],\n",
       "        [ 1.14371   ]], dtype=float32),\n",
       " array([1.3584133], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_autompg, history_autompg, evaluate_autompg=NN_model_structure_regression(X_train_autompg, X_val_autompg, Y_train_autompg, Y_val_autompg, RMSprop, 32, 1000, x_test_autompg, y_test_autompg)\n",
    "model_autompg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autompg.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_autompg_rmsprop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.1838\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 15us/step - loss: 0.1105 - val_loss: 0.0239\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0454 - val_loss: 0.0335\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0300 - val_loss: 0.0258\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0345 - val_loss: 0.0274\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0289 - val_loss: 0.0129\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0234 - val_loss: 0.0095\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0200 - val_loss: 0.0086\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0185 - val_loss: 0.0077\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0161 - val_loss: 0.0079\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0138 - val_loss: 0.0078\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0126 - val_loss: 0.0067\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0058\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0078 - val_loss: 0.0052\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0045\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 118us/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 106us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0041\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 124us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 219us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 99us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 50us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.006 - 0s 109us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 56us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 301/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.004 - 0s 109us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 103us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 377/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 212us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 28us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 151us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 175us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 455/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 196us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 16us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 219us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.003 - 0s 0us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 192us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 117us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 170us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 15us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 213us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 609/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 62us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 19us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 763/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 64us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 204us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 42us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.002 - 0s 109us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 80us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 161us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 17us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 917/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 145us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 63us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 163us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0016 - val_loss: 0.0031\n",
      "0.008868318982422352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.29680791e-01, -3.25725108e-01, -1.53504517e-02,\n",
       "          4.32914793e-01, -1.04041183e+00],\n",
       "        [-2.23307967e-01,  1.01031056e-02, -1.22327246e-01,\n",
       "         -6.72626436e-01,  2.06743762e-01],\n",
       "        [ 7.41706133e-01, -3.15109611e-01,  3.25972401e-02,\n",
       "          1.25615641e-01,  1.31149590e+00],\n",
       "        [-2.28908216e-03, -7.10812807e-01,  8.14740360e-02,\n",
       "         -3.08187038e-01,  3.74538630e-01],\n",
       "        [-1.41407236e-01, -2.51665562e-01, -1.57846481e-01,\n",
       "         -2.61490166e-01,  2.41048113e-01],\n",
       "        [-3.31043333e-01,  1.35839563e-02, -1.02597189e+00,\n",
       "         -1.74393207e-01, -8.68754923e-01],\n",
       "        [-5.65763056e-01, -5.84106743e-02, -6.97795212e-01,\n",
       "         -7.55099118e-01,  1.95976600e-01],\n",
       "        [-3.39076430e-01,  1.83794245e-01,  2.65133917e-01,\n",
       "         -3.10411751e-01, -6.68103620e-02],\n",
       "        [ 8.16033334e-02, -4.71576542e-01, -7.59522676e-01,\n",
       "         -4.61577848e-02,  9.88743082e-02],\n",
       "        [-1.10499966e+00, -2.02303991e-01,  8.35567951e-01,\n",
       "         -6.70429409e-01, -9.96120274e-02],\n",
       "        [ 5.28871477e-01,  1.39400512e-01,  1.02450848e+00,\n",
       "         -3.06787044e-01,  2.13706329e-01],\n",
       "        [ 7.39012659e-01, -2.17143312e-01,  1.89059794e+00,\n",
       "          1.29607987e+00,  1.85159981e-01],\n",
       "        [ 7.29766733e-04, -4.56147224e-01,  1.34102178e+00,\n",
       "          2.15897635e-01,  4.21486109e-01],\n",
       "        [ 1.08667421e+00, -4.22664851e-01,  4.80841100e-01,\n",
       "         -4.28947121e-01, -1.64390552e+00],\n",
       "        [ 4.26345170e-01, -6.48213863e-01, -3.57933521e-01,\n",
       "          1.00067757e-01, -2.39627615e-01],\n",
       "        [-3.09296995e-01, -4.85391557e-01,  2.87634313e-01,\n",
       "         -8.58499110e-02, -9.24596041e-02],\n",
       "        [ 3.13410878e-01, -1.15885869e-01, -6.43728614e-01,\n",
       "          4.65911031e-01, -9.40242186e-02],\n",
       "        [ 2.25680515e-01, -2.86106199e-01, -1.52013466e-01,\n",
       "          5.35017885e-02, -1.88605785e-01],\n",
       "        [ 1.53193974e+00, -4.27730441e-01, -8.97365272e-01,\n",
       "          5.24911761e-01,  2.55649477e-01],\n",
       "        [ 3.41032147e-01, -2.15455666e-01,  7.24387884e-01,\n",
       "          3.79390955e-01, -5.98874211e-01],\n",
       "        [ 2.39274457e-01, -6.44615069e-02,  1.68496862e-01,\n",
       "          2.18593761e-01,  2.39542985e+00],\n",
       "        [ 5.35655499e-01,  2.57510632e-01,  5.70606112e-01,\n",
       "         -2.61061102e-01,  2.78472215e-01]], dtype=float32),\n",
       " array([ 0.06602878, -0.08988699,  0.38863435,  0.18826681,  0.50772893],\n",
       "       dtype=float32),\n",
       " array([[ 0.90906215,  0.13426216,  0.25739136, -0.26656315,  0.18652612,\n",
       "         -0.20188652,  0.1732468 ,  0.35352895, -0.48990545, -0.2838778 ],\n",
       "        [ 0.37517965, -0.08471543, -0.30845788, -0.28993222,  0.09566008,\n",
       "         -0.19111864, -0.29379368,  0.3189336 , -0.16264485, -0.28660816],\n",
       "        [ 0.30589586, -0.00438714, -0.32634646, -0.4249607 , -0.40741515,\n",
       "         -0.6544484 ,  0.21657138, -0.10693631,  0.03561773,  0.54811835],\n",
       "        [-0.28063866,  0.2825834 , -0.0899627 ,  0.09945888,  0.30099654,\n",
       "         -0.03987215, -0.6455139 , -0.10430564,  0.18285808, -0.23843329],\n",
       "        [-0.5991229 , -0.50243956, -0.11292527,  0.22054818,  0.2649239 ,\n",
       "          0.75744694, -0.3758051 ,  0.04459549,  0.16828343, -0.46416524]],\n",
       "       dtype=float32),\n",
       " array([ 0.04168705,  0.10878725, -0.06897765,  0.06259663, -0.00172526,\n",
       "        -0.08988637, -0.04870339,  0.11734074,  0.02770849, -0.05040947],\n",
       "       dtype=float32),\n",
       " array([[ 0.37941715],\n",
       "        [ 0.00591554],\n",
       "        [ 0.00978075],\n",
       "        [-0.09633639],\n",
       "        [-0.04759453],\n",
       "        [-0.14833073],\n",
       "        [ 0.20509619],\n",
       "        [ 0.01567147],\n",
       "        [-0.01978724],\n",
       "        [ 0.10443597]], dtype=float32),\n",
       " array([0.12764767], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, adam2, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9939 - val_loss: 1.0135\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 22us/step - loss: 0.9920 - val_loss: 1.0109\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9891 - val_loss: 1.0077\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9857 - val_loss: 1.0040\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9820 - val_loss: 1.0001\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9780 - val_loss: 0.9961\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9740 - val_loss: 0.9921\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9700 - val_loss: 0.9880\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.9659 - val_loss: 0.9839\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9619 - val_loss: 0.9798\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9578 - val_loss: 0.9758\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9538 - val_loss: 0.9718\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9498 - val_loss: 0.9677\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9458 - val_loss: 0.9637\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9418 - val_loss: 0.9597\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9378 - val_loss: 0.9558\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9339 - val_loss: 0.9518\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 49us/step - loss: 0.9299 - val_loss: 0.9479\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9260 - val_loss: 0.9440\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9221 - val_loss: 0.9401\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9183 - val_loss: 0.9362\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9144 - val_loss: 0.9323\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.9106 - val_loss: 0.9284\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.9067 - val_loss: 0.9246\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.9030 - val_loss: 0.9208\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8991 - val_loss: 0.9171\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8954 - val_loss: 0.9133\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8917 - val_loss: 0.9096\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8880 - val_loss: 0.9059\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8843 - val_loss: 0.9022\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.8806 - val_loss: 0.8984\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8769 - val_loss: 0.8948\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8733 - val_loss: 0.8911\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8697 - val_loss: 0.8875\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8660 - val_loss: 0.8838\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8624 - val_loss: 0.8802\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8588 - val_loss: 0.8767\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.8553 - val_loss: 0.8731\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.8517 - val_loss: 0.8695\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8482 - val_loss: 0.8660\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8447 - val_loss: 0.8625\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8412 - val_loss: 0.8590\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8377 - val_loss: 0.8555\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8343 - val_loss: 0.8520\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8309 - val_loss: 0.8486\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8274 - val_loss: 0.8451\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.808 - 0s 109us/step - loss: 0.8240 - val_loss: 0.8417\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8206 - val_loss: 0.8383\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8173 - val_loss: 0.8349\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8139 - val_loss: 0.8316\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.8106 - val_loss: 0.8282\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8072 - val_loss: 0.8248\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8039 - val_loss: 0.8215\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.8006 - val_loss: 0.8182\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7973 - val_loss: 0.8149\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7941 - val_loss: 0.8117\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7908 - val_loss: 0.8084\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7876 - val_loss: 0.8051\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7844 - val_loss: 0.8019\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.7812 - val_loss: 0.7987\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 15us/step - loss: 0.7780 - val_loss: 0.7956\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7749 - val_loss: 0.7924\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7718 - val_loss: 0.7892\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7686 - val_loss: 0.7861\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7655 - val_loss: 0.7830\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7624 - val_loss: 0.7798\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.7593 - val_loss: 0.7767\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.7562 - val_loss: 0.7736\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.7532 - val_loss: 0.7706\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7502 - val_loss: 0.7675\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7471 - val_loss: 0.7645\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7442 - val_loss: 0.7615\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7412 - val_loss: 0.7585\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7382 - val_loss: 0.7555\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7353 - val_loss: 0.7526\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.7323 - val_loss: 0.7496\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.7294 - val_loss: 0.7466\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 93us/step - loss: 0.7265 - val_loss: 0.7437\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 21us/step - loss: 0.7236 - val_loss: 0.7408\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7207 - val_loss: 0.7379\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7178 - val_loss: 0.7350\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7150 - val_loss: 0.7321\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.7121 - val_loss: 0.7293\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.7093 - val_loss: 0.7265\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7065 - val_loss: 0.7236\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7037 - val_loss: 0.7208\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.7009 - val_loss: 0.7180\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6981 - val_loss: 0.7152\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6953 - val_loss: 0.7124\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6926 - val_loss: 0.7097\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6898 - val_loss: 0.7069\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6871 - val_loss: 0.7042\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6845 - val_loss: 0.7014\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6817 - val_loss: 0.6988\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6791 - val_loss: 0.6960\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6764 - val_loss: 0.6933\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6737 - val_loss: 0.6907\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6710 - val_loss: 0.6880\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6685 - val_loss: 0.6854\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6658 - val_loss: 0.6827\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6632 - val_loss: 0.6801\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6607 - val_loss: 0.6775\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6581 - val_loss: 0.6749\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6555 - val_loss: 0.6723\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6529 - val_loss: 0.6697\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6504 - val_loss: 0.6672\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6479 - val_loss: 0.6646\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6453 - val_loss: 0.6621\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6428 - val_loss: 0.6596\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6404 - val_loss: 0.6570\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6378 - val_loss: 0.6545\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6353 - val_loss: 0.6520\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6329 - val_loss: 0.6496\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.6305 - val_loss: 0.6471\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6280 - val_loss: 0.6446\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6256 - val_loss: 0.6422\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6232 - val_loss: 0.6398\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.6208 - val_loss: 0.6373\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6184 - val_loss: 0.6349\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6160 - val_loss: 0.6325\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6136 - val_loss: 0.6301\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6112 - val_loss: 0.6277\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6089 - val_loss: 0.6253\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6066 - val_loss: 0.6230\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6042 - val_loss: 0.6206\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.6019 - val_loss: 0.6183\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5996 - val_loss: 0.6160\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5973 - val_loss: 0.6137\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5950 - val_loss: 0.6114\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5928 - val_loss: 0.6091\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5905 - val_loss: 0.6069\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.5883 - val_loss: 0.6046\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5861 - val_loss: 0.6023\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5838 - val_loss: 0.6001\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5816 - val_loss: 0.5979\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5794 - val_loss: 0.5956\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5772 - val_loss: 0.5934\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5751 - val_loss: 0.5912\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5729 - val_loss: 0.5890\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5707 - val_loss: 0.5868\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5685 - val_loss: 0.5847\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5664 - val_loss: 0.5825\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5643 - val_loss: 0.5804\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5622 - val_loss: 0.5782\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5601 - val_loss: 0.5761\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5579 - val_loss: 0.5740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5558 - val_loss: 0.5718\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5537 - val_loss: 0.5697\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5517 - val_loss: 0.5676\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5496 - val_loss: 0.5655\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5475 - val_loss: 0.5634\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5454 - val_loss: 0.5613\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5434 - val_loss: 0.5593\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5413 - val_loss: 0.5572\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5393 - val_loss: 0.5551\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5373 - val_loss: 0.5531\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5352 - val_loss: 0.5510\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5333 - val_loss: 0.5490\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5312 - val_loss: 0.5470\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5293 - val_loss: 0.5450\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5273 - val_loss: 0.5430\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5253 - val_loss: 0.5411\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5234 - val_loss: 0.5391\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5214 - val_loss: 0.5371\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5195 - val_loss: 0.5352\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5176 - val_loss: 0.5332\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5157 - val_loss: 0.5313\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5138 - val_loss: 0.5294\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5119 - val_loss: 0.5275\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5100 - val_loss: 0.5256\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5081 - val_loss: 0.5237\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5063 - val_loss: 0.5218\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5044 - val_loss: 0.5199\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.5025 - val_loss: 0.5180\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.5007 - val_loss: 0.5162\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4989 - val_loss: 0.5143\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4970 - val_loss: 0.5125\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4952 - val_loss: 0.5106\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4934 - val_loss: 0.5088\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4916 - val_loss: 0.5070\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4898 - val_loss: 0.5052\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4880 - val_loss: 0.5033\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4862 - val_loss: 0.5015\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4845 - val_loss: 0.4997\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4827 - val_loss: 0.4980\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4809 - val_loss: 0.4962\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4792 - val_loss: 0.4944\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4775 - val_loss: 0.4927\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4758 - val_loss: 0.4909\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4740 - val_loss: 0.4892\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4723 - val_loss: 0.4875\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4706 - val_loss: 0.4857\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4689 - val_loss: 0.4840\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4672 - val_loss: 0.4823\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4656 - val_loss: 0.4806\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4639 - val_loss: 0.4789\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4622 - val_loss: 0.4772\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4605 - val_loss: 0.4755\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4589 - val_loss: 0.4739\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4572 - val_loss: 0.4722\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4556 - val_loss: 0.4706\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4540 - val_loss: 0.4689\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4524 - val_loss: 0.4673\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 139us/step - loss: 0.4508 - val_loss: 0.4657\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 17us/step - loss: 0.4491 - val_loss: 0.4640\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4475 - val_loss: 0.4624\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4460 - val_loss: 0.4608\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4444 - val_loss: 0.4592\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4428 - val_loss: 0.4576\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4412 - val_loss: 0.4560\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4396 - val_loss: 0.4544\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4381 - val_loss: 0.4528\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4365 - val_loss: 0.4513\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4349 - val_loss: 0.4497\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4334 - val_loss: 0.4481\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4318 - val_loss: 0.4465\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4303 - val_loss: 0.4450\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4288 - val_loss: 0.4434\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4273 - val_loss: 0.4419\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4258 - val_loss: 0.4404\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4243 - val_loss: 0.4389\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4228 - val_loss: 0.4374\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4213 - val_loss: 0.4359\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4198 - val_loss: 0.4344\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4184 - val_loss: 0.4329\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4169 - val_loss: 0.4314\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4155 - val_loss: 0.4300\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4140 - val_loss: 0.4285\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4126 - val_loss: 0.4271\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4111 - val_loss: 0.4256\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4097 - val_loss: 0.4241\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.4083 - val_loss: 0.4227\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4068 - val_loss: 0.4213\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4054 - val_loss: 0.4198\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4040 - val_loss: 0.4184\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4026 - val_loss: 0.4170\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.4013 - val_loss: 0.4156\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3999 - val_loss: 0.4142\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3985 - val_loss: 0.4128\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3971 - val_loss: 0.4114\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3957 - val_loss: 0.4100\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3944 - val_loss: 0.4086\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3930 - val_loss: 0.4073\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3917 - val_loss: 0.4059\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3903 - val_loss: 0.4045\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3890 - val_loss: 0.4031\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3876 - val_loss: 0.4018\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3863 - val_loss: 0.4004\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3850 - val_loss: 0.3991\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3837 - val_loss: 0.3978\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3823 - val_loss: 0.3964\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3810 - val_loss: 0.3951\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3797 - val_loss: 0.3938\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3784 - val_loss: 0.3925\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3771 - val_loss: 0.3912\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3759 - val_loss: 0.3899\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3746 - val_loss: 0.3886\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3733 - val_loss: 0.3873\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3720 - val_loss: 0.3860\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3708 - val_loss: 0.3847\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3695 - val_loss: 0.3834\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3682 - val_loss: 0.3821\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3670 - val_loss: 0.3809\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3657 - val_loss: 0.3796\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3645 - val_loss: 0.3783\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3632 - val_loss: 0.3771\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3620 - val_loss: 0.3758\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3608 - val_loss: 0.3746\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3596 - val_loss: 0.3734\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3584 - val_loss: 0.3722\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3572 - val_loss: 0.3709\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3560 - val_loss: 0.3697\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3548 - val_loss: 0.3685\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3536 - val_loss: 0.3673\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3524 - val_loss: 0.3661\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 60us/step - loss: 0.3512 - val_loss: 0.3649\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3500 - val_loss: 0.3637\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3489 - val_loss: 0.3625\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3477 - val_loss: 0.3614\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3465 - val_loss: 0.3602\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3454 - val_loss: 0.3590\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3442 - val_loss: 0.3578\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3431 - val_loss: 0.3567\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3419 - val_loss: 0.3555\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3408 - val_loss: 0.3544\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3397 - val_loss: 0.3532\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3386 - val_loss: 0.3521\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3375 - val_loss: 0.3510\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3364 - val_loss: 0.3499\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3353 - val_loss: 0.3487\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3341 - val_loss: 0.3476\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3331 - val_loss: 0.3465\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3320 - val_loss: 0.3454\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3309 - val_loss: 0.3443\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3298 - val_loss: 0.3432\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3287 - val_loss: 0.3421\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3277 - val_loss: 0.3410\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3266 - val_loss: 0.3399\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3255 - val_loss: 0.3389\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3245 - val_loss: 0.3378\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 0us/step - loss: 0.3234 - val_loss: 0.3367\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 219us/step - loss: 0.3224 - val_loss: 0.3357\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3213 - val_loss: 0.3346\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3203 - val_loss: 0.3336\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3192 - val_loss: 0.3325\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3182 - val_loss: 0.3315\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3172 - val_loss: 0.3304\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3161 - val_loss: 0.3293\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3151 - val_loss: 0.3283\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3141 - val_loss: 0.3273\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3130 - val_loss: 0.3262\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3121 - val_loss: 0.3252\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3110 - val_loss: 0.3242\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3100 - val_loss: 0.3231\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3090 - val_loss: 0.3221\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3080 - val_loss: 0.3211\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3070 - val_loss: 0.3201\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3060 - val_loss: 0.3191\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3050 - val_loss: 0.3181\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3041 - val_loss: 0.3171\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.3031 - val_loss: 0.3161\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3021 - val_loss: 0.3151\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3011 - val_loss: 0.3141\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.3002 - val_loss: 0.3132\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2992 - val_loss: 0.3122\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2983 - val_loss: 0.3113\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2974 - val_loss: 0.3103\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2964 - val_loss: 0.3094\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2955 - val_loss: 0.3084\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2946 - val_loss: 0.3075\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2937 - val_loss: 0.3066\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2927 - val_loss: 0.3056\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2918 - val_loss: 0.3047\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2909 - val_loss: 0.3038\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2900 - val_loss: 0.3028\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2891 - val_loss: 0.3019\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2882 - val_loss: 0.3010\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2873 - val_loss: 0.3001\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2864 - val_loss: 0.2992\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2855 - val_loss: 0.2983\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2846 - val_loss: 0.2974\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2837 - val_loss: 0.2964\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2828 - val_loss: 0.2956\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2819 - val_loss: 0.2947\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2810 - val_loss: 0.2938\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2802 - val_loss: 0.2929\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2793 - val_loss: 0.2920\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 146us/step - loss: 0.2784 - val_loss: 0.2911\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 4us/step - loss: 0.2776 - val_loss: 0.2902\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2767 - val_loss: 0.2894\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2758 - val_loss: 0.2885\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2750 - val_loss: 0.2876\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2741 - val_loss: 0.2868\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2733 - val_loss: 0.2859\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2724 - val_loss: 0.2850\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2716 - val_loss: 0.2842\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2707 - val_loss: 0.2833\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2699 - val_loss: 0.2825\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2691 - val_loss: 0.2816\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2682 - val_loss: 0.2808\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2674 - val_loss: 0.2799\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2666 - val_loss: 0.2791\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2658 - val_loss: 0.2783\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2649 - val_loss: 0.2775\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2642 - val_loss: 0.2766\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2633 - val_loss: 0.2758\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2625 - val_loss: 0.2750\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2617 - val_loss: 0.2742\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.269 - 0s 0us/step - loss: 0.2609 - val_loss: 0.2733\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2601 - val_loss: 0.2725\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 205us/step - loss: 0.2593 - val_loss: 0.2717\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2585 - val_loss: 0.2709\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2577 - val_loss: 0.2702\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2570 - val_loss: 0.2694\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.2562 - val_loss: 0.2686\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2554 - val_loss: 0.2678\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 114us/step - loss: 0.2546 - val_loss: 0.2670\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 63us/step - loss: 0.2539 - val_loss: 0.2662\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 144us/step - loss: 0.2531 - val_loss: 0.2654\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 14us/step - loss: 0.2524 - val_loss: 0.2647\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 198us/step - loss: 0.2516 - val_loss: 0.2639\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.2508 - val_loss: 0.2631\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2501 - val_loss: 0.2624\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2493 - val_loss: 0.2616\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2486 - val_loss: 0.2609\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2478 - val_loss: 0.2601\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2471 - val_loss: 0.2593\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2464 - val_loss: 0.2586\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2456 - val_loss: 0.2578\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2449 - val_loss: 0.2571\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2442 - val_loss: 0.2564\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2434 - val_loss: 0.2556\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2427 - val_loss: 0.2549\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2420 - val_loss: 0.2542\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 96us/step - loss: 0.2413 - val_loss: 0.2534\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2406 - val_loss: 0.2527\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.2399 - val_loss: 0.2520\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 42us/step - loss: 0.2392 - val_loss: 0.2513\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2385 - val_loss: 0.2506\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2377 - val_loss: 0.2499\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2371 - val_loss: 0.2492\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2364 - val_loss: 0.2485\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2357 - val_loss: 0.2478\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2350 - val_loss: 0.2471\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2343 - val_loss: 0.2464\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2336 - val_loss: 0.2457\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2329 - val_loss: 0.2450\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2322 - val_loss: 0.2443\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2316 - val_loss: 0.2436\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2309 - val_loss: 0.2429\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2302 - val_loss: 0.2422\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2295 - val_loss: 0.2415\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2289 - val_loss: 0.2409\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2282 - val_loss: 0.2402\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2276 - val_loss: 0.2395\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 184us/step - loss: 0.2269 - val_loss: 0.2388\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 15us/step - loss: 0.2262 - val_loss: 0.2382\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 45us/step - loss: 0.2256 - val_loss: 0.2375\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2249 - val_loss: 0.2369\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2243 - val_loss: 0.2362\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2237 - val_loss: 0.2356\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 155us/step - loss: 0.2230 - val_loss: 0.2349\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 49us/step - loss: 0.2224 - val_loss: 0.2343\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2218 - val_loss: 0.2336\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2211 - val_loss: 0.2330\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2205 - val_loss: 0.2323\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2199 - val_loss: 0.2317\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2193 - val_loss: 0.2311\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2186 - val_loss: 0.2305\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2180 - val_loss: 0.2299\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2174 - val_loss: 0.2292\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2168 - val_loss: 0.2286\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2162 - val_loss: 0.2280\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2156 - val_loss: 0.2274\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2150 - val_loss: 0.2267\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2143 - val_loss: 0.2261\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2137 - val_loss: 0.2255\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2131 - val_loss: 0.2249\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2125 - val_loss: 0.2243\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2119 - val_loss: 0.2237\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2114 - val_loss: 0.2231\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2108 - val_loss: 0.2225\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 185us/step - loss: 0.2102 - val_loss: 0.2219\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 137us/step - loss: 0.2096 - val_loss: 0.2213\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.2090 - val_loss: 0.2207\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2084 - val_loss: 0.2201\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2078 - val_loss: 0.2195\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2073 - val_loss: 0.2189\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2067 - val_loss: 0.2183\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2061 - val_loss: 0.2178\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2055 - val_loss: 0.2172\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2050 - val_loss: 0.2166\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2044 - val_loss: 0.2160\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2038 - val_loss: 0.2155\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.2033 - val_loss: 0.2149\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2027 - val_loss: 0.2143\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2022 - val_loss: 0.2137\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2016 - val_loss: 0.2132\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.2010 - val_loss: 0.2126\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.2005 - val_loss: 0.2121\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1999 - val_loss: 0.2115\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1994 - val_loss: 0.2109\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1988 - val_loss: 0.2104\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1983 - val_loss: 0.2098\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1977 - val_loss: 0.2093\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1972 - val_loss: 0.2087\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1967 - val_loss: 0.2082\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1961 - val_loss: 0.2076\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1956 - val_loss: 0.2071\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1950 - val_loss: 0.2065\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1945 - val_loss: 0.2060\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1940 - val_loss: 0.2054\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1935 - val_loss: 0.2049\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1929 - val_loss: 0.2044\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1924 - val_loss: 0.2039\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1919 - val_loss: 0.2033\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1914 - val_loss: 0.2028\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1908 - val_loss: 0.2023\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1903 - val_loss: 0.2017\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1898 - val_loss: 0.2012\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1893 - val_loss: 0.2007\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1888 - val_loss: 0.2002\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1883 - val_loss: 0.1997\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 131us/step - loss: 0.1878 - val_loss: 0.1992\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 14us/step - loss: 0.1873 - val_loss: 0.1987\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1868 - val_loss: 0.1982\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1863 - val_loss: 0.1977\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 112us/step - loss: 0.1858 - val_loss: 0.1972\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1854 - val_loss: 0.1967\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1849 - val_loss: 0.1962\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1844 - val_loss: 0.1957\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1839 - val_loss: 0.1952\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1834 - val_loss: 0.1947\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1829 - val_loss: 0.1942\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1824 - val_loss: 0.1937\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1820 - val_loss: 0.1932\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1815 - val_loss: 0.1928\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1810 - val_loss: 0.1923\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1805 - val_loss: 0.1918\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1800 - val_loss: 0.1913\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1796 - val_loss: 0.1908\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1791 - val_loss: 0.1903\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1786 - val_loss: 0.1899\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1782 - val_loss: 0.1894\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1777 - val_loss: 0.1889\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1772 - val_loss: 0.1885\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1768 - val_loss: 0.1880\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1763 - val_loss: 0.1875\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1759 - val_loss: 0.1871\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1754 - val_loss: 0.1866\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1750 - val_loss: 0.1862\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1745 - val_loss: 0.1857\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1741 - val_loss: 0.1852\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1736 - val_loss: 0.1848\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1732 - val_loss: 0.1843\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1727 - val_loss: 0.1839\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1723 - val_loss: 0.1834\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1719 - val_loss: 0.1830\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1714 - val_loss: 0.1826\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1710 - val_loss: 0.1821\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1706 - val_loss: 0.1817\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1701 - val_loss: 0.1812\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1697 - val_loss: 0.1808\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1693 - val_loss: 0.1804\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1688 - val_loss: 0.1799\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1684 - val_loss: 0.1795\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1680 - val_loss: 0.1791\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1676 - val_loss: 0.1786\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1671 - val_loss: 0.1782\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1667 - val_loss: 0.1778\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1663 - val_loss: 0.1774\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1659 - val_loss: 0.1769\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1655 - val_loss: 0.1765\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1651 - val_loss: 0.1761\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1647 - val_loss: 0.1757\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 168us/step - loss: 0.1643 - val_loss: 0.1753\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1639 - val_loss: 0.1749\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1635 - val_loss: 0.1745\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1631 - val_loss: 0.1741\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1627 - val_loss: 0.1737\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1623 - val_loss: 0.1733\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1619 - val_loss: 0.1728\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1615 - val_loss: 0.1724\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1611 - val_loss: 0.1720\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1607 - val_loss: 0.1716\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1603 - val_loss: 0.1712\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1599 - val_loss: 0.1708\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1595 - val_loss: 0.1704\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1591 - val_loss: 0.1700\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1587 - val_loss: 0.1696\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1583 - val_loss: 0.1692\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1579 - val_loss: 0.1688\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1575 - val_loss: 0.1685\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1571 - val_loss: 0.1681\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1568 - val_loss: 0.1677\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1564 - val_loss: 0.1673\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1560 - val_loss: 0.1669\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1556 - val_loss: 0.1665\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1553 - val_loss: 0.1662\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1549 - val_loss: 0.1658\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 85us/step - loss: 0.1545 - val_loss: 0.1654\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 101us/step - loss: 0.1541 - val_loss: 0.1650\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1538 - val_loss: 0.1646\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1534 - val_loss: 0.1642\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1530 - val_loss: 0.1639\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1527 - val_loss: 0.1635\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1523 - val_loss: 0.1631\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1519 - val_loss: 0.1628\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1516 - val_loss: 0.1624\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1512 - val_loss: 0.1620\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1508 - val_loss: 0.1617\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1505 - val_loss: 0.1613\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1501 - val_loss: 0.1610\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1498 - val_loss: 0.1606\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1494 - val_loss: 0.1602\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1491 - val_loss: 0.1599\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1487 - val_loss: 0.1595\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1484 - val_loss: 0.1592\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1480 - val_loss: 0.1588\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1477 - val_loss: 0.1585\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1473 - val_loss: 0.1581\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1470 - val_loss: 0.1578\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1466 - val_loss: 0.1574\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1463 - val_loss: 0.1571\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1460 - val_loss: 0.1567\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1456 - val_loss: 0.1564\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1453 - val_loss: 0.1560\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1449 - val_loss: 0.1557\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1446 - val_loss: 0.1553\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1443 - val_loss: 0.1550\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1439 - val_loss: 0.1547\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1436 - val_loss: 0.1543\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1433 - val_loss: 0.1540\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1430 - val_loss: 0.1537\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1426 - val_loss: 0.1533\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1423 - val_loss: 0.1530\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1420 - val_loss: 0.1527\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.1417 - val_loss: 0.1523\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1413 - val_loss: 0.1520\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1410 - val_loss: 0.1517\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1407 - val_loss: 0.1514\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1404 - val_loss: 0.1510\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1400 - val_loss: 0.1507\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1397 - val_loss: 0.1504\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1394 - val_loss: 0.1501\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1391 - val_loss: 0.1498\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1388 - val_loss: 0.1494\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1385 - val_loss: 0.1491\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.1382 - val_loss: 0.1488\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1379 - val_loss: 0.1485\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1376 - val_loss: 0.1482\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1373 - val_loss: 0.1479\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1370 - val_loss: 0.1476\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1367 - val_loss: 0.1473\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1363 - val_loss: 0.1470\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1360 - val_loss: 0.1467\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1357 - val_loss: 0.1463\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1354 - val_loss: 0.1460\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1351 - val_loss: 0.1457\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1348 - val_loss: 0.1454\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1346 - val_loss: 0.1451\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1343 - val_loss: 0.1448\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 219us/step - loss: 0.1340 - val_loss: 0.1445\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1337 - val_loss: 0.1442\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1334 - val_loss: 0.1439\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.1331 - val_loss: 0.1437\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 92us/step - loss: 0.1328 - val_loss: 0.1434\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1325 - val_loss: 0.1431\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1322 - val_loss: 0.1428\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1319 - val_loss: 0.1425\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1317 - val_loss: 0.1422\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1314 - val_loss: 0.1419\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1311 - val_loss: 0.1416\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1308 - val_loss: 0.1413\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 208us/step - loss: 0.1305 - val_loss: 0.1411\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 56us/step - loss: 0.1303 - val_loss: 0.1408\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1300 - val_loss: 0.1405\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1297 - val_loss: 0.1402\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1294 - val_loss: 0.1399\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1291 - val_loss: 0.1396\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1289 - val_loss: 0.1394\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1286 - val_loss: 0.1391\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1283 - val_loss: 0.1388\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1280 - val_loss: 0.1385\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1278 - val_loss: 0.1383\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1275 - val_loss: 0.1380\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1272 - val_loss: 0.1377\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1269 - val_loss: 0.1374\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1267 - val_loss: 0.1371\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.1264 - val_loss: 0.1369\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1261 - val_loss: 0.1366\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1259 - val_loss: 0.1363\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1256 - val_loss: 0.1361\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1254 - val_loss: 0.1358\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1251 - val_loss: 0.1355\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1248 - val_loss: 0.1353\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1246 - val_loss: 0.1350\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1243 - val_loss: 0.1348\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1241 - val_loss: 0.1345\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1238 - val_loss: 0.1342\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1236 - val_loss: 0.1340\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1233 - val_loss: 0.1337\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1231 - val_loss: 0.1335\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1228 - val_loss: 0.1332\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1225 - val_loss: 0.1329\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1223 - val_loss: 0.1327\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1220 - val_loss: 0.1324\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1218 - val_loss: 0.1322\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1215 - val_loss: 0.1319\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1213 - val_loss: 0.1317\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1210 - val_loss: 0.1314\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1208 - val_loss: 0.1312\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1205 - val_loss: 0.1309\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1203 - val_loss: 0.1307\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1200 - val_loss: 0.1304\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1198 - val_loss: 0.1302\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1196 - val_loss: 0.1299\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1193 - val_loss: 0.1297\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1191 - val_loss: 0.1294\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1188 - val_loss: 0.1292\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1186 - val_loss: 0.1290\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1184 - val_loss: 0.1287\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1181 - val_loss: 0.1285\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1179 - val_loss: 0.1282\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1177 - val_loss: 0.1280\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1174 - val_loss: 0.1278\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1172 - val_loss: 0.1275\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1170 - val_loss: 0.1273\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1167 - val_loss: 0.1271\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1165 - val_loss: 0.1268\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1163 - val_loss: 0.1266\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1161 - val_loss: 0.1264\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 62us/step - loss: 0.1158 - val_loss: 0.1261\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 86us/step - loss: 0.1156 - val_loss: 0.1259\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1154 - val_loss: 0.1257\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1151 - val_loss: 0.1254\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1149 - val_loss: 0.1252\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1147 - val_loss: 0.1250\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1145 - val_loss: 0.1248\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1143 - val_loss: 0.1245\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1140 - val_loss: 0.1243\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1138 - val_loss: 0.1241\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1136 - val_loss: 0.1239\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1134 - val_loss: 0.1237\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1132 - val_loss: 0.1234\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1130 - val_loss: 0.1232\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1127 - val_loss: 0.1230\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1125 - val_loss: 0.1228\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1123 - val_loss: 0.1225\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1121 - val_loss: 0.1223\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1119 - val_loss: 0.1221\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1117 - val_loss: 0.1219\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1114 - val_loss: 0.1217\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1112 - val_loss: 0.1215\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1110 - val_loss: 0.1212\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1108 - val_loss: 0.1210\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1106 - val_loss: 0.1208\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1104 - val_loss: 0.1206\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1102 - val_loss: 0.1204\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1100 - val_loss: 0.1202\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1098 - val_loss: 0.1200\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1096 - val_loss: 0.1198\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1094 - val_loss: 0.1196\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1091 - val_loss: 0.1194\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 191us/step - loss: 0.1089 - val_loss: 0.1192\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.1087 - val_loss: 0.1189\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1085 - val_loss: 0.1187\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1083 - val_loss: 0.1185\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1081 - val_loss: 0.1183\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1079 - val_loss: 0.1181\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1077 - val_loss: 0.1179\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1075 - val_loss: 0.1177\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1074 - val_loss: 0.1175\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1071 - val_loss: 0.1173\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1070 - val_loss: 0.1171\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1068 - val_loss: 0.1169\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1066 - val_loss: 0.1167\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1064 - val_loss: 0.1166\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1062 - val_loss: 0.1164\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1060 - val_loss: 0.1162\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1058 - val_loss: 0.1160\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1056 - val_loss: 0.1158\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1054 - val_loss: 0.1156\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1052 - val_loss: 0.1154\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1050 - val_loss: 0.1152\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1048 - val_loss: 0.1150\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1047 - val_loss: 0.1148\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1045 - val_loss: 0.1146\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1043 - val_loss: 0.1144\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1041 - val_loss: 0.1142\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1039 - val_loss: 0.1140\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1037 - val_loss: 0.1138\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1035 - val_loss: 0.1137\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1033 - val_loss: 0.1135\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1032 - val_loss: 0.1133\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1030 - val_loss: 0.1131\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1028 - val_loss: 0.1129\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1026 - val_loss: 0.1127\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1024 - val_loss: 0.1125\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1022 - val_loss: 0.1124\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1021 - val_loss: 0.1122\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1019 - val_loss: 0.1120\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.1017 - val_loss: 0.1118\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.1015 - val_loss: 0.1116\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 80us/step - loss: 0.1014 - val_loss: 0.1115\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1012 - val_loss: 0.1113\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1010 - val_loss: 0.1111\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.1008 - val_loss: 0.1109\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1007 - val_loss: 0.1108\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1005 - val_loss: 0.1106\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1003 - val_loss: 0.1104\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1002 - val_loss: 0.1102\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.1000 - val_loss: 0.1100\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0998 - val_loss: 0.1099\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0996 - val_loss: 0.1097\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0995 - val_loss: 0.1095\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0993 - val_loss: 0.1094\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0991 - val_loss: 0.1092\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0990 - val_loss: 0.1090\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0988 - val_loss: 0.1089\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0986 - val_loss: 0.1087\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0985 - val_loss: 0.1085\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0983 - val_loss: 0.1083\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0981 - val_loss: 0.1082\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0980 - val_loss: 0.1080\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.058 - 0s 109us/step - loss: 0.0978 - val_loss: 0.1078\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0976 - val_loss: 0.1077\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0975 - val_loss: 0.1075\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0973 - val_loss: 0.1074\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0972 - val_loss: 0.1072\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0970 - val_loss: 0.1070\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0969 - val_loss: 0.1069\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0967 - val_loss: 0.1067\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0965 - val_loss: 0.1066\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0964 - val_loss: 0.1064\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0962 - val_loss: 0.1062\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0961 - val_loss: 0.1061\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0959 - val_loss: 0.1059\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0958 - val_loss: 0.1058\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0956 - val_loss: 0.1056\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0955 - val_loss: 0.1055\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0953 - val_loss: 0.1053\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0951 - val_loss: 0.1052\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0950 - val_loss: 0.1050\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0948 - val_loss: 0.1048\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0947 - val_loss: 0.1047\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0945 - val_loss: 0.1045\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0944 - val_loss: 0.1044\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0942 - val_loss: 0.1042\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0941 - val_loss: 0.1041\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0939 - val_loss: 0.1039\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0938 - val_loss: 0.1038\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0936 - val_loss: 0.1036\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0935 - val_loss: 0.1035\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0933 - val_loss: 0.1033\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0932 - val_loss: 0.1032\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0930 - val_loss: 0.1030\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0929 - val_loss: 0.1029\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0927 - val_loss: 0.1027\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0926 - val_loss: 0.1026\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0925 - val_loss: 0.1024\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0923 - val_loss: 0.1023\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0922 - val_loss: 0.1021\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0920 - val_loss: 0.1020\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0919 - val_loss: 0.1019\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0918 - val_loss: 0.1017\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0916 - val_loss: 0.1016\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0915 - val_loss: 0.1014\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0913 - val_loss: 0.1013\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0912 - val_loss: 0.1011\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0911 - val_loss: 0.1010\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0909 - val_loss: 0.1009\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0908 - val_loss: 0.1007\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0907 - val_loss: 0.1006\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0905 - val_loss: 0.1004\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0904 - val_loss: 0.1003\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0902 - val_loss: 0.1002\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 125us/step - loss: 0.0901 - val_loss: 0.1000\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 83us/step - loss: 0.0900 - val_loss: 0.0999\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0898 - val_loss: 0.0998\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0897 - val_loss: 0.0996\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0896 - val_loss: 0.0995\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0894 - val_loss: 0.0993\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 202us/step - loss: 0.0893 - val_loss: 0.0992\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 63us/step - loss: 0.0892 - val_loss: 0.0991\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0890 - val_loss: 0.0989\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0889 - val_loss: 0.0988\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0888 - val_loss: 0.0987\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0886 - val_loss: 0.0985\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0885 - val_loss: 0.0984\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0884 - val_loss: 0.0983\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0882 - val_loss: 0.0981\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0881 - val_loss: 0.0980\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0880 - val_loss: 0.0979\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0879 - val_loss: 0.0978\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 163us/step - loss: 0.0877 - val_loss: 0.0976\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0876 - val_loss: 0.0975\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.080 - 0s 0us/step - loss: 0.0875 - val_loss: 0.0974\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0874 - val_loss: 0.0972\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0872 - val_loss: 0.0971\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0871 - val_loss: 0.0970\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0870 - val_loss: 0.0969\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0869 - val_loss: 0.0967\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0867 - val_loss: 0.0966\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0866 - val_loss: 0.0965\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0865 - val_loss: 0.0963\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0864 - val_loss: 0.0962\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0862 - val_loss: 0.0961\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0861 - val_loss: 0.0960\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0860 - val_loss: 0.0958\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0859 - val_loss: 0.0957\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0857 - val_loss: 0.0956\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0856 - val_loss: 0.0955\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0855 - val_loss: 0.0954\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0854 - val_loss: 0.0952\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0853 - val_loss: 0.0951\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0851 - val_loss: 0.0950\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0850 - val_loss: 0.0949\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0849 - val_loss: 0.0947\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0848 - val_loss: 0.0946\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0847 - val_loss: 0.0945\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0845 - val_loss: 0.0944\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0844 - val_loss: 0.0943\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0843 - val_loss: 0.0942\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0842 - val_loss: 0.0940\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0841 - val_loss: 0.0939\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0840 - val_loss: 0.0938\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0838 - val_loss: 0.0937\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0837 - val_loss: 0.0936\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0836 - val_loss: 0.0935\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0835 - val_loss: 0.0933\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0834 - val_loss: 0.0932\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0833 - val_loss: 0.0931\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0832 - val_loss: 0.0930\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0831 - val_loss: 0.0929\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0830 - val_loss: 0.0928\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0828 - val_loss: 0.0927\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0827 - val_loss: 0.0926\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0826 - val_loss: 0.0924\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0825 - val_loss: 0.0923\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0824 - val_loss: 0.0922\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0823 - val_loss: 0.0921\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0822 - val_loss: 0.0920\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0821 - val_loss: 0.0919\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0820 - val_loss: 0.0918\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0819 - val_loss: 0.0917\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0818 - val_loss: 0.0916\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0817 - val_loss: 0.0914\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0815 - val_loss: 0.0913\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0814 - val_loss: 0.0912\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0813 - val_loss: 0.0911\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0812 - val_loss: 0.0910\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0811 - val_loss: 0.0909\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0810 - val_loss: 0.0908\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 49us/step - loss: 0.0809 - val_loss: 0.0907\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 95us/step - loss: 0.0808 - val_loss: 0.0906\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0807 - val_loss: 0.0905\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0806 - val_loss: 0.0904\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0805 - val_loss: 0.0903\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0804 - val_loss: 0.0902\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0803 - val_loss: 0.0901\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0802 - val_loss: 0.0900\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0801 - val_loss: 0.0899\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0800 - val_loss: 0.0898\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0799 - val_loss: 0.0897\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0798 - val_loss: 0.0896\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0797 - val_loss: 0.0895\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0796 - val_loss: 0.0894\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0795 - val_loss: 0.0892\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0794 - val_loss: 0.0891\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0793 - val_loss: 0.0890\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0792 - val_loss: 0.0889\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0791 - val_loss: 0.0888\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0790 - val_loss: 0.0887\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0789 - val_loss: 0.0886\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0788 - val_loss: 0.0885\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0787 - val_loss: 0.0884\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0786 - val_loss: 0.0883\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0785 - val_loss: 0.0883\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0784 - val_loss: 0.0882\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0783 - val_loss: 0.0881\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0782 - val_loss: 0.0880\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0781 - val_loss: 0.0879\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0780 - val_loss: 0.0878\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0779 - val_loss: 0.0877\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0778 - val_loss: 0.0876\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0778 - val_loss: 0.0875\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0777 - val_loss: 0.0874\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0776 - val_loss: 0.0873\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0775 - val_loss: 0.0872\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0774 - val_loss: 0.0871\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0773 - val_loss: 0.0870\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0772 - val_loss: 0.0869\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0771 - val_loss: 0.0868\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0770 - val_loss: 0.0867\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0769 - val_loss: 0.0867\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0768 - val_loss: 0.0866\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0768 - val_loss: 0.0865\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0767 - val_loss: 0.0864\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0766 - val_loss: 0.0863\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0765 - val_loss: 0.0862\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0764 - val_loss: 0.0861\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0763 - val_loss: 0.0860\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0762 - val_loss: 0.0859\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0761 - val_loss: 0.0858\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0760 - val_loss: 0.0857\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0759 - val_loss: 0.0856\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0759 - val_loss: 0.0856\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0758 - val_loss: 0.0855\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0757 - val_loss: 0.0854\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0756 - val_loss: 0.0853\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0755 - val_loss: 0.0852\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0754 - val_loss: 0.0851\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0753 - val_loss: 0.0850\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0753 - val_loss: 0.0849\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0752 - val_loss: 0.0849\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0751 - val_loss: 0.0848\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0750 - val_loss: 0.0847\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0749 - val_loss: 0.0846\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0748 - val_loss: 0.0845\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0748 - val_loss: 0.0844\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0747 - val_loss: 0.0843\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0746 - val_loss: 0.0843\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0745 - val_loss: 0.0842\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0744 - val_loss: 0.0841\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0743 - val_loss: 0.0840\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0743 - val_loss: 0.0839\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0742 - val_loss: 0.0839\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0741 - val_loss: 0.0838\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 76us/step - loss: 0.0740 - val_loss: 0.0837\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0739 - val_loss: 0.0836\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0739 - val_loss: 0.0835\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0738 - val_loss: 0.0834\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0737 - val_loss: 0.0834\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0736 - val_loss: 0.0833\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0735 - val_loss: 0.0832\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0735 - val_loss: 0.0831\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0734 - val_loss: 0.0830\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0733 - val_loss: 0.0830\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0732 - val_loss: 0.0829\n",
      "0.08429797738790512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-2.61135995e-01,  1.43971264e-01,  2.96889991e-01,\n",
       "          3.98186326e-01, -4.12563205e-01],\n",
       "        [ 1.58642039e-01,  1.32152587e-01,  3.66374373e-01,\n",
       "          3.50283593e-01, -3.07209879e-01],\n",
       "        [ 3.59283030e-01,  1.79995671e-01, -6.67479187e-02,\n",
       "         -5.31876534e-02, -2.38777623e-02],\n",
       "        [-3.34320188e-01,  2.12319285e-01,  3.15750659e-01,\n",
       "         -2.26555735e-01, -4.47914004e-01],\n",
       "        [-1.38410509e-01, -3.82760257e-01, -1.56087071e-01,\n",
       "         -2.97018379e-01, -1.18955620e-01],\n",
       "        [-4.63127106e-01,  1.68042153e-01,  2.30370909e-01,\n",
       "         -1.27137169e-01, -3.57784539e-01],\n",
       "        [-1.81369245e-01, -3.96997690e-01,  4.38129485e-01,\n",
       "          4.78234366e-02, -3.60565186e-01],\n",
       "        [-4.39341038e-01, -2.10335538e-01, -5.30892536e-02,\n",
       "          6.25511110e-02, -1.49749845e-01],\n",
       "        [ 4.08220440e-01,  5.71146309e-02, -4.17859524e-01,\n",
       "          3.18556204e-02, -3.50507915e-01],\n",
       "        [-9.63277444e-02, -4.47599500e-01, -6.11512922e-02,\n",
       "         -3.52042526e-01,  1.94994599e-01],\n",
       "        [-4.93905842e-02, -2.45522559e-01,  2.74280280e-01,\n",
       "         -1.19964100e-01,  2.10134536e-02],\n",
       "        [-3.22094679e-01,  1.68421045e-01,  3.59549791e-01,\n",
       "         -4.07179475e-01, -2.47342840e-01],\n",
       "        [ 1.53731838e-01, -1.19247094e-01,  3.11106831e-01,\n",
       "          1.37986124e-01, -2.17273444e-01],\n",
       "        [-1.54234730e-02,  3.08903158e-01,  2.05543011e-01,\n",
       "          3.84007365e-01, -1.98608726e-01],\n",
       "        [ 2.12529585e-01, -2.97127306e-01, -3.99755031e-01,\n",
       "          8.93734023e-02,  2.20179856e-01],\n",
       "        [ 3.89477648e-02,  1.02705933e-01, -4.43072051e-01,\n",
       "          4.25299257e-01, -6.70175478e-02],\n",
       "        [ 1.42653331e-01, -4.88018356e-02, -2.20591441e-01,\n",
       "         -5.65936510e-03, -5.66263162e-02],\n",
       "        [-2.16306046e-01, -1.29886150e-01,  1.87944174e-01,\n",
       "         -4.49936002e-01, -8.25068355e-02],\n",
       "        [-3.83396417e-01, -4.59037840e-01, -2.91932613e-01,\n",
       "          2.09706545e-01,  3.39947551e-01],\n",
       "        [-3.91883641e-01, -3.17192167e-01, -2.29300067e-01,\n",
       "         -2.37725228e-01, -2.44117871e-01],\n",
       "        [ 7.22414209e-03, -4.00169611e-01,  4.63609219e-01,\n",
       "         -1.25403628e-01,  3.05440131e-04],\n",
       "        [ 1.47056982e-01,  1.33511558e-01, -2.43995637e-01,\n",
       "         -2.04460591e-01,  3.29303145e-01]], dtype=float32),\n",
       " array([-0.06438507,  0.0055465 ,  0.00233178, -0.01419306,  0.02538363],\n",
       "       dtype=float32),\n",
       " array([[ 0.5630468 ,  0.16525257,  0.07088209,  0.26705253,  0.42469838,\n",
       "          0.4190518 , -0.1708925 , -0.6350529 , -0.308145  ,  0.20140712],\n",
       "        [-0.21387172, -0.4273299 , -0.46860975,  0.54361486, -0.51811117,\n",
       "         -0.31061184,  0.6049919 , -0.20816562, -0.16515595,  0.06019074],\n",
       "        [ 0.21062389, -0.50110596,  0.14709602, -0.1659141 , -0.5111628 ,\n",
       "          0.1406031 , -0.34747922,  0.32876927,  0.03973621, -0.07276587],\n",
       "        [-0.49030277,  0.24558565,  0.47870573,  0.37196454,  0.24550739,\n",
       "          0.52697587, -0.44118455, -0.43947643,  0.40270016,  0.43037257],\n",
       "        [-0.43673018,  0.5357246 , -0.30898932, -0.03724435, -0.3949973 ,\n",
       "         -0.54596525, -0.59551644,  0.14549397,  0.3854483 , -0.15317425]],\n",
       "       dtype=float32),\n",
       " array([-0.01457256,  0.03330735,  0.00945017,  0.00971417, -0.02681975,\n",
       "        -0.04057517,  0.01568225,  0.05410749,  0.05132972, -0.00144493],\n",
       "       dtype=float32),\n",
       " array([[-0.17939469],\n",
       "        [ 0.4219259 ],\n",
       "        [ 0.14186095],\n",
       "        [ 0.11036994],\n",
       "        [-0.33054423],\n",
       "        [-0.50842434],\n",
       "        [ 0.21060191],\n",
       "        [ 0.71191174],\n",
       "        [ 0.6621617 ],\n",
       "        [-0.01852484]], dtype=float32),\n",
       " array([0.07720365], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, sgd, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 5)                 115       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 143 samples, validate on 31 samples\n",
      "Epoch 1/1000\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.0472\n",
      "Epoch 2/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0444 - val_loss: 0.0275\n",
      "Epoch 3/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0346 - val_loss: 0.0290\n",
      "Epoch 4/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0381 - val_loss: 0.0172\n",
      "Epoch 5/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0325 - val_loss: 0.0161\n",
      "Epoch 6/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0268 - val_loss: 0.0166\n",
      "Epoch 7/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0316 - val_loss: 0.0199\n",
      "Epoch 8/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0339 - val_loss: 0.0284\n",
      "Epoch 9/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0238 - val_loss: 0.0117\n",
      "Epoch 10/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0207 - val_loss: 0.0269\n",
      "Epoch 11/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0250 - val_loss: 0.0101\n",
      "Epoch 12/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 13/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0392 - val_loss: 0.0128\n",
      "Epoch 14/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0190 - val_loss: 0.0134\n",
      "Epoch 15/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 16/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0257 - val_loss: 0.0115\n",
      "Epoch 17/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0155 - val_loss: 0.0120\n",
      "Epoch 18/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0282 - val_loss: 0.0159\n",
      "Epoch 19/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0150 - val_loss: 0.0068\n",
      "Epoch 20/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 21/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0195 - val_loss: 0.0303\n",
      "Epoch 22/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0234 - val_loss: 0.0060\n",
      "Epoch 23/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0127 - val_loss: 0.0069\n",
      "Epoch 24/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0201 - val_loss: 0.0145\n",
      "Epoch 25/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0144 - val_loss: 0.0087\n",
      "Epoch 26/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0169 - val_loss: 0.0076\n",
      "Epoch 27/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 28/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0242 - val_loss: 0.0089\n",
      "Epoch 29/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 30/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 31/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0299 - val_loss: 0.0054\n",
      "Epoch 32/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 33/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0186 - val_loss: 0.0136\n",
      "Epoch 34/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0233 - val_loss: 0.0079\n",
      "Epoch 35/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0155 - val_loss: 0.0251\n",
      "Epoch 36/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0243 - val_loss: 0.0078\n",
      "Epoch 37/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 38/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0144 - val_loss: 0.0062\n",
      "Epoch 39/1000\n",
      "143/143 [==============================] - 0s 110us/step - loss: 0.0266 - val_loss: 0.0079\n",
      "Epoch 40/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 41/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0160 - val_loss: 0.0083\n",
      "Epoch 42/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0206 - val_loss: 0.0100\n",
      "Epoch 43/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0107 - val_loss: 0.0073\n",
      "Epoch 44/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0206 - val_loss: 0.0081\n",
      "Epoch 45/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 46/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 48/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0615\n",
      "Epoch 49/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0264 - val_loss: 0.0135\n",
      "Epoch 50/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 51/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0189 - val_loss: 0.0086\n",
      "Epoch 52/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 53/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0166\n",
      "Epoch 54/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0150 - val_loss: 0.0048\n",
      "Epoch 55/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 56/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0205 - val_loss: 0.0075\n",
      "Epoch 57/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 58/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 59/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 60/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0123 - val_loss: 0.0056\n",
      "Epoch 61/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0088 - val_loss: 0.0161\n",
      "Epoch 62/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0168 - val_loss: 0.0137\n",
      "Epoch 63/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0161 - val_loss: 0.0096\n",
      "Epoch 64/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 65/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0212 - val_loss: 0.0057\n",
      "Epoch 66/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0107 - val_loss: 0.0052\n",
      "Epoch 67/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0101 - val_loss: 0.0176\n",
      "Epoch 68/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0046\n",
      "Epoch 69/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 70/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0148 - val_loss: 0.0051\n",
      "Epoch 71/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0118 - val_loss: 0.0049\n",
      "Epoch 72/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 73/1000\n",
      "143/143 [==============================] - 0s 201us/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 74/1000\n",
      "143/143 [==============================] - 0s 16us/step - loss: 0.0116 - val_loss: 0.0157\n",
      "Epoch 75/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 76/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 77/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0121 - val_loss: 0.0063\n",
      "Epoch 78/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 79/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0186\n",
      "Epoch 80/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0150 - val_loss: 0.0053\n",
      "Epoch 81/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 82/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 83/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 84/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 85/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 86/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 87/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 88/1000\n",
      "143/143 [==============================] - 0s 183us/step - loss: 0.0107 - val_loss: 0.0198\n",
      "Epoch 89/1000\n",
      "143/143 [==============================] - 0s 94us/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 90/1000\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 91/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 92/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 93/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0139\n",
      "Epoch 94/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0187 - val_loss: 0.0052\n",
      "Epoch 95/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 96/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 97/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 98/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 99/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0070\n",
      "Epoch 100/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0140 - val_loss: 0.0049\n",
      "Epoch 101/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 102/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0110 - val_loss: 0.0049\n",
      "Epoch 103/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 104/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 105/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 106/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 107/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 108/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0126 - val_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0096\n",
      "Epoch 110/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0135 - val_loss: 0.0047\n",
      "Epoch 111/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0083 - val_loss: 0.0049\n",
      "Epoch 112/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 113/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 114/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 115/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 116/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 117/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 118/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 119/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 120/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 121/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 122/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 123/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 124/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0138 - val_loss: 0.0058\n",
      "Epoch 125/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 126/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 127/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 128/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 129/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 130/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 131/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 132/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 133/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 134/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 135/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 136/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0090 - val_loss: 0.0127\n",
      "Epoch 137/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 138/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 139/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 140/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0093 - val_loss: 0.0042\n",
      "Epoch 141/1000\n",
      "143/143 [==============================] - 0s 132us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 142/1000\n",
      "143/143 [==============================] - 0s 104us/step - loss: 0.0124 - val_loss: 0.0051\n",
      "Epoch 143/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 144/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 145/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 146/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0107 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 148/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 149/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 150/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 151/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 152/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 153/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0095 - val_loss: 0.0068\n",
      "Epoch 154/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0052\n",
      "Epoch 155/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 156/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 157/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 158/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 159/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 160/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 161/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 162/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 163/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 164/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 165/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 166/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 167/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0114 - val_loss: 0.0074\n",
      "Epoch 168/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 169/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 170/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 171/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 172/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 173/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 174/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 175/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 176/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0102 - val_loss: 0.0050\n",
      "Epoch 177/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 178/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 179/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 180/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0107 - val_loss: 0.0055\n",
      "Epoch 181/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 182/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 183/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 184/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0093\n",
      "Epoch 185/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 186/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 187/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0084 - val_loss: 0.0049\n",
      "Epoch 188/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 189/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0039\n",
      "Epoch 190/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 191/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 192/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 193/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 194/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 195/1000\n",
      "143/143 [==============================] - 0s 102us/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 196/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 197/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0111 - val_loss: 0.0045\n",
      "Epoch 198/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 199/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 200/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 201/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0056\n",
      "Epoch 202/1000\n",
      "143/143 [==============================] - 0s 168us/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 203/1000\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 204/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 205/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 206/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0035\n",
      "Epoch 207/1000\n",
      "143/143 [==============================] - 0s 180us/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 208/1000\n",
      "143/143 [==============================] - 0s 22us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 209/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 210/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0086 - val_loss: 0.0038\n",
      "Epoch 211/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 212/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 213/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 214/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0076 - val_loss: 0.0113\n",
      "Epoch 215/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0093 - val_loss: 0.0043\n",
      "Epoch 216/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 217/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 218/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0051\n",
      "Epoch 219/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 220/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 221/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 222/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 223/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 224/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 225/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 226/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 227/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 228/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 229/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 230/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 231/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 232/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 233/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 234/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 235/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 236/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 237/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 238/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 239/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 240/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 241/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 242/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 243/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 244/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 245/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 246/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 247/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 248/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 250/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 251/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 252/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 253/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 254/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 255/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 256/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 257/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 258/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 259/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 260/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 262/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 263/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 264/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 265/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 266/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 267/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 268/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 269/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 270/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0119\n",
      "Epoch 271/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0037\n",
      "Epoch 272/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 273/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 274/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 275/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 276/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 277/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 278/1000\n",
      "143/143 [==============================] - 0s 75us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 279/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 280/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 281/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 282/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 283/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 284/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 285/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 286/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 287/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 288/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 289/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 290/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 291/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 292/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 293/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 294/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 295/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 296/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 297/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 298/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 299/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0106\n",
      "Epoch 300/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 302/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 303/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 304/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0044 - val_loss: 0.0087\n",
      "Epoch 305/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 306/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 307/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 308/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 309/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 310/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 311/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 312/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 313/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 314/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 315/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 316/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 317/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 318/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 319/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 320/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 321/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 322/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 323/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 324/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 325/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 326/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 327/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 328/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 329/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 330/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 331/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0068\n",
      "Epoch 332/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 333/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 334/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 335/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 336/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 337/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 338/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 339/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 340/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 341/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0081\n",
      "Epoch 342/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 343/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 344/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 345/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 346/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 347/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 348/1000\n",
      "143/143 [==============================] - 0s 123us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 349/1000\n",
      "143/143 [==============================] - 0s 22us/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 350/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 351/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 352/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 353/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 354/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 355/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 356/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 357/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 358/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 359/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 360/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 361/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 362/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 363/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0056\n",
      "Epoch 364/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 365/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 366/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 367/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 368/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 369/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 370/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 371/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 372/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 373/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 374/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 375/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 376/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 377/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 378/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 379/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0074\n",
      "Epoch 380/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 381/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 382/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 383/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 384/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 385/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 386/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 387/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 388/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 389/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 390/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 391/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 392/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 393/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 394/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 395/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0076\n",
      "Epoch 396/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 397/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 398/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 399/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 400/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 401/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 402/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 403/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 404/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 405/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 406/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 407/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 408/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 409/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 410/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 411/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 412/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 413/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 414/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 415/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0089\n",
      "Epoch 416/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 417/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 418/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 419/1000\n",
      "143/143 [==============================] - 0s 38us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 420/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0106\n",
      "Epoch 421/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 422/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0079\n",
      "Epoch 423/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 424/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 425/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 426/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 427/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 428/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 429/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.005 - 0s 109us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 430/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0081\n",
      "Epoch 431/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 432/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 433/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 434/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 435/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 436/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 437/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 438/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 439/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 440/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 441/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 442/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 443/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 444/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 445/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 446/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 447/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 448/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 449/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 450/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0105\n",
      "Epoch 451/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 452/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 453/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 454/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 456/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 457/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 458/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 459/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 460/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 461/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 462/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 463/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 464/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 465/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 466/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0075\n",
      "Epoch 467/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 468/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 469/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 470/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 471/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 472/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 473/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 474/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 475/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 476/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 477/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 478/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 479/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 480/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 481/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0094\n",
      "Epoch 482/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 483/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 484/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 485/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 486/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 487/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 488/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 489/1000\n",
      "143/143 [==============================] - 0s 176us/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 490/1000\n",
      "143/143 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 491/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 492/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 493/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 494/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 495/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 496/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 497/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 498/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 499/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 500/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 501/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 502/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 503/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 504/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 505/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 506/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 507/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 508/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 509/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 510/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 511/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 512/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 513/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 514/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0097\n",
      "Epoch 515/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 516/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 517/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 518/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 519/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 520/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 521/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 522/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 523/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 524/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 525/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 526/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 527/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 528/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0080\n",
      "Epoch 529/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 530/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 531/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 532/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 533/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 534/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 535/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 536/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 537/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 538/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 539/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 540/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 541/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 542/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 543/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 544/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 545/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 546/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 547/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 548/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 549/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 550/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 551/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 552/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 553/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 554/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0076\n",
      "Epoch 555/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 556/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Epoch 557/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 558/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 559/1000\n",
      "143/143 [==============================] - 0s 190us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 560/1000\n",
      "143/143 [==============================] - 0s 12us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 561/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 562/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 563/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0070\n",
      "Epoch 564/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 565/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 566/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 567/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 568/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 569/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 570/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 571/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0058\n",
      "Epoch 572/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 573/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 574/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 575/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 576/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 577/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 578/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 579/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 580/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 581/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 582/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 583/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 584/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 585/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 586/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 587/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 588/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 589/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 590/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0092\n",
      "Epoch 591/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 592/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0070\n",
      "Epoch 593/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 594/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 595/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 596/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 597/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 598/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 599/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 600/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 601/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 602/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 603/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 0.0066\n",
      "Epoch 604/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 605/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 606/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 607/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 608/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 610/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0078\n",
      "Epoch 611/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 612/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 613/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0090\n",
      "Epoch 614/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 615/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 616/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 617/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 618/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0084\n",
      "Epoch 619/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 620/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 621/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 622/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0073\n",
      "Epoch 623/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0085\n",
      "Epoch 624/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 625/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 626/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 627/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 628/1000\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 629/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0081\n",
      "Epoch 630/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 631/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 632/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 633/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0059\n",
      "Epoch 634/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 635/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 636/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 637/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 638/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 639/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 640/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 641/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 642/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0060\n",
      "Epoch 643/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 644/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 645/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 646/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 647/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 648/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 649/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 650/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 651/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0075\n",
      "Epoch 652/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 653/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 654/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 655/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0083\n",
      "Epoch 656/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 657/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 658/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 659/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 660/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 661/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 662/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 663/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 664/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0057\n",
      "Epoch 665/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 666/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 667/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 668/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 669/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 670/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 671/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 672/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 673/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0066\n",
      "Epoch 674/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 675/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 676/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 677/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 678/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 679/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0081\n",
      "Epoch 680/1000\n",
      "143/143 [==============================] - 0s 218us/step - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 681/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 682/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Epoch 683/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 684/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0077\n",
      "Epoch 685/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 686/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 687/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 688/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 689/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 690/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 691/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 692/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 693/1000\n",
      "143/143 [==============================] - 0s 122us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 694/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 695/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 696/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 697/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 698/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 699/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 700/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 701/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 702/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 703/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 704/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 705/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 706/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 707/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 708/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 709/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 710/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 711/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 712/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 713/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 714/1000\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.008 - 0s 0us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 715/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 716/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 717/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 718/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 719/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 720/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 721/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 722/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 723/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0069\n",
      "Epoch 724/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 725/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0078\n",
      "Epoch 726/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 727/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 728/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 729/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 730/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 731/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 732/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 733/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 734/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 735/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 736/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 737/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 738/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 739/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 740/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 741/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 742/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 743/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 744/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 745/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 746/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 747/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 748/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0062\n",
      "Epoch 749/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 750/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 751/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 752/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 753/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0067\n",
      "Epoch 754/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 755/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 756/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 757/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 758/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 759/1000\n",
      "143/143 [==============================] - 0s 111us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 760/1000\n",
      "143/143 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 761/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 762/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 764/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 765/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 766/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 767/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 768/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 769/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 770/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 771/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 772/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 773/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 774/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 775/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 776/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 777/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 778/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 779/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 780/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 781/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 782/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 783/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 784/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 785/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0065\n",
      "Epoch 786/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0088\n",
      "Epoch 787/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 788/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0066\n",
      "Epoch 789/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 790/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 791/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 792/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 793/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0038 - val_loss: 0.0094\n",
      "Epoch 794/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 795/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 796/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 797/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 798/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0082\n",
      "Epoch 799/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 800/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 801/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 802/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 803/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 804/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 805/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 806/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 807/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 808/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 809/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 810/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 811/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 812/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 813/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 814/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 815/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 816/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 817/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 818/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 819/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 820/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 821/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 822/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 823/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 824/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 825/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 826/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 827/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 828/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 829/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 830/1000\n",
      "143/143 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 831/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 832/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 833/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 834/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 835/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 836/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 837/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 838/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0067\n",
      "Epoch 839/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 840/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 841/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 842/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 843/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 844/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 845/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 846/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 847/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 848/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 849/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 850/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0054\n",
      "Epoch 851/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 852/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 853/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 854/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 855/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 856/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 857/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 858/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 859/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 860/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 861/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 862/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 863/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 864/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 865/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 866/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 867/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 868/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 869/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 870/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 871/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 872/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 873/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 874/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0071\n",
      "Epoch 875/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 876/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 877/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 878/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 879/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 880/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 881/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 882/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0091\n",
      "Epoch 883/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 884/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 885/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 886/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 887/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 888/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 889/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 890/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 891/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 892/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 893/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 894/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 895/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 896/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 897/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 898/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 899/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 900/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 901/1000\n",
      "143/143 [==============================] - 0s 185us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 902/1000\n",
      "143/143 [==============================] - 0s 19us/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 903/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 904/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 905/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 906/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 907/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 908/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 909/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 910/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 911/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 912/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 914/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0081\n",
      "Epoch 915/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 916/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 917/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 918/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 919/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 920/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 921/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 922/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 923/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 924/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 925/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 926/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 927/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 928/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 929/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 930/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 931/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 932/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 933/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 934/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 935/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 936/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 937/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 938/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 939/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 940/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 941/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 942/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 943/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 944/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 945/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 946/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 947/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 948/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 949/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 950/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 951/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 952/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 953/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 954/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 955/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 956/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 957/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 958/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 959/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 960/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 961/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 962/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 963/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 964/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 965/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 966/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 967/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 968/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 969/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 970/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 971/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0076\n",
      "Epoch 972/1000\n",
      "143/143 [==============================] - 0s 89us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 973/1000\n",
      "143/143 [==============================] - 0s 97us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 974/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 975/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 976/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 977/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 978/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 979/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 980/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 981/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 982/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 983/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 984/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 985/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 986/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0075\n",
      "Epoch 987/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 988/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 989/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 990/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 991/1000\n",
      "143/143 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 992/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 993/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 994/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 995/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 996/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0023 - val_loss: 0.0069\n",
      "Epoch 997/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 998/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 999/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 1000/1000\n",
      "143/143 [==============================] - 0s 109us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "0.00970353651791811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.11332440e+00,  7.49457836e-01,  1.84156954e-01,\n",
       "          5.71338177e-01,  1.41287923e+00],\n",
       "        [ 1.54389286e+00, -3.43615770e-01,  2.35196188e-01,\n",
       "          3.99971455e-01,  6.83304906e-01],\n",
       "        [ 1.36241496e+00, -3.80690098e-01, -9.54309944e-05,\n",
       "         -3.98674905e-01,  2.09895223e-01],\n",
       "        [ 1.57396924e+00,  2.55836964e-01,  6.60162121e-02,\n",
       "          4.92314696e-01,  5.97380972e+00],\n",
       "        [ 6.59281492e-01, -2.26774111e-01,  2.48968929e-01,\n",
       "         -4.63987917e-01,  1.63887095e+00],\n",
       "        [-1.40971923e+00, -1.99838787e-01,  3.30479026e-01,\n",
       "         -1.09866428e+00,  2.04394147e-01],\n",
       "        [ 2.16032580e-01,  3.27382952e-01,  8.79763663e-02,\n",
       "          3.98458131e-02,  5.73907316e-01],\n",
       "        [-1.82221178e-02,  3.34991604e-01,  1.43153623e-01,\n",
       "         -1.50669083e-01,  2.55337656e-02],\n",
       "        [-4.49178278e-01, -1.15429389e+00, -5.40514942e-04,\n",
       "         -9.50398803e-01,  1.24408293e+00],\n",
       "        [ 1.67693142e-02,  4.34514314e-01, -1.77944183e-01,\n",
       "          1.38053238e+00,  5.47130764e-01],\n",
       "        [ 4.07198787e-01, -7.43260980e-01, -3.53351712e-01,\n",
       "         -1.70634016e-01, -1.12078989e+00],\n",
       "        [-5.09248674e-01,  8.14259350e-01,  2.34438375e-01,\n",
       "          1.41223454e+00, -1.72840929e+00],\n",
       "        [-5.05014539e-01,  4.74889904e-01, -3.03116083e-01,\n",
       "          1.36039925e+00, -1.58315122e+00],\n",
       "        [-2.82281804e+00, -1.85098636e+00,  1.19897828e-01,\n",
       "          1.49108577e+00, -2.18281731e-01],\n",
       "        [ 4.52017635e-01, -5.83086371e-01,  6.18410818e-02,\n",
       "         -7.24792063e-01, -4.89277899e-01],\n",
       "        [ 2.11943537e-01, -5.63178919e-02, -3.16465855e-01,\n",
       "          1.03024185e+00,  5.54432906e-03],\n",
       "        [ 2.95095325e-01,  1.28739285e+00, -4.57370102e-01,\n",
       "          2.98867598e-02,  1.45766854e+00],\n",
       "        [-8.17582011e-01, -9.95212257e-01,  1.40698016e-01,\n",
       "          1.54388666e+00, -1.67582178e+00],\n",
       "        [-1.10170648e-01, -1.61912417e+00, -9.37494636e-02,\n",
       "         -6.18212044e-01, -2.16755629e-01],\n",
       "        [ 3.01766306e-01, -6.97646081e-01,  9.22593847e-02,\n",
       "          1.20405089e-02, -3.94181907e-01],\n",
       "        [ 2.63367367e+00,  1.66332138e+00, -1.33623779e-01,\n",
       "          3.28653336e-01,  1.25863767e+00],\n",
       "        [ 1.29105461e+00, -4.59706075e-02,  1.16252154e-01,\n",
       "          1.75088048e-01,  2.06939459e+00]], dtype=float32),\n",
       " array([ 0.8139257 ,  0.2824968 , -0.08493264, -0.16597492, -0.23398884],\n",
       "       dtype=float32),\n",
       " array([[ 1.0510954e-01,  3.7572805e-02, -1.7897712e-02,  1.7811422e-01,\n",
       "         -1.3585517e-02,  1.1070803e+00,  4.5971707e-02,  1.5179075e-02,\n",
       "         -4.1615134e-03, -1.6139857e-02],\n",
       "        [ 5.2174954e-03, -8.5338699e-03, -8.8272756e-04,  1.4660881e-02,\n",
       "         -3.5271996e-03,  6.4403892e-01, -3.7089411e-02, -3.3241969e-02,\n",
       "         -1.8039893e-02,  9.9357106e-03],\n",
       "        [ 1.2720949e-02,  2.8234635e-02, -1.2484440e-02, -5.3840848e-03,\n",
       "         -1.2708236e-02,  1.4576826e-02,  9.9265397e-02,  3.7757501e-02,\n",
       "          5.7926513e-02,  8.9696705e-02],\n",
       "        [ 1.6210960e-02,  5.0253015e-02, -8.2334066e-03, -1.3482259e-01,\n",
       "         -1.7534437e-03, -5.7423985e-01,  3.2702383e-02,  2.5853960e-02,\n",
       "          3.1818666e-02, -9.5788098e-05],\n",
       "        [-1.4145109e-01, -9.2812292e-03, -3.3080839e-02, -2.7900440e-01,\n",
       "          1.1128453e-03, -6.1701429e-01,  4.7774520e-03,  4.5308825e-02,\n",
       "          5.3422492e-02, -8.8610798e-03]], dtype=float32),\n",
       " array([ 0.01770688, -0.04416022,  0.06582851,  0.19465001,  0.02471095,\n",
       "        -0.03388675, -0.0633929 , -0.05856603, -0.06669264,  0.01517319],\n",
       "       dtype=float32),\n",
       " array([[ 0.00665615],\n",
       "        [ 0.00066118],\n",
       "        [-0.00177753],\n",
       "        [ 0.01180893],\n",
       "        [-0.00056294],\n",
       "        [-0.28666815],\n",
       "        [ 0.00158498],\n",
       "        [ 0.00240502],\n",
       "        [-0.00169423],\n",
       "        [-0.00455871]], dtype=float32),\n",
       " array([0.222192], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_automobile, history_automobile, evaluate_automobile=NN_model_structure_regression(X_train_automobile, X_val_automobile, Y_train_automobile, Y_val_automobile, RMSprop, 32, 1000, x_test_automobile, y_test_automobile)\n",
    "model_automobile.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_automobile.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_automobile_rmsprop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 36.4845 - val_loss: 33.1960\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 549us/step - loss: 33.9021 - val_loss: 30.5285\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 58us/step - loss: 30.5088 - val_loss: 26.1012\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 25.8793 - val_loss: 19.8745\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 19.9231 - val_loss: 12.2949\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 12.9782 - val_loss: 5.2368\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.2301 - val_loss: 1.7061\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.6742 - val_loss: 2.9824\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.3706 - val_loss: 5.6883\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4720 - val_loss: 5.6524\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3688 - val_loss: 3.9003\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.6015 - val_loss: 2.3995\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7809 - val_loss: 1.7161\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2326 - val_loss: 1.5643\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.3786 - val_loss: 1.5831\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.1114 - val_loss: 1.5682\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.1499 - val_loss: 1.4564\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.2554 - val_loss: 1.2627\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.3020 - val_loss: 1.0384\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.2617 - val_loss: 0.8460\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.1609 - val_loss: 0.7408\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.0410 - val_loss: 0.7533\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.9327 - val_loss: 0.8743\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.8485 - val_loss: 1.0507\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.7844 - val_loss: 1.1970\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.7232 - val_loss: 1.2280\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.6433 - val_loss: 1.0994\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.5307 - val_loss: 0.8334\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.3910 - val_loss: 0.5116\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.2506 - val_loss: 0.2365\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1453 - val_loss: 0.0852\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.1020 - val_loss: 0.0788\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1243 - val_loss: 0.1805\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1909 - val_loss: 0.3197\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.2659 - val_loss: 0.4267\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.3157 - val_loss: 0.4600\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.3225 - val_loss: 0.4153\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.2874 - val_loss: 0.3168\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.2249 - val_loss: 0.2008\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1547 - val_loss: 0.1009\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0940 - val_loss: 0.0375\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0536 - val_loss: 0.0158\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0367 - val_loss: 0.0278\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0403 - val_loss: 0.0583\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0568 - val_loss: 0.0910\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0768 - val_loss: 0.1134\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0924 - val_loss: 0.1197\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0989 - val_loss: 0.1108\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0957 - val_loss: 0.0919\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0857 - val_loss: 0.0697\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0728 - val_loss: 0.0501\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0605 - val_loss: 0.0365\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0506 - val_loss: 0.0298\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0434 - val_loss: 0.0286\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0381 - val_loss: 0.0306\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0339 - val_loss: 0.0335\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0305 - val_loss: 0.0353\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0278 - val_loss: 0.0352\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0262 - val_loss: 0.0331\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0257 - val_loss: 0.0296\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0262 - val_loss: 0.0254\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0273 - val_loss: 0.0214\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0283 - val_loss: 0.0179\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0260 - val_loss: 0.0101\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0231 - val_loss: 0.0080\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0198 - val_loss: 0.0063\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0167 - val_loss: 0.0051\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0143 - val_loss: 0.0048\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0131 - val_loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0129 - val_loss: 0.0060\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0136 - val_loss: 0.0070\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0146 - val_loss: 0.0077\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0154 - val_loss: 0.0078\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0158 - val_loss: 0.0075\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0155 - val_loss: 0.0068\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0148 - val_loss: 0.0060\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0138 - val_loss: 0.0052\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0128 - val_loss: 0.0046\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0119 - val_loss: 0.0041\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0113 - val_loss: 0.0038\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0106 - val_loss: 0.0033\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0105 - val_loss: 0.0032\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0104 - val_loss: 0.0031\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0103 - val_loss: 0.0031\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0102 - val_loss: 0.0032\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0100 - val_loss: 0.0033\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0099 - val_loss: 0.0035\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0097 - val_loss: 0.0037\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0095 - val_loss: 0.0038\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0093 - val_loss: 0.0038\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0091 - val_loss: 0.0037\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0035\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0086 - val_loss: 0.0033\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0079 - val_loss: 0.0030\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0076 - val_loss: 0.0029\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0075 - val_loss: 0.0029\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0072 - val_loss: 0.0026\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0070 - val_loss: 0.0025\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0064 - val_loss: 0.0023\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 74us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0034 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0033 - val_loss: 9.9795e-04\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0032 - val_loss: 9.8053e-04\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0032 - val_loss: 9.6233e-04\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0031 - val_loss: 9.4376e-04\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0031 - val_loss: 9.2524e-04\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 9.0708e-04\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0030 - val_loss: 8.8956e-04\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0030 - val_loss: 8.7283e-04\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0029 - val_loss: 8.5692e-04\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0029 - val_loss: 8.4176e-04\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 8.2726e-04\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 8.1327e-04\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0028 - val_loss: 7.9963e-04\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0027 - val_loss: 7.8625e-04\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 7.7306e-04\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0027 - val_loss: 7.6012e-04\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0026 - val_loss: 7.4748e-04\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 7.3525e-04\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0026 - val_loss: 7.2353e-04\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0025 - val_loss: 7.1234e-04\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 7.0170e-04\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0025 - val_loss: 6.9157e-04\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0024 - val_loss: 6.8184e-04\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 6.7235e-04\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0024 - val_loss: 6.6302e-04\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 6.5370e-04\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 6.4433e-04\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 6.3489e-04\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0023 - val_loss: 6.2539e-04\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0022 - val_loss: 6.1588e-04\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0022 - val_loss: 6.0638e-04\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0022 - val_loss: 5.9697e-04\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0022 - val_loss: 5.8768e-04\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 5.7857e-04\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 5.6961e-04\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0021 - val_loss: 5.6085e-04\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0021 - val_loss: 5.5227e-04\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0020 - val_loss: 5.4383e-04\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 553us/step - loss: 0.0020 - val_loss: 5.3557e-04\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0020 - val_loss: 5.2748e-04\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 152us/step - loss: 0.0020 - val_loss: 5.1958e-04\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 5.1189e-04\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 5.0443e-04\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 113us/step - loss: 0.0019 - val_loss: 4.9723e-04\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0019 - val_loss: 4.9027e-04\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 63us/step - loss: 0.0019 - val_loss: 4.8355e-04\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0019 - val_loss: 4.7706e-04\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 4.7075e-04\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0018 - val_loss: 4.6459e-04\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 4.5854e-04\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0018 - val_loss: 4.5257e-04\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0018 - val_loss: 4.4665e-04\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 4.4073e-04\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 4.3484e-04\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0017 - val_loss: 4.2896e-04\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 4.2312e-04\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 4.1732e-04\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0017 - val_loss: 4.1158e-04\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0017 - val_loss: 4.0594e-04\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 4.0040e-04\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 3.9496e-04\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0016 - val_loss: 3.8962e-04\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 3.8442e-04\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 3.7932e-04\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0016 - val_loss: 3.7433e-04\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0016 - val_loss: 3.6945e-04\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.6468e-04\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0015 - val_loss: 3.6000e-04\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.5544e-04\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.5096e-04\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0015 - val_loss: 3.4659e-04\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.4230e-04\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.3811e-04\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0015 - val_loss: 3.3399e-04\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.2995e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.2598e-04\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.2207e-04\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0014 - val_loss: 3.1820e-04\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.1438e-04\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.1062e-04\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0014 - val_loss: 3.0690e-04\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 3.0325e-04\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0014 - val_loss: 2.9965e-04\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0014 - val_loss: 2.9610e-04\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.9262e-04\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.8921e-04\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0013 - val_loss: 2.8585e-04\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.8256e-04\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.7935e-04\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0013 - val_loss: 2.7618e-04\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.7307e-04\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.7003e-04\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0013 - val_loss: 2.6703e-04\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.6410e-04\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0013 - val_loss: 2.6122e-04\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0013 - val_loss: 2.5841e-04\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.5564e-04\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.5293e-04\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0012 - val_loss: 2.5028e-04\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.4767e-04\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.4511e-04\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.4261e-04\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.4014e-04\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.3772e-04\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.3533e-04\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0012 - val_loss: 2.3300e-04\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.3069e-04\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.2843e-04\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0012 - val_loss: 2.2621e-04\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.2403e-04\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0012 - val_loss: 2.2189e-04\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0011 - val_loss: 2.1978e-04\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.1771e-04\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.1569e-04\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.1371e-04\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.1176e-04\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.0986e-04\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.0799e-04\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0011 - val_loss: 2.0616e-04\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.0437e-04\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 2.0261e-04\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0011 - val_loss: 2.0088e-04\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.9919e-04\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.9753e-04\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0011 - val_loss: 1.9592e-04\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.9432e-04\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.9277e-04\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0011 - val_loss: 1.9123e-04\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.8973e-04\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0011 - val_loss: 1.8826e-04\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.8682e-04\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0010 - val_loss: 1.8539e-04\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.8400e-04\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.8264e-04\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0010 - val_loss: 1.8130e-04\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.7998e-04\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.7869e-04\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0010 - val_loss: 1.7743e-04\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.7619e-04\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0010 - val_loss: 1.7498e-04\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0010 - val_loss: 1.7379e-04\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.9722e-04 - val_loss: 1.7263e-04\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.9313e-04 - val_loss: 1.7149e-04\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.8907e-04 - val_loss: 1.7037e-04\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.8507e-04 - val_loss: 1.6927e-04\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.8109e-04 - val_loss: 1.6820e-04\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.7716e-04 - val_loss: 1.6715e-04\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.7326e-04 - val_loss: 1.6612e-04\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.6941e-04 - val_loss: 1.6511e-04\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.6559e-04 - val_loss: 1.6411e-04\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.6182e-04 - val_loss: 1.6314e-04\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.5806e-04 - val_loss: 1.6218e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.5435e-04 - val_loss: 1.6125e-04\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.5068e-04 - val_loss: 1.6033e-04\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.4704e-04 - val_loss: 1.5943e-04\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.4344e-04 - val_loss: 1.5855e-04\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.3987e-04 - val_loss: 1.5769e-04\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.3633e-04 - val_loss: 1.5684e-04\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.3281e-04 - val_loss: 1.5601e-04\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.2934e-04 - val_loss: 1.5519e-04\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.2589e-04 - val_loss: 1.5439e-04\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.2247e-04 - val_loss: 1.5361e-04\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.1909e-04 - val_loss: 1.5283e-04\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.1573e-04 - val_loss: 1.5207e-04\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.1240e-04 - val_loss: 1.5134e-04\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.0909e-04 - val_loss: 1.5061e-04\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 9.0582e-04 - val_loss: 1.4989e-04\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.0257e-04 - val_loss: 1.4920e-04\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.9935e-04 - val_loss: 1.4851e-04\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 8.9614e-04 - val_loss: 1.4784e-04\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.9298e-04 - val_loss: 1.4718e-04\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.8983e-04 - val_loss: 1.4653e-04\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 8.8670e-04 - val_loss: 1.4589e-04\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.8361e-04 - val_loss: 1.4527e-04\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.8053e-04 - val_loss: 1.4465e-04\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.7747e-04 - val_loss: 1.4405e-04\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.7445e-04 - val_loss: 1.4346e-04\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.7144e-04 - val_loss: 1.4289e-04\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.6845e-04 - val_loss: 1.4231e-04\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 8.6549e-04 - val_loss: 1.4175e-04\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.6255e-04 - val_loss: 1.4120e-04\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.5962e-04 - val_loss: 1.4066e-04\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 8.5672e-04 - val_loss: 1.4013e-04\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.5385e-04 - val_loss: 1.3961e-04\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.5099e-04 - val_loss: 1.3910e-04\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 8.4815e-04 - val_loss: 1.3860e-04\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.4533e-04 - val_loss: 1.3810e-04\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.4252e-04 - val_loss: 1.3761e-04\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 8.3974e-04 - val_loss: 1.3714e-04\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.3697e-04 - val_loss: 1.3666e-04\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.3422e-04 - val_loss: 1.3621e-04\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.3150e-04 - val_loss: 1.3575e-04\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.2878e-04 - val_loss: 1.3531e-04\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.2610e-04 - val_loss: 1.3486e-04\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.2342e-04 - val_loss: 1.3444e-04\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 90us/step - loss: 8.2076e-04 - val_loss: 1.3401e-04\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 194us/step - loss: 8.1811e-04 - val_loss: 1.3358e-04\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 61us/step - loss: 8.1549e-04 - val_loss: 1.3317e-04\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.1287e-04 - val_loss: 1.3277e-04\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.1028e-04 - val_loss: 1.3236e-04\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 8.0770e-04 - val_loss: 1.3197e-04\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.0514e-04 - val_loss: 1.3158e-04\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.0259e-04 - val_loss: 1.3121e-04\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.0006e-04 - val_loss: 1.3082e-04\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.9754e-04 - val_loss: 1.3046e-04\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.9504e-04 - val_loss: 1.3010e-04\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.9255e-04 - val_loss: 1.2974e-04\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 7.9007e-04 - val_loss: 1.2938e-04\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.8761e-04 - val_loss: 1.2903e-04\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.8516e-04 - val_loss: 1.2869e-04\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.8273e-04 - val_loss: 1.2835e-04\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.8032e-04 - val_loss: 1.2802e-04\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.7791e-04 - val_loss: 1.2768e-04\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.7551e-04 - val_loss: 1.2735e-04\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.7315e-04 - val_loss: 1.2703e-04\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.7077e-04 - val_loss: 1.2672e-04\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.6842e-04 - val_loss: 1.2640e-04\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 7.6608e-04 - val_loss: 1.2609e-04\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.6374e-04 - val_loss: 1.2578e-04\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.6143e-04 - val_loss: 1.2548e-04\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 7.5913e-04 - val_loss: 1.2518e-04\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.5684e-04 - val_loss: 1.2488e-04\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.5456e-04 - val_loss: 1.2460e-04\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.5228e-04 - val_loss: 1.2430e-04\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.5003e-04 - val_loss: 1.2402e-04\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.4779e-04 - val_loss: 1.2374e-04\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.4555e-04 - val_loss: 1.2346e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.4333e-04 - val_loss: 1.2317e-04\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.4112e-04 - val_loss: 1.2290e-04\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.3892e-04 - val_loss: 1.2263e-04\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.3673e-04 - val_loss: 1.2237e-04\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.3455e-04 - val_loss: 1.2211e-04\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.3239e-04 - val_loss: 1.2184e-04\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 7.3022e-04 - val_loss: 1.2159e-04\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.2808e-04 - val_loss: 1.2133e-04\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.2595e-04 - val_loss: 1.2107e-04\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 7.2381e-04 - val_loss: 1.2081e-04\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.2170e-04 - val_loss: 1.2056e-04\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.1960e-04 - val_loss: 1.2031e-04\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.1750e-04 - val_loss: 1.2007e-04\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.1541e-04 - val_loss: 1.1983e-04\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.1333e-04 - val_loss: 1.1958e-04\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 7.1127e-04 - val_loss: 1.1934e-04\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.0920e-04 - val_loss: 1.1911e-04\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.0717e-04 - val_loss: 1.1888e-04\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.0512e-04 - val_loss: 1.1864e-04\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.0310e-04 - val_loss: 1.1840e-04\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 7.0108e-04 - val_loss: 1.1817e-04\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.9906e-04 - val_loss: 1.1795e-04\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.9706e-04 - val_loss: 1.1772e-04\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.9507e-04 - val_loss: 1.1749e-04\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.9308e-04 - val_loss: 1.1727e-04\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 6.9110e-04 - val_loss: 1.1705e-04\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.8914e-04 - val_loss: 1.1683e-04\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.8719e-04 - val_loss: 1.1660e-04\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 6.8523e-04 - val_loss: 1.1638e-04\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.8330e-04 - val_loss: 1.1616e-04\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.8135e-04 - val_loss: 1.1595e-04\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.7944e-04 - val_loss: 1.1573e-04\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.7752e-04 - val_loss: 1.1551e-04\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.7561e-04 - val_loss: 1.1530e-04\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.7372e-04 - val_loss: 1.1509e-04\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.7182e-04 - val_loss: 1.1488e-04\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.6994e-04 - val_loss: 1.1467e-04\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.6807e-04 - val_loss: 1.1447e-04\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 6.6619e-04 - val_loss: 1.1426e-04\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.6434e-04 - val_loss: 1.1406e-04\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.6249e-04 - val_loss: 1.1385e-04\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 6.6064e-04 - val_loss: 1.1365e-04\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.5881e-04 - val_loss: 1.1344e-04\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.5697e-04 - val_loss: 1.1324e-04\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.5515e-04 - val_loss: 1.1303e-04\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.5334e-04 - val_loss: 1.1283e-04\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.5154e-04 - val_loss: 1.1263e-04\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.4974e-04 - val_loss: 1.1244e-04\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.4795e-04 - val_loss: 1.1223e-04\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.4616e-04 - val_loss: 1.1204e-04\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.4439e-04 - val_loss: 1.1184e-04\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.4261e-04 - val_loss: 1.1165e-04\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.4085e-04 - val_loss: 1.1146e-04\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3910e-04 - val_loss: 1.1125e-04\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 6.3735e-04 - val_loss: 1.1106e-04\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3560e-04 - val_loss: 1.1087e-04\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3387e-04 - val_loss: 1.1068e-04\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3214e-04 - val_loss: 1.1049e-04\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.3042e-04 - val_loss: 1.1029e-04\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.2870e-04 - val_loss: 1.1011e-04\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.2700e-04 - val_loss: 1.0991e-04\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 6.2530e-04 - val_loss: 1.0972e-04\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.2360e-04 - val_loss: 1.0953e-04\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.2192e-04 - val_loss: 1.0935e-04\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 6.2024e-04 - val_loss: 1.0915e-04\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.1856e-04 - val_loss: 1.0896e-04\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.1689e-04 - val_loss: 1.0877e-04\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 6.1523e-04 - val_loss: 1.0859e-04\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.1357e-04 - val_loss: 1.0840e-04\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.1193e-04 - val_loss: 1.0822e-04\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 6.1028e-04 - val_loss: 1.0803e-04\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.0864e-04 - val_loss: 1.0785e-04\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.0701e-04 - val_loss: 1.0766e-04\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.0539e-04 - val_loss: 1.0748e-04\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 0us/step - loss: 6.0377e-04 - val_loss: 1.0730e-04\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.0215e-04 - val_loss: 1.0711e-04\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 6.0055e-04 - val_loss: 1.0692e-04\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.9895e-04 - val_loss: 1.0674e-04\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.9736e-04 - val_loss: 1.0657e-04\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.9577e-04 - val_loss: 1.0639e-04\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.9419e-04 - val_loss: 1.0620e-04\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.9261e-04 - val_loss: 1.0602e-04\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.9104e-04 - val_loss: 1.0584e-04\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.8947e-04 - val_loss: 1.0566e-04\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.8792e-04 - val_loss: 1.0548e-04\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.8637e-04 - val_loss: 1.0531e-04\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.8482e-04 - val_loss: 1.0513e-04\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.8327e-04 - val_loss: 1.0495e-04\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.8173e-04 - val_loss: 1.0477e-04\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.8020e-04 - val_loss: 1.0459e-04\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.7868e-04 - val_loss: 1.0441e-04\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.7716e-04 - val_loss: 1.0423e-04\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.7565e-04 - val_loss: 1.0405e-04\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.7414e-04 - val_loss: 1.0387e-04\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.7263e-04 - val_loss: 1.0370e-04\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.7114e-04 - val_loss: 1.0352e-04\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 5.6964e-04 - val_loss: 1.0335e-04\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.6816e-04 - val_loss: 1.0317e-04\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.6667e-04 - val_loss: 1.0300e-04\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 5.6520e-04 - val_loss: 1.0282e-04\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.6372e-04 - val_loss: 1.0265e-04\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.6226e-04 - val_loss: 1.0248e-04\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.6080e-04 - val_loss: 1.0230e-04\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 5.5934e-04 - val_loss: 1.0213e-04\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.5789e-04 - val_loss: 1.0195e-04\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.5644e-04 - val_loss: 1.0178e-04\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.5500e-04 - val_loss: 1.0162e-04\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.5357e-04 - val_loss: 1.0144e-04\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.5214e-04 - val_loss: 1.0127e-04\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 5.5071e-04 - val_loss: 1.0109e-04\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4928e-04 - val_loss: 1.0092e-04\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4787e-04 - val_loss: 1.0075e-04\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.4646e-04 - val_loss: 1.0058e-04\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4506e-04 - val_loss: 1.0041e-04\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4366e-04 - val_loss: 1.0024e-04\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4227e-04 - val_loss: 1.0007e-04\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.4087e-04 - val_loss: 9.9901e-05\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.3949e-04 - val_loss: 9.9729e-05\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.3811e-04 - val_loss: 9.9562e-05\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 5.3672e-04 - val_loss: 9.9394e-05\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.3535e-04 - val_loss: 9.9228e-05\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.3399e-04 - val_loss: 9.9060e-05\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 5.3262e-04 - val_loss: 9.8896e-05\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.3127e-04 - val_loss: 9.8724e-05\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.2991e-04 - val_loss: 9.8555e-05\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.2856e-04 - val_loss: 9.8391e-05\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.2722e-04 - val_loss: 9.8226e-05\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.2588e-04 - val_loss: 9.8059e-05\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 5.2454e-04 - val_loss: 9.7896e-05\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.2321e-04 - val_loss: 9.7730e-05\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.2189e-04 - val_loss: 9.7567e-05\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.2056e-04 - val_loss: 9.7397e-05\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1924e-04 - val_loss: 9.7230e-05\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1792e-04 - val_loss: 9.7066e-05\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 5.1662e-04 - val_loss: 9.6906e-05\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1531e-04 - val_loss: 9.6740e-05\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1402e-04 - val_loss: 9.6580e-05\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1272e-04 - val_loss: 9.6417e-05\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.1143e-04 - val_loss: 9.6251e-05\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.1015e-04 - val_loss: 9.6088e-05\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0886e-04 - val_loss: 9.5924e-05\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.0759e-04 - val_loss: 9.5763e-05\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0632e-04 - val_loss: 9.5610e-05\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0504e-04 - val_loss: 9.5448e-05\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.0376e-04 - val_loss: 9.5287e-05\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0250e-04 - val_loss: 9.5129e-05\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0125e-04 - val_loss: 9.4970e-05\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 5.0000e-04 - val_loss: 9.4809e-05\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9875e-04 - val_loss: 9.4651e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9751e-04 - val_loss: 9.4492e-05\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9626e-04 - val_loss: 9.4342e-05\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9503e-04 - val_loss: 9.4183e-05\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9379e-04 - val_loss: 9.4022e-05\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9256e-04 - val_loss: 9.3861e-05\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9134e-04 - val_loss: 9.3706e-05\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.9012e-04 - val_loss: 9.3549e-05\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8890e-04 - val_loss: 9.3391e-05\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.8769e-04 - val_loss: 9.3233e-05\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8648e-04 - val_loss: 9.3076e-05\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8527e-04 - val_loss: 9.2920e-05\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 4.8407e-04 - val_loss: 9.2768e-05\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8287e-04 - val_loss: 9.2612e-05\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8168e-04 - val_loss: 9.2461e-05\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.8049e-04 - val_loss: 9.2307e-05\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7930e-04 - val_loss: 9.2152e-05\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7812e-04 - val_loss: 9.2004e-05\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7693e-04 - val_loss: 9.1853e-05\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.7577e-04 - val_loss: 9.1700e-05\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7459e-04 - val_loss: 9.1544e-05\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7342e-04 - val_loss: 9.1399e-05\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.7226e-04 - val_loss: 9.1245e-05\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.7110e-04 - val_loss: 9.1096e-05\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.6994e-04 - val_loss: 9.0943e-05\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.6879e-04 - val_loss: 9.0799e-05\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.6764e-04 - val_loss: 9.0649e-05\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 307us/step - loss: 4.6650e-04 - val_loss: 9.0500e-05\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 163us/step - loss: 4.6535e-04 - val_loss: 9.0348e-05\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 104us/step - loss: 4.6421e-04 - val_loss: 9.0207e-05\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.6308e-04 - val_loss: 9.0055e-05\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.6195e-04 - val_loss: 8.9911e-05\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.6082e-04 - val_loss: 8.9759e-05\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5970e-04 - val_loss: 8.9609e-05\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5857e-04 - val_loss: 8.9462e-05\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5746e-04 - val_loss: 8.9316e-05\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5634e-04 - val_loss: 8.9168e-05\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5523e-04 - val_loss: 8.9027e-05\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5413e-04 - val_loss: 8.8887e-05\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 4.5303e-04 - val_loss: 8.8745e-05\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5193e-04 - val_loss: 8.8600e-05\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.5083e-04 - val_loss: 8.8455e-05\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 4.4973e-04 - val_loss: 8.8315e-05\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4865e-04 - val_loss: 8.8177e-05\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4756e-04 - val_loss: 8.8035e-05\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 4.4648e-04 - val_loss: 8.7893e-05\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4539e-04 - val_loss: 8.7745e-05\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4432e-04 - val_loss: 8.7604e-05\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4324e-04 - val_loss: 8.7459e-05\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.4217e-04 - val_loss: 8.7321e-05\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4110e-04 - val_loss: 8.7184e-05\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.4004e-04 - val_loss: 8.7041e-05\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.3898e-04 - val_loss: 8.6901e-05\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3792e-04 - val_loss: 8.6766e-05\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3687e-04 - val_loss: 8.6627e-05\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 4.3581e-04 - val_loss: 8.6497e-05\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3477e-04 - val_loss: 8.6354e-05\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3373e-04 - val_loss: 8.6223e-05\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 4.3269e-04 - val_loss: 8.6085e-05\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3165e-04 - val_loss: 8.5951e-05\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.3062e-04 - val_loss: 8.5818e-05\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2957e-04 - val_loss: 8.5677e-05\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.2855e-04 - val_loss: 8.5546e-05\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2753e-04 - val_loss: 8.5412e-05\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2651e-04 - val_loss: 8.5273e-05\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.2549e-04 - val_loss: 8.5142e-05\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2447e-04 - val_loss: 8.5003e-05\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2346e-04 - val_loss: 8.4872e-05\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 4.2245e-04 - val_loss: 8.4736e-05\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2144e-04 - val_loss: 8.4615e-05\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.2043e-04 - val_loss: 8.4485e-05\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.1944e-04 - val_loss: 8.4355e-05\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1844e-04 - val_loss: 8.4222e-05\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1744e-04 - val_loss: 8.4095e-05\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.1645e-04 - val_loss: 8.3963e-05\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1546e-04 - val_loss: 8.3834e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1447e-04 - val_loss: 8.3705e-05\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.1349e-04 - val_loss: 8.3577e-05\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1251e-04 - val_loss: 8.3454e-05\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.1153e-04 - val_loss: 8.3325e-05\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.1056e-04 - val_loss: 8.3194e-05\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0959e-04 - val_loss: 8.3075e-05\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0862e-04 - val_loss: 8.2947e-05\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0765e-04 - val_loss: 8.2819e-05\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0669e-04 - val_loss: 8.2690e-05\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0572e-04 - val_loss: 8.2570e-05\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0477e-04 - val_loss: 8.2444e-05\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.0381e-04 - val_loss: 8.2327e-05\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0286e-04 - val_loss: 8.2204e-05\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0191e-04 - val_loss: 8.2075e-05\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.0096e-04 - val_loss: 8.1956e-05\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 4.0002e-04 - val_loss: 8.1827e-05\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9908e-04 - val_loss: 8.1708e-05\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.9814e-04 - val_loss: 8.1586e-05\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9720e-04 - val_loss: 8.1467e-05\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9627e-04 - val_loss: 8.1344e-05\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9534e-04 - val_loss: 8.1228e-05\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9441e-04 - val_loss: 8.1107e-05\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9349e-04 - val_loss: 8.0986e-05\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9257e-04 - val_loss: 8.0865e-05\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.9165e-04 - val_loss: 8.0752e-05\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.9073e-04 - val_loss: 8.0631e-05\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8982e-04 - val_loss: 8.0513e-05\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.8891e-04 - val_loss: 8.0397e-05\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8800e-04 - val_loss: 8.0284e-05\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8709e-04 - val_loss: 8.0168e-05\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.8619e-04 - val_loss: 8.0053e-05\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8528e-04 - val_loss: 7.9938e-05\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8439e-04 - val_loss: 7.9825e-05\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.8349e-04 - val_loss: 7.9705e-05\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8259e-04 - val_loss: 7.9595e-05\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.8171e-04 - val_loss: 7.9479e-05\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.8082e-04 - val_loss: 7.9366e-05\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7993e-04 - val_loss: 7.9252e-05\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7905e-04 - val_loss: 7.9136e-05\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.7817e-04 - val_loss: 7.9028e-05\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7729e-04 - val_loss: 7.8916e-05\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7641e-04 - val_loss: 7.8809e-05\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7554e-04 - val_loss: 7.8692e-05\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.7467e-04 - val_loss: 7.8581e-05\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7380e-04 - val_loss: 7.8472e-05\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7293e-04 - val_loss: 7.8361e-05\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.7207e-04 - val_loss: 7.8258e-05\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7121e-04 - val_loss: 7.8151e-05\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.7035e-04 - val_loss: 7.8039e-05\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.6949e-04 - val_loss: 7.7932e-05\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6864e-04 - val_loss: 7.7829e-05\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6779e-04 - val_loss: 7.7725e-05\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.6694e-04 - val_loss: 7.7620e-05\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6609e-04 - val_loss: 7.7513e-05\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6525e-04 - val_loss: 7.7405e-05\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6440e-04 - val_loss: 7.7296e-05\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.6356e-04 - val_loss: 7.7189e-05\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6273e-04 - val_loss: 7.7084e-05\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6189e-04 - val_loss: 7.6983e-05\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.6106e-04 - val_loss: 7.6879e-05\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.6023e-04 - val_loss: 7.6779e-05\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5940e-04 - val_loss: 7.6672e-05\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.5857e-04 - val_loss: 7.6571e-05\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5776e-04 - val_loss: 7.6465e-05\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5693e-04 - val_loss: 7.6357e-05\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.5611e-04 - val_loss: 7.6263e-05\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5529e-04 - val_loss: 7.6165e-05\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5449e-04 - val_loss: 7.6068e-05\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5367e-04 - val_loss: 7.5969e-05\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5286e-04 - val_loss: 7.5866e-05\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5205e-04 - val_loss: 7.5772e-05\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.5124e-04 - val_loss: 7.5677e-05\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.5045e-04 - val_loss: 7.5575e-05\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4964e-04 - val_loss: 7.5473e-05\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4885e-04 - val_loss: 7.5377e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.4805e-04 - val_loss: 7.5277e-05\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4725e-04 - val_loss: 7.5174e-05\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4646e-04 - val_loss: 7.5079e-05\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.4567e-04 - val_loss: 7.4981e-05\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4488e-04 - val_loss: 7.4882e-05\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4410e-04 - val_loss: 7.4787e-05\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.4331e-04 - val_loss: 7.4690e-05\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4253e-04 - val_loss: 7.4596e-05\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4175e-04 - val_loss: 7.4506e-05\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.4098e-04 - val_loss: 7.4417e-05\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.4020e-04 - val_loss: 7.4319e-05\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3943e-04 - val_loss: 7.4226e-05\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.3866e-04 - val_loss: 7.4139e-05\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3789e-04 - val_loss: 7.4050e-05\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3712e-04 - val_loss: 7.3951e-05\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3636e-04 - val_loss: 7.3864e-05\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.3560e-04 - val_loss: 7.3776e-05\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3483e-04 - val_loss: 7.3685e-05\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3407e-04 - val_loss: 7.3590e-05\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.3332e-04 - val_loss: 7.3504e-05\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3256e-04 - val_loss: 7.3409e-05\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3180e-04 - val_loss: 7.3318e-05\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.3106e-04 - val_loss: 7.3234e-05\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3031e-04 - val_loss: 7.3137e-05\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2956e-04 - val_loss: 7.3050e-05\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.2882e-04 - val_loss: 7.2959e-05\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2807e-04 - val_loss: 7.2871e-05\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2734e-04 - val_loss: 7.2788e-05\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2660e-04 - val_loss: 7.2703e-05\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2586e-04 - val_loss: 7.2620e-05\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2513e-04 - val_loss: 7.2529e-05\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2440e-04 - val_loss: 7.2441e-05\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.2366e-04 - val_loss: 7.2359e-05\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2294e-04 - val_loss: 7.2274e-05\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2221e-04 - val_loss: 7.2190e-05\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.2148e-04 - val_loss: 7.2112e-05\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2076e-04 - val_loss: 7.2016e-05\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.2004e-04 - val_loss: 7.1940e-05\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.1932e-04 - val_loss: 7.1853e-05\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1860e-04 - val_loss: 7.1769e-05\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1788e-04 - val_loss: 7.1691e-05\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.1717e-04 - val_loss: 7.1606e-05\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1646e-04 - val_loss: 7.1525e-05\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1575e-04 - val_loss: 7.1442e-05\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1504e-04 - val_loss: 7.1366e-05\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 3.1434e-04 - val_loss: 7.1284e-05\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1363e-04 - val_loss: 7.1207e-05\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1294e-04 - val_loss: 7.1125e-05\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 3.1223e-04 - val_loss: 7.1045e-05\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1153e-04 - val_loss: 7.0962e-05\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.1084e-04 - val_loss: 7.0883e-05\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.1014e-04 - val_loss: 7.0799e-05\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0945e-04 - val_loss: 7.0720e-05\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0876e-04 - val_loss: 7.0638e-05\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0807e-04 - val_loss: 7.0568e-05\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0738e-04 - val_loss: 7.0488e-05\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.0669e-04 - val_loss: 7.0420e-05\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0601e-04 - val_loss: 7.0340e-05\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0533e-04 - val_loss: 7.0265e-05\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.0465e-04 - val_loss: 7.0183e-05\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0397e-04 - val_loss: 7.0109e-05\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0329e-04 - val_loss: 7.0037e-05\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0262e-04 - val_loss: 6.9957e-05\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0194e-04 - val_loss: 6.9881e-05\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0127e-04 - val_loss: 6.9806e-05\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.0061e-04 - val_loss: 6.9731e-05\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.9994e-04 - val_loss: 6.9654e-05\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9927e-04 - val_loss: 6.9583e-05\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9860e-04 - val_loss: 6.9513e-05\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.9794e-04 - val_loss: 6.9435e-05\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9728e-04 - val_loss: 6.9370e-05\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9662e-04 - val_loss: 6.9299e-05\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.9596e-04 - val_loss: 6.9222e-05\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9531e-04 - val_loss: 6.9150e-05\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9465e-04 - val_loss: 6.9079e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9400e-04 - val_loss: 6.8999e-05\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9334e-04 - val_loss: 6.8937e-05\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9270e-04 - val_loss: 6.8860e-05\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.9205e-04 - val_loss: 6.8791e-05\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 2.9140e-04 - val_loss: 6.8728e-05\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 164us/step - loss: 2.9076e-04 - val_loss: 6.8655e-05\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 62us/step - loss: 2.9011e-04 - val_loss: 6.8586e-05\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8947e-04 - val_loss: 6.8521e-05\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8883e-04 - val_loss: 6.8452e-05\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.8819e-04 - val_loss: 6.8384e-05\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8756e-04 - val_loss: 6.8311e-05\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8692e-04 - val_loss: 6.8240e-05\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.8629e-04 - val_loss: 6.8175e-05\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8566e-04 - val_loss: 6.8101e-05\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8503e-04 - val_loss: 6.8034e-05\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.8441e-04 - val_loss: 6.7974e-05\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8377e-04 - val_loss: 6.7905e-05\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8315e-04 - val_loss: 6.7844e-05\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8252e-04 - val_loss: 6.7777e-05\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8190e-04 - val_loss: 6.7709e-05\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8128e-04 - val_loss: 6.7641e-05\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.8066e-04 - val_loss: 6.7573e-05\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.8005e-04 - val_loss: 6.7510e-05\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7943e-04 - val_loss: 6.7447e-05\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7882e-04 - val_loss: 6.7385e-05\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.7820e-04 - val_loss: 6.7328e-05\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7759e-04 - val_loss: 6.7261e-05\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7699e-04 - val_loss: 6.7194e-05\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.7637e-04 - val_loss: 6.7134e-05\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7577e-04 - val_loss: 6.7070e-05\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7516e-04 - val_loss: 6.7004e-05\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7456e-04 - val_loss: 6.6946e-05\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7396e-04 - val_loss: 6.6887e-05\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7335e-04 - val_loss: 6.6820e-05\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7275e-04 - val_loss: 6.6757e-05\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.7216e-04 - val_loss: 6.6703e-05\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7156e-04 - val_loss: 6.6640e-05\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.7097e-04 - val_loss: 6.6577e-05\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.7037e-04 - val_loss: 6.6512e-05\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6979e-04 - val_loss: 6.6447e-05\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6919e-04 - val_loss: 6.6385e-05\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.6860e-04 - val_loss: 6.6324e-05\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6802e-04 - val_loss: 6.6266e-05\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6743e-04 - val_loss: 6.6212e-05\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.6685e-04 - val_loss: 6.6152e-05\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6627e-04 - val_loss: 6.6097e-05\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6568e-04 - val_loss: 6.6035e-05\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6511e-04 - val_loss: 6.5984e-05\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.6453e-04 - val_loss: 6.5930e-05\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6395e-04 - val_loss: 6.5871e-05\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6337e-04 - val_loss: 6.5811e-05\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.6280e-04 - val_loss: 6.5758e-05\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6223e-04 - val_loss: 6.5706e-05\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6165e-04 - val_loss: 6.5643e-05\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.6108e-04 - val_loss: 6.5580e-05\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6052e-04 - val_loss: 6.5527e-05\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5995e-04 - val_loss: 6.5472e-05\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5938e-04 - val_loss: 6.5419e-05\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5882e-04 - val_loss: 6.5358e-05\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5825e-04 - val_loss: 6.5302e-05\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5770e-04 - val_loss: 6.5250e-05\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.5713e-04 - val_loss: 6.5194e-05\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5658e-04 - val_loss: 6.5133e-05\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5602e-04 - val_loss: 6.5085e-05\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.5546e-04 - val_loss: 6.5029e-05\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5491e-04 - val_loss: 6.4977e-05\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5436e-04 - val_loss: 6.4927e-05\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.5380e-04 - val_loss: 6.4871e-05\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5325e-04 - val_loss: 6.4821e-05\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5270e-04 - val_loss: 6.4765e-05\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5216e-04 - val_loss: 6.4710e-05\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5161e-04 - val_loss: 6.4656e-05\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5106e-04 - val_loss: 6.4599e-05\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.5052e-04 - val_loss: 6.4549e-05\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.4997e-04 - val_loss: 6.4496e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4944e-04 - val_loss: 6.4445e-05\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4890e-04 - val_loss: 6.4398e-05\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.4836e-04 - val_loss: 6.4345e-05\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4782e-04 - val_loss: 6.4297e-05\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4728e-04 - val_loss: 6.4247e-05\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.4674e-04 - val_loss: 6.4204e-05\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4622e-04 - val_loss: 6.4147e-05\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4569e-04 - val_loss: 6.4101e-05\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.4515e-04 - val_loss: 6.4047e-05\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4462e-04 - val_loss: 6.3995e-05\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4409e-04 - val_loss: 6.3943e-05\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.4357e-04 - val_loss: 6.3894e-05\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4304e-04 - val_loss: 6.3848e-05\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4252e-04 - val_loss: 6.3802e-05\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.4199e-04 - val_loss: 6.3748e-05\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4147e-04 - val_loss: 6.3706e-05\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4096e-04 - val_loss: 6.3654e-05\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.4043e-04 - val_loss: 6.3609e-05\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.3991e-04 - val_loss: 6.3556e-05\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3940e-04 - val_loss: 6.3505e-05\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3888e-04 - val_loss: 6.3462e-05\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.3836e-04 - val_loss: 6.3412e-05\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3785e-04 - val_loss: 6.3370e-05\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3734e-04 - val_loss: 6.3322e-05\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.3683e-04 - val_loss: 6.3272e-05\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3632e-04 - val_loss: 6.3228e-05\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3581e-04 - val_loss: 6.3183e-05\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.3530e-04 - val_loss: 6.3144e-05\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3480e-04 - val_loss: 6.3095e-05\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3429e-04 - val_loss: 6.3047e-05\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.3379e-04 - val_loss: 6.2999e-05\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3329e-04 - val_loss: 6.2955e-05\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3279e-04 - val_loss: 6.2912e-05\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3228e-04 - val_loss: 6.2869e-05\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.3179e-04 - val_loss: 6.2817e-05\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3129e-04 - val_loss: 6.2774e-05\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.3079e-04 - val_loss: 6.2729e-05\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.3030e-04 - val_loss: 6.2684e-05\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2980e-04 - val_loss: 6.2642e-05\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2931e-04 - val_loss: 6.2598e-05\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2882e-04 - val_loss: 6.2553e-05\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2833e-04 - val_loss: 6.2511e-05\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2784e-04 - val_loss: 6.2469e-05\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2735e-04 - val_loss: 6.2430e-05\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2687e-04 - val_loss: 6.2385e-05\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2638e-04 - val_loss: 6.2346e-05\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2589e-04 - val_loss: 6.2303e-05\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2541e-04 - val_loss: 6.2258e-05\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2493e-04 - val_loss: 6.2215e-05\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2445e-04 - val_loss: 6.2177e-05\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2397e-04 - val_loss: 6.2137e-05\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2349e-04 - val_loss: 6.2096e-05\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2301e-04 - val_loss: 6.2058e-05\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2254e-04 - val_loss: 6.2015e-05\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2206e-04 - val_loss: 6.1973e-05\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2158e-04 - val_loss: 6.1926e-05\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.2111e-04 - val_loss: 6.1886e-05\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2064e-04 - val_loss: 6.1844e-05\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.2017e-04 - val_loss: 6.1805e-05\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1970e-04 - val_loss: 6.1769e-05\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.1923e-04 - val_loss: 6.1729e-05\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1876e-04 - val_loss: 6.1688e-05\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1829e-04 - val_loss: 6.1650e-05\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.1783e-04 - val_loss: 6.1607e-05\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1736e-04 - val_loss: 6.1566e-05\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1690e-04 - val_loss: 6.1530e-05\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.1644e-04 - val_loss: 6.1490e-05\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1598e-04 - val_loss: 6.1450e-05\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1551e-04 - val_loss: 6.1414e-05\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.1506e-04 - val_loss: 6.1374e-05\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1460e-04 - val_loss: 6.1333e-05\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1414e-04 - val_loss: 6.1300e-05\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1369e-04 - val_loss: 6.1260e-05\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1323e-04 - val_loss: 6.1223e-05\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1278e-04 - val_loss: 6.1186e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1233e-04 - val_loss: 6.1148e-05\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1188e-04 - val_loss: 6.1111e-05\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1142e-04 - val_loss: 6.1072e-05\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1097e-04 - val_loss: 6.1034e-05\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1053e-04 - val_loss: 6.0994e-05\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.1008e-04 - val_loss: 6.0957e-05\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0963e-04 - val_loss: 6.0925e-05\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.0919e-04 - val_loss: 6.0890e-05\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0874e-04 - val_loss: 6.0855e-05\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0830e-04 - val_loss: 6.0818e-05\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.0786e-04 - val_loss: 6.0785e-05\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0741e-04 - val_loss: 6.0749e-05\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0698e-04 - val_loss: 6.0710e-05\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.0653e-04 - val_loss: 6.0673e-05\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0610e-04 - val_loss: 6.0642e-05\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0566e-04 - val_loss: 6.0602e-05\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 2.0523e-04 - val_loss: 6.0565e-05\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0479e-04 - val_loss: 6.0529e-05\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0436e-04 - val_loss: 6.0501e-05\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0392e-04 - val_loss: 6.0463e-05\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 2.0349e-04 - val_loss: 6.0427e-05\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0306e-04 - val_loss: 6.0392e-05\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0263e-04 - val_loss: 6.0366e-05\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.0220e-04 - val_loss: 6.0328e-05\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0177e-04 - val_loss: 6.0291e-05\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0135e-04 - val_loss: 6.0255e-05\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 2.0092e-04 - val_loss: 6.0227e-05\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0050e-04 - val_loss: 6.0193e-05\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0007e-04 - val_loss: 6.0159e-05\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.9965e-04 - val_loss: 6.0120e-05\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9923e-04 - val_loss: 6.0096e-05\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9881e-04 - val_loss: 6.0065e-05\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9838e-04 - val_loss: 6.0025e-05\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.9797e-04 - val_loss: 5.9992e-05\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9755e-04 - val_loss: 5.9964e-05\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9713e-04 - val_loss: 5.9932e-05\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.9671e-04 - val_loss: 5.9892e-05\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9630e-04 - val_loss: 5.9858e-05\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9588e-04 - val_loss: 5.9829e-05\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.9547e-04 - val_loss: 5.9799e-05\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9506e-04 - val_loss: 5.9765e-05\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9465e-04 - val_loss: 5.9730e-05\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 1.9423e-04 - val_loss: 5.9705e-05\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9383e-04 - val_loss: 5.9675e-05\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9342e-04 - val_loss: 5.9643e-05\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 1.9301e-04 - val_loss: 5.9611e-05\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9261e-04 - val_loss: 5.9581e-05\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9219e-04 - val_loss: 5.9555e-05\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9179e-04 - val_loss: 5.9515e-05\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9139e-04 - val_loss: 5.9482e-05\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9098e-04 - val_loss: 5.9457e-05\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.9058e-04 - val_loss: 5.9421e-05\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.9018e-04 - val_loss: 5.9397e-05\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8979e-04 - val_loss: 5.9370e-05\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8939e-04 - val_loss: 5.9333e-05\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.8898e-04 - val_loss: 5.9306e-05\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8859e-04 - val_loss: 5.9273e-05\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8819e-04 - val_loss: 5.9242e-05\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 1.8779e-04 - val_loss: 5.9216e-05\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8740e-04 - val_loss: 5.9184e-05\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 339us/step - loss: 1.8701e-04 - val_loss: 5.9152e-05\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 132us/step - loss: 1.8661e-04 - val_loss: 5.9129e-05\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 75us/step - loss: 1.8622e-04 - val_loss: 5.9098e-05\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8583e-04 - val_loss: 5.9067e-05\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8544e-04 - val_loss: 5.9038e-05\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.8505e-04 - val_loss: 5.9009e-05\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8466e-04 - val_loss: 5.8981e-05\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8427e-04 - val_loss: 5.8948e-05\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8389e-04 - val_loss: 5.8926e-05\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.8350e-04 - val_loss: 5.8897e-05\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8312e-04 - val_loss: 5.8869e-05\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8273e-04 - val_loss: 5.8845e-05\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.8235e-04 - val_loss: 5.8819e-05\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8197e-04 - val_loss: 5.8785e-05\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8158e-04 - val_loss: 5.8761e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 1.8120e-04 - val_loss: 5.8729e-05\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8082e-04 - val_loss: 5.8704e-05\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.8044e-04 - val_loss: 5.8675e-05\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 1.8007e-04 - val_loss: 5.8644e-05\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7969e-04 - val_loss: 5.8620e-05\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7931e-04 - val_loss: 5.8593e-05\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7894e-04 - val_loss: 5.8561e-05\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 1.7856e-04 - val_loss: 5.8536e-05\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7819e-04 - val_loss: 5.8512e-05\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7782e-04 - val_loss: 5.8488e-05\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.7744e-04 - val_loss: 5.8461e-05\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7707e-04 - val_loss: 5.8430e-05\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7670e-04 - val_loss: 5.8401e-05\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 1.7634e-04 - val_loss: 5.8379e-05\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7596e-04 - val_loss: 5.8351e-05\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7560e-04 - val_loss: 5.8326e-05\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 1.7523e-04 - val_loss: 5.8302e-05\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7486e-04 - val_loss: 5.8278e-05\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.7450e-04 - val_loss: 5.8250e-05\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 1.7413e-04 - val_loss: 5.8224e-05\n",
      "7.419138273689896e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.44824603, -0.5362125 ,  0.6257862 ,  0.61135906,  0.50108695],\n",
       "        [-0.662126  , -0.04732583, -0.51817155, -0.53575623,  0.3642988 ],\n",
       "        [ 0.8513131 , -1.1041515 ,  0.58935463, -0.8927515 ,  1.5539659 ]],\n",
       "       dtype=float32),\n",
       " array([-0.36749715,  0.00360253, -0.56327033,  0.57296103,  0.6493932 ],\n",
       "       dtype=float32),\n",
       " array([[-0.07041897, -0.04373741, -0.32269704, -0.34918532, -0.13602316,\n",
       "         -0.3063129 ,  0.01809474,  0.4038335 ,  0.07105578,  0.18572578],\n",
       "        [ 0.19188567, -0.7061487 , -0.10279872, -0.41128668,  0.06119973,\n",
       "          0.07042981, -0.3630594 ,  0.40914837, -0.09790229,  0.13569403],\n",
       "        [ 0.4565307 ,  0.20036274,  0.5966382 , -0.16896828,  0.2800141 ,\n",
       "         -0.74726164,  0.1998613 , -0.69925684,  0.8198914 , -0.28551838],\n",
       "        [-0.4366241 , -0.32156065, -0.60621804,  0.7880971 ,  0.42636883,\n",
       "          0.49007776, -0.78992325,  0.15568699,  0.1818488 ,  0.32909903],\n",
       "        [-0.3480384 , -0.04211389, -0.51746464,  0.50605667,  0.9210211 ,\n",
       "         -0.18424268, -0.9073708 ,  0.77608144, -0.6301163 , -0.17020154]],\n",
       "       dtype=float32),\n",
       " array([-0.2964325 , -0.3852179 , -0.5348899 ,  0.7241192 ,  0.6613483 ,\n",
       "         0.64829445, -0.71614146,  0.72988045, -0.73127335,  0.7278388 ],\n",
       "       dtype=float32),\n",
       " array([[-0.13206936],\n",
       "        [-0.1406519 ],\n",
       "        [-0.28858796],\n",
       "        [ 0.72574484],\n",
       "        [ 0.4237893 ],\n",
       "        [ 0.36330017],\n",
       "        [-0.6881559 ],\n",
       "        [ 0.71063393],\n",
       "        [-0.64558774],\n",
       "        [ 0.7769447 ]], dtype=float32),\n",
       " array([0.7941834], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, adam2, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 36.1690 - val_loss: 35.7459\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 73us/step - loss: 36.1679 - val_loss: 35.7444\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1664 - val_loss: 35.7424\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1644 - val_loss: 35.7400\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.1621 - val_loss: 35.7373\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1594 - val_loss: 35.7343\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1564 - val_loss: 35.7310\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1531 - val_loss: 35.7274\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.1496 - val_loss: 35.7237\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1459 - val_loss: 35.7197\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1420 - val_loss: 35.7155\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1379 - val_loss: 35.7112\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1336 - val_loss: 35.7068\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1292 - val_loss: 35.7022\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1247 - val_loss: 35.6975\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.1200 - val_loss: 35.6926\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1153 - val_loss: 35.6877\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1104 - val_loss: 35.6827\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.1055 - val_loss: 35.6777\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.1004 - val_loss: 35.6725\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0954 - val_loss: 35.6673\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.0902 - val_loss: 35.6620\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0850 - val_loss: 35.6567\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0798 - val_loss: 35.6514\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0745 - val_loss: 35.6460\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.0691 - val_loss: 35.6405\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0637 - val_loss: 35.6350\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0583 - val_loss: 35.6295\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.0529 - val_loss: 35.6240\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0474 - val_loss: 35.6185\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0420 - val_loss: 35.6129\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0365 - val_loss: 35.6073\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 36.0309 - val_loss: 35.6017\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0254 - val_loss: 35.5961\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0198 - val_loss: 35.5904\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0143 - val_loss: 35.5848\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 36.0087 - val_loss: 35.5791\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 36.0031 - val_loss: 35.5735\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9975 - val_loss: 35.5678\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.9919 - val_loss: 35.5621\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9863 - val_loss: 35.5564\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9807 - val_loss: 35.5507\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9750 - val_loss: 35.5450\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.9694 - val_loss: 35.5393\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9638 - val_loss: 35.5336\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9581 - val_loss: 35.5279\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9525 - val_loss: 35.5222\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.9468 - val_loss: 35.5165\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9412 - val_loss: 35.5107\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9355 - val_loss: 35.5050\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.9299 - val_loss: 35.4993\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9242 - val_loss: 35.4936\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9185 - val_loss: 35.4878\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9129 - val_loss: 35.4821\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 35.9072 - val_loss: 35.4764\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.9016 - val_loss: 35.4706\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8959 - val_loss: 35.4649\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.8902 - val_loss: 35.4592\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8846 - val_loss: 35.4535\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8789 - val_loss: 35.4477\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8732 - val_loss: 35.4420\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.8676 - val_loss: 35.4363\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8619 - val_loss: 35.4305\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8563 - val_loss: 35.4248\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.8506 - val_loss: 35.4191\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8449 - val_loss: 35.4133\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8393 - val_loss: 35.4076\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.8336 - val_loss: 35.4019\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8280 - val_loss: 35.3962\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8223 - val_loss: 35.3904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8166 - val_loss: 35.3847\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.8110 - val_loss: 35.3790\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.8053 - val_loss: 35.3733\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7997 - val_loss: 35.3675\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7940 - val_loss: 35.3618\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7884 - val_loss: 35.3561\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7827 - val_loss: 35.3504\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7771 - val_loss: 35.3446\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.7714 - val_loss: 35.3389\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7657 - val_loss: 35.3332\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7601 - val_loss: 35.3275\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7544 - val_loss: 35.3218\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.7488 - val_loss: 35.3161\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7431 - val_loss: 35.3103\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7375 - val_loss: 35.3046\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.7319 - val_loss: 35.2989\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7262 - val_loss: 35.2932\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7206 - val_loss: 35.2875\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7149 - val_loss: 35.2818\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 490us/step - loss: 35.7093 - val_loss: 35.2761\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.7036 - val_loss: 35.2704\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6980 - val_loss: 35.2647\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.6924 - val_loss: 35.2589\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6867 - val_loss: 35.2532\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6811 - val_loss: 35.2475\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6755 - val_loss: 35.2418\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6698 - val_loss: 35.2361\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6642 - val_loss: 35.2304\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6585 - val_loss: 35.2247\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.6529 - val_loss: 35.2190\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6473 - val_loss: 35.2133\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6417 - val_loss: 35.2076\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6360 - val_loss: 35.2019\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 35.6304 - val_loss: 35.1962\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6248 - val_loss: 35.1905\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6191 - val_loss: 35.1848\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.6135 - val_loss: 35.1791\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6079 - val_loss: 35.1735\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6023 - val_loss: 35.1678\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5966 - val_loss: 35.1621\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 561us/step - loss: 35.5910 - val_loss: 35.1564\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5854 - val_loss: 35.1507\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5798 - val_loss: 35.1450\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5742 - val_loss: 35.1393\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5685 - val_loss: 35.1336\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5629 - val_loss: 35.1280\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5573 - val_loss: 35.1223\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.5517 - val_loss: 35.1166\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5461 - val_loss: 35.1109\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5405 - val_loss: 35.1052\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.5349 - val_loss: 35.0995\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5292 - val_loss: 35.0939\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5236 - val_loss: 35.0882\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5180 - val_loss: 35.0825\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.5124 - val_loss: 35.0768\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5068 - val_loss: 35.0712\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.5012 - val_loss: 35.0655\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4956 - val_loss: 35.0598\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4900 - val_loss: 35.0541\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4844 - val_loss: 35.0485\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4788 - val_loss: 35.0428\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.4732 - val_loss: 35.0371\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4676 - val_loss: 35.0315\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4620 - val_loss: 35.0258\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.4564 - val_loss: 35.0201\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4508 - val_loss: 35.0145\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4452 - val_loss: 35.0088\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4396 - val_loss: 35.0031\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.4340 - val_loss: 34.9975\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4284 - val_loss: 34.9918\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4228 - val_loss: 34.9862\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.4172 - val_loss: 34.9805\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4116 - val_loss: 34.9748\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4060 - val_loss: 34.9692\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.4005 - val_loss: 34.9635\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.3949 - val_loss: 34.9579\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3893 - val_loss: 34.9522\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3837 - val_loss: 34.9466\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.3781 - val_loss: 34.9409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3725 - val_loss: 34.9353\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3669 - val_loss: 34.9296\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3614 - val_loss: 34.9240\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.3558 - val_loss: 34.9183\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3502 - val_loss: 34.9127\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3446 - val_loss: 34.9070\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3390 - val_loss: 34.9014\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 35.3335 - val_loss: 34.8957\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3279 - val_loss: 34.8901\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3223 - val_loss: 34.8844\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.3167 - val_loss: 34.8788\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3112 - val_loss: 34.8731\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3056 - val_loss: 34.8675\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.3000 - val_loss: 34.8619\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2944 - val_loss: 34.8562\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2889 - val_loss: 34.8506\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2833 - val_loss: 34.8450\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.2777 - val_loss: 34.8393\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2722 - val_loss: 34.8337\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2666 - val_loss: 34.8281\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2610 - val_loss: 34.8224\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.2555 - val_loss: 34.8168\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2499 - val_loss: 34.8112\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2443 - val_loss: 34.8055\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2388 - val_loss: 34.7999\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2332 - val_loss: 34.7943\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2277 - val_loss: 34.7886\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2221 - val_loss: 34.7830\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.2165 - val_loss: 34.7774\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2110 - val_loss: 34.7718\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.2054 - val_loss: 34.7661\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1999 - val_loss: 34.7605\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1943 - val_loss: 34.7549\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1888 - val_loss: 34.7493\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1832 - val_loss: 34.7437\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.1777 - val_loss: 34.7380\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1721 - val_loss: 34.7324\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1666 - val_loss: 34.7268\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1610 - val_loss: 34.7212\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.1555 - val_loss: 34.7156\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1499 - val_loss: 34.7099\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1444 - val_loss: 34.7043\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 35.1388 - val_loss: 34.6987\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1333 - val_loss: 34.6931\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1277 - val_loss: 34.6875\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1222 - val_loss: 34.6819\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.1167 - val_loss: 34.6763\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1111 - val_loss: 34.6707\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.1056 - val_loss: 34.6651\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.1000 - val_loss: 34.6595\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0945 - val_loss: 34.6539\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0890 - val_loss: 34.6483\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0834 - val_loss: 34.6426\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.0779 - val_loss: 34.6370\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0724 - val_loss: 34.6314\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0668 - val_loss: 34.6258\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 35.0613 - val_loss: 34.6202\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0558 - val_loss: 34.6146\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0502 - val_loss: 34.6090\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0447 - val_loss: 34.6034\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0392 - val_loss: 34.5978\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0336 - val_loss: 34.5923\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0281 - val_loss: 34.5867\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 35.0226 - val_loss: 34.5811\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0171 - val_loss: 34.5755\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0115 - val_loss: 34.5699\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0060 - val_loss: 34.5643\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.0005 - val_loss: 34.5587\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9950 - val_loss: 34.5531\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9894 - val_loss: 34.5475\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.9839 - val_loss: 34.5419\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9784 - val_loss: 34.5363\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9729 - val_loss: 34.5308\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.9674 - val_loss: 34.5252\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9619 - val_loss: 34.5196\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9563 - val_loss: 34.5140\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9508 - val_loss: 34.5084\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.9453 - val_loss: 34.5028\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9398 - val_loss: 34.4973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9343 - val_loss: 34.4917\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.9288 - val_loss: 34.4861\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9233 - val_loss: 34.4805\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9178 - val_loss: 34.4749\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9123 - val_loss: 34.4694\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9067 - val_loss: 34.4638\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.9012 - val_loss: 34.4582\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8957 - val_loss: 34.4526\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.8902 - val_loss: 34.4471\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8847 - val_loss: 34.4415\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 381us/step - loss: 34.8792 - val_loss: 34.4359\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 32us/step - loss: 34.8737 - val_loss: 34.4304\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8682 - val_loss: 34.4248\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8627 - val_loss: 34.4192\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.8572 - val_loss: 34.4137\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8517 - val_loss: 34.4081\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8462 - val_loss: 34.4025\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8407 - val_loss: 34.3970\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.8352 - val_loss: 34.3914\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8297 - val_loss: 34.3858\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8242 - val_loss: 34.3803\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.8187 - val_loss: 34.3747\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8133 - val_loss: 34.3691\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8078 - val_loss: 34.3636\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.8023 - val_loss: 34.3580\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7968 - val_loss: 34.3525\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7913 - val_loss: 34.3469\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7858 - val_loss: 34.3414\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7803 - val_loss: 34.3358\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7748 - val_loss: 34.3303\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7693 - val_loss: 34.3247\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7639 - val_loss: 34.3191\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7584 - val_loss: 34.3136\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7529 - val_loss: 34.3080\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7474 - val_loss: 34.3025\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7419 - val_loss: 34.2969\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7364 - val_loss: 34.2914\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7310 - val_loss: 34.2858\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7255 - val_loss: 34.2803\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7200 - val_loss: 34.2748\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7145 - val_loss: 34.2692\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.7091 - val_loss: 34.2637\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.7036 - val_loss: 34.2581\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6981 - val_loss: 34.2526\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6926 - val_loss: 34.2470\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6872 - val_loss: 34.2415\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.6817 - val_loss: 34.2360\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6762 - val_loss: 34.2304\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6707 - val_loss: 34.2249\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6653 - val_loss: 34.2193\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6598 - val_loss: 34.2138\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6543 - val_loss: 34.2083\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6489 - val_loss: 34.2027\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.6434 - val_loss: 34.1972\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6379 - val_loss: 34.1917\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6325 - val_loss: 34.1861\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6270 - val_loss: 34.1806\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6216 - val_loss: 34.1751\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.6161 - val_loss: 34.1696\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 445us/step - loss: 34.6106 - val_loss: 34.1640\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 124us/step - loss: 34.6052 - val_loss: 34.1585\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 120us/step - loss: 34.5997 - val_loss: 34.1530\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 126us/step - loss: 34.5943 - val_loss: 34.1474\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5888 - val_loss: 34.1419\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 34.5833 - val_loss: 34.1364\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 106us/step - loss: 34.5779 - val_loss: 34.1309\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 127us/step - loss: 34.5724 - val_loss: 34.1253\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5670 - val_loss: 34.1198\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5615 - val_loss: 34.1143\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5561 - val_loss: 34.1088\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.5506 - val_loss: 34.1033\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5452 - val_loss: 34.0977\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5397 - val_loss: 34.0922\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5343 - val_loss: 34.0867\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5288 - val_loss: 34.0812\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5234 - val_loss: 34.0757\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5179 - val_loss: 34.0702\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.5125 - val_loss: 34.0646\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5070 - val_loss: 34.0591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.5016 - val_loss: 34.0536\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4962 - val_loss: 34.0481\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4907 - val_loss: 34.0426\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4853 - val_loss: 34.0371\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4798 - val_loss: 34.0316\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.4744 - val_loss: 34.0261\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4689 - val_loss: 34.0206\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4635 - val_loss: 34.0151\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.4581 - val_loss: 34.0096\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4526 - val_loss: 34.0041\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4472 - val_loss: 33.9985\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4418 - val_loss: 33.9930\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.4363 - val_loss: 33.9875\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4309 - val_loss: 33.9820\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4255 - val_loss: 33.9765\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.4200 - val_loss: 33.9710\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4146 - val_loss: 33.9655\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4092 - val_loss: 33.9600\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.4037 - val_loss: 33.9545\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.3983 - val_loss: 33.9491\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3929 - val_loss: 33.9436\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3875 - val_loss: 33.9381\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.3820 - val_loss: 33.9326\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3766 - val_loss: 33.9271\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3712 - val_loss: 33.9216\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3658 - val_loss: 33.9161\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3603 - val_loss: 33.9106\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3549 - val_loss: 33.9051\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3495 - val_loss: 33.8996\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.3441 - val_loss: 33.8941\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3387 - val_loss: 33.8886\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3332 - val_loss: 33.8832\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3278 - val_loss: 33.8777\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.3224 - val_loss: 33.8722\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3170 - val_loss: 33.8667\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3116 - val_loss: 33.8612\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.3062 - val_loss: 33.8557\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.3007 - val_loss: 33.8503\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2953 - val_loss: 33.8448\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2899 - val_loss: 33.8393\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.2845 - val_loss: 33.8338\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2791 - val_loss: 33.8283\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2737 - val_loss: 33.8229\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.2683 - val_loss: 33.8174\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2629 - val_loss: 33.8119\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2575 - val_loss: 33.8064\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2521 - val_loss: 33.8010\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.2467 - val_loss: 33.7955\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2412 - val_loss: 33.7900\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2358 - val_loss: 33.7845\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 34.2304 - val_loss: 33.7791\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2250 - val_loss: 33.7736\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2196 - val_loss: 33.7681\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2142 - val_loss: 33.7627\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.2088 - val_loss: 33.7572\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.2034 - val_loss: 33.7517\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1980 - val_loss: 33.7463\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.1926 - val_loss: 33.7408\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1872 - val_loss: 33.7353\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1818 - val_loss: 33.7299\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1764 - val_loss: 33.7244\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.1711 - val_loss: 33.7189\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1657 - val_loss: 33.7135\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1603 - val_loss: 33.7080\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.1549 - val_loss: 33.7025\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1495 - val_loss: 33.6971\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1441 - val_loss: 33.6916\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1387 - val_loss: 33.6862\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.1333 - val_loss: 33.6807\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1279 - val_loss: 33.6753\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1225 - val_loss: 33.6698\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.1171 - val_loss: 33.6643\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1118 - val_loss: 33.6589\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1064 - val_loss: 33.6534\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.1010 - val_loss: 33.6480\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.0956 - val_loss: 33.6425\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0902 - val_loss: 33.6371\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0848 - val_loss: 33.6316\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0795 - val_loss: 33.6262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0741 - val_loss: 33.6207\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0687 - val_loss: 33.6153\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0633 - val_loss: 33.6098\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 34.0579 - val_loss: 33.6044\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0526 - val_loss: 33.5989\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0472 - val_loss: 33.5935\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0418 - val_loss: 33.5881\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0364 - val_loss: 33.5826\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0311 - val_loss: 33.5772\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0257 - val_loss: 33.5717\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.0203 - val_loss: 33.5663\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0149 - val_loss: 33.5608\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 34.0096 - val_loss: 33.5554\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 34.0042 - val_loss: 33.5500\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9988 - val_loss: 33.5445\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9935 - val_loss: 33.5391\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9881 - val_loss: 33.5337\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.9827 - val_loss: 33.5282\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9774 - val_loss: 33.5228\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9720 - val_loss: 33.5173\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.9666 - val_loss: 33.5119\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9613 - val_loss: 33.5065\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9559 - val_loss: 33.5010\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9505 - val_loss: 33.4956\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.9452 - val_loss: 33.4902\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9398 - val_loss: 33.4848\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9345 - val_loss: 33.4793\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9291 - val_loss: 33.4739\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9237 - val_loss: 33.4685\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9184 - val_loss: 33.4630\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9130 - val_loss: 33.4576\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.9077 - val_loss: 33.4522\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.9023 - val_loss: 33.4468\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8970 - val_loss: 33.4413\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8916 - val_loss: 33.4359\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8862 - val_loss: 33.4305\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8809 - val_loss: 33.4251\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8755 - val_loss: 33.4197\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.8702 - val_loss: 33.4142\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8648 - val_loss: 33.4088\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8595 - val_loss: 33.4034\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8541 - val_loss: 33.3980\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8488 - val_loss: 33.3926\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8434 - val_loss: 33.3872\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8381 - val_loss: 33.3817\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8328 - val_loss: 33.3763\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8274 - val_loss: 33.3709\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8221 - val_loss: 33.3655\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.8167 - val_loss: 33.3601\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8114 - val_loss: 33.3547\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.8060 - val_loss: 33.3493\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.8007 - val_loss: 33.3439\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7953 - val_loss: 33.3384\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7900 - val_loss: 33.3330\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7847 - val_loss: 33.3276\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.7793 - val_loss: 33.3222\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7740 - val_loss: 33.3168\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7687 - val_loss: 33.3114\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.7633 - val_loss: 33.3060\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7580 - val_loss: 33.3006\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7526 - val_loss: 33.2952\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7473 - val_loss: 33.2898\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7420 - val_loss: 33.2844\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7366 - val_loss: 33.2790\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7313 - val_loss: 33.2736\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 33.7260 - val_loss: 33.2682\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7207 - val_loss: 33.2628\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7153 - val_loss: 33.2574\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.7100 - val_loss: 33.2520\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.7047 - val_loss: 33.2466\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6993 - val_loss: 33.2412\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6940 - val_loss: 33.2358\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 85us/step - loss: 33.6887 - val_loss: 33.2304\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 178us/step - loss: 33.6834 - val_loss: 33.2250\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 100us/step - loss: 33.6780 - val_loss: 33.2196\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6727 - val_loss: 33.2142\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6674 - val_loss: 33.2088\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6621 - val_loss: 33.2034\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.6567 - val_loss: 33.1981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6514 - val_loss: 33.1927\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6461 - val_loss: 33.1873\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.6408 - val_loss: 33.1819\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6355 - val_loss: 33.1765\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6301 - val_loss: 33.1711\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.6248 - val_loss: 33.1657\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6195 - val_loss: 33.1603\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6142 - val_loss: 33.1550\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6089 - val_loss: 33.1496\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.6036 - val_loss: 33.1442\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5983 - val_loss: 33.1388\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5929 - val_loss: 33.1334\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.5876 - val_loss: 33.1280\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5823 - val_loss: 33.1227\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5770 - val_loss: 33.1173\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5717 - val_loss: 33.1119\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 33.5664 - val_loss: 33.1065\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5611 - val_loss: 33.1012\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5558 - val_loss: 33.0958\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5505 - val_loss: 33.0904\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 33.5452 - val_loss: 33.0850\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5398 - val_loss: 33.0797\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5345 - val_loss: 33.0743\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 33.5292 - val_loss: 33.0689\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5239 - val_loss: 33.0635\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5186 - val_loss: 33.0582\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5133 - val_loss: 33.0528\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 33.5080 - val_loss: 33.0474\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.5027 - val_loss: 33.0420\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4974 - val_loss: 33.0367\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.4921 - val_loss: 33.0313\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4868 - val_loss: 33.0259\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4815 - val_loss: 33.0206\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4762 - val_loss: 33.0152\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4709 - val_loss: 33.0098\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4656 - val_loss: 33.0045\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4603 - val_loss: 32.9991\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.4551 - val_loss: 32.9938\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4498 - val_loss: 32.9884\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4445 - val_loss: 32.9830\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4392 - val_loss: 32.9777\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.4339 - val_loss: 32.9723\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4286 - val_loss: 32.9669\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4233 - val_loss: 32.9616\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.4180 - val_loss: 32.9562\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4127 - val_loss: 32.9509\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.4074 - val_loss: 32.9455\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.4021 - val_loss: 32.9402\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3969 - val_loss: 32.9348\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3916 - val_loss: 32.9295\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.3863 - val_loss: 32.9241\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3810 - val_loss: 32.9187\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3757 - val_loss: 32.9134\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3704 - val_loss: 32.9080\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.3652 - val_loss: 32.9027\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3599 - val_loss: 32.8973\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3546 - val_loss: 32.8920\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3493 - val_loss: 32.8866\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3440 - val_loss: 32.8813\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3387 - val_loss: 32.8759\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3335 - val_loss: 32.8706\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.3282 - val_loss: 32.8652\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3229 - val_loss: 32.8599\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3176 - val_loss: 32.8546\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 33.3124 - val_loss: 32.8492\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3071 - val_loss: 32.8439\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.3018 - val_loss: 32.8385\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2965 - val_loss: 32.8332\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 33.2913 - val_loss: 32.8278\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2860 - val_loss: 32.8225\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2807 - val_loss: 32.8172\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 33.2755 - val_loss: 32.8118\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2702 - val_loss: 32.8065\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2649 - val_loss: 32.8011\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2596 - val_loss: 32.7958\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.2544 - val_loss: 32.7905\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2491 - val_loss: 32.7851\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2438 - val_loss: 32.7798\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.2386 - val_loss: 32.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2333 - val_loss: 32.7691\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2280 - val_loss: 32.7638\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2228 - val_loss: 32.7585\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.2175 - val_loss: 32.7531\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2123 - val_loss: 32.7478\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.2070 - val_loss: 32.7425\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.2017 - val_loss: 32.7371\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1965 - val_loss: 32.7318\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1912 - val_loss: 32.7265\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1859 - val_loss: 32.7211\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1807 - val_loss: 32.7158\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1754 - val_loss: 32.7105\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1702 - val_loss: 32.7052\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.1649 - val_loss: 32.6998\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1597 - val_loss: 32.6945\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.1544 - val_loss: 32.6892\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1492 - val_loss: 32.6839\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1439 - val_loss: 32.6786\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.1386 - val_loss: 32.6732\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1334 - val_loss: 32.6679\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1281 - val_loss: 32.6626\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1229 - val_loss: 32.6573\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.1176 - val_loss: 32.6519\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1124 - val_loss: 32.6466\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1071 - val_loss: 32.6413\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.1019 - val_loss: 32.6360\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0966 - val_loss: 32.6307\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0914 - val_loss: 32.6254\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0862 - val_loss: 32.6200\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0809 - val_loss: 32.6147\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0757 - val_loss: 32.6094\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0704 - val_loss: 32.6041\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0652 - val_loss: 32.5988\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0599 - val_loss: 32.5935\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0547 - val_loss: 32.5882\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0494 - val_loss: 32.5829\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0442 - val_loss: 32.5775\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0390 - val_loss: 32.5722\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0337 - val_loss: 32.5669\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0285 - val_loss: 32.5616\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0232 - val_loss: 32.5563\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0180 - val_loss: 32.5510\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0128 - val_loss: 32.5457\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.0075 - val_loss: 32.5404\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 33.0023 - val_loss: 32.5351\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9971 - val_loss: 32.5298\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9918 - val_loss: 32.5245\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9866 - val_loss: 32.5192\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9814 - val_loss: 32.5139\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9761 - val_loss: 32.5086\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9709 - val_loss: 32.5033\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.9657 - val_loss: 32.4980\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9604 - val_loss: 32.4927\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9552 - val_loss: 32.4874\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9500 - val_loss: 32.4821\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.9447 - val_loss: 32.4768\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9395 - val_loss: 32.4715\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9343 - val_loss: 32.4662\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.9291 - val_loss: 32.4609\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9238 - val_loss: 32.4556\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9186 - val_loss: 32.4503\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.9134 - val_loss: 32.4450\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9082 - val_loss: 32.4397\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.9029 - val_loss: 32.4344\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8977 - val_loss: 32.4291\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.8925 - val_loss: 32.4238\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8873 - val_loss: 32.4185\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8820 - val_loss: 32.4132\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.8768 - val_loss: 32.4080\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8716 - val_loss: 32.4027\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8664 - val_loss: 32.3974\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8612 - val_loss: 32.3921\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8559 - val_loss: 32.3868\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8507 - val_loss: 32.3815\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8455 - val_loss: 32.3762\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.8403 - val_loss: 32.3709\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8351 - val_loss: 32.3657\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8299 - val_loss: 32.3604\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.8247 - val_loss: 32.3551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8194 - val_loss: 32.3498\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8142 - val_loss: 32.3445\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.8090 - val_loss: 32.3393\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.8038 - val_loss: 32.3340\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7986 - val_loss: 32.3287\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7934 - val_loss: 32.3234\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7882 - val_loss: 32.3181\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.7830 - val_loss: 32.3129\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7778 - val_loss: 32.3076\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7726 - val_loss: 32.3023\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.7673 - val_loss: 32.2970\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7621 - val_loss: 32.2918\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7569 - val_loss: 32.2865\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7517 - val_loss: 32.2812\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.7465 - val_loss: 32.2759\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7413 - val_loss: 32.2707\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7361 - val_loss: 32.2654\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.7309 - val_loss: 32.2601\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7257 - val_loss: 32.2548\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7205 - val_loss: 32.2496\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7153 - val_loss: 32.2443\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7101 - val_loss: 32.2390\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.7049 - val_loss: 32.2338\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6997 - val_loss: 32.2285\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.6945 - val_loss: 32.2232\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6893 - val_loss: 32.2180\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6841 - val_loss: 32.2127\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6789 - val_loss: 32.2074\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.6737 - val_loss: 32.2022\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6685 - val_loss: 32.1969\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6633 - val_loss: 32.1916\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.6581 - val_loss: 32.1864\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6530 - val_loss: 32.1811\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6478 - val_loss: 32.1758\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6426 - val_loss: 32.1706\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 32.6374 - val_loss: 32.1653\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6322 - val_loss: 32.1601\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6270 - val_loss: 32.1548\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.6218 - val_loss: 32.1495\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6166 - val_loss: 32.1443\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6114 - val_loss: 32.1390\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6062 - val_loss: 32.1338\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.6011 - val_loss: 32.1285\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5959 - val_loss: 32.1233\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5907 - val_loss: 32.1180\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.5855 - val_loss: 32.1128\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5803 - val_loss: 32.1075\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5751 - val_loss: 32.1022\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5699 - val_loss: 32.0970\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5648 - val_loss: 32.0917\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5596 - val_loss: 32.0865\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5544 - val_loss: 32.0812\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.5492 - val_loss: 32.0760\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5440 - val_loss: 32.0707\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5389 - val_loss: 32.0655\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5337 - val_loss: 32.0602\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.5285 - val_loss: 32.0550\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 211us/step - loss: 32.5233 - val_loss: 32.0497\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 92us/step - loss: 32.5181 - val_loss: 32.0445\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 79us/step - loss: 32.5130 - val_loss: 32.0393\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5078 - val_loss: 32.0340\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.5026 - val_loss: 32.0288\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.4974 - val_loss: 32.0235\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4923 - val_loss: 32.0183\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4871 - val_loss: 32.0130\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4819 - val_loss: 32.0078\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.4767 - val_loss: 32.0025\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4716 - val_loss: 31.9973\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4664 - val_loss: 31.9921\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.4612 - val_loss: 31.9868\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4561 - val_loss: 31.9816\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4509 - val_loss: 31.9763\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4457 - val_loss: 31.9711\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.4406 - val_loss: 31.9659\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4354 - val_loss: 31.9606\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4302 - val_loss: 31.9554\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.4251 - val_loss: 31.9502\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4199 - val_loss: 31.9449\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4147 - val_loss: 31.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.4096 - val_loss: 31.9345\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.4044 - val_loss: 31.9292\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3992 - val_loss: 31.9240\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3941 - val_loss: 31.9188\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3889 - val_loss: 31.9135\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3837 - val_loss: 31.9083\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3786 - val_loss: 31.9031\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3734 - val_loss: 31.8978\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.3683 - val_loss: 31.8926\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3631 - val_loss: 31.8874\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3579 - val_loss: 31.8821\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3528 - val_loss: 31.8769\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3476 - val_loss: 31.8717\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3425 - val_loss: 31.8665\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3373 - val_loss: 31.8612\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.3322 - val_loss: 31.8560\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3270 - val_loss: 31.8508\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3218 - val_loss: 31.8456\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.3167 - val_loss: 31.8403\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3115 - val_loss: 31.8351\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3064 - val_loss: 31.8299\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.3012 - val_loss: 31.8247\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.2961 - val_loss: 31.8195\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2909 - val_loss: 31.8142\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2858 - val_loss: 31.8090\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2806 - val_loss: 31.8038\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2755 - val_loss: 31.7986\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2703 - val_loss: 31.7934\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2652 - val_loss: 31.7881\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.2600 - val_loss: 31.7829\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2549 - val_loss: 31.7777\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2497 - val_loss: 31.7725\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.2446 - val_loss: 31.7673\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2395 - val_loss: 31.7621\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2343 - val_loss: 31.7568\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2292 - val_loss: 31.7516\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.2240 - val_loss: 31.7464\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2189 - val_loss: 31.7412\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2137 - val_loss: 31.7360\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.2086 - val_loss: 31.7308\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.2035 - val_loss: 31.7256\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1983 - val_loss: 31.7204\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1932 - val_loss: 31.7152\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.1880 - val_loss: 31.7099\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1829 - val_loss: 31.7047\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1778 - val_loss: 31.6995\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1726 - val_loss: 31.6943\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1675 - val_loss: 31.6891\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1623 - val_loss: 31.6839\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1572 - val_loss: 31.6787\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.1521 - val_loss: 31.6735\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1469 - val_loss: 31.6683\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1418 - val_loss: 31.6631\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.1367 - val_loss: 31.6579\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1315 - val_loss: 31.6527\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1264 - val_loss: 31.6475\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1213 - val_loss: 31.6423\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.1161 - val_loss: 31.6371\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1110 - val_loss: 31.6319\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.1059 - val_loss: 31.6267\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.1007 - val_loss: 31.6215\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0956 - val_loss: 31.6163\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0905 - val_loss: 31.6111\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0854 - val_loss: 31.6059\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 32.0802 - val_loss: 31.6007\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0751 - val_loss: 31.5955\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0700 - val_loss: 31.5903\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 32.0649 - val_loss: 31.5851\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0597 - val_loss: 31.5799\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0546 - val_loss: 31.5747\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0495 - val_loss: 31.5695\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0444 - val_loss: 31.5643\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0392 - val_loss: 31.5591\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0341 - val_loss: 31.5539\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 32.0290 - val_loss: 31.5487\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0239 - val_loss: 31.5435\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0187 - val_loss: 31.5384\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0136 - val_loss: 31.5332\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 32.0085 - val_loss: 31.5280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 32.0034 - val_loss: 31.5228\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9983 - val_loss: 31.5176\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9932 - val_loss: 31.5124\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9880 - val_loss: 31.5072\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9829 - val_loss: 31.5020\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9778 - val_loss: 31.4969\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.9727 - val_loss: 31.4917\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9676 - val_loss: 31.4865\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9625 - val_loss: 31.4813\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.9573 - val_loss: 31.4761\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9522 - val_loss: 31.4709\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9471 - val_loss: 31.4657\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9420 - val_loss: 31.4606\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9369 - val_loss: 31.4554\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9318 - val_loss: 31.4502\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9267 - val_loss: 31.4450\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.9216 - val_loss: 31.4398\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9165 - val_loss: 31.4347\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9113 - val_loss: 31.4295\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.9062 - val_loss: 31.4243\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.9011 - val_loss: 31.4191\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8960 - val_loss: 31.4139\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8909 - val_loss: 31.4088\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.8858 - val_loss: 31.4036\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8807 - val_loss: 31.3984\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8756 - val_loss: 31.3932\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.8705 - val_loss: 31.3881\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8654 - val_loss: 31.3829\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8603 - val_loss: 31.3777\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8552 - val_loss: 31.3725\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.8501 - val_loss: 31.3674\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8450 - val_loss: 31.3622\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8399 - val_loss: 31.3570\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.8348 - val_loss: 31.3519\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8297 - val_loss: 31.3467\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8246 - val_loss: 31.3415\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8195 - val_loss: 31.3363\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.8144 - val_loss: 31.3312\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8093 - val_loss: 31.3260\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.8042 - val_loss: 31.3208\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.7991 - val_loss: 31.3157\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7940 - val_loss: 31.3105\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7889 - val_loss: 31.3053\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7838 - val_loss: 31.3002\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.7787 - val_loss: 31.2950\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7736 - val_loss: 31.2898\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7685 - val_loss: 31.2847\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7634 - val_loss: 31.2795\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7583 - val_loss: 31.2744\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7532 - val_loss: 31.2692\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7481 - val_loss: 31.2640\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.7430 - val_loss: 31.2589\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7380 - val_loss: 31.2537\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7329 - val_loss: 31.2485\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7278 - val_loss: 31.2434\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.7227 - val_loss: 31.2382\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7176 - val_loss: 31.2331\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7125 - val_loss: 31.2279\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.7074 - val_loss: 31.2228\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.7023 - val_loss: 31.2176\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6972 - val_loss: 31.2124\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6922 - val_loss: 31.2073\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6871 - val_loss: 31.2021\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6820 - val_loss: 31.1970\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6769 - val_loss: 31.1918\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.6718 - val_loss: 31.1867\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6667 - val_loss: 31.1815\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6617 - val_loss: 31.1764\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6566 - val_loss: 31.1712\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6515 - val_loss: 31.1661\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6464 - val_loss: 31.1609\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6413 - val_loss: 31.1558\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.6363 - val_loss: 31.1506\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6312 - val_loss: 31.1455\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6261 - val_loss: 31.1403\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.6210 - val_loss: 31.1352\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6159 - val_loss: 31.1300\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6109 - val_loss: 31.1249\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.6058 - val_loss: 31.1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.6007 - val_loss: 31.1146\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5956 - val_loss: 31.1094\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5906 - val_loss: 31.1043\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5855 - val_loss: 31.0991\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.5804 - val_loss: 31.0940\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5753 - val_loss: 31.0888\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5703 - val_loss: 31.0837\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.5652 - val_loss: 31.0786\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5601 - val_loss: 31.0734\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5550 - val_loss: 31.0683\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5500 - val_loss: 31.0631\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.5449 - val_loss: 31.0580\n",
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5398 - val_loss: 31.0529\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5348 - val_loss: 31.0477\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.5297 - val_loss: 31.0426\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5246 - val_loss: 31.0374\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5196 - val_loss: 31.0323\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.5145 - val_loss: 31.0272\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5094 - val_loss: 31.0220\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.5044 - val_loss: 31.0169\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4993 - val_loss: 31.0117\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.4942 - val_loss: 31.0066\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4892 - val_loss: 31.0015\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4841 - val_loss: 30.9963\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.4790 - val_loss: 30.9912\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4740 - val_loss: 30.9861\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4689 - val_loss: 30.9809\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4638 - val_loss: 30.9758\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.4588 - val_loss: 30.9707\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4537 - val_loss: 30.9655\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4487 - val_loss: 30.9604\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.4436 - val_loss: 30.9553\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4385 - val_loss: 30.9502\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4335 - val_loss: 30.9450\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4284 - val_loss: 30.9399\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4234 - val_loss: 30.9348\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4183 - val_loss: 30.9296\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4132 - val_loss: 30.9245\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.4082 - val_loss: 30.9194\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.4031 - val_loss: 30.9143\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3981 - val_loss: 30.9091\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3930 - val_loss: 30.9040\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.3880 - val_loss: 30.8989\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 257us/step - loss: 31.3829 - val_loss: 30.8938\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 137us/step - loss: 31.3779 - val_loss: 30.8886\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 96us/step - loss: 31.3728 - val_loss: 30.8835\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3677 - val_loss: 30.8784\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3627 - val_loss: 30.8733\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3576 - val_loss: 30.8681\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.3526 - val_loss: 30.8630\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3475 - val_loss: 30.8579\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3425 - val_loss: 30.8528\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.3374 - val_loss: 30.8477\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3324 - val_loss: 30.8425\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3273 - val_loss: 30.8374\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.3223 - val_loss: 30.8323\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3172 - val_loss: 30.8272\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3122 - val_loss: 30.8221\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.3071 - val_loss: 30.8169\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.3021 - val_loss: 30.8118\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2971 - val_loss: 30.8067\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2920 - val_loss: 30.8016\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.2870 - val_loss: 30.7965\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2819 - val_loss: 30.7914\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2769 - val_loss: 30.7863\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.2718 - val_loss: 30.7811\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2668 - val_loss: 30.7760\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2617 - val_loss: 30.7709\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2567 - val_loss: 30.7658\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.2517 - val_loss: 30.7607\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2466 - val_loss: 30.7556\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2416 - val_loss: 30.7505\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.2365 - val_loss: 30.7454\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2315 - val_loss: 30.7402\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2265 - val_loss: 30.7351\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2214 - val_loss: 30.7300\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.2164 - val_loss: 30.7249\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2114 - val_loss: 30.7198\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.2063 - val_loss: 30.7147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.2013 - val_loss: 30.7096\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1962 - val_loss: 30.7045\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1912 - val_loss: 30.6994\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1862 - val_loss: 30.6943\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.1811 - val_loss: 30.6892\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1761 - val_loss: 30.6841\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1711 - val_loss: 30.6790\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.1660 - val_loss: 30.6739\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1610 - val_loss: 30.6688\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1560 - val_loss: 30.6637\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1509 - val_loss: 30.6586\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.1459 - val_loss: 30.6534\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1409 - val_loss: 30.6483\n",
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1358 - val_loss: 30.6432\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.1308 - val_loss: 30.6381\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1258 - val_loss: 30.6330\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1208 - val_loss: 30.6279\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1157 - val_loss: 30.6228\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.1107 - val_loss: 30.6178\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1057 - val_loss: 30.6127\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.1006 - val_loss: 30.6076\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.0956 - val_loss: 30.6025\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0906 - val_loss: 30.5974\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0856 - val_loss: 30.5923\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0805 - val_loss: 30.5872\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 31.0755 - val_loss: 30.5821\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0705 - val_loss: 30.5770\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0655 - val_loss: 30.5719\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 31.0604 - val_loss: 30.5668\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0554 - val_loss: 30.5617\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0504 - val_loss: 30.5566\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0454 - val_loss: 30.5515\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0404 - val_loss: 30.5464\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0353 - val_loss: 30.5413\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0303 - val_loss: 30.5362\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.0253 - val_loss: 30.5311\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0203 - val_loss: 30.5261\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0153 - val_loss: 30.5210\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.0102 - val_loss: 30.5159\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0052 - val_loss: 30.5108\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 31.0002 - val_loss: 30.5057\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9952 - val_loss: 30.5006\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 30.9902 - val_loss: 30.4955\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9852 - val_loss: 30.4904\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9801 - val_loss: 30.4854\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 30.9751 - val_loss: 30.4803\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9701 - val_loss: 30.4752\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9651 - val_loss: 30.4701\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9601 - val_loss: 30.4650\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 30.9551 - val_loss: 30.4599\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9501 - val_loss: 30.4548\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9450 - val_loss: 30.4498\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 30.9400 - val_loss: 30.4447\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9350 - val_loss: 30.4396\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9300 - val_loss: 30.4345\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9250 - val_loss: 30.4294\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 30.9200 - val_loss: 30.4244\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9150 - val_loss: 30.4193\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9100 - val_loss: 30.4142\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 30.9050 - val_loss: 30.4091\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.9000 - val_loss: 30.4040\n",
      "30.49921989440918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.27329165, -0.13302097,  0.2653236 ,  0.19208816, -0.5837717 ],\n",
       "        [ 0.10231543,  0.7499549 ,  0.23936205,  0.5341293 ,  0.75497675],\n",
       "        [ 0.72581214, -0.79050475,  0.36488077, -0.24614193,  0.17588478]],\n",
       "       dtype=float32),\n",
       " array([-0.02444298, -0.01294862,  0.0406203 ,  0.00543027,  0.01965185],\n",
       "       dtype=float32),\n",
       " array([[ 0.13448219,  0.4066646 ,  0.33047602, -0.53340364, -0.14590316,\n",
       "         -0.61134714, -0.60923195,  0.47031373,  0.33777714, -0.488678  ],\n",
       "        [ 0.27700388, -0.22296569, -0.02444633, -0.26447397, -0.00203225,\n",
       "          0.22206406,  0.1464017 , -0.3197855 , -0.16842839, -0.17485476],\n",
       "        [-0.43849042, -0.21041742, -0.19037223,  0.02997789, -0.41673768,\n",
       "         -0.25269935,  0.05500212,  0.29766387,  0.23217916,  0.00433868],\n",
       "        [ 0.4229257 , -0.30426705, -0.28446198,  0.00295528,  0.59689504,\n",
       "         -0.10025524, -0.23799136, -0.02643682, -0.16870685, -0.47045293],\n",
       "        [ 0.30463013, -0.4159491 , -0.10106722,  0.21957709, -0.24719037,\n",
       "          0.46219468,  0.5742015 ,  0.17895474,  0.59686685, -0.5333627 ]],\n",
       "       dtype=float32),\n",
       " array([-0.09398332, -0.01132018, -0.11915886, -0.01824647,  0.02445269,\n",
       "         0.11552256, -0.05913313,  0.05777508,  0.04548423, -0.00319799],\n",
       "       dtype=float32),\n",
       " array([[-0.4725033 ],\n",
       "        [-0.06124266],\n",
       "        [-0.60497034],\n",
       "        [-0.0957728 ],\n",
       "        [ 0.121825  ],\n",
       "        [ 0.5872425 ],\n",
       "        [-0.29818925],\n",
       "        [ 0.2941737 ],\n",
       "        [ 0.23460773],\n",
       "        [-0.02381198]], dtype=float32),\n",
       " array([0.1997054], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, sgd, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_sgd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32 samples, validate on 7 samples\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 43.2336 - val_loss: 37.5035\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 52us/step - loss: 38.2989 - val_loss: 34.7727\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 35.6695 - val_loss: 32.6685\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 33.6879 - val_loss: 30.8448\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 31.9588 - val_loss: 29.1799\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 30.3247 - val_loss: 27.5997\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 28.7216 - val_loss: 26.0649\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 27.1296 - val_loss: 24.5588\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 25.5464 - val_loss: 23.0761\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 23.9752 - val_loss: 21.6173\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 22.4198 - val_loss: 20.1859\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 20.8830 - val_loss: 18.7862\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 19.3664 - val_loss: 17.4230\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 17.8707 - val_loss: 16.0994\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 16.3961 - val_loss: 14.8147\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 14.9439 - val_loss: 13.5637\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 13.5176 - val_loss: 12.3404\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 12.1240 - val_loss: 11.1422\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 10.7725 - val_loss: 9.9707\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 9.4732 - val_loss: 8.8316\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 8.2369 - val_loss: 7.7329\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 7.0737 - val_loss: 6.6839\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.9928 - val_loss: 5.6941\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 5.0023 - val_loss: 4.7730\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 4.1085 - val_loss: 3.9293\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 3.3154 - val_loss: 3.1709\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.6251 - val_loss: 2.5037\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 2.0370 - val_loss: 1.9309\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 1.5478 - val_loss: 1.4527\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 1.1515 - val_loss: 1.0653\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.8399 - val_loss: 0.7617\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.6027 - val_loss: 0.5320\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.4284 - val_loss: 0.3646\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.3051 - val_loss: 0.2470\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.2214 - val_loss: 0.1673\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1668 - val_loss: 0.1151\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1327 - val_loss: 0.0817\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1121 - val_loss: 0.0607\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.1000 - val_loss: 0.0476\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0929 - val_loss: 0.0394\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0886 - val_loss: 0.0342\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0858 - val_loss: 0.0309\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0837 - val_loss: 0.0287\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0820 - val_loss: 0.0272\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0804 - val_loss: 0.0261\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0789 - val_loss: 0.0253\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0775 - val_loss: 0.0247\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0760 - val_loss: 0.0241\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0745 - val_loss: 0.0236\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0731 - val_loss: 0.0232\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0716 - val_loss: 0.0228\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0702 - val_loss: 0.0223\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0688 - val_loss: 0.0220\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0674 - val_loss: 0.0216\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0664 - val_loss: 0.0241\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0693 - val_loss: 0.0355\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0956 - val_loss: 0.0501\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1174 - val_loss: 0.0445\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.1015 - val_loss: 0.0316\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0826 - val_loss: 0.0268\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0716 - val_loss: 0.0217\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0661 - val_loss: 0.0213\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0631 - val_loss: 0.0192\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0614 - val_loss: 0.0199\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0605 - val_loss: 0.0187\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0601 - val_loss: 0.0205\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0606 - val_loss: 0.0204\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0625 - val_loss: 0.0251\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0666 - val_loss: 0.0272\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0737 - val_loss: 0.0366\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0827 - val_loss: 0.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0883 - val_loss: 0.0399\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0870 - val_loss: 0.0284\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0795 - val_loss: 0.0304\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0721 - val_loss: 0.0204\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0657 - val_loss: 0.0240\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0619 - val_loss: 0.0170\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0593 - val_loss: 0.0221\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0582 - val_loss: 0.0163\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0580 - val_loss: 0.0237\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0592 - val_loss: 0.0177\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0614 - val_loss: 0.0295\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0651 - val_loss: 0.0204\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0691 - val_loss: 0.0394\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0737 - val_loss: 0.0216\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0766 - val_loss: 0.0551\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0812 - val_loss: 0.0262\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0857 - val_loss: 0.0811\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0938 - val_loss: 0.0317\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0887 - val_loss: 0.0726\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0864 - val_loss: 0.0219\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0763 - val_loss: 0.0498\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0786 - val_loss: 0.0200\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0761 - val_loss: 0.0424\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0757 - val_loss: 0.0202\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0689 - val_loss: 0.0364\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0640 - val_loss: 0.0185\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0586 - val_loss: 0.0311\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0556 - val_loss: 0.0182\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0534 - val_loss: 0.0293\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0528 - val_loss: 0.0204\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0531 - val_loss: 0.0305\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0541 - val_loss: 0.0245\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0555 - val_loss: 0.0316\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0565 - val_loss: 0.0270\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0569 - val_loss: 0.0279\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0558 - val_loss: 0.0254\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0544 - val_loss: 0.0188\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0527 - val_loss: 0.0273\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0537 - val_loss: 0.0141\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0596 - val_loss: 0.0690\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0789 - val_loss: 0.0476\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1045 - val_loss: 0.1140\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1138 - val_loss: 0.0267\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0784 - val_loss: 0.0495\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0628 - val_loss: 0.0086\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0503 - val_loss: 0.0277\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0485 - val_loss: 0.0082\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0476 - val_loss: 0.0273\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0504 - val_loss: 0.0135\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0527 - val_loss: 0.0351\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0565 - val_loss: 0.0215\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0579 - val_loss: 0.0409\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0586 - val_loss: 0.0254\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0563 - val_loss: 0.0386\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0536 - val_loss: 0.0243\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0502 - val_loss: 0.0332\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0474 - val_loss: 0.0225\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0452 - val_loss: 0.0299\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0438 - val_loss: 0.0223\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0430 - val_loss: 0.0299\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0428 - val_loss: 0.0240\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0432 - val_loss: 0.0339\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0439 - val_loss: 0.0275\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0454 - val_loss: 0.0472\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0484 - val_loss: 0.0372\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0550 - val_loss: 0.0865\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0702 - val_loss: 0.0513\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0857 - val_loss: 0.0979\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0987 - val_loss: 0.0216\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0841 - val_loss: 0.0588\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0777 - val_loss: 0.0117\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0547 - val_loss: 0.0320\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0444 - val_loss: 0.0060\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0360 - val_loss: 0.0218\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 258us/step - loss: 0.0331 - val_loss: 0.0052\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 74us/step - loss: 0.0316 - val_loss: 0.0209\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0326 - val_loss: 0.0072\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0353 - val_loss: 0.0269\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0415 - val_loss: 0.0137\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0508 - val_loss: 0.0377\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0619 - val_loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0634 - val_loss: 0.0330\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0571 - val_loss: 0.0134\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0458 - val_loss: 0.0213\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0384 - val_loss: 0.0086\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0332 - val_loss: 0.0165\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0306 - val_loss: 0.0063\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0294 - val_loss: 0.0187\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0301 - val_loss: 0.0057\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0338 - val_loss: 0.0444\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0475 - val_loss: 0.0358\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0810 - val_loss: 0.1243\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1147 - val_loss: 0.0360\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0838 - val_loss: 0.0601\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0692 - val_loss: 0.0122\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0522 - val_loss: 0.0313\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0476 - val_loss: 0.0129\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0418 - val_loss: 0.0257\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0397 - val_loss: 0.0170\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0380 - val_loss: 0.0248\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0377 - val_loss: 0.0210\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0375 - val_loss: 0.0241\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0374 - val_loss: 0.0230\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0370 - val_loss: 0.0216\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0362 - val_loss: 0.0223\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0352 - val_loss: 0.0177\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0340 - val_loss: 0.0207\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0333 - val_loss: 0.0130\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0327 - val_loss: 0.0212\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0337 - val_loss: 0.0090\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0367 - val_loss: 0.0388\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0464 - val_loss: 0.0249\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0647 - val_loss: 0.1008\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0916 - val_loss: 0.0381\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0826 - val_loss: 0.0708\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0674 - val_loss: 0.0098\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0449 - val_loss: 0.0326\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0399 - val_loss: 0.0050\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0365 - val_loss: 0.0260\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0380 - val_loss: 0.0093\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0383 - val_loss: 0.0299\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 535us/step - loss: 0.0407 - val_loss: 0.0172\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0411 - val_loss: 0.0347\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 141us/step - loss: 0.0421 - val_loss: 0.0228\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0407 - val_loss: 0.0341\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0393 - val_loss: 0.0236\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0368 - val_loss: 0.0302\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 125us/step - loss: 0.0349 - val_loss: 0.0226\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0330 - val_loss: 0.0273\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0318 - val_loss: 0.0226\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0310 - val_loss: 0.0275\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0308 - val_loss: 0.0245\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0312 - val_loss: 0.0324\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0321 - val_loss: 0.0292\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0337 - val_loss: 0.0470\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0372 - val_loss: 0.0391\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0435 - val_loss: 0.0800\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0570 - val_loss: 0.0443\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0707 - val_loss: 0.0905\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0878 - val_loss: 0.0197\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0766 - val_loss: 0.0581\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0672 - val_loss: 0.0075\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0418 - val_loss: 0.0278\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0312 - val_loss: 0.0025\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0238 - val_loss: 0.0180\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0213 - val_loss: 0.0022\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0210 - val_loss: 0.0040\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0235 - val_loss: 0.0237\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0295 - val_loss: 0.0113\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0395 - val_loss: 0.0371\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0530 - val_loss: 0.0182\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0567 - val_loss: 0.0335\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0503 - val_loss: 0.0102\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0371 - val_loss: 0.0221\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0295 - val_loss: 0.0045\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0252 - val_loss: 0.0246\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0261 - val_loss: 0.0081\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0331 - val_loss: 0.0607\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0531 - val_loss: 0.0363\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0726 - val_loss: 0.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0808 - val_loss: 0.0213\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0581 - val_loss: 0.0426\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0487 - val_loss: 0.0094\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0314 - val_loss: 0.0093\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0274 - val_loss: 0.0202\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0265 - val_loss: 0.0136\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0266 - val_loss: 0.0221\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0284 - val_loss: 0.0213\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0307 - val_loss: 0.0259\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0329 - val_loss: 0.0273\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0325 - val_loss: 0.0251\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0303 - val_loss: 0.0161\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0274 - val_loss: 0.0205\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0255 - val_loss: 0.0081\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0253\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0291 - val_loss: 0.0144\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0437 - val_loss: 0.0870\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0764 - val_loss: 0.0489\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0852 - val_loss: 0.0815\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0715 - val_loss: 0.0125\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0412 - val_loss: 0.0318\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0321 - val_loss: 0.0025\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0273 - val_loss: 0.0215\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0292 - val_loss: 0.0042\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0305 - val_loss: 0.0242\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0337 - val_loss: 0.0122\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0352 - val_loss: 0.0330\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0380 - val_loss: 0.0216\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0374 - val_loss: 0.0365\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0367 - val_loss: 0.0234\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0332 - val_loss: 0.0324\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0307 - val_loss: 0.0208\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0277 - val_loss: 0.0287\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0262 - val_loss: 0.0195\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0250 - val_loss: 0.0298\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0253 - val_loss: 0.0212\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0261 - val_loss: 0.0380\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0288 - val_loss: 0.0260\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0324 - val_loss: 0.0555\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0408 - val_loss: 0.0284\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0510 - val_loss: 0.0740\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0713 - val_loss: 0.0219\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0727 - val_loss: 0.0618\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0677 - val_loss: 0.0102\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0407 - val_loss: 0.0285\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0288 - val_loss: 0.0031\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0203 - val_loss: 0.0167\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0175 - val_loss: 0.0026\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0165 - val_loss: 0.0154\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0180 - val_loss: 0.0054\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0221 - val_loss: 0.0213\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0309 - val_loss: 0.0130\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0410 - val_loss: 0.0271\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0458 - val_loss: 0.0132\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0377 - val_loss: 0.0193\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0296 - val_loss: 0.0076\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0224 - val_loss: 0.0132\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0186 - val_loss: 0.0044\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0162 - val_loss: 0.0029\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0183 - val_loss: 0.0311\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0290 - val_loss: 0.0312\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0626 - val_loss: 0.1199\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.1073 - val_loss: 0.0402\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0759 - val_loss: 0.0544\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0545 - val_loss: 0.0084\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0338 - val_loss: 0.0224\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0293 - val_loss: 0.0075\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0255 - val_loss: 0.0183\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0253 - val_loss: 0.0128\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0252 - val_loss: 0.0206\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0267 - val_loss: 0.0220\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0266 - val_loss: 0.0197\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0254 - val_loss: 0.0201\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0238 - val_loss: 0.0175\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0221 - val_loss: 0.0185\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0209 - val_loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0204 - val_loss: 0.0222\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0212 - val_loss: 0.0185\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0242 - val_loss: 0.0445\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0335 - val_loss: 0.0394\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0513 - val_loss: 0.0939\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0774 - val_loss: 0.0339\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0701 - val_loss: 0.0589\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0611 - val_loss: 0.0090\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0404 - val_loss: 0.0303\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0320 - val_loss: 0.0042\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0221 - val_loss: 0.0176\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0178 - val_loss: 0.0023\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0142 - val_loss: 0.0028\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0145 - val_loss: 0.0169\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0172 - val_loss: 0.0067\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0223 - val_loss: 0.0274\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0325 - val_loss: 0.0148\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0437 - val_loss: 0.0348\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0502 - val_loss: 0.0123\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0402 - val_loss: 0.0261\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0312 - val_loss: 0.0064\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0248 - val_loss: 0.0301\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0269 - val_loss: 0.0151\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0347 - val_loss: 0.0597\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0506 - val_loss: 0.0312\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0552 - val_loss: 0.0607\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0567 - val_loss: 0.0198\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0428 - val_loss: 0.0344\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0374 - val_loss: 0.0116\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0285 - val_loss: 0.0220\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0250 - val_loss: 0.0102\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0214 - val_loss: 0.0182\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0204 - val_loss: 0.0118\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0204 - val_loss: 0.0155\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0212 - val_loss: 0.0229\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0227 - val_loss: 0.0199\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0236 - val_loss: 0.0277\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0247 - val_loss: 0.0229\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0251 - val_loss: 0.0357\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0269 - val_loss: 0.0285\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0302 - val_loss: 0.0574\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0397 - val_loss: 0.0381\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0497 - val_loss: 0.0725\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 543us/step - loss: 0.0619 - val_loss: 0.0207\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 167us/step - loss: 0.0523 - val_loss: 0.0452\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 55us/step - loss: 0.0476 - val_loss: 0.0093\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0347 - val_loss: 0.0272\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0282 - val_loss: 0.0045\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0195 - val_loss: 0.0154\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0156 - val_loss: 0.0018\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0119 - val_loss: 0.0014\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0133 - val_loss: 0.0032\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0165 - val_loss: 0.0229\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0244 - val_loss: 0.0122\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0375 - val_loss: 0.0409\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0544 - val_loss: 0.0178\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0505 - val_loss: 0.0310\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0378 - val_loss: 0.0071\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0248 - val_loss: 0.0232\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0214 - val_loss: 0.0083\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0226 - val_loss: 0.0387\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0321 - val_loss: 0.0263\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0440 - val_loss: 0.0631\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0581 - val_loss: 0.0311\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0527 - val_loss: 0.0452\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0470 - val_loss: 0.0169\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0248 - val_loss: 0.0095\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0186 - val_loss: 0.0156\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0161 - val_loss: 0.0078\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0152 - val_loss: 0.0193\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0174 - val_loss: 0.0157\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0203 - val_loss: 0.0314\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0252 - val_loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0298 - val_loss: 0.0499\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0363 - val_loss: 0.0356\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0388 - val_loss: 0.0581\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0426 - val_loss: 0.0261\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0378 - val_loss: 0.0422\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0365 - val_loss: 0.0091\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0313 - val_loss: 0.0306\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0342 - val_loss: 0.0102\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0329 - val_loss: 0.0277\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0293 - val_loss: 0.0067\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0208 - val_loss: 0.0167\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0163 - val_loss: 0.0031\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0127 - val_loss: 0.0029\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0175 - val_loss: 0.0065\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0328 - val_loss: 0.0103\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0335 - val_loss: 0.0222\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0292 - val_loss: 0.0064\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0225 - val_loss: 0.0194\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0201 - val_loss: 0.0070\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0212 - val_loss: 0.0357\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0306 - val_loss: 0.0269\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0443 - val_loss: 0.0668\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0584 - val_loss: 0.0330\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0511 - val_loss: 0.0475\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0478 - val_loss: 0.0204\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0356 - val_loss: 0.0278\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0298 - val_loss: 0.0139\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0225 - val_loss: 0.0179\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0188 - val_loss: 0.0098\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0144\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0137 - val_loss: 0.0160\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0242\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0190 - val_loss: 0.0207\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0232 - val_loss: 0.0434\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0308 - val_loss: 0.0355\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0366 - val_loss: 0.0613\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0431 - val_loss: 0.0330\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0383 - val_loss: 0.0458\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0352 - val_loss: 0.0140\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0268 - val_loss: 0.0249\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0253 - val_loss: 0.0047\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0254 - val_loss: 0.0222\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0302 - val_loss: 0.0075\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0278 - val_loss: 0.0213\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0252 - val_loss: 0.0055\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0204 - val_loss: 0.0183\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0188 - val_loss: 0.0052\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0175 - val_loss: 0.0189\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0188 - val_loss: 0.0065\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0205 - val_loss: 0.0226\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0248 - val_loss: 0.0091\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0281 - val_loss: 0.0248\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0306 - val_loss: 0.0103\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0289 - val_loss: 0.0228\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0264 - val_loss: 0.0060\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0212 - val_loss: 0.0185\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0193 - val_loss: 0.0060\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0181 - val_loss: 0.0251\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0216 - val_loss: 0.0155\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0282 - val_loss: 0.0487\n",
      "Epoch 458/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0411 - val_loss: 0.0334\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0478 - val_loss: 0.0578\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0557 - val_loss: 0.0305\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0467 - val_loss: 0.0370\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0395 - val_loss: 0.0175\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0264 - val_loss: 0.0199\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0202 - val_loss: 0.0095\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0154 - val_loss: 0.0129\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0128 - val_loss: 0.0071\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0121 - val_loss: 0.0187\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0183 - val_loss: 0.0367\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0256 - val_loss: 0.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0330 - val_loss: 0.0625\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0420 - val_loss: 0.0411\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0399 - val_loss: 0.0540\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0373 - val_loss: 0.0229\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0276 - val_loss: 0.0301\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0238 - val_loss: 0.0086\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0203 - val_loss: 0.0187\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0224 - val_loss: 0.0047\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0215\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0339 - val_loss: 0.0083\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0296 - val_loss: 0.0225\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0268 - val_loss: 0.0069\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0213 - val_loss: 0.0197\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0200 - val_loss: 0.0062\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0197 - val_loss: 0.0071\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0237 - val_loss: 0.0083\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0246 - val_loss: 0.0205\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0257 - val_loss: 0.0077\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0234 - val_loss: 0.0199\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0218 - val_loss: 0.0060\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0187 - val_loss: 0.0078\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0195 - val_loss: 0.0292\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0250 - val_loss: 0.0195\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0318 - val_loss: 0.0494\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0425 - val_loss: 0.0315\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0449 - val_loss: 0.0513\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0508 - val_loss: 0.0287\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0426 - val_loss: 0.0338\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0360 - val_loss: 0.0168\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0244 - val_loss: 0.0190\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0188 - val_loss: 0.0097\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0129\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0117 - val_loss: 0.0205\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0146 - val_loss: 0.0184\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0191 - val_loss: 0.0421\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0275 - val_loss: 0.0387\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0347 - val_loss: 0.0647\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0418 - val_loss: 0.0392\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0364 - val_loss: 0.0480\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0325 - val_loss: 0.0205\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0242 - val_loss: 0.0268\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0217 - val_loss: 0.0091\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0196 - val_loss: 0.0177\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0227 - val_loss: 0.0052\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0259 - val_loss: 0.0190\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0303 - val_loss: 0.0075\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0287 - val_loss: 0.0221\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0286 - val_loss: 0.0086\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0251 - val_loss: 0.0228\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0243 - val_loss: 0.0083\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0206 - val_loss: 0.0073\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0206 - val_loss: 0.0069\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0206 - val_loss: 0.0185\n",
      "Epoch 534/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0215 - val_loss: 0.0073\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0208 - val_loss: 0.0181\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0205 - val_loss: 0.0059\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0189 - val_loss: 0.0180\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0190 - val_loss: 0.0072\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0186 - val_loss: 0.0235\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0252 - val_loss: 0.0385\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0333 - val_loss: 0.0253\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0371 - val_loss: 0.0484\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0441 - val_loss: 0.0305\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0440 - val_loss: 0.0435\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0464 - val_loss: 0.0253\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0362 - val_loss: 0.0273\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0278 - val_loss: 0.0132\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0181 - val_loss: 0.0146\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0136 - val_loss: 0.0075\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0093 - val_loss: 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0091 - val_loss: 0.0146\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0127 - val_loss: 0.0290\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0181 - val_loss: 0.0300\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0255 - val_loss: 0.0594\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0359 - val_loss: 0.0470\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0383 - val_loss: 0.0607\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0383 - val_loss: 0.0308\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0295 - val_loss: 0.0357\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0259 - val_loss: 0.0142\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0214 - val_loss: 0.0208\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0221 - val_loss: 0.0069\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0230 - val_loss: 0.0177\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0067\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0212\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0290 - val_loss: 0.0085\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0254 - val_loss: 0.0210\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 238us/step - loss: 0.0240 - val_loss: 0.0077\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 179us/step - loss: 0.0199 - val_loss: 0.0183\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 79us/step - loss: 0.0188 - val_loss: 0.0066\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0171 - val_loss: 0.0176\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0182 - val_loss: 0.0071\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0189 - val_loss: 0.0190\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0216 - val_loss: 0.0079\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0221 - val_loss: 0.0203\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0233 - val_loss: 0.0080\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0213 - val_loss: 0.0177\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0206 - val_loss: 0.0069\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0191 - val_loss: 0.0193\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0188 - val_loss: 0.0087\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0193 - val_loss: 0.0274\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0240 - val_loss: 0.0184\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0292 - val_loss: 0.0438\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0381 - val_loss: 0.0292\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0406 - val_loss: 0.0473\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0470 - val_loss: 0.0286\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0406 - val_loss: 0.0331\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0343 - val_loss: 0.0168\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0229 - val_loss: 0.0180\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0099 - val_loss: 0.0138\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0113 - val_loss: 0.0230\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0146 - val_loss: 0.0230\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0195 - val_loss: 0.0480\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0281 - val_loss: 0.0443\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0339 - val_loss: 0.0639\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0378 - val_loss: 0.0385\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0316 - val_loss: 0.0437\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0282 - val_loss: 0.0202\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0231 - val_loss: 0.0273\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0231 - val_loss: 0.0105\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0225 - val_loss: 0.0196\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0262 - val_loss: 0.0076\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0271 - val_loss: 0.0197\n",
      "Epoch 610/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0290 - val_loss: 0.0076\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0190\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0233 - val_loss: 0.0072\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0190 - val_loss: 0.0168\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0178 - val_loss: 0.0063\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0164 - val_loss: 0.0068\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0198 - val_loss: 0.0088\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0218 - val_loss: 0.0210\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0243 - val_loss: 0.0090\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0247 - val_loss: 0.0204\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0244 - val_loss: 0.0079\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0196 - val_loss: 0.0177\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0179 - val_loss: 0.0073\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0168 - val_loss: 0.0223\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0196 - val_loss: 0.0146\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0239 - val_loss: 0.0381\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0329 - val_loss: 0.0280\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0381 - val_loss: 0.0480\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0460 - val_loss: 0.0299\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0411 - val_loss: 0.0363\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0367 - val_loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0198\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0184 - val_loss: 0.0103\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0109 - val_loss: 0.0084\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0107 - val_loss: 0.0226\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0136 - val_loss: 0.0231\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0181 - val_loss: 0.0466\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0260 - val_loss: 0.0439\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0315 - val_loss: 0.0624\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0353 - val_loss: 0.0392\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0303 - val_loss: 0.0460\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0297 - val_loss: 0.0247\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0258 - val_loss: 0.0302\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0115\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0236 - val_loss: 0.0209\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0082\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0267 - val_loss: 0.0193\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0274 - val_loss: 0.0073\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0222 - val_loss: 0.0162\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0198 - val_loss: 0.0057\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0147 - val_loss: 0.0052\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0145 - val_loss: 0.0066\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0157 - val_loss: 0.0182\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0196 - val_loss: 0.0100\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0231 - val_loss: 0.0229\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0272 - val_loss: 0.0106\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0274 - val_loss: 0.0214\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0259 - val_loss: 0.0086\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0201 - val_loss: 0.0169\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0174 - val_loss: 0.0067\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0213 - val_loss: 0.0349\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0303 - val_loss: 0.0275\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0371 - val_loss: 0.0481\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0460 - val_loss: 0.0304\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0407 - val_loss: 0.0359\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0356 - val_loss: 0.0184\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0239 - val_loss: 0.0195\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0177 - val_loss: 0.0102\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0104 - val_loss: 0.0084\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0092 - val_loss: 0.0143\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0096 - val_loss: 0.0119\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0107 - val_loss: 0.0245\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0140 - val_loss: 0.0264\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0190 - val_loss: 0.0495\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0266 - val_loss: 0.0445\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0305 - val_loss: 0.0581\n",
      "Epoch 686/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0325 - val_loss: 0.0381\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0291 - val_loss: 0.0438\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0284 - val_loss: 0.0223\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0253 - val_loss: 0.0302\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0266 - val_loss: 0.0122\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0258 - val_loss: 0.0218\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0289 - val_loss: 0.0086\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0261 - val_loss: 0.0180\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0246 - val_loss: 0.0063\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0189 - val_loss: 0.0137\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0166 - val_loss: 0.0048\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0129 - val_loss: 0.0047\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0136 - val_loss: 0.0067\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0185\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0197 - val_loss: 0.0109\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0237 - val_loss: 0.0250\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0291 - val_loss: 0.0125\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0280 - val_loss: 0.0217\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0271 - val_loss: 0.0093\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0217 - val_loss: 0.0176\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0179 - val_loss: 0.0063\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0149 - val_loss: 0.0090\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0166 - val_loss: 0.0264\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0230 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0307 - val_loss: 0.0459\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0430 - val_loss: 0.0337\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0440 - val_loss: 0.0429\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0424 - val_loss: 0.0224\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0283 - val_loss: 0.0226\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0106 - val_loss: 0.0083\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0089 - val_loss: 0.0133\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0095 - val_loss: 0.0218\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0121 - val_loss: 0.0236\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0165 - val_loss: 0.0444\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0234 - val_loss: 0.0420\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0276 - val_loss: 0.0562\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0303 - val_loss: 0.0378\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0279 - val_loss: 0.0452\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0288 - val_loss: 0.0270\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0265 - val_loss: 0.0341\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0280 - val_loss: 0.0151\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0271 - val_loss: 0.0238\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0293 - val_loss: 0.0093\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0257 - val_loss: 0.0176\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0241 - val_loss: 0.0062\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0163 - val_loss: 0.0046\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0124 - val_loss: 0.0043\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0125 - val_loss: 0.0060\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0136 - val_loss: 0.0164\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0208 - val_loss: 0.0239\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0271 - val_loss: 0.0138\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0293 - val_loss: 0.0254\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0299 - val_loss: 0.0106\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0228 - val_loss: 0.0175\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0212 - val_loss: 0.0080\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0134 - val_loss: 0.0168\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0185 - val_loss: 0.0318\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0280 - val_loss: 0.0287\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0374 - val_loss: 0.0502\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0485 - val_loss: 0.0325\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0415 - val_loss: 0.0350\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0338 - val_loss: 0.0169\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0208 - val_loss: 0.0174\n",
      "Epoch 762/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0088 - val_loss: 0.0142\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0107 - val_loss: 0.0288\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0152 - val_loss: 0.0321\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0209 - val_loss: 0.0515\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0269 - val_loss: 0.0423\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0278 - val_loss: 0.0510\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0286 - val_loss: 0.0324\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0263 - val_loss: 0.0393\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0273 - val_loss: 0.0220\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0268 - val_loss: 0.0303\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0303 - val_loss: 0.0133\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0280 - val_loss: 0.0211\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0278 - val_loss: 0.0076\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0216 - val_loss: 0.0140\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0188 - val_loss: 0.0049\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0130 - val_loss: 0.0039\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 255us/step - loss: 0.0115 - val_loss: 0.0047\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 149us/step - loss: 0.0116 - val_loss: 0.0127\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 94us/step - loss: 0.0136 - val_loss: 0.0075\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0190\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0243 - val_loss: 0.0265\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0305 - val_loss: 0.0147\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0298 - val_loss: 0.0230\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0269 - val_loss: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0190 - val_loss: 0.0146\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0170 - val_loss: 0.0062\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0129 - val_loss: 0.0052\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0171 - val_loss: 0.0298\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0265 - val_loss: 0.0289\n",
      "Epoch 801/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0372 - val_loss: 0.0522\n",
      "Epoch 802/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0505 - val_loss: 0.0350\n",
      "Epoch 803/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0439 - val_loss: 0.0367\n",
      "Epoch 804/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0356 - val_loss: 0.0179\n",
      "Epoch 805/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0215 - val_loss: 0.0174\n",
      "Epoch 806/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 807/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 808/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 809/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0077 - val_loss: 0.0141\n",
      "Epoch 810/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 811/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0100 - val_loss: 0.0277\n",
      "Epoch 812/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0143 - val_loss: 0.0310\n",
      "Epoch 813/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0197 - val_loss: 0.0479\n",
      "Epoch 814/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0392\n",
      "Epoch 815/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0255 - val_loss: 0.0481\n",
      "Epoch 816/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0269 - val_loss: 0.0324\n",
      "Epoch 817/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0262 - val_loss: 0.0405\n",
      "Epoch 818/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0287 - val_loss: 0.0238\n",
      "Epoch 819/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0285 - val_loss: 0.0317\n",
      "Epoch 820/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0311 - val_loss: 0.0141\n",
      "Epoch 821/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0279 - val_loss: 0.0206\n",
      "Epoch 822/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0073\n",
      "Epoch 823/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0201 - val_loss: 0.0127\n",
      "Epoch 824/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0171 - val_loss: 0.0044\n",
      "Epoch 825/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 826/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0120 - val_loss: 0.0038\n",
      "Epoch 827/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 828/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0112 - val_loss: 0.0049\n",
      "Epoch 829/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 830/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0137 - val_loss: 0.0079\n",
      "Epoch 831/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0158 - val_loss: 0.0185\n",
      "Epoch 832/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0202 - val_loss: 0.0124\n",
      "Epoch 833/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0236 - val_loss: 0.0255\n",
      "Epoch 834/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0292 - val_loss: 0.0147\n",
      "Epoch 835/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0286 - val_loss: 0.0228\n",
      "Epoch 836/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0263 - val_loss: 0.0094\n",
      "Epoch 837/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0194 - val_loss: 0.0153\n",
      "Epoch 838/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0154 - val_loss: 0.0061\n",
      "Epoch 839/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 840/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0150 - val_loss: 0.0069\n",
      "Epoch 841/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 842/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 843/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0178 - val_loss: 0.0272\n",
      "Epoch 844/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0249 - val_loss: 0.0252\n",
      "Epoch 845/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0329 - val_loss: 0.0469\n",
      "Epoch 846/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0460 - val_loss: 0.0350\n",
      "Epoch 847/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0433 - val_loss: 0.0375\n",
      "Epoch 848/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0365 - val_loss: 0.0188\n",
      "Epoch 849/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 850/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0148 - val_loss: 0.0097\n",
      "Epoch 851/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 852/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 853/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 854/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0083 - val_loss: 0.0153\n",
      "Epoch 855/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0106 - val_loss: 0.0298\n",
      "Epoch 856/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0316\n",
      "Epoch 857/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0200 - val_loss: 0.0459\n",
      "Epoch 858/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0239 - val_loss: 0.0367\n",
      "Epoch 859/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0242 - val_loss: 0.0455\n",
      "Epoch 860/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0259 - val_loss: 0.0313\n",
      "Epoch 861/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0255 - val_loss: 0.0390\n",
      "Epoch 862/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0284 - val_loss: 0.0223\n",
      "Epoch 863/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0275 - val_loss: 0.0309\n",
      "Epoch 864/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0309 - val_loss: 0.0144\n",
      "Epoch 865/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0277 - val_loss: 0.0195\n",
      "Epoch 866/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0253 - val_loss: 0.0072\n",
      "Epoch 867/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0191 - val_loss: 0.0122\n",
      "Epoch 868/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0167 - val_loss: 0.0047\n",
      "Epoch 869/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 870/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0121 - val_loss: 0.0043\n",
      "Epoch 871/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 872/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0113 - val_loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 874/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0135 - val_loss: 0.0080\n",
      "Epoch 875/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0176\n",
      "Epoch 876/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 877/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0230 - val_loss: 0.0250\n",
      "Epoch 878/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0286 - val_loss: 0.0147\n",
      "Epoch 879/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0275 - val_loss: 0.0226\n",
      "Epoch 880/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0249 - val_loss: 0.0100\n",
      "Epoch 881/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0183 - val_loss: 0.0159\n",
      "Epoch 882/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0167 - val_loss: 0.0075\n",
      "Epoch 883/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 884/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0078\n",
      "Epoch 885/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 886/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 887/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0207 - val_loss: 0.0331\n",
      "Epoch 888/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0313 - val_loss: 0.0323\n",
      "Epoch 889/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0406 - val_loss: 0.0471\n",
      "Epoch 890/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0469 - val_loss: 0.0285\n",
      "Epoch 891/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0330 - val_loss: 0.0266\n",
      "Epoch 892/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0229 - val_loss: 0.0139\n",
      "Epoch 893/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 894/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 895/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0083 - val_loss: 0.0147\n",
      "Epoch 896/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0082 - val_loss: 0.0131\n",
      "Epoch 897/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0093 - val_loss: 0.0245\n",
      "Epoch 898/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0125 - val_loss: 0.0253\n",
      "Epoch 899/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0162 - val_loss: 0.0385\n",
      "Epoch 900/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0199 - val_loss: 0.0322\n",
      "Epoch 901/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0206 - val_loss: 0.0411\n",
      "Epoch 902/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0223 - val_loss: 0.0310\n",
      "Epoch 903/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0228 - val_loss: 0.0402\n",
      "Epoch 904/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0261 - val_loss: 0.0266\n",
      "Epoch 905/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0268 - val_loss: 0.0343\n",
      "Epoch 906/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0301 - val_loss: 0.0184\n",
      "Epoch 907/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0287 - val_loss: 0.0247\n",
      "Epoch 908/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0289 - val_loss: 0.0098\n",
      "Epoch 909/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0225 - val_loss: 0.0144\n",
      "Epoch 910/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0200 - val_loss: 0.0055\n",
      "Epoch 911/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 912/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0132 - val_loss: 0.0042\n",
      "Epoch 913/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0109 - val_loss: 0.0087\n",
      "Epoch 914/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0107 - val_loss: 0.0045\n",
      "Epoch 915/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 916/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 917/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 918/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 919/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0186 - val_loss: 0.0218\n",
      "Epoch 920/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0249 - val_loss: 0.0155\n",
      "Epoch 921/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0283 - val_loss: 0.0262\n",
      "Epoch 922/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0298 - val_loss: 0.0131\n",
      "Epoch 923/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0235 - val_loss: 0.0193\n",
      "Epoch 924/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0193 - val_loss: 0.0082\n",
      "Epoch 925/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 926/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0151 - val_loss: 0.0073\n",
      "Epoch 927/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 928/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 929/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0161 - val_loss: 0.0249\n",
      "Epoch 930/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0233 - val_loss: 0.0261\n",
      "Epoch 931/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0330 - val_loss: 0.0461\n",
      "Epoch 932/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0458 - val_loss: 0.0334\n",
      "Epoch 933/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0385 - val_loss: 0.0327\n",
      "Epoch 934/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0289 - val_loss: 0.0167\n",
      "Epoch 935/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 936/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0120 - val_loss: 0.0103\n",
      "Epoch 937/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0089 - val_loss: 0.0147\n",
      "Epoch 938/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 939/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0090 - val_loss: 0.0229\n",
      "Epoch 940/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0117 - val_loss: 0.0235\n",
      "Epoch 941/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0150 - val_loss: 0.0358\n",
      "Epoch 942/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0185 - val_loss: 0.0306\n",
      "Epoch 943/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0193 - val_loss: 0.0388\n",
      "Epoch 944/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0206 - val_loss: 0.0300\n",
      "Epoch 945/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0210 - val_loss: 0.0387\n",
      "Epoch 946/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0239 - val_loss: 0.0274\n",
      "Epoch 947/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0252 - val_loss: 0.0374\n",
      "Epoch 948/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0300 - val_loss: 0.0222\n",
      "Epoch 949/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0293 - val_loss: 0.0274\n",
      "Epoch 950/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0302 - val_loss: 0.0117\n",
      "Epoch 951/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0246 - val_loss: 0.0159\n",
      "Epoch 952/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0216 - val_loss: 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0159 - val_loss: 0.0101\n",
      "Epoch 954/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0137 - val_loss: 0.0044\n",
      "Epoch 955/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 956/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 957/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 958/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 959/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 960/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 961/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0157 - val_loss: 0.0187\n",
      "Epoch 962/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0211 - val_loss: 0.0145\n",
      "Epoch 963/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0258 - val_loss: 0.0275\n",
      "Epoch 964/1000\n",
      "32/32 [==============================] - 0s 489us/step - loss: 0.0308 - val_loss: 0.0151\n",
      "Epoch 965/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0259 - val_loss: 0.0210\n",
      "Epoch 966/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0217 - val_loss: 0.0091\n",
      "Epoch 967/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0156 - val_loss: 0.0147\n",
      "Epoch 968/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0153 - val_loss: 0.0083\n",
      "Epoch 969/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 970/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 971/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0143 - val_loss: 0.0184\n",
      "Epoch 972/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0172 - val_loss: 0.0160\n",
      "Epoch 973/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0222 - val_loss: 0.0350\n",
      "Epoch 974/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0352 - val_loss: 0.0345\n",
      "Epoch 975/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0425 - val_loss: 0.0423\n",
      "Epoch 976/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0410 - val_loss: 0.0233\n",
      "Epoch 977/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0250 - val_loss: 0.0217\n",
      "Epoch 978/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0168 - val_loss: 0.0123\n",
      "Epoch 979/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 980/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 981/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0082 - val_loss: 0.0189\n",
      "Epoch 982/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0097 - val_loss: 0.0189\n",
      "Epoch 983/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0123 - val_loss: 0.0308\n",
      "Epoch 984/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0158 - val_loss: 0.0277\n",
      "Epoch 985/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0174 - val_loss: 0.0359\n",
      "Epoch 986/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0187 - val_loss: 0.0286\n",
      "Epoch 987/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0189 - val_loss: 0.0371\n",
      "Epoch 988/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0214 - val_loss: 0.0284\n",
      "Epoch 989/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0230 - val_loss: 0.0375\n",
      "Epoch 990/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0271 - val_loss: 0.0240\n",
      "Epoch 991/1000\n",
      "32/32 [==============================] - 0s 487us/step - loss: 0.0274 - val_loss: 0.0309\n",
      "Epoch 992/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0300 - val_loss: 0.0148\n",
      "Epoch 993/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0254 - val_loss: 0.0193\n",
      "Epoch 994/1000\n",
      "32/32 [==============================] - 0s 488us/step - loss: 0.0248 - val_loss: 0.0084\n",
      "Epoch 995/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 996/1000\n",
      "32/32 [==============================] - 0s 290us/step - loss: 0.0173 - val_loss: 0.0051\n",
      "Epoch 997/1000\n",
      "32/32 [==============================] - 0s 143us/step - loss: 0.0130 - val_loss: 0.0086\n",
      "Epoch 998/1000\n",
      "32/32 [==============================] - 0s 57us/step - loss: 0.0114 - val_loss: 0.0041\n",
      "Epoch 999/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 1000/1000\n",
      "32/32 [==============================] - 0s 0us/step - loss: 0.0096 - val_loss: 0.0045\n",
      "0.00828734040260315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.16869327, -0.7028091 ,  0.19091664, -0.05091389, -0.42100996],\n",
       "        [-0.10379342,  0.45014456, -0.38592345, -0.04836174,  0.32234126],\n",
       "        [-0.6189677 ,  0.7206661 , -0.37803945,  0.02417222, -0.23914549]],\n",
       "       dtype=float32),\n",
       " array([-3.5920426e-01, -9.2068844e-02,  4.0622973e-01, -3.3739858e-04,\n",
       "         3.2936671e-01], dtype=float32),\n",
       " array([[ 0.0029519 ,  0.38498607,  0.14179392, -0.45090765, -0.6728841 ,\n",
       "         -0.77447635,  0.8127178 ,  0.576019  , -0.2365474 ,  0.5149411 ],\n",
       "        [-0.432804  ,  0.07383288,  0.35399702,  0.11030995, -0.38934827,\n",
       "         -0.26872385,  0.02268389, -0.19497088,  0.02194052,  0.314507  ],\n",
       "        [ 0.38337153, -0.30797952, -0.05082429,  0.6944473 ,  0.3157798 ,\n",
       "          0.5046    , -0.41499552, -0.08126837, -0.18509294,  0.12852567],\n",
       "        [-0.30005515, -0.02371627, -0.22033378,  0.5938354 , -0.3041826 ,\n",
       "         -0.18783678, -0.47074306, -0.6765789 ,  0.04879604,  0.15810741],\n",
       "        [ 0.5483183 , -0.3296121 ,  0.9410952 ,  0.35376188, -0.2173626 ,\n",
       "         -0.29714295, -0.70632845, -0.5490186 ,  0.3297682 , -0.88710904]],\n",
       "       dtype=float32),\n",
       " array([ 0.6068732 ,  0.29097524,  0.6635171 ,  0.6234604 ,  0.5896949 ,\n",
       "         0.5857122 , -0.63329756, -0.6200384 , -0.3775492 , -0.62308276],\n",
       "       dtype=float32),\n",
       " array([[ 0.9701236 ],\n",
       "        [-0.00180312],\n",
       "        [ 0.5739542 ],\n",
       "        [ 0.71410054],\n",
       "        [ 0.8249287 ],\n",
       "        [ 0.66501766],\n",
       "        [-0.56606376],\n",
       "        [-0.39196235],\n",
       "        [-0.11716127],\n",
       "        [-0.98551106]], dtype=float32),\n",
       " array([0.6185362], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_challenger, history_challenger, evaluate_challenger=NN_model_structure_regression(X_train_challenger, X_val_challenger, Y_train_challenger, Y_val_challenger, RMSprop, 32, 1000, x_test_challenger, y_test_challenger)\n",
    "model_challenger.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_challenger.save('C:\\\\Users\\\\user\\\\Desktop\\\\Thesis\\\\model_weights\\\\MLP_challenger_rmsprop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
